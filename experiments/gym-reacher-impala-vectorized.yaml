# This can reach 18-19 reward within 10 minutes on a Tesla M60 GPU (e.g., G3 EC2 node)
# with 32 workers and 10 envs per worker. This is more efficient than the non-vectorized
# configuration which requires 128 workers to achieve the same performance.
gym-reacher-impala-vectorized:
    env: RoboschoolReacher-v1
    run: IMPALA
    local_dir: ~/kayray_results
    checkpoint_freq: 100
    checkpoint_at_end: True
    stop:
      timesteps_total: 2000000 # 2M steps
      episode_reward_mean: 21
      training_iteration: 500
    config:
        sample_batch_size: 50
        train_batch_size: 500
#        num_workers: 3 # 32
        num_workers:
          grid_search: [63, 31, 15] # grid_search: [11, 9, 7, 5, 3] # grid_search: [63, 31, 15]
        num_envs_per_worker:
          grid_search: [32, 16, 8] # grid_search: [16, 8, 4] # grid_search: [32, 16, 8] 
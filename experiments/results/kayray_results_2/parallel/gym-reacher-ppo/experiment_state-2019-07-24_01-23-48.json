{
  "checkpoints": [
    {
      "trainable_name": "PPO",
      "config": {
        "env_config": {
          "env_type": "openai"
        },
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 16,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "0_num_envs_per_worker=16",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 21,
        "timesteps_total": 10000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 39.76825729211206,
        "episode_reward_min": 1.4560066991504834,
        "episode_reward_mean": 21.2797415909532,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 242,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 4.002141302777733,
          "mean_processing_ms": 3.304759570700735,
          "mean_inference_ms": 1.3629026663090487
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 6336000,
          "num_steps_sampled": 6388800,
          "sample_time_ms": 1741.847,
          "load_time_ms": 1.66,
          "grad_time_ms": 6702.683,
          "update_time_ms": 4.465,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.421875,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": -0.0001791672984836623,
              "policy_loss": -0.02001659758388996,
              "vf_loss": 0.013365227729082108,
              "vf_explained_var": 0.9996951222419739,
              "kl": 0.015341522172093391,
              "entropy": 0.6990776658058167
            }
          }
        },
        "timesteps_this_iter": 36300,
        "done": true,
        "timesteps_total": 6388800,
        "episodes_total": 42592,
        "training_iteration": 176,
        "experiment_id": "39f68b4f9fc040a6b441fbeee39166d1",
        "date": "2019-07-24_01-48-37",
        "timestamp": 1563925717,
        "time_this_iter_s": 8.785799503326416,
        "time_total_s": 1479.3923859596252,
        "pid": 30530,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {
            "env_type": "openai"
          },
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 16,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 1479.3923859596252,
        "timesteps_since_restore": 6388800,
        "iterations_since_restore": 176,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563925717.064136,
      "checkpoint_freq": 50,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_0_num_envs_per_worker=16_2019-07-24_01-23-48gxbrmkpb",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563925717.0641277,
      "trial_id": "ec8f2c78",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "env_config": {
          "env_type": "openai"
        },
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 8,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "1_num_envs_per_worker=8",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 21,
        "timesteps_total": 10000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 39.44353344874787,
        "episode_reward_min": -0.5001369927266222,
        "episode_reward_mean": 21.358557190570707,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 176,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 1.888723591694597,
          "mean_processing_ms": 1.563602204130453,
          "mean_inference_ms": 1.1124032471135457
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 5408000,
          "num_steps_sampled": 5491200,
          "sample_time_ms": 1754.142,
          "load_time_ms": 0.722,
          "grad_time_ms": 4762.166,
          "update_time_ms": 4.202,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.421875,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": -0.004351236391812563,
              "policy_loss": -0.02524218149483204,
              "vf_loss": 0.013625139370560646,
              "vf_explained_var": 0.9996935129165649,
              "kl": 0.017222652211785316,
              "entropy": 0.696738600730896
            }
          }
        },
        "timesteps_this_iter": 26400,
        "done": true,
        "timesteps_total": 5491200,
        "episodes_total": 36608,
        "training_iteration": 208,
        "experiment_id": "53b78cc0032c4f85ab134c2fc9ebe152",
        "date": "2019-07-24_02-10-50",
        "timestamp": 1563927050,
        "time_this_iter_s": 7.2707977294921875,
        "time_total_s": 1322.0918536186218,
        "pid": 30529,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {
            "env_type": "openai"
          },
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 8,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 1322.0918536186218,
        "timesteps_since_restore": 5491200,
        "iterations_since_restore": 208,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563927050.9631345,
      "checkpoint_freq": 50,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "800495c40d0000000000008c0e7261792e74756e652e747269616c948c0a436865636b706f696e749493942981947d94288c0773746f72616765948c046469736b948c0576616c7565948c9c2f686f6d652f616d722f6b61797261795f726573756c74732f706172616c6c656c2f67796d2d726561636865722d70706f2f50504f5f526f626f7363686f6f6c526561636865722d76315f315f6e756d5f656e76735f7065725f776f726b65723d385f323031392d30372d32345f30312d34382d3337696f3764707479672f636865636b706f696e745f3230382f636865636b706f696e742d323038948c0b6c6173745f726573756c74947d94288c12657069736f64655f7265776172645f6d617894474043b8c5b43c86f08c12657069736f64655f7265776172645f6d696e9447bfe0011f4b68faf08c13657069736f64655f7265776172645f6d65616e944740355bca676f3f308c10657069736f64655f6c656e5f6d65616e94474062c000000000008c12657069736f6465735f746869735f69746572944bb08c12706f6c6963795f7265776172645f6d65616e947d948c0e637573746f6d5f6d657472696373947d948c0c73616d706c65725f70657266947d94288c106d65616e5f656e765f776169745f6d7394473ffe38363a9830f48c126d65616e5f70726f63657373696e675f6d7394473ff90483beab19da8c116d65616e5f696e666572656e63655f6d7394473ff1cc6758e511f6758c146f66665f706f6c6963795f657374696d61746f72947d948c1a6e756d5f6d65747269635f626174636865735f64726f70706564944b008c04696e666f947d94288c116e756d5f73746570735f747261696e6564944a008552008c116e756d5f73746570735f73616d706c6564944a00ca53008c0e73616d706c655f74696d655f6d739447409b68916872b0218c0c6c6f61645f74696d655f6d7394473fe71a9fbe76c8b48c0c677261645f74696d655f6d73944740b29a2a7ef9db238c0e7570646174655f74696d655f6d7394474010ced916872b028c076c6561726e6572947d948c0e64656661756c745f706f6c696379947d94288c0c6375725f6b6c5f636f65666694473fdb0000000000008c066375725f6c7294473f1a36e2e00000008c0a746f74616c5f6c6f73739447bf71d29a200000008c0b706f6c6963795f6c6f73739447bf99d916200000008c0776665f6c6f737394473f8be77f400000008c1076665f6578706c61696e65645f76617294473feffd7d400000008c026b6c94473f91a2d0a00000008c07656e74726f707994473fe64baec00000007573758c1374696d6573746570735f746869735f69746572944d20678c04646f6e6594888c0f74696d6573746570735f746f74616c944a00ca53008c0e657069736f6465735f746f74616c944d008f8c12747261696e696e675f697465726174696f6e944bd08c0d6578706572696d656e745f6964948c203533623738636330303332633466383561623133346332666339656265313532948c0464617465948c13323031392d30372d32345f30322d31302d3530948c0974696d657374616d70944a0aa2375d8c1074696d655f746869735f697465725f739447401d154c000000008c0c74696d655f746f74616c5f7394474094a85e0ee000008c03706964944d41778c08686f73746e616d65948c106e6176656c2d6e6f7465626f6f6b2d31948c076e6f64655f6970948c0c31302e31362e3132382e3633948c06636f6e666967947d94288c076d6f6e69746f7294898c096c6f675f6c6576656c948c04494e464f948c0963616c6c6261636b73947d94288c106f6e5f657069736f64655f7374617274944e8c0f6f6e5f657069736f64655f73746570944e8c0e6f6e5f657069736f64655f656e64944e8c0d6f6e5f73616d706c655f656e64944e8c0f6f6e5f747261696e5f726573756c74944e8c136f6e5f706f737470726f636573735f7472616a944e758c1669676e6f72655f776f726b65725f6661696c7572657394898c097573655f656167657294898c056d6f64656c947d94288c0c636f6e765f66696c74657273944e8c0f636f6e765f61637469766174696f6e948c0472656c75948c1066636e65745f61637469766174696f6e948c0474616e68948c0d66636e65745f68696464656e73945d94284d00014d0001658c0c667265655f6c6f675f73746494888c0f7371756173685f746f5f72616e676594898c087573655f6c73746d94898c0b6d61785f7365715f6c656e944b148c0e6c73746d5f63656c6c5f73697a65944d00018c1b6c73746d5f7573655f707265765f616374696f6e5f72657761726494898c0a6672616d65737461636b94888c0364696d944b548c09677261797363616c6594898c097a65726f5f6d65616e94888c13637573746f6d5f70726570726f636573736f72944e8c0c637573746f6d5f6d6f64656c944e8c0e637573746f6d5f6f7074696f6e73947d94758c096f7074696d697a6572947d948c0567616d6d6194473fefd70a3d70a3d78c07686f72697a6f6e944e8c0c736f66745f686f72697a6f6e94898c0a656e765f636f6e666967947d948c08656e765f74797065948c066f70656e616994738c03656e76948c14526f626f7363686f6f6c526561636865722d7631948c0c636c69705f72657761726473944e8c0c636c69705f616374696f6e7394888c1170726570726f636573736f725f70726566948c08646565706d696e64948c026c7294473f1a36e2eb1c432d8c136576616c756174696f6e5f696e74657276616c944e8c176576616c756174696f6e5f6e756d5f657069736f646573944b0a8c116576616c756174696f6e5f636f6e666967947d948c0b6e756d5f776f726b657273944b0b8c086e756d5f67707573944b018c136e756d5f637075735f7065725f776f726b6572944b018c136e756d5f677075735f7065725f776f726b6572944b008c1b637573746f6d5f7265736f75726365735f7065725f776f726b6572947d948c136e756d5f637075735f666f725f647269766572944b018c136e756d5f656e76735f7065725f776f726b6572944b088c1173616d706c655f62617463685f73697a65944bc88c10747261696e5f62617463685f73697a65944da8618c0a62617463685f6d6f6465948c11636f6d706c6574655f657069736f646573948c0c73616d706c655f6173796e6394898c126f62736572766174696f6e5f66696c746572948c0d4d65616e53746446696c746572948c1373796e6368726f6e697a655f66696c7465727394888c0f74665f73657373696f6e5f61726773947d94288c1c696e7472615f6f705f706172616c6c656c69736d5f74687265616473944b028c1c696e7465725f6f705f706172616c6c656c69736d5f74687265616473944b028c0b6770755f6f7074696f6e73947d948c0c616c6c6f775f67726f7774689488738c146c6f675f6465766963655f706c6163656d656e7494898c0c6465766963655f636f756e74947d948c03435055944b01738c14616c6c6f775f736f66745f706c6163656d656e749488758c156c6f63616c5f74665f73657373696f6e5f61726773947d94288c1c696e7472615f6f705f706172616c6c656c69736d5f74687265616473944b088c1c696e7465725f6f705f706172616c6c656c69736d5f74687265616473944b08758c15636f6d70726573735f6f62736572766174696f6e7394898c17636f6c6c6563745f6d6574726963735f74696d656f7574944bb48c1a6d6574726963735f736d6f6f7468696e675f657069736f646573944b648c1272656d6f74655f776f726b65725f656e767394898c1872656d6f74655f656e765f62617463685f776169745f6d73944b008c0f6d696e5f697465725f74696d655f73944b008c1774696d6573746570735f7065725f697465726174696f6e944b008c05696e707574948c0773616d706c6572948c10696e7075745f6576616c756174696f6e945d94288c026973948c0377697394658c12706f737470726f636573735f696e7075747394898c1373687566666c655f6275666665725f73697a65944b008c066f7574707574944e8c176f75747075745f636f6d70726573735f636f6c756d6e73945d94288c036f6273948c076e65775f6f627394658c146f75747075745f6d61785f66696c655f73697a65944a000000048c0a6d756c74696167656e74947d94288c08706f6c6963696573947d948c11706f6c6963795f6d617070696e675f666e944e8c11706f6c69636965735f746f5f747261696e944e758c077573655f67616594888c066c616d62646194473ff00000000000008c086b6c5f636f65666694473ff00000000000008c127367645f6d696e6962617463685f73697a65944de8038c0c6e756d5f7367645f69746572944b148c0b6c725f7363686564756c65944e8c0f76665f73686172655f6c617965727394898c0d76665f6c6f73735f636f65666694473ff00000000000008c0d656e74726f70795f636f656666944700000000000000008c0a636c69705f706172616d94473fd33333333333338c0d76665f636c69705f706172616d944740240000000000008c09677261645f636c6970944e8c096b6c5f74617267657494473f847ae147ae147b8c1073696d706c655f6f7074696d697a657294898c147374726167676c65725f6d697469676174696f6e9489758c1274696d655f73696e63655f726573746f726594474094a85e0ee000008c1774696d6573746570735f73696e63655f726573746f7265944a00ca53008c18697465726174696f6e735f73696e63655f726573746f7265944bd08c136e756d5f6865616c7468795f776f726b657273944b0b7575622e",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_1_num_envs_per_worker=8_2019-07-24_01-48-37io7dptyg",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563927050.963123,
      "trial_id": "ec8f2c79",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "env_config": {
          "env_type": "openai"
        },
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 4,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "2_num_envs_per_worker=4",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 21,
        "timesteps_total": 10000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 38.532868259593485,
        "episode_reward_min": 3.211131531089146,
        "episode_reward_mean": 21.269950694737027,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 174,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 1.0499528117665637,
          "mean_processing_ms": 0.8813718486590841,
          "mean_inference_ms": 1.1134891383808614
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 4784000,
          "num_steps_sampled": 4802400,
          "sample_time_ms": 2132.948,
          "load_time_ms": 0.818,
          "grad_time_ms": 4774.304,
          "update_time_ms": 4.316,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.421875,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": -0.005818742793053389,
              "policy_loss": -0.029619941487908363,
              "vf_loss": 0.017740823328495026,
              "vf_explained_var": 0.9996141195297241,
              "kl": 0.014365334063768387,
              "entropy": 0.6611513495445251
            }
          }
        },
        "timesteps_this_iter": 26100,
        "done": true,
        "timesteps_total": 4802400,
        "episodes_total": 32016,
        "training_iteration": 184,
        "experiment_id": "60286fbce0a343a4bf45a137b68d4730",
        "date": "2019-07-24_02-32-07",
        "timestamp": 1563928327,
        "time_this_iter_s": 7.502395868301392,
        "time_total_s": 1270.401971578598,
        "pid": 31141,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {
            "env_type": "openai"
          },
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 4,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 1270.401971578598,
        "timesteps_since_restore": 4802400,
        "iterations_since_restore": 184,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563928327.8156304,
      "checkpoint_freq": 50,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_2_num_envs_per_worker=4_2019-07-24_02-10-508groi6vv",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563928327.81562,
      "trial_id": "ec8f2c7a",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    }
  ],
  "runner_data": {
    "_global_time_limit": Infinity,
    "_total_time": 4071.886211156845,
    "_iteration": 570,
    "_verbose": true,
    "_server_port": 4321,
    "_metadata_checkpoint_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
    "_start_time": 1563924228.6644375,
    "_session_str": "2019-07-24_01-23-48",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1563924228.6644375,
    "timestamp": 1563928327.8260703
  }
}
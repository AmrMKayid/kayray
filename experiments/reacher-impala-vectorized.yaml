# This can reach 18-19 reward within 10 minutes on a Tesla M60 GPU (e.g., G3 EC2 node)
# with 32 workers and 10 envs per worker. This is more efficient than the non-vectorized
# configuration which requires 128 workers to achieve the same performance.
gym-reacher-impala-vectorized:
    env: RoboschoolReacher-v1
    run: IMPALA
    local_dir: ~/kayray_results
    checkpoint_freq: 100
    checkpoint_at_end: True
    stop:
      time_total_s: 7200 # 2 hours
      training_iteration: 1000
      episode_reward_mean: 21.5
    config:
        sample_batch_size: 50
        train_batch_size: 500
#        num_workers: 3 # 32
        num_workers:
          grid_search: [11, 9, 7, 5, 3]
        num_envs_per_worker:
          grid_search: [8, 6, 4, 2]
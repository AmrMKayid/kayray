2019-07-18 12:01:03,365	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-18_12-01-03_365348_8243/logs.
2019-07-18 12:01:03,471	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:65340 to respond...
2019-07-18 12:01:03,592	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:35247 to respond...
2019-07-18 12:01:03,596	INFO services.py:806 -- Starting Redis shard with 3.33 GB max memory.
2019-07-18 12:01:03,630	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-18_12-01-03_365348_8243/logs.
2019-07-18 12:01:03,631	INFO services.py:1446 -- Starting the Plasma object store with 5.0 GB memory using /dev/shm.
2019-07-18 12:01:03,753	INFO tune.py:61 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()
2019-07-18 12:01:03,755	INFO tune.py:233 -- Starting a new experiment.
2019-07-18 12:01:03,778	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-18 12:01:03,916	WARNING util.py:64 -- The `start_trial` operation took 0.15225958824157715 seconds to complete, which may be a performance bottleneck.
[32m [     0.22173s,  INFO] Registering env:  Reacher [0m
[32m [     0.22207s,  INFO] Experiment configs: 
 {
  "unity-reacher-ppo-baseline": {
    "env": "Reacher",
    "run": "PPO",
    "local_dir": "~/kayray_results/local",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "training_iteration": 500
    },
    "config": {
      "env_config": {
        "env_type": "unity"
      },
      "gamma": 0.995,
      "kl_coeff": 1.0,
      "num_sgd_iter": 20,
      "lr": 0.0001,
      "sgd_minibatch_size": 1000,
      "train_batch_size": 25000,
      "model": {
        "free_log_std": true
      },
      "num_gpus": 1,
      "num_workers": 3,
      "batch_mode": "complete_episodes",
      "observation_filter": "MeanStdFilter"
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 5.4/16.7 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 5.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING

[2m[36m(pid=8299)[0m {'env_type': 'unity'}
[2m[36m(pid=8299)[0m [32m [     0.01763s,  INFO] Starting env: linux/Reacher | worker_id: 0 [0m
[2m[36m(pid=8299)[0m 2019-07-18 12:01:05,725	WARNING ppo.py:151 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=8299)[0m Found path: /home/amr/kayray/kayray/envs/build/linux/Reacher.x86_64
[2m[36m(pid=8299)[0m Mono path[0] = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Managed'
[2m[36m(pid=8299)[0m Mono config path = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/MonoBleedingEdge/etc'
[2m[36m(pid=8299)[0m PlayerConnection initialized from /home/amr/kayray/kayray/envs/build/linux/Reacher_Data (debug = 0)
[2m[36m(pid=8299)[0m PlayerConnection initialized network socket : 0.0.0.0 55261
[2m[36m(pid=8299)[0m Multi-casting "[IP] 10.16.128.63 [Port] 55261 [Flags] 2 [Guid] 2046210679 [EditorId] 3707127039 [Version] 1048832 [Id] LinuxPlayer(10.16.128.63) [Debug] 0 [PackageName] LinuxPlayer" to [225.0.0.222:54997]...
[2m[36m(pid=8299)[0m Started listening to [0.0.0.0:55261]
[2m[36m(pid=8299)[0m Preloaded 'ScreenSelector.so'
[2m[36m(pid=8299)[0m Preloaded 'libgrpc_csharp_ext.x64.so'
[2m[36m(pid=8299)[0m PlayerConnection already initialized - listening to [0.0.0.0:55261]
[2m[36m(pid=8299)[0m Initialize engine version: 2019.1.10f1 (f007ed779b7a)
[2m[36m(pid=8299)[0m Forcing GfxDevice: Null
[2m[36m(pid=8299)[0m GfxDevice: creating device client; threaded=0
[2m[36m(pid=8299)[0m NullGfxDevice:
[2m[36m(pid=8299)[0m     Version:  NULL 1.0 [1.0]
[2m[36m(pid=8299)[0m     Renderer: Null Device
[2m[36m(pid=8299)[0m     Vendor:   Unity Technologies
[2m[36m(pid=8299)[0m Begin MonoManager ReloadAssembly
[2m[36m(pid=8299)[0m - Completed reload, in  0.071 seconds
[2m[36m(pid=8299)[0m UnloadTime: 0.418052 ms
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8299)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8299)[0m INFO:mlagents.envs:
[2m[36m(pid=8299)[0m 'Academy' started successfully!
[2m[36m(pid=8299)[0m Unity Academy name: Academy
[2m[36m(pid=8299)[0m         Number of Brains: 1
[2m[36m(pid=8299)[0m         Number of Training Brains : 1
[2m[36m(pid=8299)[0m         Reset Parameters :
[2m[36m(pid=8299)[0m 		goal_speed -> 1.0
[2m[36m(pid=8299)[0m 		goal_size -> 5.0
[2m[36m(pid=8299)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8299)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8299)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8299)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8299)[0m         Vector Action space type: continuous
[2m[36m(pid=8299)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8299)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8299)[0m [32m [     1.04636s,  INFO] UnityEnv:
[2m[36m(pid=8299)[0m - _env = Unity Academy name: Academy
[2m[36m(pid=8299)[0m         Number of Brains: 1
[2m[36m(pid=8299)[0m         Number of Training Brains : 1
[2m[36m(pid=8299)[0m         Reset Parameters :
[2m[36m(pid=8299)[0m 		goal_speed -> 1.0
[2m[36m(pid=8299)[0m 		goal_size -> 5.0
[2m[36m(pid=8299)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8299)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8299)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8299)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8299)[0m         Vector Action space type: continuous
[2m[36m(pid=8299)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8299)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8299)[0m - name = Academy
[2m[36m(pid=8299)[0m - visual_obs = None
[2m[36m(pid=8299)[0m - _current_state = None
[2m[36m(pid=8299)[0m - _n_agents = 1
[2m[36m(pid=8299)[0m - _multiagent = False
[2m[36m(pid=8299)[0m - _flattener = None
[2m[36m(pid=8299)[0m - game_over = False
[2m[36m(pid=8299)[0m - _allow_multiple_visual_obs = False
[2m[36m(pid=8299)[0m - brain_name = ReacherLearning
[2m[36m(pid=8299)[0m - use_visual = False
[2m[36m(pid=8299)[0m - uint8_visual = False
[2m[36m(pid=8299)[0m - _action_space = Box(4,)
[2m[36m(pid=8299)[0m - action_meanings = ['', '', '', '']
[2m[36m(pid=8299)[0m - _observation_space = Box(33,) [0m
[2m[36m(pid=8299)[0m [32m [     1.04642s,  INFO] UnityRayEnv:
[2m[36m(pid=8299)[0m - env = <UnityEnv instance>
[2m[36m(pid=8299)[0m - observation_space = Box(33,)
[2m[36m(pid=8299)[0m - action_space = Box(4,) [0m
[2m[36m(pid=8299)[0m INFO:gym_unity:1 agents within environment.
[2m[36m(pid=8299)[0m 2019-07-18 12:01:06.755527: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=8299)[0m 2019-07-18 12:01:06,849	INFO dynamic_tf_policy.py:313 -- Initializing loss function with dummy input:
[2m[36m(pid=8299)[0m 
[2m[36m(pid=8299)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8299)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 8) dtype=float32>,
[2m[36m(pid=8299)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=8299)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 33) dtype=float32>,
[2m[36m(pid=8299)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 33) dtype=float32>,
[2m[36m(pid=8299)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8299)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=8299)[0m 
[2m[36m(pid=8299)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=8299)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=8299)[0m 2019-07-18 12:01:07,403	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7fc9d535ee48>}
[2m[36m(pid=8299)[0m 2019-07-18 12:01:07,403	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7fc9d535ea90>}
[2m[36m(pid=8299)[0m 2019-07-18 12:01:07,403	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': MeanStdFilter((33,), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}
[2m[36m(pid=8299)[0m 2019-07-18 12:01:07,426	INFO multi_gpu_optimizer.py:79 -- LocalMultiGPUOptimizer devices ['/gpu:0']
[2m[36m(pid=8294)[0m {'env_type': 'unity'}
[2m[36m(pid=8294)[0m [32m [     0.01570s,  INFO] Starting env: linux/Reacher | worker_id: 2 [0m
[2m[36m(pid=8291)[0m {'env_type': 'unity'}
[2m[36m(pid=8291)[0m [32m [     0.01543s,  INFO] Starting env: linux/Reacher | worker_id: 3 [0m
[2m[36m(pid=8288)[0m {'env_type': 'unity'}
[2m[36m(pid=8288)[0m [32m [     0.01706s,  INFO] Starting env: linux/Reacher | worker_id: 1 [0m
[2m[36m(pid=8294)[0m Found path: /home/amr/kayray/kayray/envs/build/linux/Reacher.x86_64
[2m[36m(pid=8294)[0m Mono path[0] = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Managed'
[2m[36m(pid=8294)[0m Mono config path = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/MonoBleedingEdge/etc'
[2m[36m(pid=8294)[0m PlayerConnection initialized from /home/amr/kayray/kayray/envs/build/linux/Reacher_Data (debug = 0)
[2m[36m(pid=8294)[0m PlayerConnection initialized network socket : 0.0.0.0 55046
[2m[36m(pid=8294)[0m Multi-casting "[IP] 10.16.128.63 [Port] 55046 [Flags] 2 [Guid] 1088567833 [EditorId] 3707127039 [Version] 1048832 [Id] LinuxPlayer(10.16.128.63) [Debug] 0 [PackageName] LinuxPlayer" to [225.0.0.222:54997]...
[2m[36m(pid=8294)[0m Started listening to [0.0.0.0:55046]
[2m[36m(pid=8291)[0m Found path: /home/amr/kayray/kayray/envs/build/linux/Reacher.x86_64
[2m[36m(pid=8291)[0m Mono path[0] = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Managed'
[2m[36m(pid=8291)[0m Mono config path = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/MonoBleedingEdge/etc'
[2m[36m(pid=8291)[0m PlayerConnection initialized from /home/amr/kayray/kayray/envs/build/linux/Reacher_Data (debug = 0)
[2m[36m(pid=8291)[0m PlayerConnection initialized network socket : 0.0.0.0 55006
[2m[36m(pid=8291)[0m Multi-casting "[IP] 10.16.128.63 [Port] 55006 [Flags] 2 [Guid] 1591156870 [EditorId] 3707127039 [Version] 1048832 [Id] LinuxPlayer(10.16.128.63) [Debug] 0 [PackageName] LinuxPlayer" to [225.0.0.222:54997]...
[2m[36m(pid=8291)[0m Started listening to [0.0.0.0:55006]
[2m[36m(pid=8291)[0m Preloaded 'ScreenSelector.so'
[2m[36m(pid=8291)[0m Preloaded 'libgrpc_csharp_ext.x64.so'
[2m[36m(pid=8291)[0m PlayerConnection already initialized - listening to [0.0.0.0:55006]
[2m[36m(pid=8291)[0m Initialize engine version: 2019.1.10f1 (f007ed779b7a)
[2m[36m(pid=8291)[0m Forcing GfxDevice: Null
[2m[36m(pid=8291)[0m GfxDevice: creating device client; threaded=0
[2m[36m(pid=8291)[0m NullGfxDevice:
[2m[36m(pid=8291)[0m     Version:  NULL 1.0 [1.0]
[2m[36m(pid=8291)[0m     Renderer: Null Device
[2m[36m(pid=8291)[0m     Vendor:   Unity Technologies
[2m[36m(pid=8288)[0m Found path: /home/amr/kayray/kayray/envs/build/linux/Reacher.x86_64
[2m[36m(pid=8288)[0m Mono path[0] = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Managed'
[2m[36m(pid=8288)[0m Mono config path = '/home/amr/kayray/kayray/envs/build/linux/Reacher_Data/MonoBleedingEdge/etc'
[2m[36m(pid=8288)[0m PlayerConnection initialized from /home/amr/kayray/kayray/envs/build/linux/Reacher_Data (debug = 0)
[2m[36m(pid=8288)[0m PlayerConnection initialized network socket : 0.0.0.0 55038
[2m[36m(pid=8288)[0m Multi-casting "[IP] 10.16.128.63 [Port] 55038 [Flags] 2 [Guid] 3580222835 [EditorId] 3707127039 [Version] 1048832 [Id] LinuxPlayer(10.16.128.63) [Debug] 0 [PackageName] LinuxPlayer" to [225.0.0.222:54997]...
[2m[36m(pid=8288)[0m Started listening to [0.0.0.0:55038]
[2m[36m(pid=8294)[0m Preloaded 'ScreenSelector.so'
[2m[36m(pid=8294)[0m Preloaded 'libgrpc_csharp_ext.x64.so'
[2m[36m(pid=8294)[0m PlayerConnection already initialized - listening to [0.0.0.0:55046]
[2m[36m(pid=8294)[0m Initialize engine version: 2019.1.10f1 (f007ed779b7a)
[2m[36m(pid=8294)[0m Forcing GfxDevice: Null
[2m[36m(pid=8294)[0m GfxDevice: creating device client; threaded=0
[2m[36m(pid=8294)[0m NullGfxDevice:
[2m[36m(pid=8294)[0m     Version:  NULL 1.0 [1.0]
[2m[36m(pid=8294)[0m     Renderer: Null Device
[2m[36m(pid=8294)[0m     Vendor:   Unity Technologies
[2m[36m(pid=8294)[0m Begin MonoManager ReloadAssembly
[2m[36m(pid=8291)[0m Begin MonoManager ReloadAssembly
[2m[36m(pid=8288)[0m Preloaded 'ScreenSelector.so'
[2m[36m(pid=8288)[0m Preloaded 'libgrpc_csharp_ext.x64.so'
[2m[36m(pid=8288)[0m PlayerConnection already initialized - listening to [0.0.0.0:55038]
[2m[36m(pid=8288)[0m Initialize engine version: 2019.1.10f1 (f007ed779b7a)
[2m[36m(pid=8288)[0m Forcing GfxDevice: Null
[2m[36m(pid=8288)[0m GfxDevice: creating device client; threaded=0
[2m[36m(pid=8288)[0m NullGfxDevice:
[2m[36m(pid=8288)[0m     Version:  NULL 1.0 [1.0]
[2m[36m(pid=8288)[0m     Renderer: Null Device
[2m[36m(pid=8288)[0m     Vendor:   Unity Technologies
[2m[36m(pid=8288)[0m Begin MonoManager ReloadAssembly
[2m[36m(pid=8294)[0m - Completed reload, in  0.057 seconds
[2m[36m(pid=8291)[0m - Completed reload, in  0.052 seconds
[2m[36m(pid=8288)[0m - Completed reload, in  0.051 seconds
[2m[36m(pid=8294)[0m UnloadTime: 0.518468 ms
[2m[36m(pid=8291)[0m UnloadTime: 0.399764 ms
[2m[36m(pid=8288)[0m UnloadTime: 0.422581 ms
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8294)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8291)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libcoreclr.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib.so
[2m[36m(pid=8288)[0m Fallback handler could not load library /home/amr/kayray/kayray/envs/build/linux/Reacher_Data/Mono/libSystem.dylib
[2m[36m(pid=8291)[0m INFO:mlagents.envs:
[2m[36m(pid=8291)[0m 'Academy' started successfully!
[2m[36m(pid=8291)[0m Unity Academy name: Academy
[2m[36m(pid=8291)[0m         Number of Brains: 1
[2m[36m(pid=8291)[0m         Number of Training Brains : 1
[2m[36m(pid=8291)[0m         Reset Parameters :
[2m[36m(pid=8291)[0m 		goal_size -> 5.0
[2m[36m(pid=8291)[0m 		goal_speed -> 1.0
[2m[36m(pid=8291)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8291)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8291)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8291)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8291)[0m         Vector Action space type: continuous
[2m[36m(pid=8291)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8291)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8294)[0m INFO:mlagents.envs:
[2m[36m(pid=8294)[0m 'Academy' started successfully!
[2m[36m(pid=8294)[0m Unity Academy name: Academy
[2m[36m(pid=8294)[0m         Number of Brains: 1
[2m[36m(pid=8294)[0m         Number of Training Brains : 1
[2m[36m(pid=8294)[0m         Reset Parameters :
[2m[36m(pid=8294)[0m 		goal_speed -> 1.0
[2m[36m(pid=8294)[0m 		goal_size -> 5.0
[2m[36m(pid=8294)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8294)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8294)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8294)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8294)[0m         Vector Action space type: continuous
[2m[36m(pid=8294)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8294)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8288)[0m INFO:mlagents.envs:
[2m[36m(pid=8288)[0m 'Academy' started successfully!
[2m[36m(pid=8288)[0m Unity Academy name: Academy
[2m[36m(pid=8288)[0m         Number of Brains: 1
[2m[36m(pid=8288)[0m         Number of Training Brains : 1
[2m[36m(pid=8288)[0m         Reset Parameters :
[2m[36m(pid=8288)[0m 		goal_speed -> 1.0
[2m[36m(pid=8288)[0m 		goal_size -> 5.0
[2m[36m(pid=8288)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8288)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8288)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8288)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8288)[0m         Vector Action space type: continuous
[2m[36m(pid=8288)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8288)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8291)[0m INFO:gym_unity:1 agents within environment.
[2m[36m(pid=8291)[0m 2019-07-18 12:01:09,210	INFO rollout_worker.py:301 -- Creating policy evaluation worker 3 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=8291)[0m 2019-07-18 12:01:09.211522: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=8291)[0m [32m [     0.56156s,  INFO] UnityEnv:
[2m[36m(pid=8291)[0m - _env = Unity Academy name: Academy
[2m[36m(pid=8291)[0m         Number of Brains: 1
[2m[36m(pid=8291)[0m         Number of Training Brains : 1
[2m[36m(pid=8291)[0m         Reset Parameters :
[2m[36m(pid=8291)[0m 		goal_size -> 5.0
[2m[36m(pid=8291)[0m 		goal_speed -> 1.0
[2m[36m(pid=8291)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8291)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8291)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8291)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8291)[0m         Vector Action space type: continuous
[2m[36m(pid=8291)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8291)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8291)[0m - name = Academy
[2m[36m(pid=8291)[0m - visual_obs = None
[2m[36m(pid=8291)[0m - _current_state = None
[2m[36m(pid=8291)[0m - _n_agents = 1
[2m[36m(pid=8291)[0m - _multiagent = False
[2m[36m(pid=8291)[0m - _flattener = None
[2m[36m(pid=8291)[0m - game_over = False
[2m[36m(pid=8291)[0m - _allow_multiple_visual_obs = False
[2m[36m(pid=8291)[0m - brain_name = ReacherLearning
[2m[36m(pid=8291)[0m - use_visual = False
[2m[36m(pid=8291)[0m - uint8_visual = False
[2m[36m(pid=8291)[0m - _action_space = Box(4,)
[2m[36m(pid=8291)[0m - action_meanings = ['', '', '', '']
[2m[36m(pid=8291)[0m - _observation_space = Box(33,) [0m
[2m[36m(pid=8291)[0m [32m [     0.56162s,  INFO] UnityRayEnv:
[2m[36m(pid=8291)[0m - env = <UnityEnv instance>
[2m[36m(pid=8291)[0m - observation_space = Box(33,)
[2m[36m(pid=8291)[0m - action_space = Box(4,) [0m
[2m[36m(pid=8294)[0m [32m [     0.56937s,  INFO] UnityEnv:
[2m[36m(pid=8294)[0m - _env = Unity Academy name: Academy
[2m[36m(pid=8294)[0m         Number of Brains: 1
[2m[36m(pid=8294)[0m         Number of Training Brains : 1
[2m[36m(pid=8294)[0m         Reset Parameters :
[2m[36m(pid=8294)[0m 		goal_speed -> 1.0
[2m[36m(pid=8294)[0m 		goal_size -> 5.0
[2m[36m(pid=8294)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8294)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8294)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8294)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8294)[0m         Vector Action space type: continuous
[2m[36m(pid=8294)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8294)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8294)[0m - name = Academy
[2m[36m(pid=8294)[0m - visual_obs = None
[2m[36m(pid=8294)[0m - _current_state = None
[2m[36m(pid=8294)[0m - _n_agents = 1
[2m[36m(pid=8294)[0m - _multiagent = False
[2m[36m(pid=8294)[0m - _flattener = None
[2m[36m(pid=8294)[0m - game_over = False
[2m[36m(pid=8294)[0m - _allow_multiple_visual_obs = False
[2m[36m(pid=8294)[0m - brain_name = ReacherLearning
[2m[36m(pid=8294)[0m - use_visual = False
[2m[36m(pid=8294)[0m - uint8_visual = False
[2m[36m(pid=8294)[0m - _action_space = Box(4,)
[2m[36m(pid=8294)[0m - action_meanings = ['', '', '', '']
[2m[36m(pid=8294)[0m - _observation_space = Box(33,) [0m
[2m[36m(pid=8294)[0m [32m [     0.56942s,  INFO] UnityRayEnv:
[2m[36m(pid=8294)[0m - env = <UnityEnv instance>
[2m[36m(pid=8294)[0m - observation_space = Box(33,)
[2m[36m(pid=8294)[0m - action_space = Box(4,) [0m
[2m[36m(pid=8288)[0m [32m [     0.57708s,  INFO] UnityEnv:
[2m[36m(pid=8288)[0m - _env = Unity Academy name: Academy
[2m[36m(pid=8288)[0m         Number of Brains: 1
[2m[36m(pid=8288)[0m         Number of Training Brains : 1
[2m[36m(pid=8288)[0m         Reset Parameters :
[2m[36m(pid=8288)[0m 		goal_speed -> 1.0
[2m[36m(pid=8288)[0m 		goal_size -> 5.0
[2m[36m(pid=8288)[0m Unity brain name: ReacherLearning
[2m[36m(pid=8288)[0m         Number of Visual Observations (per agent): 0
[2m[36m(pid=8288)[0m         Vector Observation space size (per agent): 33
[2m[36m(pid=8288)[0m         Number of stacked Vector Observation: 1
[2m[36m(pid=8288)[0m         Vector Action space type: continuous
[2m[36m(pid=8288)[0m         Vector Action space size (per agent): [4]
[2m[36m(pid=8288)[0m         Vector Action descriptions: , , , 
[2m[36m(pid=8288)[0m - name = Academy
[2m[36m(pid=8288)[0m - visual_obs = None
[2m[36m(pid=8288)[0m - _current_state = None
[2m[36m(pid=8288)[0m - _n_agents = 1
[2m[36m(pid=8288)[0m - _multiagent = False
[2m[36m(pid=8288)[0m - _flattener = None
[2m[36m(pid=8288)[0m - game_over = False
[2m[36m(pid=8288)[0m - _allow_multiple_visual_obs = False
[2m[36m(pid=8288)[0m - brain_name = ReacherLearning
[2m[36m(pid=8288)[0m - use_visual = False
[2m[36m(pid=8288)[0m - uint8_visual = False
[2m[36m(pid=8288)[0m - _action_space = Box(4,)
[2m[36m(pid=8288)[0m - action_meanings = ['', '', '', '']
[2m[36m(pid=8288)[0m - _observation_space = Box(33,) [0m
[2m[36m(pid=8288)[0m [32m [     0.57717s,  INFO] UnityRayEnv:
[2m[36m(pid=8288)[0m - env = <UnityEnv instance>
[2m[36m(pid=8288)[0m - observation_space = Box(33,)
[2m[36m(pid=8288)[0m - action_space = Box(4,) [0m
[2m[36m(pid=8294)[0m INFO:gym_unity:1 agents within environment.
[2m[36m(pid=8294)[0m 2019-07-18 12:01:09,218	INFO rollout_worker.py:301 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=8294)[0m 2019-07-18 12:01:09.219110: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=8288)[0m INFO:gym_unity:1 agents within environment.
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,242	INFO rollout_worker.py:301 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09.242918: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,356	INFO dynamic_tf_policy.py:313 -- Initializing loss function with dummy input:
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8288)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8288)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8288)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 8) dtype=float32>,
[2m[36m(pid=8288)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=8288)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 33) dtype=float32>,
[2m[36m(pid=8288)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 33) dtype=float32>,
[2m[36m(pid=8288)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8288)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8288)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8288)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8288)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8291)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=8291)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=8294)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=8294)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=8288)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=8288)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,991	INFO rollout_worker.py:428 -- Generating sample batch of size 200
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,998	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((33,), dtype=float64, min=-10.0, max=1.0, mean=-0.72)}}
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,999	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,999	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((33,), dtype=float64, min=-10.0, max=1.0, mean=-0.72)
[2m[36m(pid=8288)[0m 2019-07-18 12:01:09,999	INFO sampler.py:411 -- Filtered obs: np.ndarray((33,), dtype=float64, min=0.0, max=0.0, mean=0.0)
[2m[36m(pid=8288)[0m 2019-07-18 12:01:10,000	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=8288)[0m                                   'env_id': 0,
[2m[36m(pid=8288)[0m                                   'info': None,
[2m[36m(pid=8288)[0m                                   'obs': np.ndarray((33,), dtype=float64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                                   'prev_action': np.ndarray((4,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=8288)[0m                                   'rnn_state': []},
[2m[36m(pid=8288)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m 2019-07-18 12:01:10,000	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=8288)[0m 2019-07-18 12:01:10,021	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m { 'default_policy': ( np.ndarray((1, 4), dtype=float32, min=-0.029, max=1.724, mean=0.977),
[2m[36m(pid=8288)[0m                       [],
[2m[36m(pid=8288)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.001, max=0.001, mean=0.001),
[2m[36m(pid=8288)[0m                         'behaviour_logits': np.ndarray((1, 8), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8294)[0m Setting up 6 worker threads for Enlighten.
[2m[36m(pid=8294)[0m requesting resize 80 x 80
[2m[36m(pid=8294)[0m   Thread -> id: 7faa729fa700 -> priority: 1 
[2m[36m(pid=8294)[0m   Thread -> id: 7faa721f9700 -> priority: 1 
[2m[36m(pid=8294)[0m   Thread -> id: 7faa719f8700 -> priority: 1 
[2m[36m(pid=8294)[0m   Thread -> id: 7faa711f7700 -> priority: 1 
[2m[36m(pid=8294)[0m   Thread -> id: 7faa709f6700 -> priority: 1 
[2m[36m(pid=8294)[0m   Thread -> id: 7faa4bfff700 -> priority: 1 
[2m[36m(pid=8291)[0m Setting up 6 worker threads for Enlighten.
[2m[36m(pid=8291)[0m   Thread -> id: 7f8229be2700 -> priority: 1 
[2m[36m(pid=8291)[0m   Thread -> id: 7f82293e1700 -> priority: 1 
[2m[36m(pid=8291)[0m   Thread -> id: 7f8228be0700 -> priority: 1 
[2m[36m(pid=8291)[0m   Thread -> id: 7f81f3fff700 -> priority: 1 
[2m[36m(pid=8291)[0m   Thread -> id: 7f81f37fe700 -> priority: 1 
[2m[36m(pid=8291)[0m   Thread -> id: 7f81f2ffd700 -> priority: 1 
[2m[36m(pid=8291)[0m requesting resize 80 x 80
[2m[36m(pid=8288)[0m Setting up 6 worker threads for Enlighten.
[2m[36m(pid=8288)[0m requesting resize 80 x 80
[2m[36m(pid=8288)[0m   Thread -> id: 7f368ffff700 -> priority: 1 
[2m[36m(pid=8288)[0m   Thread -> id: 7f368f7fe700 -> priority: 1 
[2m[36m(pid=8288)[0m   Thread -> id: 7f368effd700 -> priority: 1 
[2m[36m(pid=8288)[0m   Thread -> id: 7f368e7fc700 -> priority: 1 
[2m[36m(pid=8288)[0m   Thread -> id: 7f368dffb700 -> priority: 1 
[2m[36m(pid=8288)[0m   Thread -> id: 7f368d7fa700 -> priority: 1 
[2m[36m(pid=8294)[0m 2019-07-18 12:01:13,320	WARNING worker.py:343 -- WARNING: Falling back to serializing objects of type <class 'mlagents.envs.communicator_objects.custom_observation_pb2.CustomObservation'> by using pickle. This may be inefficient.
[2m[36m(pid=8288)[0m 2019-07-18 12:01:13,455	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((1001,), dtype=float32, min=0.0, max=0.024, mean=0.007),
[2m[36m(pid=8288)[0m                         'actions': np.ndarray((1001, 4), dtype=float32, min=-3.732, max=3.302, mean=-0.03),
[2m[36m(pid=8288)[0m                         'advantages': np.ndarray((1001,), dtype=float32, min=-0.012, max=0.012, mean=-0.0),
[2m[36m(pid=8288)[0m                         'agent_index': np.ndarray((1001,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         'behaviour_logits': np.ndarray((1001, 8), dtype=float32, min=-0.016, max=0.017, mean=0.0),
[2m[36m(pid=8288)[0m                         'dones': np.ndarray((1001,), dtype=bool, min=0.0, max=1.0, mean=0.001),
[2m[36m(pid=8288)[0m                         'eps_id': np.ndarray((1001,), dtype=int64, min=1202833436.0, max=1202833436.0, mean=1202833436.0),
[2m[36m(pid=8288)[0m                         'infos': np.ndarray((1001,), dtype=object, head={'text_observation': '', 'brain_info': <mlagents.envs.brain.BrainInfo object at 0x7f7596a6a908>}),
[2m[36m(pid=8288)[0m                         'new_obs': np.ndarray((1001, 33), dtype=float32, min=-5.715, max=31.623, mean=-0.03),
[2m[36m(pid=8288)[0m                         'obs': np.ndarray((1001, 33), dtype=float32, min=-5.715, max=5.318, mean=-0.031),
[2m[36m(pid=8288)[0m                         'prev_actions': np.ndarray((1001, 4), dtype=float32, min=-3.732, max=3.302, mean=-0.031),
[2m[36m(pid=8288)[0m                         'prev_rewards': np.ndarray((1001,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         'rewards': np.ndarray((1001,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         't': np.ndarray((1001,), dtype=int64, min=0.0, max=1000.0, mean=500.0),
[2m[36m(pid=8288)[0m                         'unroll_id': np.ndarray((1001,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         'value_targets': np.ndarray((1001,), dtype=float32, min=-0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m                         'vf_preds': np.ndarray((1001,), dtype=float32, min=-0.012, max=0.012, mean=0.0)},
[2m[36m(pid=8288)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m 2019-07-18 12:01:13,470	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8288)[0m { 'data': { 'action_prob': np.ndarray((1001,), dtype=float32, min=0.0, max=0.024, mean=0.007),
[2m[36m(pid=8288)[0m             'actions': np.ndarray((1001, 4), dtype=float32, min=-3.732, max=3.302, mean=-0.03),
[2m[36m(pid=8288)[0m             'advantages': np.ndarray((1001,), dtype=float32, min=-0.012, max=0.012, mean=-0.0),
[2m[36m(pid=8288)[0m             'agent_index': np.ndarray((1001,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m             'behaviour_logits': np.ndarray((1001, 8), dtype=float32, min=-0.016, max=0.017, mean=0.0),
[2m[36m(pid=8288)[0m             'dones': np.ndarray((1001,), dtype=bool, min=0.0, max=1.0, mean=0.001),
[2m[36m(pid=8288)[0m             'eps_id': np.ndarray((1001,), dtype=int64, min=1202833436.0, max=1202833436.0, mean=1202833436.0),
[2m[36m(pid=8288)[0m             'infos': np.ndarray((1001,), dtype=object, head={'text_observation': '', 'brain_info': <mlagents.envs.brain.BrainInfo object at 0x7f7596a6a908>}),
[2m[36m(pid=8288)[0m             'new_obs': np.ndarray((1001, 33), dtype=float32, min=-5.715, max=31.623, mean=-0.03),
[2m[36m(pid=8288)[0m             'obs': np.ndarray((1001, 33), dtype=float32, min=-5.715, max=5.318, mean=-0.031),
[2m[36m(pid=8288)[0m             'prev_actions': np.ndarray((1001, 4), dtype=float32, min=-3.732, max=3.302, mean=-0.031),
[2m[36m(pid=8288)[0m             'prev_rewards': np.ndarray((1001,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m             'rewards': np.ndarray((1001,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m             't': np.ndarray((1001,), dtype=int64, min=0.0, max=1000.0, mean=500.0),
[2m[36m(pid=8288)[0m             'unroll_id': np.ndarray((1001,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m             'value_targets': np.ndarray((1001,), dtype=float32, min=-0.0, max=0.0, mean=0.0),
[2m[36m(pid=8288)[0m             'vf_preds': np.ndarray((1001,), dtype=float32, min=-0.012, max=0.012, mean=0.0)},
[2m[36m(pid=8288)[0m   'type': 'SampleBatch'}
[2m[36m(pid=8288)[0m 
[2m[36m(pid=8299)[0m 2019-07-18 12:01:42,206	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=8299)[0m 
[2m[36m(pid=8299)[0m { 'inputs': [ np.ndarray((27027, 4), dtype=float32, min=-4.471, max=4.427, mean=-0.004),
[2m[36m(pid=8299)[0m               np.ndarray((27027,), dtype=float32, min=0.0, max=0.04, mean=0.0),
[2m[36m(pid=8299)[0m               np.ndarray((27027, 33), dtype=float32, min=-7.83, max=28.95, mean=0.024),
[2m[36m(pid=8299)[0m               np.ndarray((27027, 4), dtype=float32, min=-4.471, max=4.427, mean=-0.004),
[2m[36m(pid=8299)[0m               np.ndarray((27027,), dtype=float32, min=-0.609, max=6.998, mean=-0.0),
[2m[36m(pid=8299)[0m               np.ndarray((27027, 8), dtype=float32, min=-0.019, max=0.018, mean=0.0),
[2m[36m(pid=8299)[0m               np.ndarray((27027,), dtype=float32, min=-0.0, max=0.541, mean=0.031),
[2m[36m(pid=8299)[0m               np.ndarray((27027,), dtype=float32, min=-0.015, max=0.014, mean=0.0)],
[2m[36m(pid=8299)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 33) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 8) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=8299)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=8299)[0m   'state_inputs': []}
[2m[36m(pid=8299)[0m 
[2m[36m(pid=8299)[0m 2019-07-18 12:01:42,206	INFO multi_gpu_impl.py:191 -- Divided 27027 rollout sequences, each of length 1, among 1 devices.
Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-01-47
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.1099999751895666
  episode_reward_mean: 0.1911111068394449
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 27
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4837.633
    learner:
      default_policy:
        cur_kl_coeff: 1.0
        cur_lr: 9.999999747378752e-05
        entropy: 5.674673557281494
        kl: 0.002516753738746047
        policy_loss: -0.00902849156409502
        total_loss: -0.002818987239152193
        vf_explained_var: 0.28175026178359985
        vf_loss: 0.0036927491892129183
    load_time_ms: 23.323
    num_steps_sampled: 27027
    num_steps_trained: 27000
    sample_time_ms: 32755.369
    update_time_ms: 233.51
  iterations_since_restore: 1
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.508162226096551
    mean_inference_ms: 0.7021453175066668
    mean_processing_ms: 0.21391429153143188
  time_since_restore: 37.94915580749512
  time_this_iter_s: 37.94915580749512
  time_total_s: 37.94915580749512
  timestamp: 1563444107
  timesteps_since_restore: 27027
  timesteps_this_iter: 27027
  timesteps_total: 27027
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 7.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 37 s, 1 iter, 27027 ts, 0.191 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-02-26
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.1099999751895666
  episode_reward_mean: 0.1396296265086642
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 54
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5032.146
    learner:
      default_policy:
        cur_kl_coeff: 0.5
        cur_lr: 9.999999747378752e-05
        entropy: 5.674137592315674
        kl: 0.005322949029505253
        policy_loss: -0.012697183527052402
        total_loss: -0.00886353850364685
        vf_explained_var: 0.21671031415462494
        vf_loss: 0.0011721740011125803
    load_time_ms: 13.263
    num_steps_sampled: 54054
    num_steps_trained: 54000
    sample_time_ms: 33221.139
    update_time_ms: 117.907
  iterations_since_restore: 2
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.542197641499535
    mean_inference_ms: 0.7083287660790687
    mean_processing_ms: 0.21706494929039102
  time_since_restore: 76.94639754295349
  time_this_iter_s: 38.997241735458374
  time_total_s: 76.94639754295349
  timestamp: 1563444146
  timesteps_since_restore: 54054
  timesteps_this_iter: 27027
  timesteps_total: 54054
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 76 s, 2 iter, 54054 ts, 0.14 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-03-05
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.1099999751895666
  episode_reward_mean: 0.13518518216356082
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 81
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4948.434
    learner:
      default_policy:
        cur_kl_coeff: 0.5
        cur_lr: 9.999999747378752e-05
        entropy: 5.667520999908447
        kl: 0.0049246554262936115
        policy_loss: -0.014235788024961948
        total_loss: -0.009308939799666405
        vf_explained_var: 0.330430269241333
        vf_loss: 0.0024645195808261633
    load_time_ms: 9.818
    num_steps_sampled: 81081
    num_steps_trained: 81000
    sample_time_ms: 33546.238
    update_time_ms: 79.2
  iterations_since_restore: 3
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.563816386575964
    mean_inference_ms: 0.7132513769862834
    mean_processing_ms: 0.21907136961214807
  time_since_restore: 115.99896168708801
  time_this_iter_s: 39.05256414413452
  time_total_s: 115.99896168708801
  timestamp: 1563444185
  timesteps_since_restore: 81081
  timesteps_this_iter: 27027
  timesteps_total: 81081
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 115 s, 3 iter, 81081 ts, 0.135 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-03-43
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.339999970048666
  episode_reward_mean: 0.18229999592527746
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 108
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4894.97
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.650690078735352
        kl: 0.006923687178641558
        policy_loss: -0.015028794296085835
        total_loss: -0.007083069998770952
        vf_explained_var: 0.3918704390525818
        vf_loss: 0.006214798428118229
    load_time_ms: 8.005
    num_steps_sampled: 108108
    num_steps_trained: 108000
    sample_time_ms: 33414.817
    update_time_ms: 60.038
  iterations_since_restore: 4
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.578912866427519
    mean_inference_ms: 0.7166598621627847
    mean_processing_ms: 0.22028286238435477
  time_since_restore: 153.8311927318573
  time_this_iter_s: 37.83223104476929
  time_total_s: 153.8311927318573
  timestamp: 1563444223
  timesteps_since_restore: 108108
  timesteps_this_iter: 27027
  timesteps_total: 108108
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 153 s, 4 iter, 108108 ts, 0.182 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-04-22
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.339999970048666
  episode_reward_mean: 0.25149999437853693
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 135
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4866.132
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.645025730133057
        kl: 0.007486616726964712
        policy_loss: -0.01588803343474865
        total_loss: -0.005603767465800047
        vf_explained_var: 0.3489963412284851
        vf_loss: 0.008412607945501804
    load_time_ms: 6.905
    num_steps_sampled: 135135
    num_steps_trained: 135000
    sample_time_ms: 33562.598
    update_time_ms: 48.431
  iterations_since_restore: 5
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.60356655835928
    mean_inference_ms: 0.7216241606183739
    mean_processing_ms: 0.22233667640361277
  time_since_restore: 192.81298089027405
  time_this_iter_s: 38.98178815841675
  time_total_s: 192.81298089027405
  timestamp: 1563444262
  timesteps_since_restore: 135135
  timesteps_this_iter: 27027
  timesteps_total: 135135
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 192 s, 5 iter, 135135 ts, 0.251 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-05-01
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.4299999680370092
  episode_reward_mean: 0.35679999202489854
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 162
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4891.649
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.634094715118408
        kl: 0.007199541199952364
        policy_loss: -0.016211526468396187
        total_loss: -0.0041968729346990585
        vf_explained_var: 0.34477698802948
        vf_loss: 0.010214765556156635
    load_time_ms: 6.176
    num_steps_sampled: 162162
    num_steps_trained: 162000
    sample_time_ms: 33660.033
    update_time_ms: 40.84
  iterations_since_restore: 6
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6148123002396555
    mean_inference_ms: 0.7242261051196653
    mean_processing_ms: 0.22326006875572502
  time_since_restore: 232.0591435432434
  time_this_iter_s: 39.24616265296936
  time_total_s: 232.0591435432434
  timestamp: 1563444301
  timesteps_since_restore: 162162
  timesteps_this_iter: 27027
  timesteps_total: 162162
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 232 s, 6 iter, 162162 ts, 0.357 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-05-43
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.4999999664723873
  episode_reward_mean: 0.43779999021440746
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 189
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4923.647
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.627617359161377
        kl: 0.00748109258711338
        policy_loss: -0.01843935437500477
        total_loss: -0.007241144310683012
        vf_explained_var: 0.35183411836624146
        vf_loss: 0.009327935054898262
    load_time_ms: 5.76
    num_steps_sampled: 189189
    num_steps_trained: 189000
    sample_time_ms: 34118.249
    update_time_ms: 35.318
  iterations_since_restore: 7
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.631049055178068
    mean_inference_ms: 0.7278391374752823
    mean_processing_ms: 0.22462042124888548
  time_since_restore: 274.11927461624146
  time_this_iter_s: 42.06013107299805
  time_total_s: 274.11927461624146
  timestamp: 1563444343
  timesteps_since_restore: 189189
  timesteps_this_iter: 27027
  timesteps_total: 189189
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 274 s, 7 iter, 189189 ts, 0.438 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-06-25
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 1.7099999617785215
  episode_reward_mean: 0.46869998952373865
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 216
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4947.171
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.616424560546875
        kl: 0.007409499958157539
        policy_loss: -0.018237460404634476
        total_loss: -0.006006642710417509
        vf_explained_var: 0.421475350856781
        vf_loss: 0.01037844642996788
    load_time_ms: 5.402
    num_steps_sampled: 216216
    num_steps_trained: 216000
    sample_time_ms: 34482.142
    update_time_ms: 31.193
  iterations_since_restore: 8
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.655074734770448
    mean_inference_ms: 0.7334037855956055
    mean_processing_ms: 0.22647515498268447
  time_since_restore: 316.3380558490753
  time_this_iter_s: 42.21878123283386
  time_total_s: 316.3380558490753
  timestamp: 1563444385
  timesteps_since_restore: 216216
  timesteps_this_iter: 27027
  timesteps_total: 216216
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 316 s, 8 iter, 216216 ts, 0.469 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-07-07
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 2.2899999488145113
  episode_reward_mean: 0.530499988142401
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 243
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4963.459
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.603975296020508
        kl: 0.0074024200439453125
        policy_loss: -0.019160380586981773
        total_loss: -0.0029791747219860554
        vf_explained_var: 0.3976621925830841
        vf_loss: 0.014330603182315826
    load_time_ms: 5.181
    num_steps_sampled: 243243
    num_steps_trained: 243000
    sample_time_ms: 34771.969
    update_time_ms: 28.006
  iterations_since_restore: 9
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6818839028995503
    mean_inference_ms: 0.739596456556865
    mean_processing_ms: 0.22868462468848713
  time_since_restore: 358.60263538360596
  time_this_iter_s: 42.26457953453064
  time_total_s: 358.60263538360596
  timestamp: 1563444427
  timesteps_since_restore: 243243
  timesteps_this_iter: 27027
  timesteps_total: 243243
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 358 s, 9 iter, 243243 ts, 0.53 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-07-50
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 2.389999946579337
  episode_reward_mean: 0.615999986231327
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 270
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4989.68
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.592902660369873
        kl: 0.007977096363902092
        policy_loss: -0.02082855813205242
        total_loss: -0.0034753906074911356
        vf_explained_var: 0.40331214666366577
        vf_loss: 0.01535889320075512
    load_time_ms: 4.911
    num_steps_sampled: 270270
    num_steps_trained: 270000
    sample_time_ms: 35008.952
    update_time_ms: 25.519
  iterations_since_restore: 10
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7090234953874233
    mean_inference_ms: 0.746037707960827
    mean_processing_ms: 0.23095824584477442
  time_since_restore: 401.0619487762451
  time_this_iter_s: 42.45931339263916
  time_total_s: 401.0619487762451
  timestamp: 1563444470
  timesteps_since_restore: 270270
  timesteps_this_iter: 27027
  timesteps_total: 270270
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 401 s, 10 iter, 270270 ts, 0.616 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-08-33
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 2.389999946579337
  episode_reward_mean: 0.7058999842219055
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 297
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5019.058
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.571945667266846
        kl: 0.007839709520339966
        policy_loss: -0.022058537229895592
        total_loss: -0.008703194558620453
        vf_explained_var: 0.3703817129135132
        vf_loss: 0.011395419016480446
    load_time_ms: 2.846
    num_steps_sampled: 297297
    num_steps_trained: 297000
    sample_time_ms: 35533.671
    update_time_ms: 2.465
  iterations_since_restore: 11
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.732448527103529
    mean_inference_ms: 0.7517117801116149
    mean_processing_ms: 0.23291996260258305
  time_since_restore: 444.28211641311646
  time_this_iter_s: 43.22016763687134
  time_total_s: 444.28211641311646
  timestamp: 1563444513
  timesteps_since_restore: 297297
  timesteps_this_iter: 27027
  timesteps_total: 297297
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 444 s, 11 iter, 297297 ts, 0.706 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-09-14
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 2.5499999430030584
  episode_reward_mean: 0.7941999822482466
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 324
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4973.79
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.560848712921143
        kl: 0.00753531139343977
        policy_loss: -0.022330883890390396
        total_loss: -0.0016425863141193986
        vf_explained_var: 0.384649395942688
        vf_loss: 0.018804466351866722
    load_time_ms: 2.796
    num_steps_sampled: 324324
    num_steps_trained: 324000
    sample_time_ms: 35746.133
    update_time_ms: 2.498
  iterations_since_restore: 12
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7496893930830244
    mean_inference_ms: 0.7558645111397891
    mean_processing_ms: 0.23423460175782906
  time_since_restore: 484.94809103012085
  time_this_iter_s: 40.665974617004395
  time_total_s: 484.94809103012085
  timestamp: 1563444554
  timesteps_since_restore: 324324
  timesteps_this_iter: 27027
  timesteps_total: 324324
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 484 s, 12 iter, 324324 ts, 0.794 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-09-55
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 2.5499999430030584
  episode_reward_mean: 0.9477999788150191
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 351
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4978.222
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.536632537841797
        kl: 0.008598356507718563
        policy_loss: -0.023519359529018402
        total_loss: 0.002221581758931279
        vf_explained_var: 0.4207248091697693
        vf_loss: 0.023591352626681328
    load_time_ms: 2.769
    num_steps_sampled: 351351
    num_steps_trained: 351000
    sample_time_ms: 35935.37
    update_time_ms: 2.562
  iterations_since_restore: 13
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.762469761307925
    mean_inference_ms: 0.7585845578745528
    mean_processing_ms: 0.23511160624236807
  time_since_restore: 525.9409141540527
  time_this_iter_s: 40.992823123931885
  time_total_s: 525.9409141540527
  timestamp: 1563444595
  timesteps_since_restore: 351351
  timesteps_this_iter: 27027
  timesteps_total: 351351
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 525 s, 13 iter, 351351 ts, 0.948 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-10-36
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.539999920874834
  episode_reward_mean: 1.058099976349622
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 378
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5017.371
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.524747848510742
        kl: 0.00829374697059393
        policy_loss: -0.02606222964823246
        total_loss: -0.00020949494501110166
        vf_explained_var: 0.46336162090301514
        vf_loss: 0.02377929911017418
    load_time_ms: 2.813
    num_steps_sampled: 378378
    num_steps_trained: 378000
    sample_time_ms: 36231.339
    update_time_ms: 2.528
  iterations_since_restore: 14
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.77102042057456
    mean_inference_ms: 0.760006691117212
    mean_processing_ms: 0.23555245575619438
  time_since_restore: 567.1240701675415
  time_this_iter_s: 41.18315601348877
  time_total_s: 567.1240701675415
  timestamp: 1563444636
  timesteps_since_restore: 378378
  timesteps_this_iter: 27027
  timesteps_total: 378378
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 567 s, 14 iter, 378378 ts, 1.06 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-11-18
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.539999920874834
  episode_reward_mean: 1.2726999715529381
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 405
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5064.627
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.509695053100586
        kl: 0.00769607350230217
        policy_loss: -0.024631500244140625
        total_loss: 0.004135319031774998
        vf_explained_var: 0.4643270969390869
        vf_loss: 0.026842806488275528
    load_time_ms: 2.856
    num_steps_sampled: 405405
    num_steps_trained: 405000
    sample_time_ms: 36451.447
    update_time_ms: 2.631
  iterations_since_restore: 15
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.776195430347243
    mean_inference_ms: 0.7606781902807828
    mean_processing_ms: 0.23579628735307814
  time_since_restore: 608.7908961772919
  time_this_iter_s: 41.666826009750366
  time_total_s: 608.7908961772919
  timestamp: 1563444678
  timesteps_since_restore: 405405
  timesteps_this_iter: 27027
  timesteps_total: 405405
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 608 s, 15 iter, 405405 ts, 1.27 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-11-59
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.539999920874834
  episode_reward_mean: 1.3504999698139728
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 432
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5050.691
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.496392726898193
        kl: 0.008096300065517426
        policy_loss: -0.02438238449394703
        total_loss: 0.005919884890317917
        vf_explained_var: 0.40156301856040955
        vf_loss: 0.02827819250524044
    load_time_ms: 2.875
    num_steps_sampled: 432432
    num_steps_trained: 432000
    sample_time_ms: 36687.073
    update_time_ms: 2.561
  iterations_since_restore: 16
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.781551143581106
    mean_inference_ms: 0.761493126437297
    mean_processing_ms: 0.2361689132796645
  time_since_restore: 650.2606153488159
  time_this_iter_s: 41.46971917152405
  time_total_s: 650.2606153488159
  timestamp: 1563444719
  timesteps_since_restore: 432432
  timesteps_this_iter: 27027
  timesteps_total: 432432
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 650 s, 16 iter, 432432 ts, 1.35 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-12-36
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.8099999148398638
  episode_reward_mean: 1.4196999682672322
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 459
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4984.998
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.480777740478516
        kl: 0.008404577150940895
        policy_loss: -0.026768306270241737
        total_loss: 0.009324352256953716
        vf_explained_var: 0.5084134340286255
        vf_loss: 0.03399151936173439
    load_time_ms: 2.832
    num_steps_sampled: 459459
    num_steps_trained: 459000
    sample_time_ms: 36219.639
    update_time_ms: 2.592
  iterations_since_restore: 17
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.781246893685756
    mean_inference_ms: 0.7610495853356732
    mean_processing_ms: 0.2361139410199019
  time_since_restore: 686.9878559112549
  time_this_iter_s: 36.727240562438965
  time_total_s: 686.9878559112549
  timestamp: 1563444756
  timesteps_since_restore: 459459
  timesteps_this_iter: 27027
  timesteps_total: 459459
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 686 s, 17 iter, 459459 ts, 1.42 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-13-12
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.8099999148398638
  episode_reward_mean: 1.5284999658353626
  episode_reward_min: 0.1099999975413084
  episodes_this_iter: 27
  episodes_total: 486
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4886.285
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.4706501960754395
        kl: 0.00766671122983098
        policy_loss: -0.027668721973896027
        total_loss: 0.009574097581207752
        vf_explained_var: 0.4352414309978485
        vf_loss: 0.035326141864061356
    load_time_ms: 2.814
    num_steps_sampled: 486486
    num_steps_trained: 486000
    sample_time_ms: 35715.388
    update_time_ms: 2.579
  iterations_since_restore: 18
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7756822087572597
    mean_inference_ms: 0.7593637802347523
    mean_processing_ms: 0.23562609342320806
  time_since_restore: 723.1751992702484
  time_this_iter_s: 36.18734335899353
  time_total_s: 723.1751992702484
  timestamp: 1563444792
  timesteps_since_restore: 486486
  timesteps_this_iter: 27027
  timesteps_total: 486486
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 723 s, 18 iter, 486486 ts, 1.53 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-13-49
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.8099999148398638
  episode_reward_mean: 1.57879996471107
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 513
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4801.655
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.45484733581543
        kl: 0.00875814724713564
        policy_loss: -0.02818026766180992
        total_loss: 0.010710036382079124
        vf_explained_var: 0.4640880525112152
        vf_loss: 0.036700766533613205
    load_time_ms: 2.746
    num_steps_sampled: 513513
    num_steps_trained: 513000
    sample_time_ms: 35239.034
    update_time_ms: 2.552
  iterations_since_restore: 19
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7655159996658814
    mean_inference_ms: 0.7566180275518658
    mean_processing_ms: 0.23475054460144743
  time_since_restore: 759.8318769931793
  time_this_iter_s: 36.65667772293091
  time_total_s: 759.8318769931793
  timestamp: 1563444829
  timesteps_since_restore: 513513
  timesteps_this_iter: 27027
  timesteps_total: 513513
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 759 s, 19 iter, 513513 ts, 1.58 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-14-25
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.8099999148398638
  episode_reward_mean: 1.6726999626122414
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 540
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4736.463
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.442464828491211
        kl: 0.009114665910601616
        policy_loss: -0.028933154419064522
        total_loss: 0.000810451281722635
        vf_explained_var: 0.4446914792060852
        vf_loss: 0.027464939281344414
    load_time_ms: 2.773
    num_steps_sampled: 540540
    num_steps_trained: 540000
    sample_time_ms: 34725.178
    update_time_ms: 2.44
  iterations_since_restore: 20
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.752406203066305
    mean_inference_ms: 0.7531767433052727
    mean_processing_ms: 0.2335913467144925
  time_since_restore: 796.4863090515137
  time_this_iter_s: 36.65443205833435
  time_total_s: 796.4863090515137
  timestamp: 1563444865
  timesteps_since_restore: 540540
  timesteps_this_iter: 27027
  timesteps_total: 540540
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 796 s, 20 iter, 540540 ts, 1.67 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-15-07
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 3.8199999146163464
  episode_reward_mean: 1.6539999630302191
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 567
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4724.166
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.430975437164307
        kl: 0.008222022093832493
        policy_loss: -0.02934531681239605
        total_loss: 0.008429128676652908
        vf_explained_var: 0.4494566321372986
        vf_loss: 0.03571893647313118
    load_time_ms: 2.823
    num_steps_sampled: 567567
    num_steps_trained: 567000
    sample_time_ms: 34536.085
    update_time_ms: 2.346
  iterations_since_restore: 21
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7446982721591486
    mean_inference_ms: 0.751072157897013
    mean_processing_ms: 0.2329193407971971
  time_since_restore: 837.6848764419556
  time_this_iter_s: 41.198567390441895
  time_total_s: 837.6848764419556
  timestamp: 1563444907
  timesteps_since_restore: 567567
  timesteps_this_iter: 27027
  timesteps_total: 567567
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 837 s, 21 iter, 567567 ts, 1.65 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-15-49
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 4.499999899417162
  episode_reward_mean: 1.7354999612085522
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 594
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4788.731
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.414694786071777
        kl: 0.009276158176362514
        policy_loss: -0.031310539692640305
        total_loss: 0.014944817870855331
        vf_explained_var: 0.5323341488838196
        vf_loss: 0.043936315923929214
    load_time_ms: 2.904
    num_steps_sampled: 594594
    num_steps_trained: 594000
    sample_time_ms: 34682.458
    update_time_ms: 2.335
  iterations_since_restore: 22
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.743173839815065
    mean_inference_ms: 0.7506196609639824
    mean_processing_ms: 0.23273535824502722
  time_since_restore: 880.4735581874847
  time_this_iter_s: 42.788681745529175
  time_total_s: 880.4735581874847
  timestamp: 1563444949
  timesteps_since_restore: 594594
  timesteps_this_iter: 27027
  timesteps_total: 594594
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 880 s, 22 iter, 594594 ts, 1.74 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-16-31
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 4.499999899417162
  episode_reward_mean: 1.8460999587364495
  episode_reward_min: 0.19999999552965164
  episodes_this_iter: 27
  episodes_total: 621
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4833.747
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.4040141105651855
        kl: 0.008657432161271572
        policy_loss: -0.030604593455791473
        total_loss: 0.021638862788677216
        vf_explained_var: 0.46725761890411377
        vf_loss: 0.0500791035592556
    load_time_ms: 2.91
    num_steps_sampled: 621621
    num_steps_trained: 621000
    sample_time_ms: 34728.128
    update_time_ms: 2.315
  iterations_since_restore: 23
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7462969882080297
    mean_inference_ms: 0.7513015787845334
    mean_processing_ms: 0.23295139066784448
  time_since_restore: 922.3717422485352
  time_this_iter_s: 41.898184061050415
  time_total_s: 922.3717422485352
  timestamp: 1563444991
  timesteps_since_restore: 621621
  timesteps_this_iter: 27027
  timesteps_total: 621621
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 922 s, 23 iter, 621621 ts, 1.85 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-17-12
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 4.499999899417162
  episode_reward_mean: 1.9604999561794103
  episode_reward_min: 0.19999999552965164
  episodes_this_iter: 27
  episodes_total: 648
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4822.722
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.385260105133057
        kl: 0.009477321058511734
        policy_loss: -0.030780255794525146
        total_loss: 0.022857915610074997
        vf_explained_var: 0.472796767950058
        vf_loss: 0.05126884579658508
    load_time_ms: 2.892
    num_steps_sampled: 648648
    num_steps_trained: 648000
    sample_time_ms: 34728.123
    update_time_ms: 2.377
  iterations_since_restore: 24
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.752122079476046
    mean_inference_ms: 0.7527317262788974
    mean_processing_ms: 0.2333557837168469
  time_since_restore: 963.4451851844788
  time_this_iter_s: 41.0734429359436
  time_total_s: 963.4451851844788
  timestamp: 1563445032
  timesteps_since_restore: 648648
  timesteps_this_iter: 27027
  timesteps_total: 648648
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 963 s, 24 iter, 648648 ts, 1.96 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-17-49
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 4.499999899417162
  episode_reward_mean: 2.138599952198565
  episode_reward_min: 0.17999999597668648
  episodes_this_iter: 27
  episodes_total: 675
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4722.595
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.3751678466796875
        kl: 0.008953213691711426
        policy_loss: -0.03265778347849846
        total_loss: 0.021165065467357635
        vf_explained_var: 0.4710715711116791
        vf_loss: 0.051584549248218536
    load_time_ms: 2.854
    num_steps_sampled: 675675
    num_steps_trained: 675000
    sample_time_ms: 34358.704
    update_time_ms: 2.269
  iterations_since_restore: 25
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7542207332119664
    mean_inference_ms: 0.7532675310697674
    mean_processing_ms: 0.23346392632956714
  time_since_restore: 1000.4056236743927
  time_this_iter_s: 36.96043848991394
  time_total_s: 1000.4056236743927
  timestamp: 1563445069
  timesteps_since_restore: 675675
  timesteps_this_iter: 27027
  timesteps_total: 675675
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1000 s, 25 iter, 675675 ts, 2.14 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-18-27
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 5.289999881759286
  episode_reward_mean: 2.2375999499857424
  episode_reward_min: 0.17999999597668648
  episodes_this_iter: 27
  episodes_total: 702
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4761.522
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.363404273986816
        kl: 0.00939211156219244
        policy_loss: -0.03332153335213661
        total_loss: 0.010731487534940243
        vf_explained_var: 0.514753520488739
        vf_loss: 0.041704993695020676
    load_time_ms: 2.853
    num_steps_sampled: 702702
    num_steps_trained: 702000
    sample_time_ms: 33951.59
    update_time_ms: 2.288
  iterations_since_restore: 26
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.752097419379863
    mean_inference_ms: 0.7526893631920296
    mean_processing_ms: 0.23327553216600727
  time_since_restore: 1038.1951513290405
  time_this_iter_s: 37.78952765464783
  time_total_s: 1038.1951513290405
  timestamp: 1563445107
  timesteps_since_restore: 702702
  timesteps_this_iter: 27027
  timesteps_total: 702702
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1038 s, 26 iter, 702702 ts, 2.24 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-19-05
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 5.289999881759286
  episode_reward_mean: 2.2800999490357934
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 729
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4753.999
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.345671653747559
        kl: 0.01061912253499031
        policy_loss: -0.034313470125198364
        total_loss: 0.013544389046728611
        vf_explained_var: 0.5111693143844604
        vf_loss: 0.0452030710875988
    load_time_ms: 2.834
    num_steps_sampled: 729729
    num_steps_trained: 729000
    sample_time_ms: 34036.336
    update_time_ms: 2.324
  iterations_since_restore: 27
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.747147923535091
    mean_inference_ms: 0.7513385422889399
    mean_processing_ms: 0.23283668475159736
  time_since_restore: 1075.695995092392
  time_this_iter_s: 37.50084376335144
  time_total_s: 1075.695995092392
  timestamp: 1563445145
  timesteps_since_restore: 729729
  timesteps_this_iter: 27027
  timesteps_total: 729729
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1075 s, 27 iter, 729729 ts, 2.28 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-19-42
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 5.289999881759286
  episode_reward_mean: 2.362899947185069
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 756
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4794.32
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.326539039611816
        kl: 0.01054367981851101
        policy_loss: -0.035373393446207047
        total_loss: 0.03036900982260704
        vf_explained_var: 0.5124775171279907
        vf_loss: 0.0631064847111702
    load_time_ms: 2.836
    num_steps_sampled: 756756
    num_steps_trained: 756000
    sample_time_ms: 34158.798
    update_time_ms: 2.327
  iterations_since_restore: 28
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.740949703296366
    mean_inference_ms: 0.7496046594193578
    mean_processing_ms: 0.23233231716013314
  time_since_restore: 1113.5158643722534
  time_this_iter_s: 37.81986927986145
  time_total_s: 1113.5158643722534
  timestamp: 1563445182
  timesteps_since_restore: 756756
  timesteps_this_iter: 27027
  timesteps_total: 756756
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1113 s, 28 iter, 756756 ts, 2.36 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-20-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.03999986499548
  episode_reward_mean: 2.5303999434411524
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 783
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4843.188
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.315569877624512
        kl: 0.010726609267294407
        policy_loss: -0.03577273339033127
        total_loss: 0.04318738728761673
        vf_explained_var: 0.5093502998352051
        vf_loss: 0.07627846300601959
    load_time_ms: 2.841
    num_steps_sampled: 783783
    num_steps_trained: 783000
    sample_time_ms: 34200.178
    update_time_ms: 2.321
  iterations_since_restore: 29
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.735457752796783
    mean_inference_ms: 0.7479589780880623
    mean_processing_ms: 0.23186936718409712
  time_since_restore: 1151.0702064037323
  time_this_iter_s: 37.55434203147888
  time_total_s: 1151.0702064037323
  timestamp: 1563445220
  timesteps_since_restore: 783783
  timesteps_this_iter: 27027
  timesteps_total: 783783
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1151 s, 29 iter, 783783 ts, 2.53 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-20-59
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.03999986499548
  episode_reward_mean: 2.6922999398224055
  episode_reward_min: 0.0
  episodes_this_iter: 27
  episodes_total: 810
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4861.722
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.298587799072266
        kl: 0.010232859291136265
        policy_loss: -0.03482896462082863
        total_loss: 0.03735361620783806
        vf_explained_var: 0.49624931812286377
        vf_loss: 0.06962436437606812
    load_time_ms: 2.833
    num_steps_sampled: 810810
    num_steps_trained: 810000
    sample_time_ms: 34435.3
    update_time_ms: 2.323
  iterations_since_restore: 30
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7317222283907436
    mean_inference_ms: 0.7467645357504185
    mean_processing_ms: 0.23151543988966594
  time_since_restore: 1190.2600491046906
  time_this_iter_s: 39.18984270095825
  time_total_s: 1190.2600491046906
  timestamp: 1563445259
  timesteps_since_restore: 810810
  timesteps_this_iter: 27027
  timesteps_total: 810810
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1190 s, 30 iter, 810810 ts, 2.69 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-21-36
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.239999860525131
  episode_reward_mean: 2.8629999360069633
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 837
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4865.484
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.276394367218018
        kl: 0.01055116020143032
        policy_loss: -0.03636258840560913
        total_loss: 0.040636658668518066
        vf_explained_var: 0.5143271088600159
        vf_loss: 0.07436145842075348
    load_time_ms: 2.776
    num_steps_sampled: 837837
    num_steps_trained: 837000
    sample_time_ms: 34032.066
    update_time_ms: 2.336
  iterations_since_restore: 31
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7275891819502225
    mean_inference_ms: 0.7455238686718598
    mean_processing_ms: 0.23112584458280472
  time_since_restore: 1227.4651443958282
  time_this_iter_s: 37.205095291137695
  time_total_s: 1227.4651443958282
  timestamp: 1563445296
  timesteps_since_restore: 837837
  timesteps_this_iter: 27027
  timesteps_total: 837837
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1227 s, 31 iter, 837837 ts, 2.86 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-22-12
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.239999860525131
  episode_reward_mean: 2.950299934055656
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 864
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4752.452
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.26295804977417
        kl: 0.011206550523638725
        policy_loss: -0.03623967617750168
        total_loss: 0.03763820230960846
        vf_explained_var: 0.4727090895175934
        vf_loss: 0.07107623666524887
    load_time_ms: 2.697
    num_steps_sampled: 864864
    num_steps_trained: 864000
    sample_time_ms: 33468.714
    update_time_ms: 2.301
  iterations_since_restore: 32
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7227135067328017
    mean_inference_ms: 0.7441262406136565
    mean_processing_ms: 0.2307167865289574
  time_since_restore: 1263.4747061729431
  time_this_iter_s: 36.00956177711487
  time_total_s: 1263.4747061729431
  timestamp: 1563445332
  timesteps_since_restore: 864864
  timesteps_this_iter: 27027
  timesteps_total: 864864
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1263 s, 32 iter, 864864 ts, 2.95 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-22-51
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.239999860525131
  episode_reward_mean: 2.8047999373078345
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 891
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4681.112
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.238159656524658
        kl: 0.01183981541544199
        policy_loss: -0.0387403666973114
        total_loss: 0.011434227228164673
        vf_explained_var: 0.47884613275527954
        vf_loss: 0.04721464216709137
    load_time_ms: 2.671
    num_steps_sampled: 891891
    num_steps_trained: 891000
    sample_time_ms: 33245.416
    update_time_ms: 2.288
  iterations_since_restore: 33
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7187698051452753
    mean_inference_ms: 0.7429552087249607
    mean_processing_ms: 0.23037447475874992
  time_since_restore: 1302.42338681221
  time_this_iter_s: 38.94868063926697
  time_total_s: 1302.42338681221
  timestamp: 1563445371
  timesteps_since_restore: 891891
  timesteps_this_iter: 27027
  timesteps_total: 891891
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1302 s, 33 iter, 891891 ts, 2.8 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-23-29
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.459999855607748
  episode_reward_mean: 2.8398999365232886
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 918
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4645.756
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.220132350921631
        kl: 0.01181123498827219
        policy_loss: -0.03718647360801697
        total_loss: 0.026905521750450134
        vf_explained_var: 0.5725887417793274
        vf_loss: 0.06113918498158455
    load_time_ms: 2.663
    num_steps_sampled: 918918
    num_steps_trained: 918000
    sample_time_ms: 32884.169
    update_time_ms: 2.24
  iterations_since_restore: 34
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7141602483041085
    mean_inference_ms: 0.7416558562380205
    mean_processing_ms: 0.22996943938656486
  time_since_restore: 1339.5306599140167
  time_this_iter_s: 37.10727310180664
  time_total_s: 1339.5306599140167
  timestamp: 1563445409
  timesteps_since_restore: 918918
  timesteps_this_iter: 27027
  timesteps_total: 918918
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1339 s, 34 iter, 918918 ts, 2.84 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-24-07
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.459999855607748
  episode_reward_mean: 2.871199935823679
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 945
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4761.538
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.204127788543701
        kl: 0.011506211012601852
        policy_loss: -0.039594866335392
        total_loss: 0.02448221668601036
        vf_explained_var: 0.5253321528434753
        vf_loss: 0.06120053306221962
    load_time_ms: 2.656
    num_steps_sampled: 945945
    num_steps_trained: 945000
    sample_time_ms: 32895.401
    update_time_ms: 2.295
  iterations_since_restore: 35
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.7103864929936856
    mean_inference_ms: 0.7405583961810425
    mean_processing_ms: 0.2296132652322656
  time_since_restore: 1377.7685804367065
  time_this_iter_s: 38.23792052268982
  time_total_s: 1377.7685804367065
  timestamp: 1563445447
  timesteps_since_restore: 945945
  timesteps_this_iter: 27027
  timesteps_total: 945945
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1377 s, 35 iter, 945945 ts, 2.87 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-24-43
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.489999854937196
  episode_reward_mean: 2.987599933221936
  episode_reward_min: 0.3399999924004078
  episodes_this_iter: 27
  episodes_total: 972
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4750.476
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.188639163970947
        kl: 0.010912437923252583
        policy_loss: -0.03749973326921463
        total_loss: 0.03916730731725693
        vf_explained_var: 0.5473892688751221
        vf_loss: 0.07393892854452133
    load_time_ms: 2.66
    num_steps_sampled: 972972
    num_steps_trained: 972000
    sample_time_ms: 32788.836
    update_time_ms: 2.268
  iterations_since_restore: 36
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.706129582481185
    mean_inference_ms: 0.739351399873249
    mean_processing_ms: 0.22924607794554916
  time_since_restore: 1414.375304222107
  time_this_iter_s: 36.60672378540039
  time_total_s: 1414.375304222107
  timestamp: 1563445483
  timesteps_since_restore: 972972
  timesteps_this_iter: 27027
  timesteps_total: 972972
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1414 s, 36 iter, 972972 ts, 2.99 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-25-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.489999854937196
  episode_reward_mean: 3.132499929983169
  episode_reward_min: 0.6899999845772982
  episodes_this_iter: 27
  episodes_total: 999
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4773.544
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.1754608154296875
        kl: 0.012765198014676571
        policy_loss: -0.04289825260639191
        total_loss: 0.027809832245111465
        vf_explained_var: 0.5414626002311707
        vf_loss: 0.06751678884029388
    load_time_ms: 2.731
    num_steps_sampled: 999999
    num_steps_trained: 999000
    sample_time_ms: 32629.866
    update_time_ms: 2.184
  iterations_since_restore: 37
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.700667541381165
    mean_inference_ms: 0.7378875859166059
    mean_processing_ms: 0.228807710125348
  time_since_restore: 1450.5193240642548
  time_this_iter_s: 36.14401984214783
  time_total_s: 1450.5193240642548
  timestamp: 1563445520
  timesteps_since_restore: 999999
  timesteps_this_iter: 27027
  timesteps_total: 999999
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1450 s, 37 iter, 999999 ts, 3.13 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-25-57
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.489999854937196
  episode_reward_mean: 3.1384999298490586
  episode_reward_min: 0.549999987706542
  episodes_this_iter: 27
  episodes_total: 1026
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4795.463
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.164373397827148
        kl: 0.011825097724795341
        policy_loss: -0.04158756136894226
        total_loss: 0.02671913616359234
        vf_explained_var: 0.5592135190963745
        vf_loss: 0.06535041332244873
    load_time_ms: 2.72
    num_steps_sampled: 1027026
    num_steps_trained: 1026000
    sample_time_ms: 32581.935
    update_time_ms: 2.206
  iterations_since_restore: 38
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6954932864703016
    mean_inference_ms: 0.7364973316749887
    mean_processing_ms: 0.22841838627505687
  time_since_restore: 1488.0827078819275
  time_this_iter_s: 37.56338381767273
  time_total_s: 1488.0827078819275
  timestamp: 1563445557
  timesteps_since_restore: 1027026
  timesteps_this_iter: 27027
  timesteps_total: 1027026
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1488 s, 38 iter, 1027026 ts, 3.14 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-26-35
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 5.939999867230654
  episode_reward_mean: 3.079099931176752
  episode_reward_min: 0.549999987706542
  episodes_this_iter: 27
  episodes_total: 1053
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4817.374
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.147460460662842
        kl: 0.011893563903868198
        policy_loss: -0.04159312695264816
        total_loss: 0.015272684395313263
        vf_explained_var: 0.6259128451347351
        vf_loss: 0.05389242246747017
    load_time_ms: 2.724
    num_steps_sampled: 1054053
    num_steps_trained: 1053000
    sample_time_ms: 32633.62
    update_time_ms: 2.21
  iterations_since_restore: 39
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6911335562838508
    mean_inference_ms: 0.7353417624203351
    mean_processing_ms: 0.2280901151625904
  time_since_restore: 1526.3727176189423
  time_this_iter_s: 38.29000973701477
  time_total_s: 1526.3727176189423
  timestamp: 1563445595
  timesteps_since_restore: 1054053
  timesteps_this_iter: 27027
  timesteps_total: 1054053
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1526 s, 39 iter, 1054053 ts, 3.08 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-27-13
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.509999854490161
  episode_reward_mean: 3.2791999267041683
  episode_reward_min: 0.549999987706542
  episodes_this_iter: 27
  episodes_total: 1080
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4823.405
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.132748126983643
        kl: 0.012290770187973976
        policy_loss: -0.04305219277739525
        total_loss: 0.04383078217506409
        vf_explained_var: 0.5377275347709656
        vf_loss: 0.08381027728319168
    load_time_ms: 2.709
    num_steps_sampled: 1081080
    num_steps_trained: 1080000
    sample_time_ms: 32465.575
    update_time_ms: 2.218
  iterations_since_restore: 40
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.687750573197184
    mean_inference_ms: 0.7344570696978977
    mean_processing_ms: 0.22782257679927262
  time_since_restore: 1563.9482634067535
  time_this_iter_s: 37.57554578781128
  time_total_s: 1563.9482634067535
  timestamp: 1563445633
  timesteps_since_restore: 1081080
  timesteps_this_iter: 27027
  timesteps_total: 1081080
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 8.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1563 s, 40 iter, 1081080 ts, 3.28 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-27-52
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.509999854490161
  episode_reward_mean: 3.39319992415607
  episode_reward_min: 0.549999987706542
  episodes_this_iter: 27
  episodes_total: 1107
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4797.841
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.109658241271973
        kl: 0.013251524418592453
        policy_loss: -0.04370005428791046
        total_loss: 0.03980857878923416
        vf_explained_var: 0.5012633204460144
        vf_loss: 0.08019574731588364
    load_time_ms: 2.731
    num_steps_sampled: 1108107
    num_steps_trained: 1107000
    sample_time_ms: 32690.93
    update_time_ms: 2.258
  iterations_since_restore: 41
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.685854330073708
    mean_inference_ms: 0.7338960727987838
    mean_processing_ms: 0.22768557432832967
  time_since_restore: 1603.156146287918
  time_this_iter_s: 39.20788288116455
  time_total_s: 1603.156146287918
  timestamp: 1563445672
  timesteps_since_restore: 1108107
  timesteps_this_iter: 27027
  timesteps_total: 1108107
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1603 s, 41 iter, 1108107 ts, 3.39 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-28-29
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.919999822974205
  episode_reward_mean: 3.6136999192275105
  episode_reward_min: 0.7099999841302633
  episodes_this_iter: 27
  episodes_total: 1134
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4846.973
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.093123912811279
        kl: 0.013387001119554043
        policy_loss: -0.04190796986222267
        total_loss: 0.043429937213659286
        vf_explained_var: 0.5766142010688782
        vf_loss: 0.08199115097522736
    load_time_ms: 2.741
    num_steps_sampled: 1135134
    num_steps_trained: 1134000
    sample_time_ms: 32749.476
    update_time_ms: 2.251
  iterations_since_restore: 42
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6837515455366927
    mean_inference_ms: 0.7333045874454399
    mean_processing_ms: 0.22751095062064214
  time_since_restore: 1640.2472553253174
  time_this_iter_s: 37.09110903739929
  time_total_s: 1640.2472553253174
  timestamp: 1563445709
  timesteps_since_restore: 1135134
  timesteps_this_iter: 27027
  timesteps_total: 1135134
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1640 s, 42 iter, 1135134 ts, 3.61 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-29-06
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.919999822974205
  episode_reward_mean: 3.7141999169811606
  episode_reward_min: 1.0599999763071537
  episodes_this_iter: 27
  episodes_total: 1161
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4876.721
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.076798439025879
        kl: 0.013989963568747044
        policy_loss: -0.04565662890672684
        total_loss: 0.026054445654153824
        vf_explained_var: 0.5725690126419067
        vf_loss: 0.0682135745882988
    load_time_ms: 2.76
    num_steps_sampled: 1162161
    num_steps_trained: 1161000
    sample_time_ms: 32481.776
    update_time_ms: 2.284
  iterations_since_restore: 43
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.681039340586574
    mean_inference_ms: 0.7325545528640436
    mean_processing_ms: 0.22728038732084307
  time_since_restore: 1676.819394826889
  time_this_iter_s: 36.572139501571655
  time_total_s: 1676.819394826889
  timestamp: 1563445746
  timesteps_since_restore: 1162161
  timesteps_this_iter: 27027
  timesteps_total: 1162161
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1676 s, 43 iter, 1162161 ts, 3.71 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-29-42
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.919999822974205
  episode_reward_mean: 3.557199920490384
  episode_reward_min: 1.0599999763071537
  episodes_this_iter: 27
  episodes_total: 1188
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4875.912
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.064101219177246
        kl: 0.01331018004566431
        policy_loss: -0.04589494690299034
        total_loss: 0.02853124402463436
        vf_explained_var: 0.5520983934402466
        vf_loss: 0.07109864801168442
    load_time_ms: 2.755
    num_steps_sampled: 1189188
    num_steps_trained: 1188000
    sample_time_ms: 32416.033
    update_time_ms: 2.274
  iterations_since_restore: 44
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.677772435330644
    mean_inference_ms: 0.7316574967066191
    mean_processing_ms: 0.2270005945171802
  time_since_restore: 1713.2596893310547
  time_this_iter_s: 36.44029450416565
  time_total_s: 1713.2596893310547
  timestamp: 1563445782
  timesteps_since_restore: 1189188
  timesteps_this_iter: 27027
  timesteps_total: 1189188
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1713 s, 44 iter, 1189188 ts, 3.56 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-30-19
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 6.669999850913882
  episode_reward_mean: 3.5578999204747377
  episode_reward_min: 1.0599999763071537
  episodes_this_iter: 27
  episodes_total: 1215
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4823.866
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.047860145568848
        kl: 0.013173967599868774
        policy_loss: -0.044919684529304504
        total_loss: 0.018841121345758438
        vf_explained_var: 0.545333743095398
        vf_loss: 0.06046731770038605
    load_time_ms: 2.759
    num_steps_sampled: 1216215
    num_steps_trained: 1215000
    sample_time_ms: 32351.631
    update_time_ms: 2.205
  iterations_since_restore: 45
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6738648790294324
    mean_inference_ms: 0.7306241625330565
    mean_processing_ms: 0.22668086040833382
  time_since_restore: 1750.3276302814484
  time_this_iter_s: 37.06794095039368
  time_total_s: 1750.3276302814484
  timestamp: 1563445819
  timesteps_since_restore: 1216215
  timesteps_this_iter: 27027
  timesteps_total: 1216215
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1750 s, 45 iter, 1216215 ts, 3.56 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-31-00
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.039999842643738
  episode_reward_mean: 3.5717999201640485
  episode_reward_min: 1.0599999763071537
  episodes_this_iter: 27
  episodes_total: 1242
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4815.969
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.027801513671875
        kl: 0.014352849684655666
        policy_loss: -0.04625706374645233
        total_loss: 0.05129745602607727
        vf_explained_var: 0.5399963855743408
        vf_loss: 0.09396631270647049
    load_time_ms: 2.742
    num_steps_sampled: 1243242
    num_steps_trained: 1242000
    sample_time_ms: 32718.832
    update_time_ms: 2.19
  iterations_since_restore: 46
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.671512847591008
    mean_inference_ms: 0.729964913412031
    mean_processing_ms: 0.22648184079959782
  time_since_restore: 1790.529783964157
  time_this_iter_s: 40.20215368270874
  time_total_s: 1790.529783964157
  timestamp: 1563445860
  timesteps_since_restore: 1243242
  timesteps_this_iter: 27027
  timesteps_total: 1243242
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1790 s, 46 iter, 1243242 ts, 3.57 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-31-38
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.039999842643738
  episode_reward_mean: 3.67439991787076
  episode_reward_min: 1.149999974295497
  episodes_this_iter: 27
  episodes_total: 1269
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4814.659
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 5.007259368896484
        kl: 0.014237246476113796
        policy_loss: -0.04787742346525192
        total_loss: 0.03838300332427025
        vf_explained_var: 0.529615581035614
        vf_loss: 0.08270110934972763
    load_time_ms: 2.675
    num_steps_sampled: 1270269
    num_steps_trained: 1269000
    sample_time_ms: 32990.871
    update_time_ms: 2.206
  iterations_since_restore: 47
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6704671964996134
    mean_inference_ms: 0.7296304637207801
    mean_processing_ms: 0.22636720842518002
  time_since_restore: 1829.3839945793152
  time_this_iter_s: 38.85421061515808
  time_total_s: 1829.3839945793152
  timestamp: 1563445898
  timesteps_since_restore: 1270269
  timesteps_this_iter: 27027
  timesteps_total: 1270269
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1829 s, 47 iter, 1270269 ts, 3.67 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-32-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.039999842643738
  episode_reward_mean: 3.602599919475615
  episode_reward_min: 0.9199999794363976
  episodes_this_iter: 27
  episodes_total: 1296
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4833.675
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.991472244262695
        kl: 0.014500199817121029
        policy_loss: -0.05079391971230507
        total_loss: 0.021523574367165565
        vf_explained_var: 0.6316276788711548
        vf_loss: 0.06869245320558548
    load_time_ms: 2.67
    num_steps_sampled: 1297296
    num_steps_trained: 1296000
    sample_time_ms: 33385.372
    update_time_ms: 2.203
  iterations_since_restore: 48
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.671632592417601
    mean_inference_ms: 0.7298615623487915
    mean_processing_ms: 0.22644265117488616
  time_since_restore: 1871.0774643421173
  time_this_iter_s: 41.693469762802124
  time_total_s: 1871.0774643421173
  timestamp: 1563445940
  timesteps_since_restore: 1297296
  timesteps_this_iter: 27027
  timesteps_total: 1297296
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1871 s, 48 iter, 1297296 ts, 3.6 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-32-57
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.039999842643738
  episode_reward_mean: 3.7474999162368476
  episode_reward_min: 0.9199999794363976
  episodes_this_iter: 27
  episodes_total: 1323
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4754.352
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.9709601402282715
        kl: 0.0145937604829669
        policy_loss: -0.04890555515885353
        total_loss: 0.03984161838889122
        vf_explained_var: 0.5407295823097229
        vf_loss: 0.0850987359881401
    load_time_ms: 2.671
    num_steps_sampled: 1324323
    num_steps_trained: 1323000
    sample_time_ms: 33350.631
    update_time_ms: 2.198
  iterations_since_restore: 49
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6728046165167165
    mean_inference_ms: 0.7301364015150774
    mean_processing_ms: 0.22650809629007834
  time_since_restore: 1908.2273082733154
  time_this_iter_s: 37.14984393119812
  time_total_s: 1908.2273082733154
  timestamp: 1563445977
  timesteps_since_restore: 1324323
  timesteps_this_iter: 27027
  timesteps_total: 1324323
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1908 s, 49 iter, 1324323 ts, 3.75 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-33-36
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.0699998419731855
  episode_reward_mean: 3.759399915970862
  episode_reward_min: 0.9199999794363976
  episodes_this_iter: 27
  episodes_total: 1350
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4745.796
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.960756778717041
        kl: 0.014585625380277634
        policy_loss: -0.04999685287475586
        total_loss: 0.030168520286679268
        vf_explained_var: 0.5592073798179626
        vf_loss: 0.0765189602971077
    load_time_ms: 2.694
    num_steps_sampled: 1351350
    num_steps_trained: 1350000
    sample_time_ms: 33468.086
    update_time_ms: 2.23
  iterations_since_restore: 50
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.673563199944049
    mean_inference_ms: 0.7303170479319959
    mean_processing_ms: 0.22654807169645555
  time_since_restore: 1946.8999948501587
  time_this_iter_s: 38.67268657684326
  time_total_s: 1946.8999948501587
  timestamp: 1563446016
  timesteps_since_restore: 1351350
  timesteps_this_iter: 27027
  timesteps_total: 1351350
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1946 s, 50 iter, 1351350 ts, 3.76 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-34-14
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 7.0699998419731855
  episode_reward_mean: 3.9904999108053745
  episode_reward_min: 0.9199999794363976
  episodes_this_iter: 27
  episodes_total: 1377
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4773.922
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.941658973693848
        kl: 0.015287232585251331
        policy_loss: -0.051989976316690445
        total_loss: 0.03790108859539032
        vf_explained_var: 0.5409039258956909
        vf_loss: 0.086069256067276
    load_time_ms: 2.663
    num_steps_sampled: 1378377
    num_steps_trained: 1377000
    sample_time_ms: 33313.503
    update_time_ms: 2.207
  iterations_since_restore: 51
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6732352271068502
    mean_inference_ms: 0.730246684418353
    mean_processing_ms: 0.22653235166754138
  time_since_restore: 1984.8390810489655
  time_this_iter_s: 37.93908619880676
  time_total_s: 1984.8390810489655
  timestamp: 1563446054
  timesteps_since_restore: 1378377
  timesteps_this_iter: 27027
  timesteps_total: 1378377
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 1984 s, 51 iter, 1378377 ts, 3.99 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-34-54
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.649999806657434
  episode_reward_mean: 4.2516999049671
  episode_reward_min: 1.7799999602138996
  episodes_this_iter: 27
  episodes_total: 1404
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4760.935
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.927384376525879
        kl: 0.014768771827220917
        policy_loss: -0.04887522757053375
        total_loss: 0.05780402198433876
        vf_explained_var: 0.527433454990387
        vf_loss: 0.10298705846071243
    load_time_ms: 2.653
    num_steps_sampled: 1405404
    num_steps_trained: 1404000
    sample_time_ms: 33573.109
    update_time_ms: 2.257
  iterations_since_restore: 52
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.672632327359661
    mean_inference_ms: 0.7300733361186085
    mean_processing_ms: 0.22648709211375992
  time_since_restore: 2024.3909575939178
  time_this_iter_s: 39.55187654495239
  time_total_s: 2024.3909575939178
  timestamp: 1563446094
  timesteps_since_restore: 1405404
  timesteps_this_iter: 27027
  timesteps_total: 1405404
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2024 s, 52 iter, 1405404 ts, 4.25 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-35-32
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.649999806657434
  episode_reward_mean: 4.353799902684987
  episode_reward_min: 1.7799999602138996
  episodes_this_iter: 27
  episodes_total: 1431
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4754.59
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.915374755859375
        kl: 0.015601159073412418
        policy_loss: -0.05175317823886871
        total_loss: 0.043626587837934494
        vf_explained_var: 0.5100560188293457
        vf_loss: 0.09147947281599045
    load_time_ms: 2.691
    num_steps_sampled: 1432431
    num_steps_trained: 1431000
    sample_time_ms: 33799.254
    update_time_ms: 2.236
  iterations_since_restore: 53
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6723152801487107
    mean_inference_ms: 0.7300096372641772
    mean_processing_ms: 0.22646694164436723
  time_since_restore: 2063.168619632721
  time_this_iter_s: 38.7776620388031
  time_total_s: 2063.168619632721
  timestamp: 1563446132
  timesteps_since_restore: 1432431
  timesteps_this_iter: 27027
  timesteps_total: 1432431
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 9.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2063 s, 53 iter, 1432431 ts, 4.35 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-36-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.339999791234732
  episode_reward_mean: 4.629499896522612
  episode_reward_min: 1.9899999555200338
  episodes_this_iter: 27
  episodes_total: 1458
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4779.152
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.896878242492676
        kl: 0.015748778358101845
        policy_loss: -0.0493905283510685
        total_loss: 0.06296892464160919
        vf_explained_var: 0.5080562233924866
        vf_loss: 0.10842227935791016
    load_time_ms: 2.701
    num_steps_sampled: 1459458
    num_steps_trained: 1458000
    sample_time_ms: 34860.393
    update_time_ms: 2.393
  iterations_since_restore: 54
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6754135029093415
    mean_inference_ms: 0.7309790685657389
    mean_processing_ms: 0.2266714410238116
  time_since_restore: 2110.4723608493805
  time_this_iter_s: 47.303741216659546
  time_total_s: 2110.4723608493805
  timestamp: 1563446180
  timesteps_since_restore: 1459458
  timesteps_this_iter: 27027
  timesteps_total: 1459458
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2110 s, 54 iter, 1459458 ts, 4.63 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-36-59
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.339999791234732
  episode_reward_mean: 4.643099896218628
  episode_reward_min: 1.839999958872795
  episodes_this_iter: 27
  episodes_total: 1485
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4738.423
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.874493598937988
        kl: 0.0162173043936491
        policy_loss: -0.05146682634949684
        total_loss: 0.04759851098060608
        vf_explained_var: 0.6066933274269104
        vf_loss: 0.09501100331544876
    load_time_ms: 2.727
    num_steps_sampled: 1486485
    num_steps_trained: 1485000
    sample_time_ms: 35093.35
    update_time_ms: 2.445
  iterations_since_restore: 55
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6789196075496955
    mean_inference_ms: 0.7320254039066336
    mean_processing_ms: 0.226916869218774
  time_since_restore: 2149.4602041244507
  time_this_iter_s: 38.98784327507019
  time_total_s: 2149.4602041244507
  timestamp: 1563446219
  timesteps_since_restore: 1486485
  timesteps_this_iter: 27027
  timesteps_total: 1486485
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2149 s, 55 iter, 1486485 ts, 4.64 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-37-41
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.339999791234732
  episode_reward_mean: 4.673599895536899
  episode_reward_min: 0.669999985024333
  episodes_this_iter: 27
  episodes_total: 1512
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4715.591
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.850678443908691
        kl: 0.01718744821846485
        policy_loss: -0.053664304316043854
        total_loss: 0.0655607134103775
        vf_explained_var: 0.5696839690208435
        vf_loss: 0.11492814868688583
    load_time_ms: 2.751
    num_steps_sampled: 1513512
    num_steps_trained: 1512000
    sample_time_ms: 35362.056
    update_time_ms: 2.494
  iterations_since_restore: 56
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.683577001648971
    mean_inference_ms: 0.733393936027752
    mean_processing_ms: 0.22723527208640473
  time_since_restore: 2192.122932910919
  time_this_iter_s: 42.662728786468506
  time_total_s: 2192.122932910919
  timestamp: 1563446261
  timesteps_since_restore: 1513512
  timesteps_this_iter: 27027
  timesteps_total: 1513512
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2192 s, 56 iter, 1513512 ts, 4.67 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-38-23
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.339999791234732
  episode_reward_mean: 4.740099894050509
  episode_reward_min: 0.669999985024333
  episodes_this_iter: 27
  episodes_total: 1539
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5138.839
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.833902835845947
        kl: 0.015475631691515446
        policy_loss: -0.05099445953965187
        total_loss: 0.05486271157860756
        vf_explained_var: 0.588084876537323
        vf_loss: 0.10198826342821121
    load_time_ms: 2.745
    num_steps_sampled: 1540539
    num_steps_trained: 1539000
    sample_time_ms: 35244.193
    update_time_ms: 2.489
  iterations_since_restore: 57
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.686823859188108
    mean_inference_ms: 0.7343983396340933
    mean_processing_ms: 0.22747562014068518
  time_since_restore: 2234.020243167877
  time_this_iter_s: 41.89731025695801
  time_total_s: 2234.020243167877
  timestamp: 1563446303
  timesteps_since_restore: 1540539
  timesteps_this_iter: 27027
  timesteps_total: 1540539
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2234 s, 57 iter, 1540539 ts, 4.74 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-39-03
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.779999803751707
  episode_reward_mean: 4.7719998933374885
  episode_reward_min: 0.669999985024333
  episodes_this_iter: 27
  episodes_total: 1566
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5110.274
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.818191051483154
        kl: 0.015688855201005936
        policy_loss: -0.051099419593811035
        total_loss: 0.07466444373130798
        vf_explained_var: 0.5633448958396912
        vf_loss: 0.12184165418148041
    load_time_ms: 2.756
    num_steps_sampled: 1567566
    num_steps_trained: 1566000
    sample_time_ms: 35043.137
    update_time_ms: 2.468
  iterations_since_restore: 58
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6880355613036397
    mean_inference_ms: 0.7347389461862798
    mean_processing_ms: 0.22756554286993358
  time_since_restore: 2273.4137423038483
  time_this_iter_s: 39.39349913597107
  time_total_s: 2273.4137423038483
  timestamp: 1563446343
  timesteps_since_restore: 1567566
  timesteps_this_iter: 27027
  timesteps_total: 1567566
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2273 s, 58 iter, 1567566 ts, 4.77 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-39-39
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.799999803304672
  episode_reward_mean: 4.9632998890616
  episode_reward_min: 0.669999985024333
  episodes_this_iter: 27
  episodes_total: 1593
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5148.395
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.801193714141846
        kl: 0.016867419704794884
        policy_loss: -0.05514004826545715
        total_loss: 0.0811016857624054
        vf_explained_var: 0.5745152235031128
        vf_loss: 0.1320248693227768
    load_time_ms: 2.764
    num_steps_sampled: 1594593
    num_steps_trained: 1593000
    sample_time_ms: 34916.222
    update_time_ms: 2.486
  iterations_since_restore: 59
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6878245594502825
    mean_inference_ms: 0.734729972817068
    mean_processing_ms: 0.22753239000814557
  time_since_restore: 2309.6737127304077
  time_this_iter_s: 36.25997042655945
  time_total_s: 2309.6737127304077
  timestamp: 1563446379
  timesteps_since_restore: 1594593
  timesteps_this_iter: 27027
  timesteps_total: 1594593
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2309 s, 59 iter, 1594593 ts, 4.96 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-40-22
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.799999803304672
  episode_reward_mean: 4.999399888254702
  episode_reward_min: 1.0499999765306711
  episodes_this_iter: 27
  episodes_total: 1620
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5487.048
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.775688648223877
        kl: 0.017608966678380966
        policy_loss: -0.056583255529403687
        total_loss: 0.05572578310966492
        vf_explained_var: 0.5894882678985596
        vf_loss: 0.10790678858757019
    load_time_ms: 3.032
    num_steps_sampled: 1621620
    num_steps_trained: 1620000
    sample_time_ms: 35046.314
    update_time_ms: 2.455
  iterations_since_restore: 60
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6869562862573537
    mean_inference_ms: 0.7345819753389979
    mean_processing_ms: 0.2275549238641962
  time_since_restore: 2353.035631418228
  time_this_iter_s: 43.361918687820435
  time_total_s: 2353.035631418228
  timestamp: 1563446422
  timesteps_since_restore: 1621620
  timesteps_this_iter: 27027
  timesteps_total: 1621620
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2353 s, 60 iter, 1621620 ts, 5 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-41-02
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.799999803304672
  episode_reward_mean: 4.969299888927489
  episode_reward_min: 1.0499999765306711
  episodes_this_iter: 27
  episodes_total: 1647
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5466.695
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.764251232147217
        kl: 0.01632104627788067
        policy_loss: -0.05531105026602745
        total_loss: 0.037787146866321564
        vf_explained_var: 0.5974781513214111
        vf_loss: 0.08901793509721756
    load_time_ms: 3.051
    num_steps_sampled: 1648647
    num_steps_trained: 1647000
    sample_time_ms: 35254.351
    update_time_ms: 2.466
  iterations_since_restore: 61
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.686649551150676
    mean_inference_ms: 0.7345277817875587
    mean_processing_ms: 0.22758591353845736
  time_since_restore: 2392.846792459488
  time_this_iter_s: 39.811161041259766
  time_total_s: 2392.846792459488
  timestamp: 1563446462
  timesteps_since_restore: 1648647
  timesteps_this_iter: 27027
  timesteps_total: 1648647
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2392 s, 61 iter, 1648647 ts, 4.97 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-41-42
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.799999803304672
  episode_reward_mean: 4.9303998897969725
  episode_reward_min: 1.0499999765306711
  episodes_this_iter: 27
  episodes_total: 1674
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5490.648
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.745683670043945
        kl: 0.01722843386232853
        policy_loss: -0.054051775485277176
        total_loss: 0.0463198721408844
        vf_explained_var: 0.4693089723587036
        vf_loss: 0.09606453031301498
    load_time_ms: 3.054
    num_steps_sampled: 1675674
    num_steps_trained: 1674000
    sample_time_ms: 35246.085
    update_time_ms: 2.419
  iterations_since_restore: 62
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.686748219745941
    mean_inference_ms: 0.73456780798997
    mean_processing_ms: 0.22764057591477943
  time_since_restore: 2432.559129714966
  time_this_iter_s: 39.712337255477905
  time_total_s: 2432.559129714966
  timestamp: 1563446502
  timesteps_since_restore: 1675674
  timesteps_this_iter: 27027
  timesteps_total: 1675674
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2432 s, 62 iter, 1675674 ts, 4.93 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-42-18
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.449999811127782
  episode_reward_mean: 4.999499888252467
  episode_reward_min: 1.0499999765306711
  episodes_this_iter: 27
  episodes_total: 1701
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5506.406
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.730689525604248
        kl: 0.016656281426548958
        policy_loss: -0.05532524362206459
        total_loss: 0.0499429889023304
        vf_explained_var: 0.5737778544425964
        vf_loss: 0.10110414773225784
    load_time_ms: 3.029
    num_steps_sampled: 1702701
    num_steps_trained: 1701000
    sample_time_ms: 34999.243
    update_time_ms: 2.407
  iterations_since_restore: 63
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6865055848300448
    mean_inference_ms: 0.7344767503743028
    mean_processing_ms: 0.22764780348903854
  time_since_restore: 2469.01699924469
  time_this_iter_s: 36.45786952972412
  time_total_s: 2469.01699924469
  timestamp: 1563446538
  timesteps_since_restore: 1702701
  timesteps_this_iter: 27027
  timesteps_total: 1702701
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2469 s, 63 iter, 1702701 ts, 5 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-42-56
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 8.769999803975224
  episode_reward_mean: 5.0997998860105875
  episode_reward_min: 1.4799999669194221
  episodes_this_iter: 27
  episodes_total: 1728
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5443.774
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.708582401275635
        kl: 0.018207576125860214
        policy_loss: -0.05743424966931343
        total_loss: 0.06201251968741417
        vf_explained_var: 0.513451337814331
        vf_loss: 0.11489488184452057
    load_time_ms: 3.016
    num_steps_sampled: 1729728
    num_steps_trained: 1728000
    sample_time_ms: 34089.44
    update_time_ms: 2.245
  iterations_since_restore: 64
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6857450090347497
    mean_inference_ms: 0.734165313880706
    mean_processing_ms: 0.22755629746564338
  time_since_restore: 2506.5897002220154
  time_this_iter_s: 37.57270097732544
  time_total_s: 2506.5897002220154
  timestamp: 1563446576
  timesteps_since_restore: 1729728
  timesteps_this_iter: 27027
  timesteps_total: 1729728
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2506 s, 64 iter, 1729728 ts, 5.1 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-43-32
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.589999785646796
  episode_reward_mean: 5.321399881057442
  episode_reward_min: 1.1999999731779099
  episodes_this_iter: 27
  episodes_total: 1755
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5408.468
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.68865966796875
        kl: 0.017378443852066994
        policy_loss: -0.05560135096311569
        total_loss: 0.05493798479437828
        vf_explained_var: 0.5617561340332031
        vf_loss: 0.10619472712278366
    load_time_ms: 3.005
    num_steps_sampled: 1756755
    num_steps_trained: 1755000
    sample_time_ms: 33821.335
    update_time_ms: 2.205
  iterations_since_restore: 65
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.683913417723773
    mean_inference_ms: 0.7336168830467276
    mean_processing_ms: 0.22739858498549445
  time_since_restore: 2542.5424585342407
  time_this_iter_s: 35.95275831222534
  time_total_s: 2542.5424585342407
  timestamp: 1563446612
  timesteps_since_restore: 1756755
  timesteps_this_iter: 27027
  timesteps_total: 1756755
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2542 s, 65 iter, 1756755 ts, 5.32 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-44-09
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.589999785646796
  episode_reward_mean: 5.371099879946559
  episode_reward_min: 1.1999999731779099
  episodes_this_iter: 27
  episodes_total: 1782
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5393.288
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.66687536239624
        kl: 0.01819915883243084
        policy_loss: -0.058227378875017166
        total_loss: 0.06211399659514427
        vf_explained_var: 0.544623851776123
        vf_loss: 0.11579160392284393
    load_time_ms: 3.025
    num_steps_sampled: 1783782
    num_steps_trained: 1782000
    sample_time_ms: 33297.735
    update_time_ms: 2.178
  iterations_since_restore: 66
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6816211186143515
    mean_inference_ms: 0.7329596621064419
    mean_processing_ms: 0.2272137276442098
  time_since_restore: 2579.8122251033783
  time_this_iter_s: 37.26976656913757
  time_total_s: 2579.8122251033783
  timestamp: 1563446649
  timesteps_since_restore: 1783782
  timesteps_this_iter: 27027
  timesteps_total: 1783782
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2579 s, 66 iter, 1783782 ts, 5.37 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-44-50
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.589999785646796
  episode_reward_mean: 5.590699875038117
  episode_reward_min: 1.1999999731779099
  episodes_this_iter: 27
  episodes_total: 1809
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5061.932
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.648894309997559
        kl: 0.018367422744631767
        policy_loss: -0.05703234672546387
        total_loss: 0.09529726952314377
        vf_explained_var: 0.4634580910205841
        vf_loss: 0.14773774147033691
    load_time_ms: 3.129
    num_steps_sampled: 1810809
    num_steps_trained: 1809000
    sample_time_ms: 33518.512
    update_time_ms: 2.189
  iterations_since_restore: 67
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.680407767856175
    mean_inference_ms: 0.7325764812603053
    mean_processing_ms: 0.22711933587972016
  time_since_restore: 2620.6120657920837
  time_this_iter_s: 40.799840688705444
  time_total_s: 2620.6120657920837
  timestamp: 1563446690
  timesteps_since_restore: 1810809
  timesteps_this_iter: 27027
  timesteps_total: 1810809
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2620 s, 67 iter, 1810809 ts, 5.59 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-45-30
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 10.33999976888299
  episode_reward_mean: 5.8499998692423105
  episode_reward_min: 2.2199999503791332
  episodes_this_iter: 27
  episodes_total: 1836
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5056.923
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.6305365562438965
        kl: 0.018457023426890373
        policy_loss: -0.058520108461380005
        total_loss: 0.1017073467373848
        vf_explained_var: 0.4878685176372528
        vf_loss: 0.15561316907405853
    load_time_ms: 3.146
    num_steps_sampled: 1837836
    num_steps_trained: 1836000
    sample_time_ms: 33639.175
    update_time_ms: 2.203
  iterations_since_restore: 68
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6802465935708084
    mean_inference_ms: 0.7324550334147695
    mean_processing_ms: 0.22710244481883213
  time_since_restore: 2661.166315317154
  time_this_iter_s: 40.55424952507019
  time_total_s: 2661.166315317154
  timestamp: 1563446730
  timesteps_since_restore: 1837836
  timesteps_this_iter: 27027
  timesteps_total: 1837836
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2661 s, 68 iter, 1837836 ts, 5.85 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-46-10
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 10.33999976888299
  episode_reward_mean: 5.687599872872234
  episode_reward_min: 1.7999999597668648
  episodes_this_iter: 27
  episodes_total: 1863
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 5068.7
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.614830493927002
        kl: 0.018047641962766647
        policy_loss: -0.05880379676818848
        total_loss: 0.09317399561405182
        vf_explained_var: 0.4775000810623169
        vf_loss: 0.14746588468551636
    load_time_ms: 3.122
    num_steps_sampled: 1864863
    num_steps_trained: 1863000
    sample_time_ms: 33940.322
    update_time_ms: 2.173
  iterations_since_restore: 69
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.680994358733322
    mean_inference_ms: 0.7325543109403828
    mean_processing_ms: 0.227151865436522
  time_since_restore: 2700.5599024295807
  time_this_iter_s: 39.39358711242676
  time_total_s: 2700.5599024295807
  timestamp: 1563446770
  timesteps_since_restore: 1864863
  timesteps_this_iter: 27027
  timesteps_total: 1864863
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2700 s, 69 iter, 1864863 ts, 5.69 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-46-48
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 10.33999976888299
  episode_reward_mean: 5.708899872396142
  episode_reward_min: 1.7999999597668648
  episodes_this_iter: 27
  episodes_total: 1890
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4691.236
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.592517375946045
        kl: 0.018195129930973053
        policy_loss: -0.05554001033306122
        total_loss: 0.09044316411018372
        vf_explained_var: 0.4884026348590851
        vf_loss: 0.14143437147140503
    load_time_ms: 2.839
    num_steps_sampled: 1891890
    num_steps_trained: 1890000
    sample_time_ms: 33828.849
    update_time_ms: 2.192
  iterations_since_restore: 70
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6820402625969733
    mean_inference_ms: 0.7327301634493739
    mean_processing_ms: 0.22721999307706142
  time_since_restore: 2739.0186541080475
  time_this_iter_s: 38.4587516784668
  time_total_s: 2739.0186541080475
  timestamp: 1563446808
  timesteps_since_restore: 1891890
  timesteps_this_iter: 27027
  timesteps_total: 1891890
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2739 s, 70 iter, 1891890 ts, 5.71 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-47-25
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 9.749999782070518
  episode_reward_mean: 5.723199872076512
  episode_reward_min: 0.979999978095293
  episodes_this_iter: 27
  episodes_total: 1917
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4654.154
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.573833465576172
        kl: 0.018680928274989128
        policy_loss: -0.05949883535504341
        total_loss: 0.09831326454877853
        vf_explained_var: 0.5808736681938171
        vf_loss: 0.15314187109470367
    load_time_ms: 2.837
    num_steps_sampled: 1918917
    num_steps_trained: 1917000
    sample_time_ms: 33531.263
    update_time_ms: 2.17
  iterations_since_restore: 71
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.681957706658241
    mean_inference_ms: 0.7326270906469153
    mean_processing_ms: 0.2271882959784672
  time_since_restore: 2775.4849729537964
  time_this_iter_s: 36.4663188457489
  time_total_s: 2775.4849729537964
  timestamp: 1563446845
  timesteps_since_restore: 1918917
  timesteps_this_iter: 27027
  timesteps_total: 1918917
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2775 s, 71 iter, 1918917 ts, 5.72 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-48-03
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.049999753013253
  episode_reward_mean: 5.871699868757278
  episode_reward_min: 0.979999978095293
  episodes_this_iter: 27
  episodes_total: 1944
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4604.743
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.560094833374023
        kl: 0.01898735947906971
        policy_loss: -0.05996420979499817
        total_loss: 0.08991821855306625
        vf_explained_var: 0.5439068675041199
        vf_loss: 0.14513558149337769
    load_time_ms: 2.867
    num_steps_sampled: 1945944
    num_steps_trained: 1944000
    sample_time_ms: 33422.006
    update_time_ms: 2.17
  iterations_since_restore: 72
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.681298185079598
    mean_inference_ms: 0.7323705999298847
    mean_processing_ms: 0.22711825115280596
  time_since_restore: 2813.6063828468323
  time_this_iter_s: 38.12140989303589
  time_total_s: 2813.6063828468323
  timestamp: 1563446883
  timesteps_since_restore: 1945944
  timesteps_this_iter: 27027
  timesteps_total: 1945944
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2813 s, 72 iter, 1945944 ts, 5.87 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-48-39
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.049999753013253
  episode_reward_mean: 5.9870998661778865
  episode_reward_min: 0.979999978095293
  episodes_this_iter: 27
  episodes_total: 1971
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4620.769
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.5439066886901855
        kl: 0.018592199310660362
        policy_loss: -0.05948914960026741
        total_loss: 0.09330468624830246
        vf_explained_var: 0.5500728487968445
        vf_loss: 0.14814579486846924
    load_time_ms: 2.867
    num_steps_sampled: 1972971
    num_steps_trained: 1971000
    sample_time_ms: 33399.018
    update_time_ms: 2.186
  iterations_since_restore: 73
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6796715211966444
    mean_inference_ms: 0.7318861753853113
    mean_processing_ms: 0.22696160047997382
  time_since_restore: 2850.00027179718
  time_this_iter_s: 36.3938889503479
  time_total_s: 2850.00027179718
  timestamp: 1563446919
  timesteps_since_restore: 1972971
  timesteps_this_iter: 27027
  timesteps_total: 1972971
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2850 s, 73 iter, 1972971 ts, 5.99 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-49-17
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.049999753013253
  episode_reward_mean: 6.2641998599842195
  episode_reward_min: 0.979999978095293
  episodes_this_iter: 27
  episodes_total: 1998
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4700.476
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.527340888977051
        kl: 0.018436256796121597
        policy_loss: -0.05637910217046738
        total_loss: 0.13344477117061615
        vf_explained_var: 0.43915557861328125
        vf_loss: 0.1852148175239563
    load_time_ms: 2.883
    num_steps_sampled: 1999998
    num_steps_trained: 1998000
    sample_time_ms: 33344.971
    update_time_ms: 2.173
  iterations_since_restore: 74
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6778776050041944
    mean_inference_ms: 0.7313744973609673
    mean_processing_ms: 0.2267911525972939
  time_since_restore: 2887.8298959732056
  time_this_iter_s: 37.82962417602539
  time_total_s: 2887.8298959732056
  timestamp: 1563446957
  timesteps_since_restore: 1999998
  timesteps_this_iter: 27027
  timesteps_total: 1999998
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2887 s, 74 iter, 1999998 ts, 6.26 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-49-57
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.049999753013253
  episode_reward_mean: 6.361099857818335
  episode_reward_min: 2.249999949708581
  episodes_this_iter: 27
  episodes_total: 2025
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4771.347
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 4.496631145477295
        kl: 0.020258881151676178
        policy_loss: -0.05923078954219818
        total_loss: 0.11184142529964447
        vf_explained_var: 0.583514392375946
        vf_loss: 0.16600750386714935
    load_time_ms: 2.891
    num_steps_sampled: 2027025
    num_steps_trained: 2025000
    sample_time_ms: 33622.99
    update_time_ms: 2.192
  iterations_since_restore: 75
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6768043245716546
    mean_inference_ms: 0.7310560856407201
    mean_processing_ms: 0.22668362956031735
  time_since_restore: 2927.2804293632507
  time_this_iter_s: 39.450533390045166
  time_total_s: 2927.2804293632507
  timestamp: 1563446997
  timesteps_since_restore: 2027025
  timesteps_this_iter: 27027
  timesteps_total: 2027025
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2927 s, 75 iter, 2027025 ts, 6.36 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-50-34
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 10.199999772012234
  episode_reward_mean: 6.41859985653311
  episode_reward_min: 2.249999949708581
  episodes_this_iter: 27
  episodes_total: 2052
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4784.584
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.484067916870117
        kl: 0.017309343442320824
        policy_loss: -0.05939438194036484
        total_loss: 0.07897985726594925
        vf_explained_var: 0.5200784206390381
        vf_loss: 0.13188321888446808
    load_time_ms: 2.868
    num_steps_sampled: 2054052
    num_steps_trained: 2052000
    sample_time_ms: 33644.387
    update_time_ms: 2.172
  iterations_since_restore: 76
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6756897366617194
    mean_inference_ms: 0.7307496261904075
    mean_processing_ms: 0.22656492046151275
  time_since_restore: 2964.901981830597
  time_this_iter_s: 37.62155246734619
  time_total_s: 2964.901981830597
  timestamp: 1563447034
  timesteps_since_restore: 2054052
  timesteps_this_iter: 27027
  timesteps_total: 2054052
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 2964 s, 76 iter, 2054052 ts, 6.42 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-51-10
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.289999747648835
  episode_reward_mean: 6.552699853535741
  episode_reward_min: 2.249999949708581
  episodes_this_iter: 27
  episodes_total: 2079
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4673.053
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.467493057250977
        kl: 0.017342858016490936
        policy_loss: -0.06056656688451767
        total_loss: 0.09389737248420715
        vf_explained_var: 0.5660880208015442
        vf_loss: 0.147960364818573
    load_time_ms: 2.768
    num_steps_sampled: 2081079
    num_steps_trained: 2079000
    sample_time_ms: 33296.468
    update_time_ms: 2.192
  iterations_since_restore: 77
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6746095032395956
    mean_inference_ms: 0.7304656481313277
    mean_processing_ms: 0.22645756872232517
  time_since_restore: 3001.1063520908356
  time_this_iter_s: 36.20437026023865
  time_total_s: 3001.1063520908356
  timestamp: 1563447070
  timesteps_since_restore: 2081079
  timesteps_this_iter: 27027
  timesteps_total: 2081079
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3001 s, 77 iter, 2081079 ts, 6.55 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-51-49
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.289999747648835
  episode_reward_mean: 6.6502998513542115
  episode_reward_min: 3.399999924004078
  episodes_this_iter: 27
  episodes_total: 2106
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4721.491
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.451237201690674
        kl: 0.01670890301465988
        policy_loss: -0.05604887008666992
        total_loss: 0.12061619013547897
        vf_explained_var: 0.536091148853302
        vf_loss: 0.17039918899536133
    load_time_ms: 2.771
    num_steps_sampled: 2108106
    num_steps_trained: 2106000
    sample_time_ms: 33088.453
    update_time_ms: 2.158
  iterations_since_restore: 78
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.673748329129079
    mean_inference_ms: 0.7302181389334776
    mean_processing_ms: 0.22636622634247502
  time_since_restore: 3040.064694404602
  time_this_iter_s: 38.95834231376648
  time_total_s: 3040.064694404602
  timestamp: 1563447109
  timesteps_since_restore: 2108106
  timesteps_this_iter: 27027
  timesteps_total: 2108106
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3040 s, 78 iter, 2108106 ts, 6.65 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-52-28
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.339999746531248
  episode_reward_mean: 6.753699849043041
  episode_reward_min: 3.609999919310212
  episodes_this_iter: 27
  episodes_total: 2133
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4734.113
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.4374613761901855
        kl: 0.017165744677186012
        policy_loss: -0.05789333954453468
        total_loss: 0.13191772997379303
        vf_explained_var: 0.5293605923652649
        vf_loss: 0.18337389826774597
    load_time_ms: 2.763
    num_steps_sampled: 2135133
    num_steps_trained: 2133000
    sample_time_ms: 32968.351
    update_time_ms: 2.151
  iterations_since_restore: 79
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.672732364657744
    mean_inference_ms: 0.7299135866457657
    mean_processing_ms: 0.2262623601750313
  time_since_restore: 3078.3796186447144
  time_this_iter_s: 38.314924240112305
  time_total_s: 3078.3796186447144
  timestamp: 1563447148
  timesteps_since_restore: 2135133
  timesteps_this_iter: 27027
  timesteps_total: 2135133
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3078 s, 79 iter, 2135133 ts, 6.75 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-53-03
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.339999746531248
  episode_reward_mean: 6.956999844498933
  episode_reward_min: 1.50999996624887
  episodes_this_iter: 27
  episodes_total: 2160
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4736.326
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.417764663696289
        kl: 0.018959475681185722
        policy_loss: -0.06284741312265396
        total_loss: 0.16248829662799835
        vf_explained_var: 0.518482506275177
        vf_loss: 0.2182258814573288
    load_time_ms: 2.765
    num_steps_sampled: 2162160
    num_steps_trained: 2160000
    sample_time_ms: 32677.422
    update_time_ms: 2.116
  iterations_since_restore: 80
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6713729714998458
    mean_inference_ms: 0.7294993727350919
    mean_processing_ms: 0.22613166166214843
  time_since_restore: 3113.944487094879
  time_this_iter_s: 35.564868450164795
  time_total_s: 3113.944487094879
  timestamp: 1563447183
  timesteps_since_restore: 2162160
  timesteps_this_iter: 27027
  timesteps_total: 2162160
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3113 s, 80 iter, 2162160 ts, 6.96 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-53-41
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.339999746531248
  episode_reward_mean: 6.908699845578521
  episode_reward_min: 1.50999996624887
  episodes_this_iter: 27
  episodes_total: 2187
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4785.193
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.408692359924316
        kl: 0.017818041145801544
        policy_loss: -0.05950062349438667
        total_loss: 0.09224556386470795
        vf_explained_var: 0.5980052351951599
        vf_loss: 0.14506441354751587
    load_time_ms: 2.771
    num_steps_sampled: 2189187
    num_steps_trained: 2187000
    sample_time_ms: 32701.763
    update_time_ms: 2.123
  iterations_since_restore: 81
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6699513517335816
    mean_inference_ms: 0.7291009606717117
    mean_processing_ms: 0.22600617787049493
  time_since_restore: 3151.1497564315796
  time_this_iter_s: 37.20526933670044
  time_total_s: 3151.1497564315796
  timestamp: 1563447221
  timesteps_since_restore: 2189187
  timesteps_this_iter: 27027
  timesteps_total: 2189187
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3151 s, 81 iter, 2189187 ts, 6.91 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-54-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 13.0899997074157
  episode_reward_mean: 6.927299845162779
  episode_reward_min: 1.50999996624887
  episodes_this_iter: 27
  episodes_total: 2214
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4794.326
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.390074253082275
        kl: 0.017884984612464905
        policy_loss: -0.05853763222694397
        total_loss: 0.12488366663455963
        vf_explained_var: 0.6026845574378967
        vf_loss: 0.17671442031860352
    load_time_ms: 2.766
    num_steps_sampled: 2216214
    num_steps_trained: 2214000
    sample_time_ms: 32864.048
    update_time_ms: 2.164
  iterations_since_restore: 82
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.668909932521156
    mean_inference_ms: 0.7288094768551789
    mean_processing_ms: 0.2259306048930641
  time_since_restore: 3190.9883420467377
  time_this_iter_s: 39.83858561515808
  time_total_s: 3190.9883420467377
  timestamp: 1563447260
  timesteps_since_restore: 2216214
  timesteps_this_iter: 27027
  timesteps_total: 2216214
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3190 s, 82 iter, 2216214 ts, 6.93 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-55-00
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 13.0899997074157
  episode_reward_mean: 6.954299844559282
  episode_reward_min: 3.009999932721257
  episodes_this_iter: 27
  episodes_total: 2241
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4753.414
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.37078332901001
        kl: 0.018181560561060905
        policy_loss: -0.05953983590006828
        total_loss: 0.09820910543203354
        vf_explained_var: 0.5994002819061279
        vf_loss: 0.15093085169792175
    load_time_ms: 2.74
    num_steps_sampled: 2243241
    num_steps_trained: 2241000
    sample_time_ms: 33195.89
    update_time_ms: 2.172
  iterations_since_restore: 83
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6683965575306003
    mean_inference_ms: 0.72863642055577
    mean_processing_ms: 0.22589185502337095
  time_since_restore: 3230.29013133049
  time_this_iter_s: 39.30178928375244
  time_total_s: 3230.29013133049
  timestamp: 1563447300
  timesteps_since_restore: 2243241
  timesteps_this_iter: 27027
  timesteps_total: 2243241
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3230 s, 83 iter, 2243241 ts, 6.95 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-55-39
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 13.0899997074157
  episode_reward_mean: 7.326999836228788
  episode_reward_min: 3.009999932721257
  episodes_this_iter: 27
  episodes_total: 2268
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4767.001
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.358067035675049
        kl: 0.0180205125361681
        policy_loss: -0.060792844742536545
        total_loss: 0.14687974750995636
        vf_explained_var: 0.5001847147941589
        vf_loss: 0.2009148895740509
    load_time_ms: 2.715
    num_steps_sampled: 2270268
    num_steps_trained: 2268000
    sample_time_ms: 33362.791
    update_time_ms: 2.16
  iterations_since_restore: 84
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.668737379634619
    mean_inference_ms: 0.7286443101361009
    mean_processing_ms: 0.22591426435675402
  time_since_restore: 3269.9343576431274
  time_this_iter_s: 39.64422631263733
  time_total_s: 3269.9343576431274
  timestamp: 1563447339
  timesteps_since_restore: 2270268
  timesteps_this_iter: 27027
  timesteps_total: 2270268
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3269 s, 84 iter, 2270268 ts, 7.33 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-56-16
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 13.0899997074157
  episode_reward_mean: 7.507599832192064
  episode_reward_min: 2.5699999425560236
  episodes_this_iter: 27
  episodes_total: 2295
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4703.568
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.3412017822265625
        kl: 0.01863953098654747
        policy_loss: -0.060464952141046524
        total_loss: 0.1593354493379593
        vf_explained_var: 0.551298201084137
        vf_loss: 0.21281054615974426
    load_time_ms: 2.738
    num_steps_sampled: 2297295
    num_steps_trained: 2295000
    sample_time_ms: 33156.289
    update_time_ms: 2.153
  iterations_since_restore: 85
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6689743219910986
    mean_inference_ms: 0.7286096790881551
    mean_processing_ms: 0.22591934157936402
  time_since_restore: 3306.6789395809174
  time_this_iter_s: 36.74458193778992
  time_total_s: 3306.6789395809174
  timestamp: 1563447376
  timesteps_since_restore: 2297295
  timesteps_this_iter: 27027
  timesteps_total: 2297295
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3306 s, 85 iter, 2297295 ts, 7.51 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-56-53
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.589999740943313
  episode_reward_mean: 7.5204998319037255
  episode_reward_min: 2.5699999425560236
  episodes_this_iter: 27
  episodes_total: 2322
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4672.255
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.325239181518555
        kl: 0.018866799771785736
        policy_loss: -0.06386733055114746
        total_loss: 0.15478622913360596
        vf_explained_var: 0.4656997621059418
        vf_loss: 0.21157853305339813
    load_time_ms: 2.732
    num_steps_sampled: 2324322
    num_steps_trained: 2322000
    sample_time_ms: 33069.642
    update_time_ms: 2.198
  iterations_since_restore: 86
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.668387771873378
    mean_inference_ms: 0.7283892193562201
    mean_processing_ms: 0.22585740975026664
  time_since_restore: 3343.1114954948425
  time_this_iter_s: 36.43255591392517
  time_total_s: 3343.1114954948425
  timestamp: 1563447413
  timesteps_since_restore: 2324322
  timesteps_this_iter: 27027
  timesteps_total: 2324322
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3343 s, 86 iter, 2324322 ts, 7.52 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-57-30
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.589999740943313
  episode_reward_mean: 7.502199832312763
  episode_reward_min: 1.4299999680370092
  episodes_this_iter: 27
  episodes_total: 2349
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4717.484
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.314436912536621
        kl: 0.019212396815419197
        policy_loss: -0.06253758817911148
        total_loss: 0.1722070723772049
        vf_explained_var: 0.5215675830841064
        vf_loss: 0.2275400012731552
    load_time_ms: 2.728
    num_steps_sampled: 2351349
    num_steps_trained: 2349000
    sample_time_ms: 33112.99
    update_time_ms: 2.174
  iterations_since_restore: 87
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.667189683440149
    mean_inference_ms: 0.7280417168535478
    mean_processing_ms: 0.2257553124786838
  time_since_restore: 3380.2000362873077
  time_this_iter_s: 37.08854079246521
  time_total_s: 3380.2000362873077
  timestamp: 1563447450
  timesteps_since_restore: 2351349
  timesteps_this_iter: 27027
  timesteps_total: 2351349
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3380 s, 87 iter, 2351349 ts, 7.5 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-58-08
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.589999740943313
  episode_reward_mean: 7.359299835506826
  episode_reward_min: 1.4299999680370092
  episodes_this_iter: 27
  episodes_total: 2376
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4716.33
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.297190189361572
        kl: 0.01752021163702011
        policy_loss: -0.060547735542058945
        total_loss: 0.11420363187789917
        vf_explained_var: 0.5320843458175659
        vf_loss: 0.16818131506443024
    load_time_ms: 2.709
    num_steps_sampled: 2378376
    num_steps_trained: 2376000
    sample_time_ms: 33017.358
    update_time_ms: 2.198
  iterations_since_restore: 88
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6657641480000827
    mean_inference_ms: 0.7276609609802801
    mean_processing_ms: 0.22563615438487938
  time_since_restore: 3418.1955807209015
  time_this_iter_s: 37.99554443359375
  time_total_s: 3418.1955807209015
  timestamp: 1563447488
  timesteps_since_restore: 2378376
  timesteps_this_iter: 27027
  timesteps_total: 2378376
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3418 s, 88 iter, 2378376 ts, 7.36 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-58-48
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.799999736249447
  episode_reward_mean: 7.4896998325921595
  episode_reward_min: 1.4299999680370092
  episodes_this_iter: 27
  episodes_total: 2403
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4703.643
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.284256458282471
        kl: 0.01852486841380596
        policy_loss: -0.059001121670007706
        total_loss: 0.17698322236537933
        vf_explained_var: 0.4447164833545685
        vf_loss: 0.22903753817081451
    load_time_ms: 2.706
    num_steps_sampled: 2405403
    num_steps_trained: 2403000
    sample_time_ms: 33228.713
    update_time_ms: 2.224
  iterations_since_restore: 89
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6651963734076873
    mean_inference_ms: 0.727488168666241
    mean_processing_ms: 0.22558289828781086
  time_since_restore: 3458.499721288681
  time_this_iter_s: 40.30414056777954
  time_total_s: 3458.499721288681
  timestamp: 1563447528
  timesteps_since_restore: 2405403
  timesteps_this_iter: 27027
  timesteps_total: 2405403
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3458 s, 89 iter, 2405403 ts, 7.49 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_12-59-28
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.799999736249447
  episode_reward_mean: 7.537499831523746
  episode_reward_min: 2.9099999349564314
  episodes_this_iter: 27
  episodes_total: 2430
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4726.187
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.272042274475098
        kl: 0.019609633833169937
        policy_loss: -0.06450959295034409
        total_loss: 0.1244334727525711
        vf_explained_var: 0.5248337388038635
        vf_loss: 0.18158943951129913
    load_time_ms: 2.704
    num_steps_sampled: 2432430
    num_steps_trained: 2430000
    sample_time_ms: 33632.324
    update_time_ms: 2.227
  iterations_since_restore: 90
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6654493212153367
    mean_inference_ms: 0.7275274882473852
    mean_processing_ms: 0.22558294757671754
  time_since_restore: 3498.326227903366
  time_this_iter_s: 39.82650661468506
  time_total_s: 3498.326227903366
  timestamp: 1563447568
  timesteps_since_restore: 2432430
  timesteps_this_iter: 27027
  timesteps_total: 2432430
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3498 s, 90 iter, 2432430 ts, 7.54 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-00-07
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.799999736249447
  episode_reward_mean: 7.4663998331129555
  episode_reward_min: 2.9099999349564314
  episodes_this_iter: 27
  episodes_total: 2457
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4680.502
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.258752346038818
        kl: 0.019123198464512825
        policy_loss: -0.059175293892621994
        total_loss: 0.1359240710735321
        vf_explained_var: 0.5214139819145203
        vf_loss: 0.18792816996574402
    load_time_ms: 2.705
    num_steps_sampled: 2459457
    num_steps_trained: 2457000
    sample_time_ms: 33843.475
    update_time_ms: 2.251
  iterations_since_restore: 91
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6662287405713085
    mean_inference_ms: 0.7276806999257834
    mean_processing_ms: 0.22560476664868304
  time_since_restore: 3537.1795365810394
  time_this_iter_s: 38.85330867767334
  time_total_s: 3537.1795365810394
  timestamp: 1563447607
  timesteps_since_restore: 2459457
  timesteps_this_iter: 27027
  timesteps_total: 2459457
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3537 s, 91 iter, 2459457 ts, 7.47 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-00-46
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.88999962247908
  episode_reward_mean: 7.884499823767692
  episode_reward_min: 2.9099999349564314
  episodes_this_iter: 27
  episodes_total: 2484
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4692.29
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.244449615478516
        kl: 0.018152104690670967
        policy_loss: -0.05236406624317169
        total_loss: 0.18927280604839325
        vf_explained_var: 0.728210985660553
        vf_loss: 0.2348298281431198
    load_time_ms: 2.665
    num_steps_sampled: 2486484
    num_steps_trained: 2484000
    sample_time_ms: 33801.386
    update_time_ms: 2.198
  iterations_since_restore: 92
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6672916160864912
    mean_inference_ms: 0.7278890733509514
    mean_processing_ms: 0.2256474104923942
  time_since_restore: 3576.712872028351
  time_this_iter_s: 39.5333354473114
  time_total_s: 3576.712872028351
  timestamp: 1563447646
  timesteps_since_restore: 2486484
  timesteps_this_iter: 27027
  timesteps_total: 2486484
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3576 s, 92 iter, 2486484 ts, 7.88 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-01-24
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.88999962247908
  episode_reward_mean: 7.708099827710539
  episode_reward_min: 2.9099999349564314
  episodes_this_iter: 27
  episodes_total: 2511
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4708.434
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.236333847045898
        kl: 0.019123032689094543
        policy_loss: -0.05848943814635277
        total_loss: 0.16420729458332062
        vf_explained_var: 0.5583453178405762
        vf_loss: 0.21552561223506927
    load_time_ms: 2.669
    num_steps_sampled: 2513511
    num_steps_trained: 2511000
    sample_time_ms: 33651.763
    update_time_ms: 2.208
  iterations_since_restore: 93
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6676792080480096
    mean_inference_ms: 0.727929716599925
    mean_processing_ms: 0.22565402406679946
  time_since_restore: 3614.6750988960266
  time_this_iter_s: 37.96222686767578
  time_total_s: 3614.6750988960266
  timestamp: 1563447684
  timesteps_since_restore: 2513511
  timesteps_this_iter: 27027
  timesteps_total: 2513511
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3614 s, 93 iter, 2513511 ts, 7.71 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-02-02
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.88999962247908
  episode_reward_mean: 7.921799822933972
  episode_reward_min: 3.2899999264627695
  episodes_this_iter: 27
  episodes_total: 2538
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4604.369
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.223326683044434
        kl: 0.01832251064479351
        policy_loss: -0.05663255229592323
        total_loss: 0.18521730601787567
        vf_explained_var: 0.509753406047821
        vf_loss: 0.23497892916202545
    load_time_ms: 2.685
    num_steps_sampled: 2540538
    num_steps_trained: 2538000
    sample_time_ms: 33551.053
    update_time_ms: 2.252
  iterations_since_restore: 94
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6676689132635873
    mean_inference_ms: 0.7278508107841433
    mean_processing_ms: 0.2256338768552407
  time_since_restore: 3652.262542963028
  time_this_iter_s: 37.58744406700134
  time_total_s: 3652.262542963028
  timestamp: 1563447722
  timesteps_since_restore: 2540538
  timesteps_this_iter: 27027
  timesteps_total: 2540538
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3652 s, 94 iter, 2540538 ts, 7.92 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-02-39
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.88999962247908
  episode_reward_mean: 7.974699821751565
  episode_reward_min: 3.2899999264627695
  episodes_this_iter: 27
  episodes_total: 2565
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4653.864
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.202754020690918
        kl: 0.019115500152111053
        policy_loss: -0.06068982928991318
        total_loss: 0.19043280184268951
        vf_explained_var: 0.5173032879829407
        vf_loss: 0.24395431578159332
    load_time_ms: 2.666
    num_steps_sampled: 2567565
    num_steps_trained: 2565000
    sample_time_ms: 33552.516
    update_time_ms: 2.251
  iterations_since_restore: 95
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6671582838686962
    mean_inference_ms: 0.7276838595677788
    mean_processing_ms: 0.22559403339400957
  time_since_restore: 3689.5197274684906
  time_this_iter_s: 37.25718450546265
  time_total_s: 3689.5197274684906
  timestamp: 1563447759
  timesteps_since_restore: 2567565
  timesteps_this_iter: 27027
  timesteps_total: 2567565
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3689 s, 95 iter, 2567565 ts, 7.97 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-03-17
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 14.09999968484044
  episode_reward_mean: 7.809299825448543
  episode_reward_min: 3.2899999264627695
  episodes_this_iter: 27
  episodes_total: 2592
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4698.506
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.18426513671875
        kl: 0.019571982324123383
        policy_loss: -0.06175175681710243
        total_loss: 0.1795462667942047
        vf_explained_var: 0.5479690432548523
        vf_loss: 0.23395851254463196
    load_time_ms: 2.665
    num_steps_sampled: 2594592
    num_steps_trained: 2592000
    sample_time_ms: 33706.774
    update_time_ms: 2.236
  iterations_since_restore: 96
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6664556300039113
    mean_inference_ms: 0.7275003970015195
    mean_processing_ms: 0.22553011772208534
  time_since_restore: 3727.937246322632
  time_this_iter_s: 38.417518854141235
  time_total_s: 3727.937246322632
  timestamp: 1563447797
  timesteps_since_restore: 2594592
  timesteps_this_iter: 27027
  timesteps_total: 2594592
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3727 s, 96 iter, 2594592 ts, 7.81 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-03-57
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 14.09999968484044
  episode_reward_mean: 7.721299827415496
  episode_reward_min: 3.6199999190866947
  episodes_this_iter: 27
  episodes_total: 2619
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4668.043
    learner:
      default_policy:
        cur_kl_coeff: 0.375
        cur_lr: 9.999999747378752e-05
        entropy: 4.170106887817383
        kl: 0.020739570260047913
        policy_loss: -0.06641041487455368
        total_loss: 0.1440923511981964
        vf_explained_var: 0.5597337484359741
        vf_loss: 0.20272541046142578
    load_time_ms: 2.666
    num_steps_sampled: 2621619
    num_steps_trained: 2619000
    sample_time_ms: 33957.8
    update_time_ms: 2.278
  iterations_since_restore: 97
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.666163845030407
    mean_inference_ms: 0.7273984246300578
    mean_processing_ms: 0.2254855521933894
  time_since_restore: 3767.2304122447968
  time_this_iter_s: 39.29316592216492
  time_total_s: 3767.2304122447968
  timestamp: 1563447837
  timesteps_since_restore: 2621619
  timesteps_this_iter: 27027
  timesteps_total: 2621619
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3767 s, 97 iter, 2621619 ts, 7.72 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-04-33
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.989999732002616
  episode_reward_mean: 7.572299830745906
  episode_reward_min: 3.6199999190866947
  episodes_this_iter: 27
  episodes_total: 2646
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4611.864
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.16028356552124
        kl: 0.016795121133327484
        policy_loss: -0.06086720898747444
        total_loss: 0.11787047237157822
        vf_explained_var: 0.5327896475791931
        vf_loss: 0.1692904382944107
    load_time_ms: 2.67
    num_steps_sampled: 2648646
    num_steps_trained: 2646000
    sample_time_ms: 33800.244
    update_time_ms: 2.262
  iterations_since_restore: 98
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.665456097967344
    mean_inference_ms: 0.7272037756828089
    mean_processing_ms: 0.225414776896317
  time_since_restore: 3803.0803101062775
  time_this_iter_s: 35.84989786148071
  time_total_s: 3803.0803101062775
  timestamp: 1563447873
  timesteps_since_restore: 2648646
  timesteps_this_iter: 27027
  timesteps_total: 2648646
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3803 s, 98 iter, 2648646 ts, 7.57 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-05-09
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.989999732002616
  episode_reward_mean: 7.779699826110154
  episode_reward_min: 3.6199999190866947
  episodes_this_iter: 27
  episodes_total: 2673
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4597.899
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.140439033508301
        kl: 0.01640547439455986
        policy_loss: -0.05813392996788025
        total_loss: 0.1534050852060318
        vf_explained_var: 0.6042654514312744
        vf_loss: 0.20231091976165771
    load_time_ms: 2.721
    num_steps_sampled: 2675673
    num_steps_trained: 2673000
    sample_time_ms: 33403.357
    update_time_ms: 2.257
  iterations_since_restore: 99
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6645219838289576
    mean_inference_ms: 0.7269319318681025
    mean_processing_ms: 0.22532377048905694
  time_since_restore: 3839.2753047943115
  time_this_iter_s: 36.19499468803406
  time_total_s: 3839.2753047943115
  timestamp: 1563447909
  timesteps_since_restore: 2675673
  timesteps_this_iter: 27027
  timesteps_total: 2675673
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3839 s, 99 iter, 2675673 ts, 7.78 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-05-47
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 11.989999732002616
  episode_reward_mean: 7.883499823790044
  episode_reward_min: 3.449999922886491
  episodes_this_iter: 27
  episodes_total: 2700
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4615.52
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.125861644744873
        kl: 0.01711134985089302
        policy_loss: -0.06121763214468956
        total_loss: 0.1628924012184143
        vf_explained_var: 0.5477871298789978
        vf_loss: 0.21448488533496857
    load_time_ms: 2.718
    num_steps_sampled: 2702700
    num_steps_trained: 2700000
    sample_time_ms: 33185.625
    update_time_ms: 2.259
  iterations_since_restore: 100
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6633812459206183
    mean_inference_ms: 0.7266063080604135
    mean_processing_ms: 0.22523186990477412
  time_since_restore: 3877.1072142124176
  time_this_iter_s: 37.83190941810608
  time_total_s: 3877.1072142124176
  timestamp: 1563447947
  timesteps_since_restore: 2702700
  timesteps_this_iter: 27027
  timesteps_total: 2702700
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 11.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3877 s, 100 iter, 2702700 ts, 7.88 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-06-33
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 21.989999508485198
  episode_reward_mean: 8.402199812196194
  episode_reward_min: 3.449999922886491
  episodes_this_iter: 27
  episodes_total: 2727
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4769.401
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.115158557891846
        kl: 0.015185927972197533
        policy_loss: -0.048003073781728745
        total_loss: 0.22053031623363495
        vf_explained_var: 0.7916247844696045
        vf_loss: 0.259991317987442
    load_time_ms: 2.777
    num_steps_sampled: 2729727
    num_steps_trained: 2727000
    sample_time_ms: 33775.101
    update_time_ms: 2.232
  iterations_since_restore: 101
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.66359183023905
    mean_inference_ms: 0.7266817457683001
    mean_processing_ms: 0.22523983225255464
  time_since_restore: 3923.4507920742035
  time_this_iter_s: 46.34357786178589
  time_total_s: 3923.4507920742035
  timestamp: 1563447993
  timesteps_since_restore: 2729727
  timesteps_this_iter: 27027
  timesteps_total: 2729727
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3923 s, 101 iter, 2729727 ts, 8.4 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-07-15
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 21.989999508485198
  episode_reward_mean: 8.485899810325355
  episode_reward_min: 3.449999922886491
  episodes_this_iter: 27
  episodes_total: 2754
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4825.23
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.107631683349609
        kl: 0.01697278581559658
        policy_loss: -0.0622897632420063
        total_loss: 0.1795140653848648
        vf_explained_var: 0.5211962461471558
        vf_loss: 0.23225663602352142
    load_time_ms: 2.783
    num_steps_sampled: 2756754
    num_steps_trained: 2754000
    sample_time_ms: 33988.84
    update_time_ms: 2.434
  iterations_since_restore: 102
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.665003249818848
    mean_inference_ms: 0.7270849953198283
    mean_processing_ms: 0.22534504912056072
  time_since_restore: 3965.692713499069
  time_this_iter_s: 42.24192142486572
  time_total_s: 3965.692713499069
  timestamp: 1563448035
  timesteps_since_restore: 2756754
  timesteps_this_iter: 27027
  timesteps_total: 2756754
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 3965 s, 102 iter, 2756754 ts, 8.49 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-07-53
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 21.989999508485198
  episode_reward_mean: 8.604499807674438
  episode_reward_min: 3.449999922886491
  episodes_this_iter: 27
  episodes_total: 2781
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4784.933
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.092291355133057
        kl: 0.016745129600167274
        policy_loss: -0.05961129441857338
        total_loss: 0.19353468716144562
        vf_explained_var: 0.593634843826294
        vf_loss: 0.24372686445713043
    load_time_ms: 2.788
    num_steps_sampled: 2783781
    num_steps_trained: 2781000
    sample_time_ms: 33978.633
    update_time_ms: 2.407
  iterations_since_restore: 103
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6666100411098443
    mean_inference_ms: 0.7275233599019054
    mean_processing_ms: 0.22546817696085547
  time_since_restore: 4003.153227329254
  time_this_iter_s: 37.46051383018494
  time_total_s: 4003.153227329254
  timestamp: 1563448073
  timesteps_since_restore: 2783781
  timesteps_this_iter: 27027
  timesteps_total: 2783781
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4003 s, 103 iter, 2783781 ts, 8.6 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-08-30
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 21.989999508485198
  episode_reward_mean: 8.800499803293496
  episode_reward_min: 3.7199999168515205
  episodes_this_iter: 27
  episodes_total: 2808
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4821.704
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.077473163604736
        kl: 0.017699632793664932
        policy_loss: -0.06276363879442215
        total_loss: 0.17705991864204407
        vf_explained_var: 0.4994625747203827
        vf_loss: 0.22986751794815063
    load_time_ms: 2.789
    num_steps_sampled: 2810808
    num_steps_trained: 2808000
    sample_time_ms: 33940.047
    update_time_ms: 2.402
  iterations_since_restore: 104
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.667777767204927
    mean_inference_ms: 0.7278475485169703
    mean_processing_ms: 0.2255536726720211
  time_since_restore: 4040.723840236664
  time_this_iter_s: 37.57061290740967
  time_total_s: 4040.723840236664
  timestamp: 1563448110
  timesteps_since_restore: 2810808
  timesteps_this_iter: 27027
  timesteps_total: 2810808
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4040 s, 104 iter, 2810808 ts, 8.8 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-09-08
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 25.389999432489276
  episode_reward_mean: 8.760099804196507
  episode_reward_min: 3.1499999295920134
  episodes_this_iter: 27
  episodes_total: 2835
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4802.905
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.07412052154541
        kl: 0.015302159823477268
        policy_loss: -0.046171098947525024
        total_loss: 0.32961198687553406
        vf_explained_var: 0.7284382581710815
        vf_loss: 0.3671756684780121
    load_time_ms: 2.811
    num_steps_sampled: 2837835
    num_steps_trained: 2835000
    sample_time_ms: 33964.959
    update_time_ms: 2.418
  iterations_since_restore: 105
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.667636981473752
    mean_inference_ms: 0.7277938314477875
    mean_processing_ms: 0.22553121875678223
  time_since_restore: 4078.041787624359
  time_this_iter_s: 37.31794738769531
  time_total_s: 4078.041787624359
  timestamp: 1563448148
  timesteps_since_restore: 2837835
  timesteps_this_iter: 27027
  timesteps_total: 2837835
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4078 s, 105 iter, 2837835 ts, 8.76 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-09-45
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 25.389999432489276
  episode_reward_mean: 9.107699796427042
  episode_reward_min: 3.1499999295920134
  episodes_this_iter: 27
  episodes_total: 2862
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4801.458
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.058999061584473
        kl: 0.01708843559026718
        policy_loss: -0.06291884183883667
        total_loss: 0.28634950518608093
        vf_explained_var: 0.5353220701217651
        vf_loss: 0.3396560549736023
    load_time_ms: 2.799
    num_steps_sampled: 2864862
    num_steps_trained: 2862000
    sample_time_ms: 33894.677
    update_time_ms: 2.417
  iterations_since_restore: 106
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.666844833872425
    mean_inference_ms: 0.7275532142603683
    mean_processing_ms: 0.2254596382055056
  time_since_restore: 4115.752925872803
  time_this_iter_s: 37.7111382484436
  time_total_s: 4115.752925872803
  timestamp: 1563448185
  timesteps_since_restore: 2864862
  timesteps_this_iter: 27027
  timesteps_total: 2864862
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4115 s, 106 iter, 2864862 ts, 9.11 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-10-23
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 25.389999432489276
  episode_reward_mean: 9.197899794410914
  episode_reward_min: 3.1499999295920134
  episodes_this_iter: 27
  episodes_total: 2889
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4843.975
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.046830177307129
        kl: 0.01746133156120777
        policy_loss: -0.06226314976811409
        total_loss: 0.1830679178237915
        vf_explained_var: 0.592660129070282
        vf_loss: 0.23550905287265778
    load_time_ms: 2.811
    num_steps_sampled: 2891889
    num_steps_trained: 2889000
    sample_time_ms: 33700.301
    update_time_ms: 2.352
  iterations_since_restore: 107
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6660259864836156
    mean_inference_ms: 0.7273014566190631
    mean_processing_ms: 0.2253872743015395
  time_since_restore: 4153.528574466705
  time_this_iter_s: 37.77564859390259
  time_total_s: 4153.528574466705
  timestamp: 1563448223
  timesteps_since_restore: 2891889
  timesteps_this_iter: 27027
  timesteps_total: 2891889
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4153 s, 107 iter, 2891889 ts, 9.2 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-11-01
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 31.149999303743243
  episode_reward_mean: 9.818599780537188
  episode_reward_min: 3.1499999295920134
  episodes_this_iter: 27
  episodes_total: 2916
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4835.314
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.042255401611328
        kl: 0.014532458037137985
        policy_loss: -0.04277272894978523
        total_loss: 0.3265051245689392
        vf_explained_var: 0.8223267197608948
        vf_loss: 0.3611033856868744
    load_time_ms: 2.801
    num_steps_sampled: 2918916
    num_steps_trained: 2916000
    sample_time_ms: 33871.692
    update_time_ms: 2.352
  iterations_since_restore: 108
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.665239664072128
    mean_inference_ms: 0.7270561556124301
    mean_processing_ms: 0.22531335726326135
  time_since_restore: 4191.010705947876
  time_this_iter_s: 37.482131481170654
  time_total_s: 4191.010705947876
  timestamp: 1563448261
  timesteps_since_restore: 2918916
  timesteps_this_iter: 27027
  timesteps_total: 2918916
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4191 s, 108 iter, 2918916 ts, 9.82 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-11-38
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 31.149999303743243
  episode_reward_mean: 10.006699776332825
  episode_reward_min: 3.659999918192625
  episodes_this_iter: 27
  episodes_total: 2943
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4880.26
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.028910160064697
        kl: 0.017227372154593468
        policy_loss: -0.061517857015132904
        total_loss: 0.3113662302494049
        vf_explained_var: 0.497526615858078
        vf_loss: 0.36319369077682495
    load_time_ms: 2.757
    num_steps_sampled: 2945943
    num_steps_trained: 2943000
    sample_time_ms: 33979.225
    update_time_ms: 2.374
  iterations_since_restore: 109
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.664463354375737
    mean_inference_ms: 0.7268063762157396
    mean_processing_ms: 0.22523386476339827
  time_since_restore: 4228.731937646866
  time_this_iter_s: 37.72123169898987
  time_total_s: 4228.731937646866
  timestamp: 1563448298
  timesteps_since_restore: 2945943
  timesteps_this_iter: 27027
  timesteps_total: 2945943
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4228 s, 109 iter, 2945943 ts, 10 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-12-15
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 31.149999303743243
  episode_reward_mean: 9.934499777946622
  episode_reward_min: 3.8199999146163464
  episodes_this_iter: 27
  episodes_total: 2970
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4861.56
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.0207929611206055
        kl: 0.01742566004395485
        policy_loss: -0.0607936717569828
        total_loss: 0.3332383334636688
        vf_explained_var: 0.4781491458415985
        vf_loss: 0.38423001766204834
    load_time_ms: 2.755
    num_steps_sampled: 2972970
    num_steps_trained: 2970000
    sample_time_ms: 33862.286
    update_time_ms: 2.426
  iterations_since_restore: 110
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6635501905512835
    mean_inference_ms: 0.7265305561145149
    mean_processing_ms: 0.22514493674367372
  time_since_restore: 4265.206424474716
  time_this_iter_s: 36.47448682785034
  time_total_s: 4265.206424474716
  timestamp: 1563448335
  timesteps_since_restore: 2972970
  timesteps_this_iter: 27027
  timesteps_total: 2972970
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4265 s, 110 iter, 2972970 ts, 9.93 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-12-53
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 26.21999941393733
  episode_reward_mean: 9.918799778297544
  episode_reward_min: 3.8199999146163464
  episodes_this_iter: 27
  episodes_total: 2997
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4720.376
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 4.009393215179443
        kl: 0.01663411408662796
        policy_loss: -0.0600200816988945
        total_loss: 0.25360026955604553
        vf_explained_var: 0.5734123587608337
        vf_loss: 0.3042636513710022
    load_time_ms: 2.682
    num_steps_sampled: 2999997
    num_steps_trained: 2997000
    sample_time_ms: 33189.983
    update_time_ms: 2.426
  iterations_since_restore: 111
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.662760714309373
    mean_inference_ms: 0.7262709130880755
    mean_processing_ms: 0.22506720155623505
  time_since_restore: 4303.362516880035
  time_this_iter_s: 38.156092405319214
  time_total_s: 4303.362516880035
  timestamp: 1563448373
  timesteps_since_restore: 2999997
  timesteps_this_iter: 27027
  timesteps_total: 2999997
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4303 s, 111 iter, 2999997 ts, 9.92 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-13-31
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 15.229999659582973
  episode_reward_mean: 9.242599793411792
  episode_reward_min: 3.089999930933118
  episodes_this_iter: 27
  episodes_total: 3024
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4745.543
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.998224973678589
        kl: 0.016960954293608665
        policy_loss: -0.0600687712430954
        total_loss: 0.19659173488616943
        vf_explained_var: 0.5949868559837341
        vf_loss: 0.2471199929714203
    load_time_ms: 2.69
    num_steps_sampled: 3027024
    num_steps_trained: 3024000
    sample_time_ms: 32790.053
    update_time_ms: 2.264
  iterations_since_restore: 112
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.662014223093931
    mean_inference_ms: 0.7260219454026472
    mean_processing_ms: 0.2249887901009865
  time_since_restore: 4341.850595712662
  time_this_iter_s: 38.48807883262634
  time_total_s: 4341.850595712662
  timestamp: 1563448411
  timesteps_since_restore: 3027024
  timesteps_this_iter: 27027
  timesteps_total: 3027024
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4341 s, 112 iter, 3027024 ts, 9.24 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-14-09
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 15.149999661371112
  episode_reward_mean: 9.51649978728965
  episode_reward_min: 3.089999930933118
  episodes_this_iter: 27
  episodes_total: 3051
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4761.472
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.9832773208618164
        kl: 0.018179025501012802
        policy_loss: -0.06174647808074951
        total_loss: 0.29210859537124634
        vf_explained_var: 0.584847629070282
        vf_loss: 0.3436293303966522
    load_time_ms: 2.687
    num_steps_sampled: 3054051
    num_steps_trained: 3051000
    sample_time_ms: 32781.653
    update_time_ms: 2.249
  iterations_since_restore: 113
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.661348224122472
    mean_inference_ms: 0.725797469668445
    mean_processing_ms: 0.22492251480086226
  time_since_restore: 4379.386407613754
  time_this_iter_s: 37.53581190109253
  time_total_s: 4379.386407613754
  timestamp: 1563448449
  timesteps_since_restore: 3054051
  timesteps_this_iter: 27027
  timesteps_total: 3054051
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4379 s, 113 iter, 3054051 ts, 9.52 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-14-47
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.30999963544309
  episode_reward_mean: 9.931999778002501
  episode_reward_min: 3.089999930933118
  episodes_this_iter: 27
  episodes_total: 3078
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4769.243
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.964069128036499
        kl: 0.017946938052773476
        policy_loss: -0.06108424812555313
        total_loss: 0.3466537594795227
        vf_explained_var: 0.5129184722900391
        vf_loss: 0.3976428508758545
    load_time_ms: 2.685
    num_steps_sampled: 3081078
    num_steps_trained: 3078000
    sample_time_ms: 32807.391
    update_time_ms: 2.25
  iterations_since_restore: 114
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6608799624663813
    mean_inference_ms: 0.7256181614793091
    mean_processing_ms: 0.2248812052723859
  time_since_restore: 4417.296890258789
  time_this_iter_s: 37.91048264503479
  time_total_s: 4417.296890258789
  timestamp: 1563448487
  timesteps_since_restore: 3081078
  timesteps_this_iter: 27027
  timesteps_total: 3081078
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4417 s, 114 iter, 3081078 ts, 9.93 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-15-25
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.30999963544309
  episode_reward_mean: 9.840899780038745
  episode_reward_min: 3.089999930933118
  episodes_this_iter: 27
  episodes_total: 3105
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4785.82
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.9529430866241455
        kl: 0.016682378947734833
        policy_loss: -0.06052142754197121
        total_loss: 0.23194418847560883
        vf_explained_var: 0.5596156120300293
        vf_loss: 0.2830817997455597
    load_time_ms: 2.655
    num_steps_sampled: 3108105
    num_steps_trained: 3105000
    sample_time_ms: 32907.223
    update_time_ms: 2.264
  iterations_since_restore: 115
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6605398123679422
    mean_inference_ms: 0.7254741775714405
    mean_processing_ms: 0.22484454972933435
  time_since_restore: 4455.782790899277
  time_this_iter_s: 38.48590064048767
  time_total_s: 4455.782790899277
  timestamp: 1563448525
  timesteps_since_restore: 3108105
  timesteps_this_iter: 27027
  timesteps_total: 3108105
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4455 s, 115 iter, 3108105 ts, 9.84 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-16-05
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.30999963544309
  episode_reward_mean: 10.120599773786962
  episode_reward_min: 2.6699999403208494
  episodes_this_iter: 27
  episodes_total: 3132
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4737.299
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.932400941848755
        kl: 0.017970524728298187
        policy_loss: -0.06453287601470947
        total_loss: 0.26019927859306335
        vf_explained_var: 0.5685386657714844
        vf_loss: 0.31462371349334717
    load_time_ms: 2.655
    num_steps_sampled: 3135132
    num_steps_trained: 3132000
    sample_time_ms: 33132.67
    update_time_ms: 2.342
  iterations_since_restore: 116
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6605762639894626
    mean_inference_ms: 0.7254384354668107
    mean_processing_ms: 0.22483342990204241
  time_since_restore: 4495.260339975357
  time_this_iter_s: 39.47754907608032
  time_total_s: 4495.260339975357
  timestamp: 1563448565
  timesteps_since_restore: 3135132
  timesteps_this_iter: 27027
  timesteps_total: 3135132
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4495 s, 116 iter, 3135132 ts, 10.1 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-16-43
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 15.999999642372131
  episode_reward_mean: 9.83459978017956
  episode_reward_min: 2.6699999403208494
  episodes_this_iter: 27
  episodes_total: 3159
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4679.071
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.917531728744507
        kl: 0.01698620803654194
        policy_loss: -0.061538152396678925
        total_loss: 0.23394067585468292
        vf_explained_var: 0.6297962069511414
        vf_loss: 0.2859240770339966
    load_time_ms: 2.657
    num_steps_sampled: 3162159
    num_steps_trained: 3159000
    sample_time_ms: 33254.169
    update_time_ms: 2.387
  iterations_since_restore: 117
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6608161889998176
    mean_inference_ms: 0.7254604881746113
    mean_processing_ms: 0.22483012499637822
  time_since_restore: 4533.673985958099
  time_this_iter_s: 38.41364598274231
  time_total_s: 4533.673985958099
  timestamp: 1563448603
  timesteps_since_restore: 3162159
  timesteps_this_iter: 27027
  timesteps_total: 3162159
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4533 s, 117 iter, 3162159 ts, 9.83 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-17-20
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 15.999999642372131
  episode_reward_mean: 9.490899787861855
  episode_reward_min: 2.6699999403208494
  episodes_this_iter: 27
  episodes_total: 3186
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4676.825
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.9080471992492676
        kl: 0.017877114936709404
        policy_loss: -0.06104708090424538
        total_loss: 0.26396650075912476
        vf_explained_var: 0.5268713235855103
        vf_loss: 0.31495773792266846
    load_time_ms: 2.707
    num_steps_sampled: 3189186
    num_steps_trained: 3186000
    sample_time_ms: 33193.05
    update_time_ms: 2.389
  iterations_since_restore: 118
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.660839634158462
    mean_inference_ms: 0.725453554284133
    mean_processing_ms: 0.22481208746450385
  time_since_restore: 4570.5207414627075
  time_this_iter_s: 36.846755504608154
  time_total_s: 4570.5207414627075
  timestamp: 1563448640
  timesteps_since_restore: 3189186
  timesteps_this_iter: 27027
  timesteps_total: 3189186
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/12 CPUs, 1/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/unity-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_Reacher_0:	RUNNING, [4 CPUs, 1 GPUs], [pid=8299], 4570 s, 118 iter, 3189186 ts, 9.49 rew

Result for PPO_Reacher_0:
  custom_metrics: {}
  date: 2019-07-18_13-17-56
  done: false
  episode_len_mean: 1001.0
  episode_reward_max: 16.34999963454902
  episode_reward_mean: 9.617699785027654
  episode_reward_min: 2.6699999403208494
  episodes_this_iter: 27
  episodes_total: 3213
  experiment_id: 38a599506510432bb54ba95182e55fe2
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4637.639
    learner:
      default_policy:
        cur_kl_coeff: 0.5625
        cur_lr: 9.999999747378752e-05
        entropy: 3.8962085247039795
        kl: 0.018170775845646858
        policy_loss: -0.06458401679992676
        total_loss: 0.29504039883613586
        vf_explained_var: 0.4438805878162384
        vf_loss: 0.3494033217430115
    load_time_ms: 2.714
    num_steps_sampled: 3216213
    num_steps_trained: 3213000
    sample_time_ms: 33068.895
    update_time_ms: 2.359
  iterations_since_restore: 119
  node_ip: 10.16.128.63
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 8299
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 2.6603242781029337
    mean_inference_ms: 0.7253120402449963
    mean_processing_ms: 0.2247585298853262
  time_since_restore: 4606.6087038517
  time_this_iter_s: 36.08796238899231
  time_total_s: 4606.6087038517
  timestamp: 1563448676
  timesteps_since_restore: 3216213
  timesteps_this_iter: 27027
  timesteps_total: 3216213
  training_iteration: 119
  
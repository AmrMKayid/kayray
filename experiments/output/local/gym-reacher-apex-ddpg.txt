2019-07-22 04:36:04,805	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-22_04-36-04_805459_4614/logs.
2019-07-22 04:36:04,910	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-22 04:36:05,019	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-22 04:36:05,135	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:59673 to respond...
2019-07-22 04:36:05,256	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:37562 to respond...
2019-07-22 04:36:05,260	INFO services.py:806 -- Starting Redis shard with 3.33 GB max memory.
2019-07-22 04:36:05,293	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-22_04-36-04_805459_4614/logs.
2019-07-22 04:36:05,293	INFO services.py:1446 -- Starting the Plasma object store with 5.0 GB memory using /dev/shm.
2019-07-22 04:36:05,412	INFO tune.py:61 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()
2019-07-22 04:36:05,412	INFO tune.py:233 -- Starting a new experiment.
2019-07-22 04:36:05,426	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-22 04:36:05,528	WARNING util.py:64 -- The `start_trial` operation took 0.11036062240600586 seconds to complete, which may be a performance bottleneck.
[32m [     0.20948s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.20978s,  INFO] Experiment configs: 
 {
  "gym-reacher-apex-ddpg": {
    "env": "RoboschoolReacher-v1",
    "run": "APEX_DDPG",
    "local_dir": "~/kayray_results/local",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "episode_reward_mean": 21,
      "timesteps_total": 10000000
    },
    "config": {
      "env_config": {
        "env_type": "openai"
      },
      "use_huber": true,
      "clip_rewards": false,
      "num_gpus": 0,
      "num_workers": 2,
      "lr": 0.01,
      "n_step": 1,
      "exploration_ou_noise_scale": 0.7,
      "target_network_update_freq": 50000,
      "tau": 1.0,
      "evaluation_interval": 5,
      "evaluation_num_episodes": 10
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 1.1/16.7 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 1.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=4669)[0m [32m [     0.01524s,  INFO] TimeLimit:
[2m[36m(pid=4669)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=4669)[0m - action_space = Box(2,)
[2m[36m(pid=4669)[0m - observation_space = Box(9,)
[2m[36m(pid=4669)[0m - reward_range = (-inf, inf)
[2m[36m(pid=4669)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=4669)[0m - _max_episode_steps = 150
[2m[36m(pid=4669)[0m - _elapsed_steps = None [0m
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07,309	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07.309569: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=4669)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4669)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07,870	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x7f8297728dd8>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07,870	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f8297d44b00>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07,870	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f8297d39c88>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:07,872	INFO actors.py:108 -- Trying to create 4 colocated actors
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,062	INFO actors.py:101 -- Got 4 colocated actors of 4
[2m[36m(pid=4669)[0m [32m [     1.86847s,  INFO] TimeLimit:
[2m[36m(pid=4669)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=4669)[0m - action_space = Box(2,)
[2m[36m(pid=4669)[0m - observation_space = Box(9,)
[2m[36m(pid=4669)[0m - reward_range = (-inf, inf)
[2m[36m(pid=4669)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=4669)[0m - _max_episode_steps = 150
[2m[36m(pid=4669)[0m - _elapsed_steps = None [0m
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,162	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,774	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x7f8284549128>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,774	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f8284539e80>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,774	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7f82845398d0>}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,776	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,795	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,802	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.219, max=0.991, mean=0.196)}}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,802	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,803	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.219, max=0.991, mean=0.196)
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,803	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.219, max=0.991, mean=0.196)
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,803	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=4669)[0m                                   'env_id': 0,
[2m[36m(pid=4669)[0m                                   'info': None,
[2m[36m(pid=4669)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.219, max=0.991, mean=0.196),
[2m[36m(pid=4669)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4669)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=4669)[0m                                   'rnn_state': []},
[2m[36m(pid=4669)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,803	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,820	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-0.294, max=0.211, mean=-0.042),
[2m[36m(pid=4669)[0m                       [],
[2m[36m(pid=4669)[0m                       {})}
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,933	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'agent0': { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.041),
[2m[36m(pid=4669)[0m                         'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4669)[0m                         'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=4669)[0m                         'eps_id': np.ndarray((150,), dtype=int64, min=1151927750.0, max=1151927750.0, mean=1151927750.0),
[2m[36m(pid=4669)[0m                         'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=4669)[0m                         'new_obs': np.ndarray((150, 9), dtype=float32, min=-4.584, max=4.11, mean=0.04),
[2m[36m(pid=4669)[0m                         'obs': np.ndarray((150, 9), dtype=float32, min=-4.584, max=4.11, mean=0.042),
[2m[36m(pid=4669)[0m                         'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.038),
[2m[36m(pid=4669)[0m                         'prev_rewards': np.ndarray((150,), dtype=float32, min=-5.717, max=6.011, mean=-0.083),
[2m[36m(pid=4669)[0m                         'rewards': np.ndarray((150,), dtype=float32, min=-5.717, max=6.011, mean=-0.082),
[2m[36m(pid=4669)[0m                         't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=4669)[0m                         'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4669)[0m                         'weights': np.ndarray((150,), dtype=float32, min=0.001, max=6.219, mean=0.969)},
[2m[36m(pid=4669)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m 2019-07-22 04:36:09,936	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.041),
[2m[36m(pid=4669)[0m             'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4669)[0m             'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=4669)[0m             'eps_id': np.ndarray((150,), dtype=int64, min=1151927750.0, max=1151927750.0, mean=1151927750.0),
[2m[36m(pid=4669)[0m             'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=4669)[0m             'new_obs': np.ndarray((150, 9), dtype=float32, min=-4.584, max=4.11, mean=0.04),
[2m[36m(pid=4669)[0m             'obs': np.ndarray((150, 9), dtype=float32, min=-4.584, max=4.11, mean=0.042),
[2m[36m(pid=4669)[0m             'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.038),
[2m[36m(pid=4669)[0m             'prev_rewards': np.ndarray((150,), dtype=float32, min=-5.717, max=6.011, mean=-0.083),
[2m[36m(pid=4669)[0m             'rewards': np.ndarray((150,), dtype=float32, min=-5.717, max=6.011, mean=-0.082),
[2m[36m(pid=4669)[0m             't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=4669)[0m             'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4669)[0m             'weights': np.ndarray((150,), dtype=float32, min=0.001, max=6.219, mean=0.969)},
[2m[36m(pid=4669)[0m   'type': 'SampleBatch'}
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4659)[0m 2019-07-22 04:36:10,306	INFO rollout_worker.py:301 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=4659)[0m 2019-07-22 04:36:10.306483: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=4659)[0m [32m [     0.01748s,  INFO] TimeLimit:
[2m[36m(pid=4659)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=4659)[0m - action_space = Box(2,)
[2m[36m(pid=4659)[0m - observation_space = Box(9,)
[2m[36m(pid=4659)[0m - reward_range = (-inf, inf)
[2m[36m(pid=4659)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=4659)[0m - _max_episode_steps = 150
[2m[36m(pid=4659)[0m - _elapsed_steps = None [0m
[2m[36m(pid=4668)[0m [32m [     0.01795s,  INFO] TimeLimit:
[2m[36m(pid=4668)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=4668)[0m - action_space = Box(2,)
[2m[36m(pid=4668)[0m - observation_space = Box(9,)
[2m[36m(pid=4668)[0m - reward_range = (-inf, inf)
[2m[36m(pid=4668)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=4668)[0m - _max_episode_steps = 150
[2m[36m(pid=4668)[0m - _elapsed_steps = None [0m
[2m[36m(pid=4668)[0m 2019-07-22 04:36:10,310	INFO rollout_worker.py:301 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=4668)[0m 2019-07-22 04:36:10.311108: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=4659)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4659)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4668)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4668)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,041	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,050	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.067, max=0.742, mean=0.19)}}
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,050	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,051	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.067, max=0.742, mean=0.19)
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,051	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.067, max=0.742, mean=0.19)
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,051	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=4668)[0m                                   'env_id': 0,
[2m[36m(pid=4668)[0m                                   'info': None,
[2m[36m(pid=4668)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.067, max=0.742, mean=0.19),
[2m[36m(pid=4668)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=4668)[0m                                   'rnn_state': []},
[2m[36m(pid=4668)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,051	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,074	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-0.144, max=0.408, mean=0.132),
[2m[36m(pid=4668)[0m                       [],
[2m[36m(pid=4668)[0m                       {})}
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,140	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m { 'agent0': { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.59, mean=-0.215),
[2m[36m(pid=4668)[0m                         'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m                         'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m                         'eps_id': np.ndarray((50,), dtype=int64, min=199732041.0, max=199732041.0, mean=199732041.0),
[2m[36m(pid=4668)[0m                         'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=4668)[0m                         'new_obs': np.ndarray((50, 9), dtype=float32, min=-2.208, max=2.278, mean=0.029),
[2m[36m(pid=4668)[0m                         'obs': np.ndarray((50, 9), dtype=float32, min=-2.208, max=2.278, mean=0.033),
[2m[36m(pid=4668)[0m                         'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.59, mean=-0.201),
[2m[36m(pid=4668)[0m                         'prev_rewards': np.ndarray((50,), dtype=float32, min=-1.595, max=3.779, mean=0.04),
[2m[36m(pid=4668)[0m                         'rewards': np.ndarray((50,), dtype=float32, min=-1.595, max=3.779, mean=0.013),
[2m[36m(pid=4668)[0m                         't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=4668)[0m                         'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m                         'weights': np.ndarray((50,), dtype=float32, min=0.027, max=3.91, mean=0.968)},
[2m[36m(pid=4668)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m 2019-07-22 04:36:11,141	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4668)[0m { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.59, mean=-0.215),
[2m[36m(pid=4668)[0m             'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m             'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m             'eps_id': np.ndarray((50,), dtype=int64, min=199732041.0, max=199732041.0, mean=199732041.0),
[2m[36m(pid=4668)[0m             'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=4668)[0m             'new_obs': np.ndarray((50, 9), dtype=float32, min=-2.208, max=2.278, mean=0.029),
[2m[36m(pid=4668)[0m             'obs': np.ndarray((50, 9), dtype=float32, min=-2.208, max=2.278, mean=0.033),
[2m[36m(pid=4668)[0m             'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.59, mean=-0.201),
[2m[36m(pid=4668)[0m             'prev_rewards': np.ndarray((50,), dtype=float32, min=-1.595, max=3.779, mean=0.04),
[2m[36m(pid=4668)[0m             'rewards': np.ndarray((50,), dtype=float32, min=-1.595, max=3.779, mean=0.013),
[2m[36m(pid=4668)[0m             't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=4668)[0m             'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=4668)[0m             'weights': np.ndarray((50,), dtype=float32, min=0.027, max=3.91, mean=0.968)},
[2m[36m(pid=4668)[0m   'type': 'SampleBatch'}
[2m[36m(pid=4668)[0m 
[2m[36m(pid=4669)[0m 2019-07-22 04:36:34,562	INFO rollout_worker.py:552 -- Training on concatenated sample batches:
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'count': 512,
[2m[36m(pid=4669)[0m   'policy_batches': { 'default_policy': { 'data': { 'actions': np.ndarray((512, 2), dtype=float32, min=-1.0, max=0.993, mean=-0.009),
[2m[36m(pid=4669)[0m                                                     'batch_indexes': np.ndarray((512,), dtype=int64, min=3.0, max=12489.0, mean=6057.447),
[2m[36m(pid=4669)[0m                                                     'dones': np.ndarray((512,), dtype=bool, min=0.0, max=1.0, mean=0.01),
[2m[36m(pid=4669)[0m                                                     'new_obs': np.ndarray((512, 9), dtype=float32, min=-5.106, max=5.228, mean=-0.002),
[2m[36m(pid=4669)[0m                                                     'obs': np.ndarray((512, 9), dtype=float32, min=-5.556, max=5.393, mean=-0.006),
[2m[36m(pid=4669)[0m                                                     'rewards': np.ndarray((512,), dtype=float32, min=-9.116, max=7.175, mean=-0.05),
[2m[36m(pid=4669)[0m                                                     'weights': np.ndarray((512,), dtype=float64, min=0.052, max=0.244, mean=0.092)},
[2m[36m(pid=4669)[0m                                           'type': 'SampleBatch'}},
[2m[36m(pid=4669)[0m   'type': 'MultiAgentBatch'}
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m 2019-07-22 04:36:34,752	INFO rollout_worker.py:574 -- Training output:
[2m[36m(pid=4669)[0m 
[2m[36m(pid=4669)[0m { 'default_policy': { 'learner_stats': { 'max_q': 0.11504062,
[2m[36m(pid=4669)[0m                                          'mean_q': -0.03875597,
[2m[36m(pid=4669)[0m                                          'min_q': -0.20728368},
[2m[36m(pid=4669)[0m                       'td_error': np.ndarray((512,), dtype=float32, min=-7.121, max=9.182, mean=0.043)}}
[2m[36m(pid=4669)[0m 
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-36-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 19.689612184390867
  episode_reward_mean: -9.313715561769694
  episode_reward_min: -43.06470820269365
  episodes_this_iter: 187
  episodes_total: 187
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 6.208529472351074
        mean_q: 0.1336728185415268
        min_q: -5.188907623291016
    learner_queue:
      size_count: 75583
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6082762530298219
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 917
    num_steps_sampled: 55950
    num_steps_trained: 110080
    num_target_updates: 2
    num_weight_syncs: 139
    replay_shard_0:
      add_batch_time_ms: 2.691
      policy_default_policy:
        added_count: 14250
        est_size_bytes: 4859250
        num_entries: 14250
        sampled_count: 29184
      replay_time_ms: 18.391
      update_priorities_time_ms: 50.714
    sample_throughput: 0.0
    train_throughput: 25867.687
  iterations_since_restore: 1
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.2567066380839174
    mean_inference_ms: 0.6059816034842012
    mean_processing_ms: 0.15917930461596197
  time_since_restore: 30.223342895507812
  time_this_iter_s: 30.223342895507812
  time_total_s: 30.223342895507812
  timestamp: 1563763001
  timesteps_since_restore: 55950
  timesteps_this_iter: 55950
  timesteps_total: 55950
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 30 s, 1 iter, 55950 ts, -9.31 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-37-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.33769402628029
  episode_reward_mean: -1.4363104642480802
  episode_reward_min: -73.24823670822973
  episodes_this_iter: 130
  episodes_total: 317
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 29.401092529296875
        mean_q: 8.447660446166992
        min_q: -12.328291893005371
    learner_queue:
      size_count: 76978
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.6696267617113282
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 929
    num_steps_sampled: 94850
    num_steps_trained: 823808
    num_target_updates: 16
    num_weight_syncs: 236
    replay_shard_0:
      add_batch_time_ms: 3.269
      policy_default_policy:
        added_count: 22900
        est_size_bytes: 7808900
        num_entries: 22900
        sampled_count: 207360
      replay_time_ms: 18.405
      update_priorities_time_ms: 51.0
    sample_throughput: 4329.917
    train_throughput: 44338.35
  iterations_since_restore: 2
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.2912559087302882
    mean_inference_ms: 0.7340510945292954
    mean_processing_ms: 0.1820033312229947
  time_since_restore: 60.46350049972534
  time_this_iter_s: 30.24015760421753
  time_total_s: 60.46350049972534
  timestamp: 1563763031
  timesteps_since_restore: 94850
  timesteps_this_iter: 38900
  timesteps_total: 94850
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 4.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 60 s, 2 iter, 94850 ts, -1.44 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-37-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.6038251393501
  episode_reward_mean: 13.193025289567752
  episode_reward_min: -15.001050124655624
  episodes_this_iter: 130
  episodes_total: 447
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.625709533691406
        mean_q: 14.871122360229492
        min_q: -14.069198608398438
    learner_queue:
      size_count: 78353
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 938
    num_steps_sampled: 133950
    num_steps_trained: 1528832
    num_target_updates: 30
    num_weight_syncs: 334
    replay_shard_0:
      add_batch_time_ms: 3.266
      policy_default_policy:
        added_count: 33000
        est_size_bytes: 11253000
        num_entries: 33000
        sampled_count: 381952
      replay_time_ms: 18.105
      update_priorities_time_ms: 48.726
    sample_throughput: 0.0
    train_throughput: 54518.498
  iterations_since_restore: 3
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3052697011364605
    mean_inference_ms: 0.7882875574766597
    mean_processing_ms: 0.19135142727844465
  time_since_restore: 90.64013171195984
  time_this_iter_s: 30.176631212234497
  time_total_s: 90.64013171195984
  timestamp: 1563763061
  timesteps_since_restore: 133950
  timesteps_this_iter: 39100
  timesteps_total: 133950
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 4.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 90 s, 3 iter, 133950 ts, 13.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-38-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.62245028847
  episode_reward_mean: 12.039496492458445
  episode_reward_min: -15.115003171877916
  episodes_this_iter: 131
  episodes_total: 578
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 48.980804443359375
        mean_q: 17.395336151123047
        min_q: -2.192882776260376
    learner_queue:
      size_count: 79735
      size_mean: 0.58
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.6660330322138686
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 949
    num_steps_sampled: 172800
    num_steps_trained: 2235392
    num_target_updates: 44
    num_weight_syncs: 431
    replay_shard_0:
      add_batch_time_ms: 2.972
      policy_default_policy:
        added_count: 42600
        est_size_bytes: 14526600
        num_entries: 42600
        sampled_count: 559104
      replay_time_ms: 17.484
      update_priorities_time_ms: 50.112
    sample_throughput: 0.0
    train_throughput: 30819.226
  iterations_since_restore: 4
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3126905519403174
    mean_inference_ms: 0.8182672561614004
    mean_processing_ms: 0.19623799010052723
  time_since_restore: 120.8451611995697
  time_this_iter_s: 30.205029487609863
  time_total_s: 120.8451611995697
  timestamp: 1563763091
  timesteps_since_restore: 172800
  timesteps_this_iter: 38850
  timesteps_total: 172800
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 4.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 120 s, 4 iter, 172800 ts, 12 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:38:41,901	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-38-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.36728899611472
  episode_reward_mean: 8.800115291725028
  episode_reward_min: -17.69215772943324
  episodes_this_iter: 130
  episodes_total: 708
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.446996490320004
    episode_reward_mean: 10.124930524902302
    episode_reward_min: -14.631327524932113
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.15018837168311247
      mean_inference_ms: 0.3988704694107904
      mean_processing_ms: 0.08718763260553773
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 43.93313217163086
        mean_q: 18.88165855407715
        min_q: 4.371060848236084
    learner_queue:
      size_count: 81101
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 959
    num_steps_sampled: 211850
    num_steps_trained: 2935296
    num_target_updates: 58
    num_weight_syncs: 529
    replay_shard_0:
      add_batch_time_ms: 2.92
      policy_default_policy:
        added_count: 52650
        est_size_bytes: 17953650
        num_entries: 52650
        sampled_count: 731136
      replay_time_ms: 20.25
      update_priorities_time_ms: 54.934
    sample_throughput: 0.0
    train_throughput: 26996.073
  iterations_since_restore: 5
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.31756667523106824
    mean_inference_ms: 0.8373385963802747
    mean_processing_ms: 0.1990747564373949
  time_since_restore: 151.0659577846527
  time_this_iter_s: 30.220796585083008
  time_total_s: 151.0659577846527
  timestamp: 1563763121
  timesteps_since_restore: 211850
  timesteps_this_iter: 39050
  timesteps_total: 211850
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 4.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 151 s, 5 iter, 211850 ts, 8.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-39-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.40968291237948
  episode_reward_mean: 8.185643603141477
  episode_reward_min: -21.004795400803008
  episodes_this_iter: 131
  episodes_total: 839
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 45.44072341918945
        mean_q: 19.018171310424805
        min_q: 3.84059476852417
    learner_queue:
      size_count: 82466
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.49839743177508455
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 970
    num_steps_sampled: 251000
    num_steps_trained: 3634176
    num_target_updates: 72
    num_weight_syncs: 627
    replay_shard_0:
      add_batch_time_ms: 3.526
      policy_default_policy:
        added_count: 62500
        est_size_bytes: 21312500
        num_entries: 62500
        sampled_count: 905728
      replay_time_ms: 20.03
      update_priorities_time_ms: 50.104
    sample_throughput: 0.0
    train_throughput: 27459.672
  iterations_since_restore: 6
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.32119369547739834
    mean_inference_ms: 0.8500926951983472
    mean_processing_ms: 0.20081884564571745
  time_since_restore: 181.2845106124878
  time_this_iter_s: 30.218552827835083
  time_total_s: 181.2845106124878
  timestamp: 1563763153
  timesteps_since_restore: 251000
  timesteps_this_iter: 39150
  timesteps_total: 251000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 5.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 181 s, 6 iter, 251000 ts, 8.19 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-39-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.3814439300831
  episode_reward_mean: 11.071013004420383
  episode_reward_min: -19.433039375058975
  episodes_this_iter: 131
  episodes_total: 970
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 44.61381912231445
        mean_q: 18.928936004638672
        min_q: 3.743398666381836
    learner_queue:
      size_count: 83825
      size_mean: 0.26
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4386342439892262
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 980
    num_steps_sampled: 290300
    num_steps_trained: 4329984
    num_target_updates: 86
    num_weight_syncs: 725
    replay_shard_0:
      add_batch_time_ms: 2.842
      policy_default_policy:
        added_count: 72250
        est_size_bytes: 24637250
        num_entries: 72250
        sampled_count: 1077760
      replay_time_ms: 20.368
      update_priorities_time_ms: 51.583
    sample_throughput: 3600.755
    train_throughput: 36871.736
  iterations_since_restore: 7
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3229810467607028
    mean_inference_ms: 0.8600622413699172
    mean_processing_ms: 0.2023452554002838
  time_since_restore: 211.5259861946106
  time_this_iter_s: 30.241475582122803
  time_total_s: 211.5259861946106
  timestamp: 1563763183
  timesteps_since_restore: 290300
  timesteps_this_iter: 39300
  timesteps_total: 290300
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 5.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 211 s, 7 iter, 290300 ts, 11.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-40-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.24833956782667
  episode_reward_mean: 15.7239094000566
  episode_reward_min: -6.179565531062031
  episodes_this_iter: 130
  episodes_total: 1100
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 45.14690017700195
        mean_q: 19.75144386291504
        min_q: 2.7692677974700928
    learner_queue:
      size_count: 85181
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 2.0
      - 2.0
      size_std: 0.6896375859826667
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 991
    num_steps_sampled: 329550
    num_steps_trained: 5023232
    num_target_updates: 100
    num_weight_syncs: 823
    replay_shard_0:
      add_batch_time_ms: 3.253
      policy_default_policy:
        added_count: 82500
        est_size_bytes: 28132500
        num_entries: 82500
        sampled_count: 1248256
      replay_time_ms: 20.187
      update_priorities_time_ms: 47.795
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 8
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.32491934110107984
    mean_inference_ms: 0.8675168331762899
    mean_processing_ms: 0.2036242267407667
  time_since_restore: 241.72641253471375
  time_this_iter_s: 30.20042634010315
  time_total_s: 241.72641253471375
  timestamp: 1563763213
  timesteps_since_restore: 329550
  timesteps_this_iter: 39250
  timesteps_total: 329550
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 5.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 241 s, 8 iter, 329550 ts, 15.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-40-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.32783564456087
  episode_reward_mean: 14.590713392774779
  episode_reward_min: -6.173653434454507
  episodes_this_iter: 131
  episodes_total: 1231
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.01959228515625
        mean_q: 19.086217880249023
        min_q: 3.9874064922332764
    learner_queue:
      size_count: 86535
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6053098380168623
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 999
    num_steps_sampled: 368950
    num_steps_trained: 5717504
    num_target_updates: 113
    num_weight_syncs: 921
    replay_shard_0:
      add_batch_time_ms: 3.051
      policy_default_policy:
        added_count: 92100
        est_size_bytes: 31406100
        num_entries: 92100
        sampled_count: 1420288
      replay_time_ms: 17.588
      update_priorities_time_ms: 50.234
    sample_throughput: 0.0
    train_throughput: 44327.368
  iterations_since_restore: 9
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.32635851790767934
    mean_inference_ms: 0.8719680895834447
    mean_processing_ms: 0.20445446130011197
  time_since_restore: 271.9234073162079
  time_this_iter_s: 30.19699478149414
  time_total_s: 271.9234073162079
  timestamp: 1563763243
  timesteps_since_restore: 368950
  timesteps_this_iter: 39400
  timesteps_total: 368950
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 5.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 271 s, 9 iter, 368950 ts, 14.6 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:41:13,913	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-41-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.36873026190956
  episode_reward_mean: 14.368137588749578
  episode_reward_min: -15.068662624920567
  episodes_this_iter: 132
  episodes_total: 1363
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 22.934681611185454
    episode_reward_mean: 8.035461015108512
    episode_reward_min: 0.06581444277543283
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1461790869220631
      mean_inference_ms: 0.3930629292903172
      mean_processing_ms: 0.08409819426046058
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 44.033145904541016
        mean_q: 19.383018493652344
        min_q: 6.588160514831543
    learner_queue:
      size_count: 87883
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5730619512757761
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1009
    num_steps_sampled: 408450
    num_steps_trained: 6408192
    num_target_updates: 127
    num_weight_syncs: 1021
    replay_shard_0:
      add_batch_time_ms: 3.267
      policy_default_policy:
        added_count: 102300
        est_size_bytes: 34884300
        num_entries: 102300
        sampled_count: 1591808
      replay_time_ms: 20.353
      update_priorities_time_ms: 50.647
    sample_throughput: 2157.342
    train_throughput: 22091.18
  iterations_since_restore: 10
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.32727652167664883
    mean_inference_ms: 0.8756127362309554
    mean_processing_ms: 0.2051893136013297
  time_since_restore: 302.13206601142883
  time_this_iter_s: 30.208658695220947
  time_total_s: 302.13206601142883
  timestamp: 1563763273
  timesteps_since_restore: 408450
  timesteps_this_iter: 39500
  timesteps_total: 408450
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 302 s, 10 iter, 408450 ts, 14.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-41-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.39736691039684
  episode_reward_mean: 12.553945195191169
  episode_reward_min: -18.640086883394858
  episodes_this_iter: 131
  episodes_total: 1494
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.713035583496094
        mean_q: 18.061519622802734
        min_q: 5.316769599914551
    learner_queue:
      size_count: 89234
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6082762530298219
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1022
    num_steps_sampled: 447950
    num_steps_trained: 7098880
    num_target_updates: 141
    num_weight_syncs: 1119
    replay_shard_0:
      add_batch_time_ms: 2.478
      policy_default_policy:
        added_count: 113000
        est_size_bytes: 38533000
        num_entries: 113000
        sampled_count: 1763328
      replay_time_ms: 17.757
      update_priorities_time_ms: 51.549
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 11
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3280831126840153
    mean_inference_ms: 0.8791369211795975
    mean_processing_ms: 0.20571324484579515
  time_since_restore: 332.33802938461304
  time_this_iter_s: 30.205963373184204
  time_total_s: 332.33802938461304
  timestamp: 1563763305
  timesteps_since_restore: 447950
  timesteps_this_iter: 39500
  timesteps_total: 447950
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 332 s, 11 iter, 447950 ts, 12.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-42-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.267579337293625
  episode_reward_mean: 13.704807770965514
  episode_reward_min: -14.732936229865478
  episodes_this_iter: 132
  episodes_total: 1626
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.338348388671875
        mean_q: 17.170482635498047
        min_q: 5.657624244689941
    learner_queue:
      size_count: 90580
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4963869458396343
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1031
    num_steps_sampled: 487450
    num_steps_trained: 7788544
    num_target_updates: 155
    num_weight_syncs: 1217
    replay_shard_0:
      add_batch_time_ms: 3.231
      policy_default_policy:
        added_count: 122750
        est_size_bytes: 41857750
        num_entries: 122750
        sampled_count: 1934336
      replay_time_ms: 20.523
      update_priorities_time_ms: 48.918
    sample_throughput: 0.0
    train_throughput: 46189.397
  iterations_since_restore: 12
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3286108537835973
    mean_inference_ms: 0.8818398492215043
    mean_processing_ms: 0.20603600566734767
  time_since_restore: 362.55409598350525
  time_this_iter_s: 30.216066598892212
  time_total_s: 362.55409598350525
  timestamp: 1563763335
  timesteps_since_restore: 487450
  timesteps_this_iter: 39500
  timesteps_total: 487450
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 362 s, 12 iter, 487450 ts, 13.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-42-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.96555348577632
  episode_reward_mean: 15.621132570904082
  episode_reward_min: -9.95608235548051
  episodes_this_iter: 131
  episodes_total: 1757
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.955387115478516
        mean_q: 17.11416244506836
        min_q: 1.7216235399246216
    learner_queue:
      size_count: 91929
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 2.0
      - 2.0
      size_std: 0.7378346698278687
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1041
    num_steps_sampled: 526750
    num_steps_trained: 8479744
    num_target_updates: 168
    num_weight_syncs: 1316
    replay_shard_0:
      add_batch_time_ms: 2.726
      policy_default_policy:
        added_count: 132550
        est_size_bytes: 45199550
        num_entries: 132550
        sampled_count: 2103296
      replay_time_ms: 16.961
      update_priorities_time_ms: 50.671
    sample_throughput: 0.0
    train_throughput: 38276.837
  iterations_since_restore: 13
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3290973517037861
    mean_inference_ms: 0.8849915758759311
    mean_processing_ms: 0.2063673268253558
  time_since_restore: 392.7539691925049
  time_this_iter_s: 30.199873208999634
  time_total_s: 392.7539691925049
  timestamp: 1563763365
  timesteps_since_restore: 526750
  timesteps_this_iter: 39300
  timesteps_total: 526750
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 392 s, 13 iter, 526750 ts, 15.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-43-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.987754374763355
  episode_reward_mean: 13.529225411283216
  episode_reward_min: -17.920501981023843
  episodes_this_iter: 132
  episodes_total: 1889
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.00916290283203
        mean_q: 17.23908233642578
        min_q: -6.634298324584961
    learner_queue:
      size_count: 93282
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103862
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1051
    num_steps_sampled: 566250
    num_steps_trained: 9171456
    num_target_updates: 182
    num_weight_syncs: 1415
    replay_shard_0:
      add_batch_time_ms: 3.081
      policy_default_policy:
        added_count: 141500
        est_size_bytes: 48251500
        num_entries: 141500
        sampled_count: 2274816
      replay_time_ms: 18.748
      update_priorities_time_ms: 54.079
    sample_throughput: 2446.486
    train_throughput: 25052.013
  iterations_since_restore: 14
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.32973715082446703
    mean_inference_ms: 0.8866278584707529
    mean_processing_ms: 0.2068231230932736
  time_since_restore: 422.9567744731903
  time_this_iter_s: 30.202805280685425
  time_total_s: 422.9567744731903
  timestamp: 1563763395
  timesteps_since_restore: 566250
  timesteps_this_iter: 39500
  timesteps_total: 566250
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 422 s, 14 iter, 566250 ts, 13.5 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:43:45,890	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-43-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.96951354188201
  episode_reward_mean: 15.267509287454914
  episode_reward_min: -6.665334048426373
  episodes_this_iter: 131
  episodes_total: 2020
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 27.152490320618714
    episode_reward_mean: 13.358907634839628
    episode_reward_min: -1.4173111748608744
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14441113852596427
      mean_inference_ms: 0.3909192230677211
      mean_processing_ms: 0.08259743695417218
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.97749710083008
        mean_q: 16.31815528869629
        min_q: 5.182233810424805
    learner_queue:
      size_count: 94630
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5291502622129182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1059
    num_steps_sampled: 605600
    num_steps_trained: 9862656
    num_target_updates: 196
    num_weight_syncs: 1513
    replay_shard_0:
      add_batch_time_ms: 2.998
      policy_default_policy:
        added_count: 151100
        est_size_bytes: 51525100
        num_entries: 151100
        sampled_count: 2446336
      replay_time_ms: 19.279
      update_priorities_time_ms: 49.366
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 15
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33005892109941476
    mean_inference_ms: 0.8883512265845444
    mean_processing_ms: 0.20731165312076752
  time_since_restore: 453.16724491119385
  time_this_iter_s: 30.21047043800354
  time_total_s: 453.16724491119385
  timestamp: 1563763425
  timesteps_since_restore: 605600
  timesteps_this_iter: 39350
  timesteps_total: 605600
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 453 s, 15 iter, 605600 ts, 15.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-44-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.07317799267482
  episode_reward_mean: 14.45848747433653
  episode_reward_min: -8.399107408129858
  episodes_this_iter: 132
  episodes_total: 2152
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.191650390625
        mean_q: 15.598934173583984
        min_q: 4.6912407875061035
    learner_queue:
      size_count: 95972
      size_mean: 0.6
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.1000000000000014
      - 2.0
      size_std: 0.6633249580710799
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1069
    num_steps_sampled: 645200
    num_steps_trained: 10549248
    num_target_updates: 210
    num_weight_syncs: 1612
    replay_shard_0:
      add_batch_time_ms: 2.403
      policy_default_policy:
        added_count: 161300
        est_size_bytes: 55003300
        num_entries: 161300
        sampled_count: 2616832
      replay_time_ms: 21.232
      update_priorities_time_ms: 55.459
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 16
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33042174814856773
    mean_inference_ms: 0.8898324060708763
    mean_processing_ms: 0.20750124782189874
  time_since_restore: 483.39765334129333
  time_this_iter_s: 30.230408430099487
  time_total_s: 483.39765334129333
  timestamp: 1563763457
  timesteps_since_restore: 645200
  timesteps_this_iter: 39600
  timesteps_total: 645200
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 483 s, 16 iter, 645200 ts, 14.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-44-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.10057149152447
  episode_reward_mean: 14.813183549341101
  episode_reward_min: -17.30068237309676
  episodes_this_iter: 131
  episodes_total: 2283
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.56991195678711
        mean_q: 14.995800971984863
        min_q: 2.382326602935791
    learner_queue:
      size_count: 97315
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4935585071701226
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1078
    num_steps_sampled: 684600
    num_steps_trained: 11237376
    num_target_updates: 223
    num_weight_syncs: 1711
    replay_shard_0:
      add_batch_time_ms: 2.69
      policy_default_policy:
        added_count: 171900
        est_size_bytes: 58617900
        num_entries: 171900
        sampled_count: 2786816
      replay_time_ms: 17.742
      update_priorities_time_ms: 52.005
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 17
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3307110556005886
    mean_inference_ms: 0.8912812558024213
    mean_processing_ms: 0.20775067449870074
  time_since_restore: 513.5943613052368
  time_this_iter_s: 30.19670796394348
  time_total_s: 513.5943613052368
  timestamp: 1563763487
  timesteps_since_restore: 684600
  timesteps_this_iter: 39400
  timesteps_total: 684600
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 513 s, 17 iter, 684600 ts, 14.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-45-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.37495784533679
  episode_reward_mean: 14.276868714209234
  episode_reward_min: -17.41597403492744
  episodes_this_iter: 131
  episodes_total: 2414
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.38052749633789
        mean_q: 15.264333724975586
        min_q: 1.1161247491836548
    learner_queue:
      size_count: 98654
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4853864439804639
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1086
    num_steps_sampled: 724000
    num_steps_trained: 11922432
    num_target_updates: 237
    num_weight_syncs: 1810
    replay_shard_0:
      add_batch_time_ms: 2.643
      policy_default_policy:
        added_count: 181900
        est_size_bytes: 62027900
        num_entries: 181900
        sampled_count: 2957312
      replay_time_ms: 18.889
      update_priorities_time_ms: 48.892
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 18
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33107391636027805
    mean_inference_ms: 0.892668398450051
    mean_processing_ms: 0.20803507533704949
  time_since_restore: 543.8023152351379
  time_this_iter_s: 30.207953929901123
  time_total_s: 543.8023152351379
  timestamp: 1563763517
  timesteps_since_restore: 724000
  timesteps_this_iter: 39400
  timesteps_total: 724000
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 543 s, 18 iter, 724000 ts, 14.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-45-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.83883021327597
  episode_reward_mean: 16.13829099791103
  episode_reward_min: -16.31226077447006
  episodes_this_iter: 131
  episodes_total: 2545
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 40.75975036621094
        mean_q: 14.398455619812012
        min_q: 3.159146785736084
    learner_queue:
      size_count: 99994
      size_mean: 0.6
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.1000000000000014
      - 2.0
      size_std: 0.6633249580710799
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1094
    num_steps_sampled: 763450
    num_steps_trained: 12608000
    num_target_updates: 251
    num_weight_syncs: 1908
    replay_shard_0:
      add_batch_time_ms: 2.054
      policy_default_policy:
        added_count: 191500
        est_size_bytes: 65301500
        num_entries: 191500
        sampled_count: 3128320
      replay_time_ms: 19.366
      update_priorities_time_ms: 51.425
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 19
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3314002881607413
    mean_inference_ms: 0.8937213122758053
    mean_processing_ms: 0.2082601615766702
  time_since_restore: 574.0007405281067
  time_this_iter_s: 30.19842529296875
  time_total_s: 574.0007405281067
  timestamp: 1563763547
  timesteps_since_restore: 763450
  timesteps_this_iter: 39450
  timesteps_total: 763450
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 574 s, 19 iter, 763450 ts, 16.1 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:46:17,881	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-46-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.96532551566952
  episode_reward_mean: 14.40390633416925
  episode_reward_min: -17.069622315805788
  episodes_this_iter: 132
  episodes_total: 2677
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 32.371269266767825
    episode_reward_mean: 15.390837078012831
    episode_reward_min: 2.5137983040415564
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14558793258514421
      mean_inference_ms: 0.3939175539025623
      mean_processing_ms: 0.08295037208946685
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 40.50838851928711
        mean_q: 14.39760971069336
        min_q: 3.2176780700683594
    learner_queue:
      size_count: 101323
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5713142742834281
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1101
    num_steps_sampled: 803150
    num_steps_trained: 13288960
    num_target_updates: 264
    num_weight_syncs: 2007
    replay_shard_0:
      add_batch_time_ms: 2.468
      policy_default_policy:
        added_count: 200800
        est_size_bytes: 68472800
        num_entries: 200800
        sampled_count: 3295744
      replay_time_ms: 19.812
      update_priorities_time_ms: 48.3
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 20
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33168822986152763
    mean_inference_ms: 0.8943260862713739
    mean_processing_ms: 0.20829776376406803
  time_since_restore: 604.2087194919586
  time_this_iter_s: 30.20797896385193
  time_total_s: 604.2087194919586
  timestamp: 1563763577
  timesteps_since_restore: 803150
  timesteps_this_iter: 39700
  timesteps_total: 803150
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 604 s, 20 iter, 803150 ts, 14.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-46-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.20997396184734
  episode_reward_mean: 16.36908148293311
  episode_reward_min: -4.686589222803961
  episodes_this_iter: 132
  episodes_total: 2809
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.2477912902832
        mean_q: 14.060405731201172
        min_q: 4.021448612213135
    learner_queue:
      size_count: 102667
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1109
    num_steps_sampled: 842650
    num_steps_trained: 13976576
    num_target_updates: 278
    num_weight_syncs: 2106
    replay_shard_0:
      add_batch_time_ms: 3.08
      policy_default_policy:
        added_count: 211100
        est_size_bytes: 71985100
        num_entries: 211100
        sampled_count: 3464704
      replay_time_ms: 19.709
      update_priorities_time_ms: 50.492
    sample_throughput: 0.0
    train_throughput: 21915.111
  iterations_since_restore: 21
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33196356483161016
    mean_inference_ms: 0.8951120954899803
    mean_processing_ms: 0.20838145131747182
  time_since_restore: 634.4163000583649
  time_this_iter_s: 30.20758056640625
  time_total_s: 634.4163000583649
  timestamp: 1563763609
  timesteps_since_restore: 842650
  timesteps_this_iter: 39500
  timesteps_total: 842650
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 634 s, 21 iter, 842650 ts, 16.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-47-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.62595266659058
  episode_reward_mean: 17.58163940740291
  episode_reward_min: -5.0276053460580306
  episodes_this_iter: 132
  episodes_total: 2941
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 40.63673400878906
        mean_q: 13.911088943481445
        min_q: 3.035353183746338
    learner_queue:
      size_count: 103999
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5730619512757762
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1118
    num_steps_sampled: 882300
    num_steps_trained: 14659072
    num_target_updates: 292
    num_weight_syncs: 2204
    replay_shard_0:
      add_batch_time_ms: 3.466
      policy_default_policy:
        added_count: 220850
        est_size_bytes: 75309850
        num_entries: 220850
        sampled_count: 3633664
      replay_time_ms: 20.135
      update_priorities_time_ms: 48.999
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 22
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33200157883319914
    mean_inference_ms: 0.8956795501966611
    mean_processing_ms: 0.20855242876031996
  time_since_restore: 664.630006313324
  time_this_iter_s: 30.213706254959106
  time_total_s: 664.630006313324
  timestamp: 1563763639
  timesteps_since_restore: 882300
  timesteps_this_iter: 39650
  timesteps_total: 882300
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 664 s, 22 iter, 882300 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-47-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.99291353767447
  episode_reward_mean: 15.445221093923434
  episode_reward_min: -5.416980384209575
  episodes_this_iter: 132
  episodes_total: 3073
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.38393783569336
        mean_q: 13.129398345947266
        min_q: 2.953305244445801
    learner_queue:
      size_count: 105327
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5291502622129182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1127
    num_steps_sampled: 922000
    num_steps_trained: 15339008
    num_target_updates: 305
    num_weight_syncs: 2304
    replay_shard_0:
      add_batch_time_ms: 2.614
      policy_default_policy:
        added_count: 230600
        est_size_bytes: 78634600
        num_entries: 230600
        sampled_count: 3800576
      replay_time_ms: 21.221
      update_priorities_time_ms: 51.265
    sample_throughput: 2778.955
    train_throughput: 14228.248
  iterations_since_restore: 23
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33224650497661756
    mean_inference_ms: 0.8963374892377975
    mean_processing_ms: 0.2085787578452858
  time_since_restore: 694.8155255317688
  time_this_iter_s: 30.185519218444824
  time_total_s: 694.8155255317688
  timestamp: 1563763669
  timesteps_since_restore: 922000
  timesteps_this_iter: 39700
  timesteps_total: 922000
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 694 s, 23 iter, 922000 ts, 15.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-48-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.96720914212229
  episode_reward_mean: 15.384154519953686
  episode_reward_min: -8.141541425116374
  episodes_this_iter: 130
  episodes_total: 3203
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.874671936035156
        mean_q: 12.23324966430664
        min_q: 3.595144271850586
    learner_queue:
      size_count: 106650
      size_mean: 0.58
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5688585061331156
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1139
    num_steps_sampled: 961150
    num_steps_trained: 16016384
    num_target_updates: 319
    num_weight_syncs: 2402
    replay_shard_0:
      add_batch_time_ms: 3.387
      policy_default_policy:
        added_count: 239750
        est_size_bytes: 81754750
        num_entries: 239750
        sampled_count: 3971072
      replay_time_ms: 19.479
      update_priorities_time_ms: 48.245
    sample_throughput: 0.0
    train_throughput: 38565.888
  iterations_since_restore: 24
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3324316397481493
    mean_inference_ms: 0.8970012019342024
    mean_processing_ms: 0.20869104720878912
  time_since_restore: 725.0432922840118
  time_this_iter_s: 30.227766752243042
  time_total_s: 725.0432922840118
  timestamp: 1563763699
  timesteps_since_restore: 961150
  timesteps_this_iter: 39150
  timesteps_total: 961150
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 725 s, 24 iter, 961150 ts, 15.4 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:48:49,962	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-48-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.01718991903065
  episode_reward_mean: 16.374865585815776
  episode_reward_min: -9.192743555768516
  episodes_this_iter: 133
  episodes_total: 3336
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 38.272704707884095
    episode_reward_mean: 16.090331315717595
    episode_reward_min: -6.412972309745711
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14710715049876727
      mean_inference_ms: 0.39879895093612916
      mean_processing_ms: 0.08329605078805805
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.39665603637695
        mean_q: 12.382015228271484
        min_q: 2.0337235927581787
    learner_queue:
      size_count: 107979
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5381449618829484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1148
    num_steps_sampled: 1000800
    num_steps_trained: 16697344
    num_target_updates: 332
    num_weight_syncs: 2501
    replay_shard_0:
      add_batch_time_ms: 2.966
      policy_default_policy:
        added_count: 249500
        est_size_bytes: 85079500
        num_entries: 249500
        sampled_count: 4137984
      replay_time_ms: 21.298
      update_priorities_time_ms: 54.206
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 25
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3325943576146827
    mean_inference_ms: 0.8973447606924152
    mean_processing_ms: 0.20873626478029467
  time_since_restore: 755.2843623161316
  time_this_iter_s: 30.24107003211975
  time_total_s: 755.2843623161316
  timestamp: 1563763729
  timesteps_since_restore: 1000800
  timesteps_this_iter: 39650
  timesteps_total: 1000800
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 755 s, 25 iter, 1000800 ts, 16.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-49-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.84592929998433
  episode_reward_mean: 17.665999050195428
  episode_reward_min: -6.593876022053558
  episodes_this_iter: 132
  episodes_total: 3468
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.21501922607422
        mean_q: 11.391529083251953
        min_q: 1.4282751083374023
    learner_queue:
      size_count: 109310
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      - 3.0
      size_std: 0.7525955088890712
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1159
    num_steps_sampled: 1040600
    num_steps_trained: 17378816
    num_target_updates: 346
    num_weight_syncs: 2601
    replay_shard_0:
      add_batch_time_ms: 3.06
      policy_default_policy:
        added_count: 259150
        est_size_bytes: 88370150
        num_entries: 259150
        sampled_count: 4306432
      replay_time_ms: 18.898
      update_priorities_time_ms: 52.473
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 26
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3326658657728645
    mean_inference_ms: 0.8975068127463262
    mean_processing_ms: 0.2087585441718409
  time_since_restore: 785.4659059047699
  time_this_iter_s: 30.181543588638306
  time_total_s: 785.4659059047699
  timestamp: 1563763761
  timesteps_since_restore: 1040600
  timesteps_this_iter: 39800
  timesteps_total: 1040600
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 785 s, 26 iter, 1040600 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-49-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.06809305353741
  episode_reward_mean: 15.272339768519231
  episode_reward_min: -20.362694037253917
  episodes_this_iter: 132
  episodes_total: 3600
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.431419372558594
        mean_q: 10.707866668701172
        min_q: 1.044399380683899
    learner_queue:
      size_count: 110651
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.64
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1164
    num_steps_sampled: 1080250
    num_steps_trained: 18064896
    num_target_updates: 360
    num_weight_syncs: 2700
    replay_shard_0:
      add_batch_time_ms: 2.731
      policy_default_policy:
        added_count: 268650
        est_size_bytes: 91609650
        num_entries: 268650
        sampled_count: 4477440
      replay_time_ms: 18.182
      update_priorities_time_ms: 48.571
    sample_throughput: 3921.083
    train_throughput: 40151.889
  iterations_since_restore: 27
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3328086208619447
    mean_inference_ms: 0.8977190322525797
    mean_processing_ms: 0.20885156980954253
  time_since_restore: 815.664803981781
  time_this_iter_s: 30.19889807701111
  time_total_s: 815.664803981781
  timestamp: 1563763791
  timesteps_since_restore: 1080250
  timesteps_this_iter: 39650
  timesteps_total: 1080250
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 815 s, 27 iter, 1080250 ts, 15.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-50-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.917618300819015
  episode_reward_mean: 15.41115648900994
  episode_reward_min: -11.81853503726211
  episodes_this_iter: 133
  episodes_total: 3733
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.783382415771484
        mean_q: 10.230657577514648
        min_q: 0.548453688621521
    learner_queue:
      size_count: 111986
      size_mean: 0.8
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.7483314773547883
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1170
    num_steps_sampled: 1120100
    num_steps_trained: 18748416
    num_target_updates: 373
    num_weight_syncs: 2799
    replay_shard_0:
      add_batch_time_ms: 3.291
      policy_default_policy:
        added_count: 277550
        est_size_bytes: 94644550
        num_entries: 277550
        sampled_count: 4646400
      replay_time_ms: 19.839
      update_priorities_time_ms: 51.122
    sample_throughput: 0.0
    train_throughput: 35687.899
  iterations_since_restore: 28
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3328814008762878
    mean_inference_ms: 0.8979145076420229
    mean_processing_ms: 0.20895160560999843
  time_since_restore: 845.8657319545746
  time_this_iter_s: 30.20092797279358
  time_total_s: 845.8657319545746
  timestamp: 1563763821
  timesteps_since_restore: 1120100
  timesteps_this_iter: 39850
  timesteps_total: 1120100
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 845 s, 28 iter, 1120100 ts, 15.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-50-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.50769915612563
  episode_reward_mean: 17.512422748327737
  episode_reward_min: -10.287052859587916
  episodes_this_iter: 131
  episodes_total: 3864
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.10942077636719
        mean_q: 9.854857444763184
        min_q: 0.4630579650402069
    learner_queue:
      size_count: 113312
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5385164807134504
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1191
    num_steps_sampled: 1159350
    num_steps_trained: 19427328
    num_target_updates: 387
    num_weight_syncs: 2897
    replay_shard_0:
      add_batch_time_ms: 3.075
      policy_default_policy:
        added_count: 288650
        est_size_bytes: 98429650
        num_entries: 288650
        sampled_count: 4816896
      replay_time_ms: 19.811
      update_priorities_time_ms: 51.596
    sample_throughput: 3395.978
    train_throughput: 34774.811
  iterations_since_restore: 29
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33295386469811455
    mean_inference_ms: 0.8981306253288783
    mean_processing_ms: 0.20895637446285803
  time_since_restore: 876.0929751396179
  time_this_iter_s: 30.227243185043335
  time_total_s: 876.0929751396179
  timestamp: 1563763851
  timesteps_since_restore: 1159350
  timesteps_this_iter: 39250
  timesteps_total: 1159350
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 876 s, 29 iter, 1159350 ts, 17.5 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:51:22,035	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-51-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.79118044199232
  episode_reward_mean: 17.711461356236253
  episode_reward_min: -10.449636121976319
  episodes_this_iter: 132
  episodes_total: 3996
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 26.949873674932082
    episode_reward_mean: 12.965911811412147
    episode_reward_min: -1.046222016499924
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1462179301477775
      mean_inference_ms: 0.3963995974309761
      mean_processing_ms: 0.08263096175027138
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.322349548339844
        mean_q: 9.650869369506836
        min_q: 0.7054157853126526
    learner_queue:
      size_count: 114644
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.0
      - 2.0
      size_std: 0.5381449618829484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1200
    num_steps_sampled: 1199050
    num_steps_trained: 20109312
    num_target_updates: 400
    num_weight_syncs: 2997
    replay_shard_0:
      add_batch_time_ms: 3.246
      policy_default_policy:
        added_count: 298500
        est_size_bytes: 101788500
        num_entries: 298500
        sampled_count: 4985344
      replay_time_ms: 18.772
      update_priorities_time_ms: 46.405
    sample_throughput: 3652.366
    train_throughput: 37400.227
  iterations_since_restore: 30
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33306898233020704
    mean_inference_ms: 0.8984406761302904
    mean_processing_ms: 0.20898820777003596
  time_since_restore: 906.3104975223541
  time_this_iter_s: 30.217522382736206
  time_total_s: 906.3104975223541
  timestamp: 1563763882
  timesteps_since_restore: 1199050
  timesteps_this_iter: 39700
  timesteps_total: 1199050
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 906 s, 30 iter, 1199050 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-51-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.769837154383715
  episode_reward_mean: 15.968849668059166
  episode_reward_min: -17.0436392163414
  episodes_this_iter: 133
  episodes_total: 4129
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.66059112548828
        mean_q: 9.407708168029785
        min_q: 0.7022005319595337
    learner_queue:
      size_count: 115974
      size_mean: 0.6
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1209
    num_steps_sampled: 1238800
    num_steps_trained: 20790272
    num_target_updates: 414
    num_weight_syncs: 3096
    replay_shard_0:
      add_batch_time_ms: 2.495
      policy_default_policy:
        added_count: 308800
        est_size_bytes: 105300800
        num_entries: 308800
        sampled_count: 5155328
      replay_time_ms: 19.582
      update_priorities_time_ms: 51.539
    sample_throughput: 0.0
    train_throughput: 28498.98
  iterations_since_restore: 31
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3330879746954462
    mean_inference_ms: 0.8983683177992078
    mean_processing_ms: 0.2090404016805331
  time_since_restore: 936.5539445877075
  time_this_iter_s: 30.243447065353394
  time_total_s: 936.5539445877075
  timestamp: 1563763913
  timesteps_since_restore: 1238800
  timesteps_this_iter: 39750
  timesteps_total: 1238800
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 936 s, 31 iter, 1238800 ts, 16 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-52-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.10877438951946
  episode_reward_mean: 17.55665078511744
  episode_reward_min: -5.098599962804842
  episodes_this_iter: 133
  episodes_total: 4262
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.03608703613281
        mean_q: 8.768848419189453
        min_q: 0.6597000360488892
    learner_queue:
      size_count: 117301
      size_mean: 0.28
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.44899888641287294
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1217
    num_steps_sampled: 1278550
    num_steps_trained: 21469696
    num_target_updates: 427
    num_weight_syncs: 3196
    replay_shard_0:
      add_batch_time_ms: 3.266
      policy_default_policy:
        added_count: 318350
        est_size_bytes: 108557350
        num_entries: 318350
        sampled_count: 5322752
      replay_time_ms: 19.945
      update_priorities_time_ms: 52.039
    sample_throughput: 0.0
    train_throughput: 54564.211
  iterations_since_restore: 32
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3331582980828043
    mean_inference_ms: 0.8984500749213201
    mean_processing_ms: 0.20910376992085472
  time_since_restore: 966.7612674236298
  time_this_iter_s: 30.20732283592224
  time_total_s: 966.7612674236298
  timestamp: 1563763943
  timesteps_since_restore: 1278550
  timesteps_this_iter: 39750
  timesteps_total: 1278550
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 966 s, 32 iter, 1278550 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-52-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.193688538491855
  episode_reward_mean: 15.754664207328387
  episode_reward_min: -14.70145639070096
  episodes_this_iter: 130
  episodes_total: 4392
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.48929977416992
        mean_q: 9.165397644042969
        min_q: 0.8400703072547913
    learner_queue:
      size_count: 118624
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5617828762075255
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1236
    num_steps_sampled: 1317650
    num_steps_trained: 22147584
    num_target_updates: 441
    num_weight_syncs: 3293
    replay_shard_0:
      add_batch_time_ms: 2.835
      policy_default_policy:
        added_count: 328750
        est_size_bytes: 112103750
        num_entries: 328750
        sampled_count: 5489664
      replay_time_ms: 21.029
      update_priorities_time_ms: 51.546
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 33
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33330009389742665
    mean_inference_ms: 0.898787351342018
    mean_processing_ms: 0.20917697901578494
  time_since_restore: 996.9570860862732
  time_this_iter_s: 30.195818662643433
  time_total_s: 996.9570860862732
  timestamp: 1563763973
  timesteps_since_restore: 1317650
  timesteps_this_iter: 39100
  timesteps_total: 1317650
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 996 s, 33 iter, 1317650 ts, 15.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-53-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.17277518468231
  episode_reward_mean: 17.02979584868936
  episode_reward_min: -6.22311359476763
  episodes_this_iter: 133
  episodes_total: 4525
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.30741882324219
        mean_q: 8.267396926879883
        min_q: 0.3886527419090271
    learner_queue:
      size_count: 119951
      size_mean: 0.26
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4386342439892262
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1245
    num_steps_sampled: 1357350
    num_steps_trained: 22826496
    num_target_updates: 454
    num_weight_syncs: 3392
    replay_shard_0:
      add_batch_time_ms: 3.004
      policy_default_policy:
        added_count: 339000
        est_size_bytes: 115599000
        num_entries: 339000
        sampled_count: 5657600
      replay_time_ms: 18.254
      update_priorities_time_ms: 51.362
    sample_throughput: 0.0
    train_throughput: 32493.814
  iterations_since_restore: 34
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33329403213849
    mean_inference_ms: 0.8989391904995173
    mean_processing_ms: 0.20916066519826298
  time_since_restore: 1027.1617064476013
  time_this_iter_s: 30.204620361328125
  time_total_s: 1027.1617064476013
  timestamp: 1563764003
  timesteps_since_restore: 1357350
  timesteps_this_iter: 39700
  timesteps_total: 1357350
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1027 s, 34 iter, 1357350 ts, 17 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:53:54,058	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-53-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.116887959810526
  episode_reward_mean: 14.821767413558133
  episode_reward_min: -12.367659235720383
  episodes_this_iter: 132
  episodes_total: 4657
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 28.0741753477048
    episode_reward_mean: 14.744417007559743
    episode_reward_min: 1.1748485400821527
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14633781144484098
      mean_inference_ms: 0.3968556020053443
      mean_processing_ms: 0.08268124281828647
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.10340118408203
        mean_q: 8.530630111694336
        min_q: 0.5272188186645508
    learner_queue:
      size_count: 121275
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.6708203932499369
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1256
    num_steps_sampled: 1397000
    num_steps_trained: 23504384
    num_target_updates: 468
    num_weight_syncs: 3492
    replay_shard_0:
      add_batch_time_ms: 2.952
      policy_default_policy:
        added_count: 348700
        est_size_bytes: 118906700
        num_entries: 348700
        sampled_count: 5825024
      replay_time_ms: 16.436
      update_priorities_time_ms: 51.479
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 35
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.333363367955621
    mean_inference_ms: 0.8991614046246718
    mean_processing_ms: 0.2092030707050445
  time_since_restore: 1057.3827576637268
  time_this_iter_s: 30.22105121612549
  time_total_s: 1057.3827576637268
  timestamp: 1563764034
  timesteps_since_restore: 1397000
  timesteps_this_iter: 39650
  timesteps_total: 1397000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1057 s, 35 iter, 1397000 ts, 14.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-54-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.40382258321411
  episode_reward_mean: 16.523912270161894
  episode_reward_min: -2.828033848742387
  episodes_this_iter: 132
  episodes_total: 4789
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.62929916381836
        mean_q: 8.543991088867188
        min_q: -0.0410006158053875
    learner_queue:
      size_count: 122602
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5381449618829484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1265
    num_steps_sampled: 1436650
    num_steps_trained: 24183808
    num_target_updates: 481
    num_weight_syncs: 3590
    replay_shard_0:
      add_batch_time_ms: 2.591
      policy_default_policy:
        added_count: 359300
        est_size_bytes: 122521300
        num_entries: 359300
        sampled_count: 5992448
      replay_time_ms: 21.616
      update_priorities_time_ms: 54.17
    sample_throughput: 0.0
    train_throughput: 28277.944
  iterations_since_restore: 36
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3335076916215663
    mean_inference_ms: 0.8992826836196254
    mean_processing_ms: 0.20921055866619162
  time_since_restore: 1087.6050477027893
  time_this_iter_s: 30.2222900390625
  time_total_s: 1087.6050477027893
  timestamp: 1563764065
  timesteps_since_restore: 1436650
  timesteps_this_iter: 39650
  timesteps_total: 1436650
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1087 s, 36 iter, 1436650 ts, 16.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-54-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.73755224652229
  episode_reward_mean: 16.553730110209035
  episode_reward_min: -2.5334806632365527
  episodes_this_iter: 133
  episodes_total: 4922
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.75446701049805
        mean_q: 8.058164596557617
        min_q: -0.022930588573217392
    learner_queue:
      size_count: 123922
      size_mean: 0.6
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      - 2.0
      size_std: 0.6928203230275509
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1273
    num_steps_sampled: 1476550
    num_steps_trained: 24859136
    num_target_updates: 495
    num_weight_syncs: 3690
    replay_shard_0:
      add_batch_time_ms: 3.234
      policy_default_policy:
        added_count: 368900
        est_size_bytes: 125794900
        num_entries: 368900
        sampled_count: 6159360
      replay_time_ms: 21.179
      update_priorities_time_ms: 52.025
    sample_throughput: 0.0
    train_throughput: 43863.794
  iterations_since_restore: 37
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3334874317149334
    mean_inference_ms: 0.8993093166864535
    mean_processing_ms: 0.20919708989079663
  time_since_restore: 1117.8103041648865
  time_this_iter_s: 30.205256462097168
  time_total_s: 1117.8103041648865
  timestamp: 1563764095
  timesteps_since_restore: 1476550
  timesteps_this_iter: 39900
  timesteps_total: 1476550
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1117 s, 37 iter, 1476550 ts, 16.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-55-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.62679897235224
  episode_reward_mean: 15.927775762099554
  episode_reward_min: -3.612831126348436
  episodes_this_iter: 130
  episodes_total: 5052
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.52116012573242
        mean_q: 7.996226787567139
        min_q: -0.3756183683872223
    learner_queue:
      size_count: 125234
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1291
    num_steps_sampled: 1515800
    num_steps_trained: 25531392
    num_target_updates: 508
    num_weight_syncs: 3789
    replay_shard_0:
      add_batch_time_ms: 2.91
      policy_default_policy:
        added_count: 378950
        est_size_bytes: 129221950
        num_entries: 378950
        sampled_count: 6325760
      replay_time_ms: 20.26
      update_priorities_time_ms: 54.033
    sample_throughput: 2513.636
    train_throughput: 25739.637
  iterations_since_restore: 38
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.333545635176645
    mean_inference_ms: 0.8995582406476716
    mean_processing_ms: 0.2092642907061819
  time_since_restore: 1148.0335447788239
  time_this_iter_s: 30.223240613937378
  time_total_s: 1148.0335447788239
  timestamp: 1563764125
  timesteps_since_restore: 1515800
  timesteps_this_iter: 39250
  timesteps_total: 1515800
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1148 s, 38 iter, 1515800 ts, 15.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-55-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.036272175799176
  episode_reward_mean: 17.885230452210855
  episode_reward_min: -10.949434298152347
  episodes_this_iter: 133
  episodes_total: 5185
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.99903869628906
        mean_q: 8.672773361206055
        min_q: -3.8305327892303467
    learner_queue:
      size_count: 126551
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5741080037762929
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1300
    num_steps_sampled: 1555750
    num_steps_trained: 26205696
    num_target_updates: 522
    num_weight_syncs: 3889
    replay_shard_0:
      add_batch_time_ms: 2.972
      policy_default_policy:
        added_count: 388850
        est_size_bytes: 132597850
        num_entries: 388850
        sampled_count: 6492672
      replay_time_ms: 21.374
      update_priorities_time_ms: 51.599
    sample_throughput: 0.0
    train_throughput: 23830.215
  iterations_since_restore: 39
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3336085280544544
    mean_inference_ms: 0.8994580143986742
    mean_processing_ms: 0.2093013773746064
  time_since_restore: 1178.265736579895
  time_this_iter_s: 30.232191801071167
  time_total_s: 1178.265736579895
  timestamp: 1563764155
  timesteps_since_restore: 1555750
  timesteps_this_iter: 39950
  timesteps_total: 1555750
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1178 s, 39 iter, 1555750 ts, 17.9 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:56:26,134	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-56-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.700308641835925
  episode_reward_mean: 16.754652892396816
  episode_reward_min: -5.480221077634327
  episodes_this_iter: 133
  episodes_total: 5318
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 26.163704571374044
    episode_reward_mean: 17.12469487987701
    episode_reward_min: 8.92208791395097
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14558043994512235
      mean_inference_ms: 0.3951159541443201
      mean_processing_ms: 0.0821663957023239
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.837127685546875
        mean_q: 8.31950855255127
        min_q: -0.1769041270017624
    learner_queue:
      size_count: 127877
      size_mean: 0.32
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5075431016179808
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1308
    num_steps_sampled: 1595550
    num_steps_trained: 26884608
    num_target_updates: 535
    num_weight_syncs: 3988
    replay_shard_0:
      add_batch_time_ms: 2.611
      policy_default_policy:
        added_count: 398250
        est_size_bytes: 135803250
        num_entries: 398250
        sampled_count: 6661632
      replay_time_ms: 16.736
      update_priorities_time_ms: 52.253
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 40
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33373317647424183
    mean_inference_ms: 0.8994520778006132
    mean_processing_ms: 0.2092984444110149
  time_since_restore: 1208.4690470695496
  time_this_iter_s: 30.20331048965454
  time_total_s: 1208.4690470695496
  timestamp: 1563764186
  timesteps_since_restore: 1595550
  timesteps_this_iter: 39800
  timesteps_total: 1595550
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1208 s, 40 iter, 1595550 ts, 16.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-56-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.839957521787255
  episode_reward_mean: 16.876476020525274
  episode_reward_min: -6.67742736421268
  episodes_this_iter: 132
  episodes_total: 5450
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.0673828125
        mean_q: 7.745761394500732
        min_q: -0.01573306694626808
    learner_queue:
      size_count: 129207
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.52
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1319
    num_steps_sampled: 1635250
    num_steps_trained: 27566080
    num_target_updates: 549
    num_weight_syncs: 4087
    replay_shard_0:
      add_batch_time_ms: 2.712
      policy_default_policy:
        added_count: 406650
        est_size_bytes: 138667650
        num_entries: 406650
        sampled_count: 6831104
      replay_time_ms: 20.114
      update_priorities_time_ms: 50.472
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 41
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33376348880967743
    mean_inference_ms: 0.8995374324909369
    mean_processing_ms: 0.20937656739795424
  time_since_restore: 1238.6780223846436
  time_this_iter_s: 30.208975315093994
  time_total_s: 1238.6780223846436
  timestamp: 1563764217
  timesteps_since_restore: 1635250
  timesteps_this_iter: 39700
  timesteps_total: 1635250
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1238 s, 41 iter, 1635250 ts, 16.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-57-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.054334765290974
  episode_reward_mean: 18.46074033748764
  episode_reward_min: -5.254715047337805
  episodes_this_iter: 134
  episodes_total: 5584
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.53302001953125
        mean_q: 7.999960422515869
        min_q: -5.58656644821167
    learner_queue:
      size_count: 130527
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5249761899362675
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1330
    num_steps_sampled: 1675300
    num_steps_trained: 28241408
    num_target_updates: 562
    num_weight_syncs: 4187
    replay_shard_0:
      add_batch_time_ms: 3.418
      policy_default_policy:
        added_count: 416400
        est_size_bytes: 141992400
        num_entries: 416400
        sampled_count: 7001088
      replay_time_ms: 19.863
      update_priorities_time_ms: 54.591
    sample_throughput: 3249.56
    train_throughput: 33275.49
  iterations_since_restore: 42
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337423545193614
    mean_inference_ms: 0.8994933724435688
    mean_processing_ms: 0.20936378459894006
  time_since_restore: 1268.9193511009216
  time_this_iter_s: 30.241328716278076
  time_total_s: 1268.9193511009216
  timestamp: 1563764247
  timesteps_since_restore: 1675300
  timesteps_this_iter: 40050
  timesteps_total: 1675300
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1268 s, 42 iter, 1675300 ts, 18.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-57-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.777807360443234
  episode_reward_mean: 18.33317512783517
  episode_reward_min: -8.740100635930641
  episodes_this_iter: 130
  episodes_total: 5714
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.03867721557617
        mean_q: 7.653235912322998
        min_q: -0.06794525682926178
    learner_queue:
      size_count: 131842
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6248199740725323
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1347
    num_steps_sampled: 1714450
    num_steps_trained: 28914176
    num_target_updates: 576
    num_weight_syncs: 4285
    replay_shard_0:
      add_batch_time_ms: 3.376
      policy_default_policy:
        added_count: 427000
        est_size_bytes: 145607000
        num_entries: 427000
        sampled_count: 7167488
      replay_time_ms: 20.473
      update_priorities_time_ms: 54.984
    sample_throughput: 0.0
    train_throughput: 36329.679
  iterations_since_restore: 43
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337739291941484
    mean_inference_ms: 0.8997370247076235
    mean_processing_ms: 0.20934807531198768
  time_since_restore: 1299.1453638076782
  time_this_iter_s: 30.226012706756592
  time_total_s: 1299.1453638076782
  timestamp: 1563764277
  timesteps_since_restore: 1714450
  timesteps_this_iter: 39150
  timesteps_total: 1714450
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1299 s, 43 iter, 1714450 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-58-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.81170881392011
  episode_reward_mean: 16.240325951583817
  episode_reward_min: -10.655793681753337
  episodes_this_iter: 132
  episodes_total: 5846
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.09378433227539
        mean_q: 7.24229621887207
        min_q: -0.17661771178245544
    learner_queue:
      size_count: 133163
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 3.0
      size_std: 0.699714227381436
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1355
    num_steps_sampled: 1754200
    num_steps_trained: 29591040
    num_target_updates: 589
    num_weight_syncs: 4385
    replay_shard_0:
      add_batch_time_ms: 3.111
      policy_default_policy:
        added_count: 437100
        est_size_bytes: 149051100
        num_entries: 437100
        sampled_count: 7334400
      replay_time_ms: 20.702
      update_priorities_time_ms: 54.719
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 44
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337805396265281
    mean_inference_ms: 0.8998649926910548
    mean_processing_ms: 0.20937506361924751
  time_since_restore: 1329.3284168243408
  time_this_iter_s: 30.183053016662598
  time_total_s: 1329.3284168243408
  timestamp: 1563764307
  timesteps_since_restore: 1754200
  timesteps_this_iter: 39750
  timesteps_total: 1754200
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1329 s, 44 iter, 1754200 ts, 16.2 rew

[2m[36m(pid=4669)[0m 2019-07-22 04:58:58,162	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-58-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.10961715189069
  episode_reward_mean: 17.20258319302558
  episode_reward_min: -1.78833508506395
  episodes_this_iter: 134
  episodes_total: 5980
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.46204438638356
    episode_reward_mean: 20.42802295329714
    episode_reward_min: 6.715779110901448
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14549712722805785
      mean_inference_ms: 0.39475419173104936
      mean_processing_ms: 0.08207989902418777
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.846195220947266
        mean_q: 7.510533332824707
        min_q: -0.7077091336250305
    learner_queue:
      size_count: 134478
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6079473661428265
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1359
    num_steps_sampled: 1794100
    num_steps_trained: 30264320
    num_target_updates: 603
    num_weight_syncs: 4485
    replay_shard_0:
      add_batch_time_ms: 2.431
      policy_default_policy:
        added_count: 447200
        est_size_bytes: 152495200
        num_entries: 447200
        sampled_count: 7500288
      replay_time_ms: 21.73
      update_priorities_time_ms: 52.175
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 45
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337773495391135
    mean_inference_ms: 0.8997607162378912
    mean_processing_ms: 0.2093890759879958
  time_since_restore: 1359.5538499355316
  time_this_iter_s: 30.225433111190796
  time_total_s: 1359.5538499355316
  timestamp: 1563764338
  timesteps_since_restore: 1794100
  timesteps_this_iter: 39900
  timesteps_total: 1794100
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1359 s, 45 iter, 1794100 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-59-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.07174925049163
  episode_reward_mean: 17.738182799866095
  episode_reward_min: -0.4685246871290252
  episodes_this_iter: 133
  episodes_total: 6113
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.97525405883789
        mean_q: 7.881444931030273
        min_q: -0.07298454642295837
    learner_queue:
      size_count: 135791
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5713142742834281
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1368
    num_steps_sampled: 1834100
    num_steps_trained: 30936576
    num_target_updates: 616
    num_weight_syncs: 4584
    replay_shard_0:
      add_batch_time_ms: 2.804
      policy_default_policy:
        added_count: 457200
        est_size_bytes: 155905200
        num_entries: 457200
        sampled_count: 7666688
      replay_time_ms: 20.819
      update_priorities_time_ms: 55.52
    sample_throughput: 0.0
    train_throughput: 29692.545
  iterations_since_restore: 46
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337643954131763
    mean_inference_ms: 0.8997074788163925
    mean_processing_ms: 0.20934666613806613
  time_since_restore: 1389.7807786464691
  time_this_iter_s: 30.2269287109375
  time_total_s: 1389.7807786464691
  timestamp: 1563764369
  timesteps_since_restore: 1834100
  timesteps_this_iter: 40000
  timesteps_total: 1834100
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1389 s, 46 iter, 1834100 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_04-59-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.18955827061233
  episode_reward_mean: 18.522432876474436
  episode_reward_min: -9.926433800950655
  episodes_this_iter: 134
  episodes_total: 6247
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 31.82614517211914
        mean_q: 6.990828514099121
        min_q: 0.08828447014093399
    learner_queue:
      size_count: 137101
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.48
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1376
    num_steps_sampled: 1874300
    num_steps_trained: 31607808
    num_target_updates: 629
    num_weight_syncs: 4685
    replay_shard_0:
      add_batch_time_ms: 3.081
      policy_default_policy:
        added_count: 466350
        est_size_bytes: 159025350
        num_entries: 466350
        sampled_count: 7834112
      replay_time_ms: 22.204
      update_priorities_time_ms: 54.361
    sample_throughput: 14253.735
    train_throughput: 0.0
  iterations_since_restore: 47
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337043857616083
    mean_inference_ms: 0.8995535719298274
    mean_processing_ms: 0.20933891139492372
  time_since_restore: 1420.0603849887848
  time_this_iter_s: 30.279606342315674
  time_total_s: 1420.0603849887848
  timestamp: 1563764399
  timesteps_since_restore: 1874300
  timesteps_this_iter: 40200
  timesteps_total: 1874300
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1420 s, 47 iter, 1874300 ts, 18.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-00-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.489913151734115
  episode_reward_mean: 17.627685160809655
  episode_reward_min: -1.8045827887995625
  episodes_this_iter: 133
  episodes_total: 6380
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.21861267089844
        mean_q: 6.687831878662109
        min_q: 0.035210054367780685
    learner_queue:
      size_count: 138417
      size_mean: 0.32
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.46647615158762407
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1384
    num_steps_sampled: 1914100
    num_steps_trained: 32281088
    num_target_updates: 643
    num_weight_syncs: 4785
    replay_shard_0:
      add_batch_time_ms: 3.242
      policy_default_policy:
        added_count: 475750
        est_size_bytes: 162230750
        num_entries: 475750
        sampled_count: 7998976
      replay_time_ms: 19.073
      update_priorities_time_ms: 55.666
    sample_throughput: 0.0
    train_throughput: 39810.238
  iterations_since_restore: 48
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337241826658652
    mean_inference_ms: 0.8996698673269908
    mean_processing_ms: 0.20931562935586473
  time_since_restore: 1450.2687029838562
  time_this_iter_s: 30.20831799507141
  time_total_s: 1450.2687029838562
  timestamp: 1563764429
  timesteps_since_restore: 1914100
  timesteps_this_iter: 39800
  timesteps_total: 1914100
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1450 s, 48 iter, 1914100 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-01-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.13065424800036
  episode_reward_mean: 18.169768031523624
  episode_reward_min: -2.4099028671450435
  episodes_this_iter: 133
  episodes_total: 6513
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.09677505493164
        mean_q: 7.500494956970215
        min_q: -3.051783561706543
    learner_queue:
      size_count: 139726
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5291502622129182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1393
    num_steps_sampled: 1954200
    num_steps_trained: 32951808
    num_target_updates: 656
    num_weight_syncs: 4885
    replay_shard_0:
      add_batch_time_ms: 3.579
      policy_default_policy:
        added_count: 486100
        est_size_bytes: 165760100
        num_entries: 486100
        sampled_count: 8163328
      replay_time_ms: 22.589
      update_priorities_time_ms: 53.078
    sample_throughput: 3032.977
    train_throughput: 31057.685
  iterations_since_restore: 49
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33370074681066336
    mean_inference_ms: 0.899690950487938
    mean_processing_ms: 0.20930774651520662
  time_since_restore: 1480.4524097442627
  time_this_iter_s: 30.183706760406494
  time_total_s: 1480.4524097442627
  timestamp: 1563764460
  timesteps_since_restore: 1954200
  timesteps_this_iter: 40100
  timesteps_total: 1954200
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1480 s, 49 iter, 1954200 ts, 18.2 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:01:30,232	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-01-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.63870293951306
  episode_reward_mean: 18.631944751168717
  episode_reward_min: -2.908108201495013
  episodes_this_iter: 133
  episodes_total: 6646
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 34.28586023516443
    episode_reward_mean: 13.329282320989734
    episode_reward_min: -1.7625824595879216
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14521026530415207
      mean_inference_ms: 0.39460858275157656
      mean_processing_ms: 0.08184551058462278
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.57937240600586
        mean_q: 7.381350517272949
        min_q: -0.009173542261123657
    learner_queue:
      size_count: 141042
      size_mean: 0.72
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.8009993757800314
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1396
    num_steps_sampled: 1994150
    num_steps_trained: 33625088
    num_target_updates: 670
    num_weight_syncs: 4985
    replay_shard_0:
      add_batch_time_ms: 2.96
      policy_default_policy:
        added_count: 496150
        est_size_bytes: 169187150
        num_entries: 496150
        sampled_count: 8330752
      replay_time_ms: 18.79
      update_priorities_time_ms: 51.944
    sample_throughput: 0.0
    train_throughput: 35215.619
  iterations_since_restore: 50
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337142415486537
    mean_inference_ms: 0.8996195290037623
    mean_processing_ms: 0.20933140722616603
  time_since_restore: 1510.6458292007446
  time_this_iter_s: 30.193419456481934
  time_total_s: 1510.6458292007446
  timestamp: 1563764490
  timesteps_since_restore: 1994150
  timesteps_this_iter: 39950
  timesteps_total: 1994150
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1510 s, 50 iter, 1994150 ts, 18.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-02-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.26762388752585
  episode_reward_mean: 18.307701963482224
  episode_reward_min: -1.2412995538634324
  episodes_this_iter: 133
  episodes_total: 6779
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.083065032958984
        mean_q: 6.056105613708496
        min_q: -0.9739941954612732
    learner_queue:
      size_count: 142369
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.0
      - 2.0
      size_std: 0.6053098380168623
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1405
    num_steps_sampled: 2034100
    num_steps_trained: 34304000
    num_target_updates: 683
    num_weight_syncs: 5085
    replay_shard_0:
      add_batch_time_ms: 2.749
      policy_default_policy:
        added_count: 506400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 8497664
      replay_time_ms: 20.176
      update_priorities_time_ms: 52.814
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 51
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337057981319091
    mean_inference_ms: 0.8996943051319716
    mean_processing_ms: 0.20929484298533005
  time_since_restore: 1540.888127565384
  time_this_iter_s: 30.242298364639282
  time_total_s: 1540.888127565384
  timestamp: 1563764521
  timesteps_since_restore: 2034100
  timesteps_this_iter: 39950
  timesteps_total: 2034100
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1540 s, 51 iter, 2034100 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-02-31
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.95554640010589
  episode_reward_mean: 18.84740943720288
  episode_reward_min: -0.1805786479396377
  episodes_this_iter: 130
  episodes_total: 6909
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.72944259643555
        mean_q: 6.556804656982422
        min_q: -0.16673006117343903
    learner_queue:
      size_count: 143700
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4853864439804639
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1424
    num_steps_sampled: 2073150
    num_steps_trained: 34985984
    num_target_updates: 697
    num_weight_syncs: 5182
    replay_shard_0:
      add_batch_time_ms: 2.836
      policy_default_policy:
        added_count: 516200
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 8667136
      replay_time_ms: 19.389
      update_priorities_time_ms: 50.098
    sample_throughput: 0.0
    train_throughput: 44091.647
  iterations_since_restore: 52
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337444491872295
    mean_inference_ms: 0.899950270274591
    mean_processing_ms: 0.20929746862506324
  time_since_restore: 1571.1028325557709
  time_this_iter_s: 30.214704990386963
  time_total_s: 1571.1028325557709
  timestamp: 1563764551
  timesteps_since_restore: 2073150
  timesteps_this_iter: 39050
  timesteps_total: 2073150
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1571 s, 52 iter, 2073150 ts, 18.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-03-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.83370530243194
  episode_reward_mean: 16.810400105645822
  episode_reward_min: -1.6447538095779077
  episodes_this_iter: 133
  episodes_total: 7042
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.10829162597656
        mean_q: 6.341219425201416
        min_q: -0.5919801592826843
    learner_queue:
      size_count: 145025
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6390618123468182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1434
    num_steps_sampled: 2113000
    num_steps_trained: 35663872
    num_target_updates: 710
    num_weight_syncs: 5282
    replay_shard_0:
      add_batch_time_ms: 2.914
      policy_default_policy:
        added_count: 525550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 8835072
      replay_time_ms: 21.093
      update_priorities_time_ms: 48.403
    sample_throughput: 3859.813
    train_throughput: 0.0
  iterations_since_restore: 53
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337134668288897
    mean_inference_ms: 0.9000771487407688
    mean_processing_ms: 0.20931759286407198
  time_since_restore: 1601.3082294464111
  time_this_iter_s: 30.20539689064026
  time_total_s: 1601.3082294464111
  timestamp: 1563764581
  timesteps_since_restore: 2113000
  timesteps_this_iter: 39850
  timesteps_total: 2113000
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1601 s, 53 iter, 2113000 ts, 16.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-03-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.804845282089964
  episode_reward_mean: 18.471187598178435
  episode_reward_min: -1.2776175932955933
  episodes_this_iter: 132
  episodes_total: 7174
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.3752555847168
        mean_q: 5.780947685241699
        min_q: -0.5753167867660522
    learner_queue:
      size_count: 146354
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5688585061331157
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1442
    num_steps_sampled: 2152700
    num_steps_trained: 36345344
    num_target_updates: 724
    num_weight_syncs: 5381
    replay_shard_0:
      add_batch_time_ms: 2.937
      policy_default_policy:
        added_count: 535750
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9004544
      replay_time_ms: 19.122
      update_priorities_time_ms: 49.988
    sample_throughput: 8411.825
    train_throughput: 0.0
  iterations_since_restore: 54
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337697672314697
    mean_inference_ms: 0.900175964793168
    mean_processing_ms: 0.20934778033324844
  time_since_restore: 1631.5049798488617
  time_this_iter_s: 30.19675040245056
  time_total_s: 1631.5049798488617
  timestamp: 1563764612
  timesteps_since_restore: 2152700
  timesteps_this_iter: 39700
  timesteps_total: 2152700
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1631 s, 54 iter, 2152700 ts, 18.5 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:04:02,284	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-04-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.82842778419425
  episode_reward_mean: 19.240827538026863
  episode_reward_min: 1.2733568136442108
  episodes_this_iter: 132
  episodes_total: 7306
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 26.094742301975945
    episode_reward_mean: 17.363745504512348
    episode_reward_min: 4.1829090190846
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14465537695585112
      mean_inference_ms: 0.3939356103777044
      mean_processing_ms: 0.08148302284123321
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.99605941772461
        mean_q: 6.100761413574219
        min_q: 0.1451113224029541
    learner_queue:
      size_count: 147682
      size_mean: 0.28
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.44899888641287294
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1450
    num_steps_sampled: 2192550
    num_steps_trained: 37024768
    num_target_updates: 737
    num_weight_syncs: 5480
    replay_shard_0:
      add_batch_time_ms: 3.424
      policy_default_policy:
        added_count: 545450
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9173504
      replay_time_ms: 20.046
      update_priorities_time_ms: 51.785
    sample_throughput: 0.0
    train_throughput: 39274.377
  iterations_since_restore: 55
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3337735330178718
    mean_inference_ms: 0.900195037990326
    mean_processing_ms: 0.20940751242367514
  time_since_restore: 1661.7274475097656
  time_this_iter_s: 30.22246766090393
  time_total_s: 1661.7274475097656
  timestamp: 1563764642
  timesteps_since_restore: 2192550
  timesteps_this_iter: 39850
  timesteps_total: 2192550
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1661 s, 55 iter, 2192550 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-04-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.25521594999902
  episode_reward_mean: 18.18224654483243
  episode_reward_min: -10.142380560617523
  episodes_this_iter: 132
  episodes_total: 7438
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.45772933959961
        mean_q: 5.325234889984131
        min_q: -0.23418429493904114
    learner_queue:
      size_count: 149016
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.0
      - 2.0
      size_std: 0.5730619512757761
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1460
    num_steps_sampled: 2232100
    num_steps_trained: 37707776
    num_target_updates: 751
    num_weight_syncs: 5580
    replay_shard_0:
      add_batch_time_ms: 2.46
      policy_default_policy:
        added_count: 554800
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9344000
      replay_time_ms: 18.626
      update_priorities_time_ms: 49.887
    sample_throughput: 0.0
    train_throughput: 46488.367
  iterations_since_restore: 56
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3338570447556724
    mean_inference_ms: 0.9003657407830651
    mean_processing_ms: 0.20944982839306947
  time_since_restore: 1691.9481554031372
  time_this_iter_s: 30.220707893371582
  time_total_s: 1691.9481554031372
  timestamp: 1563764673
  timesteps_since_restore: 2232100
  timesteps_this_iter: 39550
  timesteps_total: 2232100
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1691 s, 56 iter, 2232100 ts, 18.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-05-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.95406944947567
  episode_reward_mean: 17.1654001858956
  episode_reward_min: -3.5948027085390666
  episodes_this_iter: 130
  episodes_total: 7568
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.4522705078125
        mean_q: 5.751925945281982
        min_q: -0.007970418781042099
    learner_queue:
      size_count: 150338
      size_mean: 0.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.47370877129308037
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1478
    num_steps_sampled: 2271250
    num_steps_trained: 38385152
    num_target_updates: 764
    num_weight_syncs: 5677
    replay_shard_0:
      add_batch_time_ms: 2.974
      policy_default_policy:
        added_count: 563700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9512448
      replay_time_ms: 19.289
      update_priorities_time_ms: 52.202
    sample_throughput: 0.0
    train_throughput: 61876.438
  iterations_since_restore: 57
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3338789820403419
    mean_inference_ms: 0.900545255244644
    mean_processing_ms: 0.2094690180535222
  time_since_restore: 1722.1453921794891
  time_this_iter_s: 30.19723677635193
  time_total_s: 1722.1453921794891
  timestamp: 1563764703
  timesteps_since_restore: 2271250
  timesteps_this_iter: 39150
  timesteps_total: 2271250
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1722 s, 57 iter, 2271250 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-05-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.34737116483487
  episode_reward_mean: 16.6346770520416
  episode_reward_min: -6.938425416240488
  episodes_this_iter: 133
  episodes_total: 7701
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.64720153808594
        mean_q: 5.72960090637207
        min_q: -0.13291066884994507
    learner_queue:
      size_count: 151662
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.48
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1488
    num_steps_sampled: 2310950
    num_steps_trained: 39062528
    num_target_updates: 778
    num_weight_syncs: 5776
    replay_shard_0:
      add_batch_time_ms: 2.795
      policy_default_policy:
        added_count: 574150
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9678336
      replay_time_ms: 18.458
      update_priorities_time_ms: 55.428
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 58
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3338877072254939
    mean_inference_ms: 0.9005342877170575
    mean_processing_ms: 0.2094944332204909
  time_since_restore: 1752.3775181770325
  time_this_iter_s: 30.232125997543335
  time_total_s: 1752.3775181770325
  timestamp: 1563764733
  timesteps_since_restore: 2310950
  timesteps_this_iter: 39700
  timesteps_total: 2310950
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1752 s, 58 iter, 2310950 ts, 16.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-06-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.87130218764006
  episode_reward_mean: 19.438807269670423
  episode_reward_min: -2.748800465075871
  episodes_this_iter: 132
  episodes_total: 7833
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.10751724243164
        mean_q: 5.49763298034668
        min_q: -0.12084443867206573
    learner_queue:
      size_count: 152989
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      - 2.0
      size_std: 0.7180529228406496
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1497
    num_steps_sampled: 2350550
    num_steps_trained: 39741952
    num_target_updates: 792
    num_weight_syncs: 5876
    replay_shard_0:
      add_batch_time_ms: 3.104
      policy_default_policy:
        added_count: 585050
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9847296
      replay_time_ms: 19.161
      update_priorities_time_ms: 52.282
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 59
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3339245318187553
    mean_inference_ms: 0.9005366625431696
    mean_processing_ms: 0.2095250880846236
  time_since_restore: 1782.6089413166046
  time_this_iter_s: 30.231423139572144
  time_total_s: 1782.6089413166046
  timestamp: 1563764764
  timesteps_since_restore: 2350550
  timesteps_this_iter: 39600
  timesteps_total: 2350550
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1782 s, 59 iter, 2350550 ts, 19.4 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:06:34,313	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-06-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.81663626812989
  episode_reward_mean: 19.340197660643597
  episode_reward_min: -3.113344551026622
  episodes_this_iter: 133
  episodes_total: 7966
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 34.90831545536223
    episode_reward_mean: 16.8518868752277
    episode_reward_min: 1.4540411297075335
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14471101807322934
      mean_inference_ms: 0.3939940803363124
      mean_processing_ms: 0.08145241081809382
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.84836959838867
        mean_q: 5.825084686279297
        min_q: -0.15441973507404327
    learner_queue:
      size_count: 154309
      size_mean: 0.58
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5688585061331156
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1504
    num_steps_sampled: 2390450
    num_steps_trained: 40417280
    num_target_updates: 805
    num_weight_syncs: 5975
    replay_shard_0:
      add_batch_time_ms: 3.008
      policy_default_policy:
        added_count: 594350
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10015744
      replay_time_ms: 18.409
      update_priorities_time_ms: 51.982
    sample_throughput: 1732.654
    train_throughput: 17742.373
  iterations_since_restore: 60
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3339545128820833
    mean_inference_ms: 0.9004800016636879
    mean_processing_ms: 0.20952795941980148
  time_since_restore: 1812.8106942176819
  time_this_iter_s: 30.20175290107727
  time_total_s: 1812.8106942176819
  timestamp: 1563764794
  timesteps_since_restore: 2390450
  timesteps_this_iter: 39900
  timesteps_total: 2390450
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1812 s, 60 iter, 2390450 ts, 19.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-07-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.781745428720235
  episode_reward_mean: 18.150786529347354
  episode_reward_min: -1.8534851316912435
  episodes_this_iter: 132
  episodes_total: 8098
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.093692779541016
        mean_q: 5.247592926025391
        min_q: -0.16616646945476532
    learner_queue:
      size_count: 155645
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1514
    num_steps_sampled: 2430000
    num_steps_trained: 41100800
    num_target_updates: 819
    num_weight_syncs: 6074
    replay_shard_0:
      add_batch_time_ms: 2.554
      policy_default_policy:
        added_count: 604150
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10184704
      replay_time_ms: 19.465
      update_priorities_time_ms: 57.85
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 61
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33399384150380335
    mean_inference_ms: 0.9006904564034163
    mean_processing_ms: 0.20954386329951877
  time_since_restore: 1843.0213506221771
  time_this_iter_s: 30.21065640449524
  time_total_s: 1843.0213506221771
  timestamp: 1563764825
  timesteps_since_restore: 2430000
  timesteps_this_iter: 39550
  timesteps_total: 2430000
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1843 s, 61 iter, 2430000 ts, 18.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-07-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.57149793300967
  episode_reward_mean: 18.99941372512687
  episode_reward_min: -4.391480829122963
  episodes_this_iter: 130
  episodes_total: 8228
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.09164047241211
        mean_q: 5.00527286529541
        min_q: -0.35328906774520874
    learner_queue:
      size_count: 156964
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.1000000000000014
      - 3.0
      size_std: 0.71442284397967
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1529
    num_steps_sampled: 2469000
    num_steps_trained: 41777152
    num_target_updates: 832
    num_weight_syncs: 6172
    replay_shard_0:
      add_batch_time_ms: 2.245
      policy_default_policy:
        added_count: 614150
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10352128
      replay_time_ms: 18.667
      update_priorities_time_ms: 51.103
    sample_throughput: 0.0
    train_throughput: 31439.166
  iterations_since_restore: 62
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33404710785124436
    mean_inference_ms: 0.9009976644609281
    mean_processing_ms: 0.20958074794610543
  time_since_restore: 1873.2448108196259
  time_this_iter_s: 30.22346019744873
  time_total_s: 1873.2448108196259
  timestamp: 1563764855
  timesteps_since_restore: 2469000
  timesteps_this_iter: 39000
  timesteps_total: 2469000
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1873 s, 62 iter, 2469000 ts, 19 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-08-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.127991770994015
  episode_reward_mean: 19.273042101311862
  episode_reward_min: -0.8073139514784115
  episodes_this_iter: 133
  episodes_total: 8361
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.13626480102539
        mean_q: 5.204702377319336
        min_q: -0.5193267464637756
    learner_queue:
      size_count: 158288
      size_mean: 0.3
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.45825756949558394
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1535
    num_steps_sampled: 2508950
    num_steps_trained: 42454528
    num_target_updates: 846
    num_weight_syncs: 6272
    replay_shard_0:
      add_batch_time_ms: 3.796
      policy_default_policy:
        added_count: 622900
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10519040
      replay_time_ms: 19.265
      update_priorities_time_ms: 50.729
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 63
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3340604009951314
    mean_inference_ms: 0.9008755946714235
    mean_processing_ms: 0.20958141529923774
  time_since_restore: 1903.4624593257904
  time_this_iter_s: 30.21764850616455
  time_total_s: 1903.4624593257904
  timestamp: 1563764885
  timesteps_since_restore: 2508950
  timesteps_this_iter: 39950
  timesteps_total: 2508950
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1903 s, 63 iter, 2508950 ts, 19.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-08-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.05102750092171
  episode_reward_mean: 19.32882455494367
  episode_reward_min: -1.5032618253241938
  episodes_this_iter: 133
  episodes_total: 8494
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.349510192871094
        mean_q: 4.451558589935303
        min_q: -0.4895697236061096
    learner_queue:
      size_count: 159613
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.6696267617113283
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1543
    num_steps_sampled: 2548800
    num_steps_trained: 43133952
    num_target_updates: 859
    num_weight_syncs: 6372
    replay_shard_0:
      add_batch_time_ms: 2.952
      policy_default_policy:
        added_count: 633550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10686976
      replay_time_ms: 18.608
      update_priorities_time_ms: 50.897
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 64
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3340767200641297
    mean_inference_ms: 0.9009235961673486
    mean_processing_ms: 0.20958276325790834
  time_since_restore: 1933.6651508808136
  time_this_iter_s: 30.202691555023193
  time_total_s: 1933.6651508808136
  timestamp: 1563764916
  timesteps_since_restore: 2548800
  timesteps_this_iter: 39850
  timesteps_total: 2548800
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1933 s, 64 iter, 2548800 ts, 19.3 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:09:06,388	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-09-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.34180918881904
  episode_reward_mean: 17.75672406044395
  episode_reward_min: -3.964276355637136
  episodes_this_iter: 133
  episodes_total: 8627
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 30.729755095843363
    episode_reward_mean: 18.77057197238268
    episode_reward_min: 7.5851473468343675
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1442962235243262
      mean_inference_ms: 0.3934996984418327
      mean_processing_ms: 0.08119812954449038
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.48881912231445
        mean_q: 4.655587196350098
        min_q: -0.614791750907898
    learner_queue:
      size_count: 160937
      size_mean: 0.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5141984052872977
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1551
    num_steps_sampled: 2588700
    num_steps_trained: 43810816
    num_target_updates: 873
    num_weight_syncs: 6471
    replay_shard_0:
      add_batch_time_ms: 2.978
      policy_default_policy:
        added_count: 644250
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10854400
      replay_time_ms: 17.613
      update_priorities_time_ms: 50.69
    sample_throughput: 0.0
    train_throughput: 25429.356
  iterations_since_restore: 65
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3340799433523362
    mean_inference_ms: 0.900902603177677
    mean_processing_ms: 0.2095506959846695
  time_since_restore: 1963.905885219574
  time_this_iter_s: 30.240734338760376
  time_total_s: 1963.905885219574
  timestamp: 1563764946
  timesteps_since_restore: 2588700
  timesteps_this_iter: 39900
  timesteps_total: 2588700
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1963 s, 65 iter, 2588700 ts, 17.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-09-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.83240289513729
  episode_reward_mean: 19.296666613435832
  episode_reward_min: -1.0356835830130044
  episodes_this_iter: 130
  episodes_total: 8757
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.43672180175781
        mean_q: 4.363262176513672
        min_q: -0.3901830017566681
    learner_queue:
      size_count: 162264
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1569
    num_steps_sampled: 2627700
    num_steps_trained: 44490752
    num_target_updates: 886
    num_weight_syncs: 6568
    replay_shard_0:
      add_batch_time_ms: 2.866
      policy_default_policy:
        added_count: 654500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11023360
      replay_time_ms: 19.909
      update_priorities_time_ms: 53.766
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 66
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3341020303715085
    mean_inference_ms: 0.9010667666324703
    mean_processing_ms: 0.20957362546273628
  time_since_restore: 1994.1164770126343
  time_this_iter_s: 30.210591793060303
  time_total_s: 1994.1164770126343
  timestamp: 1563764977
  timesteps_since_restore: 2627700
  timesteps_this_iter: 39000
  timesteps_total: 2627700
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 1994 s, 66 iter, 2627700 ts, 19.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-10-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.52878274297281
  episode_reward_mean: 19.02563994095973
  episode_reward_min: -0.30754694210705275
  episodes_this_iter: 133
  episodes_total: 8890
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.64216995239258
        mean_q: 4.278289794921875
        min_q: -0.16169975697994232
    learner_queue:
      size_count: 163589
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5385164807134504
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1577
    num_steps_sampled: 2667600
    num_steps_trained: 45169664
    num_target_updates: 900
    num_weight_syncs: 6668
    replay_shard_0:
      add_batch_time_ms: 2.836
      policy_default_policy:
        added_count: 664900
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11190784
      replay_time_ms: 18.912
      update_priorities_time_ms: 50.58
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 67
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33409420912165155
    mean_inference_ms: 0.9010576682793798
    mean_processing_ms: 0.20961817396999513
  time_since_restore: 2024.2975146770477
  time_this_iter_s: 30.181037664413452
  time_total_s: 2024.2975146770477
  timestamp: 1563765007
  timesteps_since_restore: 2667600
  timesteps_this_iter: 39900
  timesteps_total: 2667600
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2024 s, 67 iter, 2667600 ts, 19 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-10-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.85628219488636
  episode_reward_mean: 18.07286147337741
  episode_reward_min: -0.9915822351920696
  episodes_this_iter: 133
  episodes_total: 9023
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 31.8386287689209
        mean_q: 4.664646148681641
        min_q: -0.1222919225692749
    learner_queue:
      size_count: 164917
      size_mean: 0.72
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7493997598078078
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1580
    num_steps_sampled: 2707300
    num_steps_trained: 45849088
    num_target_updates: 913
    num_weight_syncs: 6767
    replay_shard_0:
      add_batch_time_ms: 2.538
      policy_default_policy:
        added_count: 675000
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11359232
      replay_time_ms: 19.421
      update_priorities_time_ms: 49.461
    sample_throughput: 0.0
    train_throughput: 37320.93
  iterations_since_restore: 68
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33409610633637393
    mean_inference_ms: 0.901059337858783
    mean_processing_ms: 0.20963495868302043
  time_since_restore: 2054.5034658908844
  time_this_iter_s: 30.20595121383667
  time_total_s: 2054.5034658908844
  timestamp: 1563765037
  timesteps_since_restore: 2707300
  timesteps_this_iter: 39700
  timesteps_total: 2707300
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2054 s, 68 iter, 2707300 ts, 18.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-11-08
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.74666686979351
  episode_reward_mean: 18.414421236703497
  episode_reward_min: 0.18964264029066702
  episodes_this_iter: 133
  episodes_total: 9156
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 31.223966598510742
        mean_q: 4.331635475158691
        min_q: -0.3179478049278259
    learner_queue:
      size_count: 166243
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1588
    num_steps_sampled: 2747100
    num_steps_trained: 46527488
    num_target_updates: 927
    num_weight_syncs: 6867
    replay_shard_0:
      add_batch_time_ms: 2.56
      policy_default_policy:
        added_count: 685250
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11527168
      replay_time_ms: 19.417
      update_priorities_time_ms: 56.722
    sample_throughput: 3034.952
    train_throughput: 0.0
  iterations_since_restore: 69
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33411644851413963
    mean_inference_ms: 0.9010183647754655
    mean_processing_ms: 0.20963316225092238
  time_since_restore: 2084.7305800914764
  time_this_iter_s: 30.22711420059204
  time_total_s: 2084.7305800914764
  timestamp: 1563765068
  timesteps_since_restore: 2747100
  timesteps_this_iter: 39800
  timesteps_total: 2747100
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2084 s, 69 iter, 2747100 ts, 18.4 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:11:38,401	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-11-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 40.08928250817826
  episode_reward_mean: 18.87465785409018
  episode_reward_min: -5.207818291995833
  episodes_this_iter: 133
  episodes_total: 9289
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 37.99108217141042
    episode_reward_mean: 23.384859075986757
    episode_reward_min: 3.9297721728271124
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14419337600227206
      mean_inference_ms: 0.39285264816884335
      mean_processing_ms: 0.0810781577805255
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.32188415527344
        mean_q: 5.390633583068848
        min_q: -0.37207239866256714
    learner_queue:
      size_count: 167567
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4963869458396343
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1596
    num_steps_sampled: 2787100
    num_steps_trained: 47205376
    num_target_updates: 940
    num_weight_syncs: 6967
    replay_shard_0:
      add_batch_time_ms: 2.339
      policy_default_policy:
        added_count: 695100
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11693568
      replay_time_ms: 19.269
      update_priorities_time_ms: 50.373
    sample_throughput: 3419.455
    train_throughput: 35015.223
  iterations_since_restore: 70
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33410053499579445
    mean_inference_ms: 0.9009879164435619
    mean_processing_ms: 0.20964542431818325
  time_since_restore: 2114.9701766967773
  time_this_iter_s: 30.239596605300903
  time_total_s: 2114.9701766967773
  timestamp: 1563765098
  timesteps_since_restore: 2787100
  timesteps_this_iter: 40000
  timesteps_total: 2787100
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2114 s, 70 iter, 2787100 ts, 18.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-12-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 40.12295506603614
  episode_reward_mean: 18.707076475218592
  episode_reward_min: -0.7103007791730065
  episodes_this_iter: 131
  episodes_total: 9420
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.66588592529297
        mean_q: 4.469463348388672
        min_q: -0.4847050607204437
    learner_queue:
      size_count: 168886
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      - 2.0
      size_std: 0.7683749084919419
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1615
    num_steps_sampled: 2826150
    num_steps_trained: 47881216
    num_target_updates: 954
    num_weight_syncs: 7065
    replay_shard_0:
      add_batch_time_ms: 2.99
      policy_default_policy:
        added_count: 705550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11862528
      replay_time_ms: 18.731
      update_priorities_time_ms: 52.507
    sample_throughput: 0.0
    train_throughput: 37874.491
  iterations_since_restore: 71
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33411224727530475
    mean_inference_ms: 0.9010005429089397
    mean_processing_ms: 0.2096670729495676
  time_since_restore: 2145.186134338379
  time_this_iter_s: 30.215957641601562
  time_total_s: 2145.186134338379
  timestamp: 1563765129
  timesteps_since_restore: 2826150
  timesteps_this_iter: 39050
  timesteps_total: 2826150
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2145 s, 71 iter, 2826150 ts, 18.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-12-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.20545968201874
  episode_reward_mean: 17.160982536662136
  episode_reward_min: -1.774959217920868
  episodes_this_iter: 132
  episodes_total: 9552
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.65301513671875
        mean_q: 4.2380690574646
        min_q: -0.8067327737808228
    learner_queue:
      size_count: 170208
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 2.0
      - 2.0
      size_std: 0.71442284397967
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1623
    num_steps_sampled: 2865950
    num_steps_trained: 48558080
    num_target_updates: 967
    num_weight_syncs: 7164
    replay_shard_0:
      add_batch_time_ms: 2.973
      policy_default_policy:
        added_count: 715450
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12028928
      replay_time_ms: 20.733
      update_priorities_time_ms: 59.786
    sample_throughput: 0.0
    train_throughput: 36991.777
  iterations_since_restore: 72
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3341082874114592
    mean_inference_ms: 0.9010559096569631
    mean_processing_ms: 0.209631766906335
  time_since_restore: 2175.4135596752167
  time_this_iter_s: 30.22742533683777
  time_total_s: 2175.4135596752167
  timestamp: 1563765159
  timesteps_since_restore: 2865950
  timesteps_this_iter: 39800
  timesteps_total: 2865950
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2175 s, 72 iter, 2865950 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-13-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.13048141203536
  episode_reward_mean: 18.965805728646444
  episode_reward_min: -5.166601662250479
  episodes_this_iter: 133
  episodes_total: 9685
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.633384704589844
        mean_q: 4.234314441680908
        min_q: -0.26377537846565247
    learner_queue:
      size_count: 171533
      size_mean: 0.32
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.466476151587624
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1630
    num_steps_sampled: 2905600
    num_steps_trained: 49235968
    num_target_updates: 981
    num_weight_syncs: 7263
    replay_shard_0:
      add_batch_time_ms: 3.019
      policy_default_policy:
        added_count: 725300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12195840
      replay_time_ms: 18.473
      update_priorities_time_ms: 51.945
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 73
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33411626570530834
    mean_inference_ms: 0.901070236443801
    mean_processing_ms: 0.20964533692606954
  time_since_restore: 2205.614023923874
  time_this_iter_s: 30.200464248657227
  time_total_s: 2205.614023923874
  timestamp: 1563765189
  timesteps_since_restore: 2905600
  timesteps_this_iter: 39650
  timesteps_total: 2905600
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2205 s, 73 iter, 2905600 ts, 19 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-13-40
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 40.18153097314636
  episode_reward_mean: 18.752335483805638
  episode_reward_min: -31.489237020061186
  episodes_this_iter: 133
  episodes_total: 9818
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.88644027709961
        mean_q: 4.764629364013672
        min_q: -0.22909696400165558
    learner_queue:
      size_count: 172858
      size_mean: 0.28
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.44899888641287294
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1635
    num_steps_sampled: 2945350
    num_steps_trained: 49915392
    num_target_updates: 994
    num_weight_syncs: 7362
    replay_shard_0:
      add_batch_time_ms: 2.863
      policy_default_policy:
        added_count: 735700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12362752
      replay_time_ms: 17.942
      update_priorities_time_ms: 49.726
    sample_throughput: 3362.383
    train_throughput: 34430.804
  iterations_since_restore: 74
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33414806514412737
    mean_inference_ms: 0.9010551839333358
    mean_processing_ms: 0.2096811978150659
  time_since_restore: 2235.8230760097504
  time_this_iter_s: 30.209052085876465
  time_total_s: 2235.8230760097504
  timestamp: 1563765220
  timesteps_since_restore: 2945350
  timesteps_this_iter: 39750
  timesteps_total: 2945350
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2235 s, 74 iter, 2945350 ts, 18.8 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:14:10,398	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-14-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.61739215450094
  episode_reward_mean: 18.110593515074385
  episode_reward_min: -1.4011640308235784
  episodes_this_iter: 132
  episodes_total: 9950
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 31.65450338787677
    episode_reward_mean: 16.047461609300633
    episode_reward_min: 6.715704140340748
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.144092665429483
      mean_inference_ms: 0.39259306932805915
      mean_processing_ms: 0.08096805607635306
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.873050689697266
        mean_q: 4.169835090637207
        min_q: -0.17709553241729736
    learner_queue:
      size_count: 174184
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5656854249492381
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1644
    num_steps_sampled: 2985000
    num_steps_trained: 50594304
    num_target_updates: 1008
    num_weight_syncs: 7462
    replay_shard_0:
      add_batch_time_ms: 2.8
      policy_default_policy:
        added_count: 745500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12530176
      replay_time_ms: 17.766
      update_priorities_time_ms: 50.248
    sample_throughput: 0.0
    train_throughput: 32480.053
  iterations_since_restore: 75
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.334157536794574
    mean_inference_ms: 0.9010640460658432
    mean_processing_ms: 0.209675727247131
  time_since_restore: 2266.0111107826233
  time_this_iter_s: 30.188034772872925
  time_total_s: 2266.0111107826233
  timestamp: 1563765250
  timesteps_since_restore: 2985000
  timesteps_this_iter: 39650
  timesteps_total: 2985000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2266 s, 75 iter, 2985000 ts, 18.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-14-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.33478196521629
  episode_reward_mean: 18.453437409666687
  episode_reward_min: 0.17683481618660216
  episodes_this_iter: 130
  episodes_total: 10080
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.32451248168945
        mean_q: 4.072330951690674
        min_q: -0.3920479714870453
    learner_queue:
      size_count: 175504
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6079473661428265
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1666
    num_steps_sampled: 3024000
    num_steps_trained: 51269632
    num_target_updates: 1021
    num_weight_syncs: 7560
    replay_shard_0:
      add_batch_time_ms: 3.199
      policy_default_policy:
        added_count: 756400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12697088
      replay_time_ms: 20.144
      update_priorities_time_ms: 51.734
    sample_throughput: 1712.464
    train_throughput: 35071.264
  iterations_since_restore: 76
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33416630554731025
    mean_inference_ms: 0.9011531636604219
    mean_processing_ms: 0.20969621048795203
  time_since_restore: 2296.2534205913544
  time_this_iter_s: 30.24230980873108
  time_total_s: 2296.2534205913544
  timestamp: 1563765281
  timesteps_since_restore: 3024000
  timesteps_this_iter: 39000
  timesteps_total: 3024000
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2296 s, 76 iter, 3024000 ts, 18.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-15-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.97361693364274
  episode_reward_mean: 19.10936951793632
  episode_reward_min: -1.0529168442649346
  episodes_this_iter: 133
  episodes_total: 10213
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.16951370239258
        mean_q: 3.6790671348571777
        min_q: -0.5120518207550049
    learner_queue:
      size_count: 176833
      size_mean: 0.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5141984052872977
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1675
    num_steps_sampled: 3063650
    num_steps_trained: 51950592
    num_target_updates: 1035
    num_weight_syncs: 7658
    replay_shard_0:
      add_batch_time_ms: 2.739
      policy_default_policy:
        added_count: 766950
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12865536
      replay_time_ms: 17.896
      update_priorities_time_ms: 47.44
    sample_throughput: 0.0
    train_throughput: 56591.658
  iterations_since_restore: 77
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3341608347896145
    mean_inference_ms: 0.9011747373674738
    mean_processing_ms: 0.2097056521904896
  time_since_restore: 2326.450491666794
  time_this_iter_s: 30.197071075439453
  time_total_s: 2326.450491666794
  timestamp: 1563765311
  timesteps_since_restore: 3063650
  timesteps_this_iter: 39650
  timesteps_total: 3063650
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2326 s, 77 iter, 3063650 ts, 19.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-15-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.701656647770434
  episode_reward_mean: 18.285073423550244
  episode_reward_min: -3.91719255776395
  episodes_this_iter: 131
  episodes_total: 10344
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.3505859375
        mean_q: 4.294224739074707
        min_q: -0.37233179807662964
    learner_queue:
      size_count: 178165
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1686
    num_steps_sampled: 3103050
    num_steps_trained: 52632064
    num_target_updates: 1048
    num_weight_syncs: 7757
    replay_shard_0:
      add_batch_time_ms: 3.466
      policy_default_policy:
        added_count: 775700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13033984
      replay_time_ms: 18.361
      update_priorities_time_ms: 48.56
    sample_throughput: 0.0
    train_throughput: 36029.187
  iterations_since_restore: 78
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3341672256251588
    mean_inference_ms: 0.9013263376659877
    mean_processing_ms: 0.2097178825928986
  time_since_restore: 2356.663016796112
  time_this_iter_s: 30.212525129318237
  time_total_s: 2356.663016796112
  timestamp: 1563765341
  timesteps_since_restore: 3103050
  timesteps_this_iter: 39400
  timesteps_total: 3103050
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2356 s, 78 iter, 3103050 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-16-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.52951844643589
  episode_reward_mean: 18.32223631891441
  episode_reward_min: -14.843694197721454
  episodes_this_iter: 132
  episodes_total: 10476
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.1486930847168
        mean_q: 4.084549427032471
        min_q: -0.9798176288604736
    learner_queue:
      size_count: 179494
      size_mean: 0.28
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.44899888641287294
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1695
    num_steps_sampled: 3142650
    num_steps_trained: 53313024
    num_target_updates: 1062
    num_weight_syncs: 7856
    replay_shard_0:
      add_batch_time_ms: 3.033
      policy_default_policy:
        added_count: 785500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13202944
      replay_time_ms: 19.162
      update_priorities_time_ms: 50.51
    sample_throughput: 0.0
    train_throughput: 58254.222
  iterations_since_restore: 79
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33420723645514694
    mean_inference_ms: 0.9014490855523382
    mean_processing_ms: 0.2097083710504977
  time_since_restore: 2386.849936246872
  time_this_iter_s: 30.186919450759888
  time_total_s: 2386.849936246872
  timestamp: 1563765372
  timesteps_since_restore: 3142650
  timesteps_this_iter: 39600
  timesteps_total: 3142650
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2386 s, 79 iter, 3142650 ts, 18.3 rew

[2m[36m(pid=4669)[0m 2019-07-22 05:16:42,402	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-16-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.2714496931976
  episode_reward_mean: 18.946311734469326
  episode_reward_min: -1.1915657876331578
  episodes_this_iter: 133
  episodes_total: 10609
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 30.271373200004554
    episode_reward_mean: 18.270494881160424
    episode_reward_min: 5.34872771303414
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.14376770276227874
      mean_inference_ms: 0.39201490337075195
      mean_processing_ms: 0.08077503844740942
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.68092727661133
        mean_q: 3.45233416557312
        min_q: -0.6796504259109497
    learner_queue:
      size_count: 180827
      size_mean: 0.76
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6499230723708769
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1702
    num_steps_sampled: 3182550
    num_steps_trained: 53995008
    num_target_updates: 1076
    num_weight_syncs: 7956
    replay_shard_0:
      add_batch_time_ms: 2.774
      policy_default_policy:
        added_count: 795250
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13370368
      replay_time_ms: 18.612
      update_priorities_time_ms: 51.065
    sample_throughput: 2536.162
    train_throughput: 25970.294
  iterations_since_restore: 80
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.334176781297002
    mean_inference_ms: 0.9014954171058271
    mean_processing_ms: 0.20971138169467746
  time_since_restore: 2417.051804304123
  time_this_iter_s: 30.201868057250977
  time_total_s: 2417.051804304123
  timestamp: 1563765402
  timesteps_since_restore: 3182550
  timesteps_this_iter: 39900
  timesteps_total: 3182550
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2417 s, 80 iter, 3182550 ts, 18.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-17-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.53035433301317
  episode_reward_mean: 20.239832740796736
  episode_reward_min: 0.794895174987597
  episodes_this_iter: 130
  episodes_total: 10739
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.40830612182617
        mean_q: 3.6274302005767822
        min_q: -0.5624299049377441
    learner_queue:
      size_count: 182143
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.64
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1720
    num_steps_sampled: 3221800
    num_steps_trained: 54668800
    num_target_updates: 1089
    num_weight_syncs: 8054
    replay_shard_0:
      add_batch_time_ms: 2.539
      policy_default_policy:
        added_count: 805350
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13537280
      replay_time_ms: 20.574
      update_priorities_time_ms: 52.567
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 81
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3341876498184822
    mean_inference_ms: 0.9016096864090433
    mean_processing_ms: 0.20966918082389624
  time_since_restore: 2447.2444276809692
  time_this_iter_s: 30.192623376846313
  time_total_s: 2447.2444276809692
  timestamp: 1563765433
  timesteps_since_restore: 3221800
  timesteps_this_iter: 39250
  timesteps_total: 3221800
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=4669], 2447 s, 81 iter, 3221800 ts, 20.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_05-17-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.35672968986637
  episode_reward_mean: 19.491600665906038
  episode_reward_min: 2.003161613223126
  episodes_this_iter: 133
  episodes_total: 10872
  experiment_id: 43539d04c2b148199b68d6f173f6c14b
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.43495178222656
        mean_q: 3.858537197113037
        min_q: -0.4614432454109192
    learner_queue:
      size_count: 183471
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6069596362197408
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1730
    num_steps_sampled: 3261600
    num_steps_trained: 55349248
    num_target_updates: 1103
    num_weight_syncs: 8154
    replay_shard_0:
      add_batch_time_ms: 3.056
      policy_default_policy:
        added_count: 815400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13705728
      replay_time_ms: 19.13
      update_priorities_time_ms: 47.87
    sample_throughput: 1957.851
    train_throughput: 40096.787
  iterations_since_restore: 82
  node_ip: 10.16.128.63
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 4669
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.33416172641113123
    mean_inference_ms: 0.901571446150313
    mean_processing_ms: 0.209649633308083
  time_since_restore: 2477.483599424362
  time_this_iter_s: 30.239171743392944
  time_total_s: 2477.483599424362
  timestamp: 1563765463
  timesteps_since_restore: 3261600
  timesteps_this_iter: 39800
  timesteps_total: 3261600
  training_iteration: 82
  
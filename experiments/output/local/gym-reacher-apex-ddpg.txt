2019-07-23 21:51:12,847	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-23_21-51-12_846811_24390/logs.
2019-07-23 21:51:12,953	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-23 21:51:13,060	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-23 21:51:13,166	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-23 21:51:13,273	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-23 21:51:13,379	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:12653 to respond...
2019-07-23 21:51:13,487	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:26968 to respond...
2019-07-23 21:51:13,489	INFO services.py:806 -- Starting Redis shard with 3.33 GB max memory.
2019-07-23 21:51:13,504	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-23_21-51-12_846811_24390/logs.
2019-07-23 21:51:13,505	INFO services.py:1446 -- Starting the Plasma object store with 5.0 GB memory using /dev/shm.
2019-07-23 21:51:13,684	INFO tune.py:61 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()
2019-07-23 21:51:13,701	INFO tune.py:233 -- Starting a new experiment.
2019-07-23 21:51:13,743	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
[32m [     0.24968s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.25010s,  INFO] Experiment configs: 
 {
  "gym-reacher-apex-ddpg": {
    "env": "RoboschoolReacher-v1",
    "run": "APEX_DDPG",
    "local_dir": "~/kayray_results/local",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "episode_reward_mean": 21,
      "timesteps_total": 10000000
    },
    "config": {
      "env_config": {
        "env_type": "openai"
      },
      "use_huber": true,
      "clip_rewards": false,
      "num_gpus": 0,
      "num_workers": 2,
      "lr": 0.1,
      "n_step": 1,
      "exploration_ou_noise_scale": 0.7,
      "target_network_update_freq": 50000,
      "tau": 1.0,
      "evaluation_interval": 5,
      "evaluation_num_episodes": 10
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.5/16.7 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=24445)[0m 2019-07-23 21:51:15,745	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=24445)[0m 2019-07-23 21:51:15.745935: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=24445)[0m [32m [     0.01735s,  INFO] TimeLimit:
[2m[36m(pid=24445)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=24445)[0m - action_space = Box(2,)
[2m[36m(pid=24445)[0m - observation_space = Box(9,)
[2m[36m(pid=24445)[0m - reward_range = (-inf, inf)
[2m[36m(pid=24445)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=24445)[0m - _max_episode_steps = 150
[2m[36m(pid=24445)[0m - _elapsed_steps = None [0m
[2m[36m(pid=24445)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24445)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24445)[0m 2019-07-23 21:51:16,401	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x7efc6ea66dd8>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:16,401	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7efc6f083b00>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:16,401	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7efc6f077c88>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:16,403	INFO actors.py:108 -- Trying to create 4 colocated actors
[2m[36m(pid=24445)[0m 2019-07-23 21:51:17,976	INFO actors.py:101 -- Got 4 colocated actors of 4
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,115	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=24445)[0m [32m [     2.38746s,  INFO] TimeLimit:
[2m[36m(pid=24445)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=24445)[0m - action_space = Box(2,)
[2m[36m(pid=24445)[0m - observation_space = Box(9,)
[2m[36m(pid=24445)[0m - reward_range = (-inf, inf)
[2m[36m(pid=24445)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=24445)[0m - _max_episode_steps = 150
[2m[36m(pid=24445)[0m - _elapsed_steps = None [0m
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,876	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x7efc5c04c0f0>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,876	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7efc5c03acf8>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,876	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x7efc5c03a908>}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,878	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,902	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,911	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.993, max=0.217, mean=-0.141)}}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,911	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,911	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.993, max=0.217, mean=-0.141)
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,911	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.993, max=0.217, mean=-0.141)
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,912	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=24445)[0m                                   'env_id': 0,
[2m[36m(pid=24445)[0m                                   'info': None,
[2m[36m(pid=24445)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.993, max=0.217, mean=-0.141),
[2m[36m(pid=24445)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24445)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=24445)[0m                                   'rnn_state': []},
[2m[36m(pid=24445)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,912	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=24445)[0m 2019-07-23 21:51:18,932	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=0.161, max=0.329, mean=0.245),
[2m[36m(pid=24445)[0m                       [],
[2m[36m(pid=24445)[0m                       {})}
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m 2019-07-23 21:51:19,069	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'agent0': { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.103),
[2m[36m(pid=24445)[0m                         'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24445)[0m                         'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=24445)[0m                         'eps_id': np.ndarray((150,), dtype=int64, min=1463718790.0, max=1463718790.0, mean=1463718790.0),
[2m[36m(pid=24445)[0m                         'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=24445)[0m                         'new_obs': np.ndarray((150, 9), dtype=float32, min=-5.831, max=3.955, mean=-0.139),
[2m[36m(pid=24445)[0m                         'obs': np.ndarray((150, 9), dtype=float32, min=-5.831, max=3.955, mean=-0.137),
[2m[36m(pid=24445)[0m                         'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.098),
[2m[36m(pid=24445)[0m                         'prev_rewards': np.ndarray((150,), dtype=float32, min=-6.794, max=5.86, mean=-0.082),
[2m[36m(pid=24445)[0m                         'rewards': np.ndarray((150,), dtype=float32, min=-6.794, max=5.86, mean=-0.086),
[2m[36m(pid=24445)[0m                         't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=24445)[0m                         'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24445)[0m                         'weights': np.ndarray((150,), dtype=float32, min=0.0, max=6.807, mean=1.432)},
[2m[36m(pid=24445)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m 2019-07-23 21:51:19,072	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.103),
[2m[36m(pid=24445)[0m             'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24445)[0m             'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=24445)[0m             'eps_id': np.ndarray((150,), dtype=int64, min=1463718790.0, max=1463718790.0, mean=1463718790.0),
[2m[36m(pid=24445)[0m             'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=24445)[0m             'new_obs': np.ndarray((150, 9), dtype=float32, min=-5.831, max=3.955, mean=-0.139),
[2m[36m(pid=24445)[0m             'obs': np.ndarray((150, 9), dtype=float32, min=-5.831, max=3.955, mean=-0.137),
[2m[36m(pid=24445)[0m             'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.098),
[2m[36m(pid=24445)[0m             'prev_rewards': np.ndarray((150,), dtype=float32, min=-6.794, max=5.86, mean=-0.082),
[2m[36m(pid=24445)[0m             'rewards': np.ndarray((150,), dtype=float32, min=-6.794, max=5.86, mean=-0.086),
[2m[36m(pid=24445)[0m             't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=24445)[0m             'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24445)[0m             'weights': np.ndarray((150,), dtype=float32, min=0.0, max=6.807, mean=1.432)},
[2m[36m(pid=24445)[0m   'type': 'SampleBatch'}
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24435)[0m [32m [     0.02165s,  INFO] TimeLimit:
[2m[36m(pid=24435)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=24435)[0m - action_space = Box(2,)
[2m[36m(pid=24435)[0m - observation_space = Box(9,)
[2m[36m(pid=24435)[0m - reward_range = (-inf, inf)
[2m[36m(pid=24435)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=24435)[0m - _max_episode_steps = 150
[2m[36m(pid=24435)[0m - _elapsed_steps = None [0m
[2m[36m(pid=24435)[0m 2019-07-23 21:51:19,488	INFO rollout_worker.py:301 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=24435)[0m 2019-07-23 21:51:19.488668: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=24439)[0m [32m [     0.02158s,  INFO] TimeLimit:
[2m[36m(pid=24439)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=24439)[0m - action_space = Box(2,)
[2m[36m(pid=24439)[0m - observation_space = Box(9,)
[2m[36m(pid=24439)[0m - reward_range = (-inf, inf)
[2m[36m(pid=24439)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=24439)[0m - _max_episode_steps = 150
[2m[36m(pid=24439)[0m - _elapsed_steps = None [0m
[2m[36m(pid=24439)[0m 2019-07-23 21:51:19,455	INFO rollout_worker.py:301 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=24439)[0m 2019-07-23 21:51:19.457729: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=24439)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24439)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24435)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24435)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,429	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,439	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.825, max=0.565, mean=-0.031)}}
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,439	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,439	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.825, max=0.565, mean=-0.031)
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,439	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.825, max=0.565, mean=-0.031)
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,440	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=24435)[0m                                   'env_id': 0,
[2m[36m(pid=24435)[0m                                   'info': None,
[2m[36m(pid=24435)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.825, max=0.565, mean=-0.031),
[2m[36m(pid=24435)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=24435)[0m                                   'rnn_state': []},
[2m[36m(pid=24435)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,440	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,467	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-0.192, max=0.021, mean=-0.086),
[2m[36m(pid=24435)[0m                       [],
[2m[36m(pid=24435)[0m                       {})}
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,570	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m { 'agent0': { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.92, mean=-0.425),
[2m[36m(pid=24435)[0m                         'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m                         'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m                         'eps_id': np.ndarray((50,), dtype=int64, min=1946918602.0, max=1946918602.0, mean=1946918602.0),
[2m[36m(pid=24435)[0m                         'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=24435)[0m                         'new_obs': np.ndarray((50, 9), dtype=float32, min=-10.0, max=10.0, mean=-0.276),
[2m[36m(pid=24435)[0m                         'obs': np.ndarray((50, 9), dtype=float32, min=-10.0, max=10.0, mean=-0.252),
[2m[36m(pid=24435)[0m                         'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.92, mean=-0.421),
[2m[36m(pid=24435)[0m                         'prev_rewards': np.ndarray((50,), dtype=float32, min=-12.5, max=10.221, mean=-0.687),
[2m[36m(pid=24435)[0m                         'rewards': np.ndarray((50,), dtype=float32, min=-12.5, max=14.156, mean=-0.404),
[2m[36m(pid=24435)[0m                         't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=24435)[0m                         'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m                         'weights': np.ndarray((50,), dtype=float32, min=0.009, max=14.142, mean=2.424)},
[2m[36m(pid=24435)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m 2019-07-23 21:51:20,573	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24435)[0m { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.92, mean=-0.425),
[2m[36m(pid=24435)[0m             'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m             'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m             'eps_id': np.ndarray((50,), dtype=int64, min=1946918602.0, max=1946918602.0, mean=1946918602.0),
[2m[36m(pid=24435)[0m             'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=24435)[0m             'new_obs': np.ndarray((50, 9), dtype=float32, min=-10.0, max=10.0, mean=-0.276),
[2m[36m(pid=24435)[0m             'obs': np.ndarray((50, 9), dtype=float32, min=-10.0, max=10.0, mean=-0.252),
[2m[36m(pid=24435)[0m             'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=0.92, mean=-0.421),
[2m[36m(pid=24435)[0m             'prev_rewards': np.ndarray((50,), dtype=float32, min=-12.5, max=10.221, mean=-0.687),
[2m[36m(pid=24435)[0m             'rewards': np.ndarray((50,), dtype=float32, min=-12.5, max=14.156, mean=-0.404),
[2m[36m(pid=24435)[0m             't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=24435)[0m             'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=24435)[0m             'weights': np.ndarray((50,), dtype=float32, min=0.009, max=14.142, mean=2.424)},
[2m[36m(pid=24435)[0m   'type': 'SampleBatch'}
[2m[36m(pid=24435)[0m 
[2m[36m(pid=24445)[0m 2019-07-23 21:51:49,400	INFO rollout_worker.py:552 -- Training on concatenated sample batches:
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'count': 512,
[2m[36m(pid=24445)[0m   'policy_batches': { 'default_policy': { 'data': { 'actions': np.ndarray((512, 2), dtype=float32, min=-1.0, max=0.998, mean=-0.005),
[2m[36m(pid=24445)[0m                                                     'batch_indexes': np.ndarray((512,), dtype=int64, min=19.0, max=12438.0, mean=6333.75),
[2m[36m(pid=24445)[0m                                                     'dones': np.ndarray((512,), dtype=bool, min=0.0, max=1.0, mean=0.004),
[2m[36m(pid=24445)[0m                                                     'new_obs': np.ndarray((512, 9), dtype=float32, min=-10.0, max=4.395, mean=0.001),
[2m[36m(pid=24445)[0m                                                     'obs': np.ndarray((512, 9), dtype=float32, min=-7.029, max=4.043, mean=-0.0),
[2m[36m(pid=24445)[0m                                                     'rewards': np.ndarray((512,), dtype=float32, min=-4.288, max=14.156, mean=-0.159),
[2m[36m(pid=24445)[0m                                                     'weights': np.ndarray((512,), dtype=float64, min=0.033, max=0.26, mean=0.068)},
[2m[36m(pid=24445)[0m                                           'type': 'SampleBatch'}},
[2m[36m(pid=24445)[0m   'type': 'MultiAgentBatch'}
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m 2019-07-23 21:51:49,604	INFO rollout_worker.py:574 -- Training output:
[2m[36m(pid=24445)[0m 
[2m[36m(pid=24445)[0m { 'default_policy': { 'learner_stats': { 'max_q': 0.12556967,
[2m[36m(pid=24445)[0m                                          'mean_q': -0.08416031,
[2m[36m(pid=24445)[0m                                          'min_q': -0.68059504},
[2m[36m(pid=24445)[0m                       'td_error': np.ndarray((512,), dtype=float32, min=-14.142, max=4.329, mean=0.142)}}
[2m[36m(pid=24445)[0m 
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-51-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 15.42601474937538
  episode_reward_mean: -10.86916530510997
  episode_reward_min: -37.19263710991836
  episodes_this_iter: 161
  episodes_total: 161
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 0.9908128380775452
        mean_q: -0.06085185334086418
        min_q: -0.765386164188385
    learner_queue:
      size_count: 65701
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      size_std: 0.3370459909270544
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 580
    num_steps_sampled: 48300
    num_steps_trained: 7680
    num_target_updates: 0
    num_weight_syncs: 120
    replay_shard_0:
      add_batch_time_ms: 2.751
      policy_default_policy:
        added_count: 12000
        est_size_bytes: 4092000
        num_entries: 12000
        sampled_count: 0
      replay_time_ms: .nan
      update_priorities_time_ms: .nan
    sample_throughput: 1111.745
    train_throughput: 11384.273
  iterations_since_restore: 1
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.285258052678537
    mean_inference_ms: 0.7113566580892695
    mean_processing_ms: 0.1845946631860813
  time_since_restore: 30.068378925323486
  time_this_iter_s: 30.068378925323486
  time_total_s: 30.068378925323486
  timestamp: 1563911510
  timesteps_since_restore: 48300
  timesteps_this_iter: 48300
  timesteps_total: 48300
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 30 s, 1 iter, 48300 ts, -10.9 rew

[2m[36m(pid=24636)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.
[2m[36m(pid=24636)[0m   out=out, **kwargs)
[2m[36m(pid=24636)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars
[2m[36m(pid=24636)[0m   ret = ret.dtype.type(ret / rcount)
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-52-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 23.727985870871755
  episode_reward_mean: -13.455182085611842
  episode_reward_min: -101.71857493264059
  episodes_this_iter: 113
  episodes_total: 274
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.50642776489258
        mean_q: 2.724125862121582
        min_q: -25.682558059692383
    learner_queue:
      size_count: 70326
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5381449618829484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 748
    num_steps_sampled: 82250
    num_steps_trained: 641536
    num_target_updates: 12
    num_weight_syncs: 205
    replay_shard_0:
      add_batch_time_ms: 3.675
      policy_default_policy:
        added_count: 21200
        est_size_bytes: 7229200
        num_entries: 21200
        sampled_count: 158208
      replay_time_ms: 18.367
      update_priorities_time_ms: 52.429
    sample_throughput: 0.0
    train_throughput: 27702.317
  iterations_since_restore: 2
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3209288620704579
    mean_inference_ms: 0.8652410711158188
    mean_processing_ms: 0.20859985785926224
  time_since_restore: 60.308141231536865
  time_this_iter_s: 30.23976230621338
  time_total_s: 60.308141231536865
  timestamp: 1563911540
  timesteps_since_restore: 82250
  timesteps_this_iter: 33950
  timesteps_total: 82250
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 60 s, 2 iter, 82250 ts, -13.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-52-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.729676630601794
  episode_reward_mean: 9.740123496434746
  episode_reward_min: -53.16905005068001
  episodes_this_iter: 102
  episodes_total: 376
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.70890808105469
        mean_q: 10.662304878234863
        min_q: -20.41086196899414
    learner_queue:
      size_count: 71532
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.596322060635023
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 760
    num_steps_sampled: 113000
    num_steps_trained: 1258496
    num_target_updates: 25
    num_weight_syncs: 281
    replay_shard_0:
      add_batch_time_ms: 3.314
      policy_default_policy:
        added_count: 28400
        est_size_bytes: 9684400
        num_entries: 28400
        sampled_count: 313856
      replay_time_ms: 19.038
      update_priorities_time_ms: 53.775
    sample_throughput: 0.0
    train_throughput: 31224.317
  iterations_since_restore: 3
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3392982435607398
    mean_inference_ms: 0.9616889539038377
    mean_processing_ms: 0.22227309136219117
  time_since_restore: 90.53875303268433
  time_this_iter_s: 30.23061180114746
  time_total_s: 90.53875303268433
  timestamp: 1563911570
  timesteps_since_restore: 113000
  timesteps_this_iter: 30750
  timesteps_total: 113000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 90 s, 3 iter, 113000 ts, 9.74 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-53-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.13383876643032
  episode_reward_mean: 11.944690234575546
  episode_reward_min: -8.065625490765083
  episodes_this_iter: 112
  episodes_total: 488
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.04044723510742
        mean_q: 14.459915161132812
        min_q: -21.841196060180664
    learner_queue:
      size_count: 72799
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6079473661428265
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 768
    num_steps_sampled: 146700
    num_steps_trained: 1908224
    num_target_updates: 38
    num_weight_syncs: 366
    replay_shard_0:
      add_batch_time_ms: 3.654
      policy_default_policy:
        added_count: 37100
        est_size_bytes: 12651100
        num_entries: 37100
        sampled_count: 476160
      replay_time_ms: 26.12
      update_priorities_time_ms: 58.392
    sample_throughput: 7821.4
    train_throughput: 0.0
  iterations_since_restore: 4
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.345631385132199
    mean_inference_ms: 0.992023070394156
    mean_processing_ms: 0.2268261981757558
  time_since_restore: 120.80474877357483
  time_this_iter_s: 30.265995740890503
  time_total_s: 120.80474877357483
  timestamp: 1563911600
  timesteps_since_restore: 146700
  timesteps_this_iter: 33700
  timesteps_total: 146700
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 120 s, 4 iter, 146700 ts, 11.9 rew

[2m[36m(pid=24445)[0m 2019-07-23 21:53:51,199	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-53-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.0874310611575
  episode_reward_mean: 11.82944232405374
  episode_reward_min: -21.608997746499554
  episodes_this_iter: 103
  episodes_total: 591
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 22.401187600002093
    episode_reward_mean: 6.58206280444743
    episode_reward_min: -14.47758708390186
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.17827195113835753
      mean_inference_ms: 0.42514346592110897
      mean_processing_ms: 0.10365996508549072
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 43.12506866455078
        mean_q: 14.95942497253418
        min_q: -26.289710998535156
    learner_queue:
      size_count: 73994
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4898979485566356
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 784
    num_steps_sampled: 177400
    num_steps_trained: 2519552
    num_target_updates: 50
    num_weight_syncs: 442
    replay_shard_0:
      add_batch_time_ms: 3.356
      policy_default_policy:
        added_count: 44600
        est_size_bytes: 15208600
        num_entries: 44600
        sampled_count: 630784
      replay_time_ms: 21.303
      update_priorities_time_ms: 56.657
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 5
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.35372697094541444
    mean_inference_ms: 1.0300425803178734
    mean_processing_ms: 0.23206315015497608
  time_since_restore: 151.0632073879242
  time_this_iter_s: 30.258458614349365
  time_total_s: 151.0632073879242
  timestamp: 1563911631
  timesteps_since_restore: 177400
  timesteps_this_iter: 30700
  timesteps_total: 177400
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 6.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 151 s, 5 iter, 177400 ts, 11.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-54-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 27.200355875650693
  episode_reward_mean: 6.8535604641865335
  episode_reward_min: -26.68336542637473
  episodes_this_iter: 113
  episodes_total: 704
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.6602783203125
        mean_q: 15.935263633728027
        min_q: -34.202720642089844
    learner_queue:
      size_count: 75256
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 2.0
      - 3.0
      size_std: 0.7644605941446556
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 798
    num_steps_sampled: 211150
    num_steps_trained: 3165696
    num_target_updates: 63
    num_weight_syncs: 527
    replay_shard_0:
      add_batch_time_ms: 3.068
      policy_default_policy:
        added_count: 52750
        est_size_bytes: 17987750
        num_entries: 52750
        sampled_count: 794112
      replay_time_ms: 18.425
      update_priorities_time_ms: 53.913
    sample_throughput: 5670.737
    train_throughput: 0.0
  iterations_since_restore: 6
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.35590386352530395
    mean_inference_ms: 1.0399220302494838
    mean_processing_ms: 0.23439187870153333
  time_since_restore: 181.28989458084106
  time_this_iter_s: 30.22668719291687
  time_total_s: 181.28989458084106
  timestamp: 1563911662
  timesteps_since_restore: 211150
  timesteps_this_iter: 33750
  timesteps_total: 211150
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 181 s, 6 iter, 211150 ts, 6.85 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-54-52
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.51115533443311
  episode_reward_mean: 8.381502339461148
  episode_reward_min: -25.44243636045913
  episodes_this_iter: 103
  episodes_total: 807
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.28028106689453
        mean_q: 17.01788330078125
        min_q: -9.482929229736328
    learner_queue:
      size_count: 76439
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5741080037762929
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 804
    num_steps_sampled: 242150
    num_steps_trained: 3771392
    num_target_updates: 75
    num_weight_syncs: 604
    replay_shard_0:
      add_batch_time_ms: 3.548
      policy_default_policy:
        added_count: 60200
        est_size_bytes: 20528200
        num_entries: 60200
        sampled_count: 947200
      replay_time_ms: 21.64
      update_priorities_time_ms: 55.895
    sample_throughput: 0.0
    train_throughput: 21518.519
  iterations_since_restore: 7
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3597515358350106
    mean_inference_ms: 1.0611230547297794
    mean_processing_ms: 0.23742197208363763
  time_since_restore: 211.5269250869751
  time_this_iter_s: 30.237030506134033
  time_total_s: 211.5269250869751
  timestamp: 1563911692
  timesteps_since_restore: 242150
  timesteps_this_iter: 31000
  timesteps_total: 242150
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 211 s, 7 iter, 242150 ts, 8.38 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-55-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.74118116425966
  episode_reward_mean: 9.079793960300705
  episode_reward_min: -23.923186892818944
  episodes_this_iter: 115
  episodes_total: 922
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 46.25011444091797
        mean_q: 16.76367950439453
        min_q: -15.506340026855469
    learner_queue:
      size_count: 77689
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6708203932499369
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 816
    num_steps_sampled: 276150
    num_steps_trained: 4411904
    num_target_updates: 87
    num_weight_syncs: 689
    replay_shard_0:
      add_batch_time_ms: 3.192
      policy_default_policy:
        added_count: 68700
        est_size_bytes: 23426700
        num_entries: 68700
        sampled_count: 1106432
      replay_time_ms: 19.209
      update_priorities_time_ms: 55.234
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 8
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3606551972705449
    mean_inference_ms: 1.0615814316639154
    mean_processing_ms: 0.23766813489825528
  time_since_restore: 241.76532912254333
  time_this_iter_s: 30.238404035568237
  time_total_s: 241.76532912254333
  timestamp: 1563911722
  timesteps_since_restore: 276150
  timesteps_this_iter: 34000
  timesteps_total: 276150
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 241 s, 8 iter, 276150 ts, 9.08 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-55-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.21158487675979
  episode_reward_mean: 9.787381422958335
  episode_reward_min: -13.08412630447665
  episodes_this_iter: 103
  episodes_total: 1025
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.29947280883789
        mean_q: 16.95281219482422
        min_q: -8.122207641601562
    learner_queue:
      size_count: 78876
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5730619512757762
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 830
    num_steps_sampled: 306950
    num_steps_trained: 5019648
    num_target_updates: 100
    num_weight_syncs: 767
    replay_shard_0:
      add_batch_time_ms: 4.493
      policy_default_policy:
        added_count: 77100
        est_size_bytes: 26291100
        num_entries: 77100
        sampled_count: 1260032
      replay_time_ms: 21.897
      update_priorities_time_ms: 56.932
    sample_throughput: 0.0
    train_throughput: 29109.739
  iterations_since_restore: 9
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36309149685352965
    mean_inference_ms: 1.0765937998055541
    mean_processing_ms: 0.24007782205819023
  time_since_restore: 271.9873917102814
  time_this_iter_s: 30.222062587738037
  time_total_s: 271.9873917102814
  timestamp: 1563911753
  timesteps_since_restore: 306950
  timesteps_this_iter: 30800
  timesteps_total: 306950
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 271 s, 9 iter, 306950 ts, 9.79 rew

[2m[36m(pid=24445)[0m 2019-07-23 21:56:23,387	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-56-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.12391657239546
  episode_reward_mean: 10.948911686948646
  episode_reward_min: -22.25658335276183
  episodes_this_iter: 113
  episodes_total: 1138
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 23.953663541097026
    episode_reward_mean: 6.763162776416595
    episode_reward_min: -9.926466843890802
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1721184562508516
      mean_inference_ms: 0.41239596928153877
      mean_processing_ms: 0.09930501962020591
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 43.35454177856445
        mean_q: 17.29839324951172
        min_q: -14.512261390686035
    learner_queue:
      size_count: 80126
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5381449618829484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 836
    num_steps_sampled: 340850
    num_steps_trained: 5659136
    num_target_updates: 112
    num_weight_syncs: 851
    replay_shard_0:
      add_batch_time_ms: 3.235
      policy_default_policy:
        added_count: 85800
        est_size_bytes: 29257800
        num_entries: 85800
        sampled_count: 1419776
      replay_time_ms: 21.595
      update_priorities_time_ms: 61.787
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 10
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3633209638928193
    mean_inference_ms: 1.0767870968727828
    mean_processing_ms: 0.24045930595611684
  time_since_restore: 302.2603533267975
  time_this_iter_s: 30.272961616516113
  time_total_s: 302.2603533267975
  timestamp: 1563911783
  timesteps_since_restore: 340850
  timesteps_this_iter: 33900
  timesteps_total: 340850
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 7.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 302 s, 10 iter, 340850 ts, 10.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-56-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.312868725116
  episode_reward_mean: 11.759377664933382
  episode_reward_min: -10.96137796060267
  episodes_this_iter: 103
  episodes_total: 1241
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 46.30686569213867
        mean_q: 17.502689361572266
        min_q: -10.507250785827637
    learner_queue:
      size_count: 81307
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 848
    num_steps_sampled: 371900
    num_steps_trained: 6263808
    num_target_updates: 124
    num_weight_syncs: 929
    replay_shard_0:
      add_batch_time_ms: 3.547
      policy_default_policy:
        added_count: 93250
        est_size_bytes: 31798250
        num_entries: 93250
        sampled_count: 1570816
      replay_time_ms: 22.857
      update_priorities_time_ms: 52.868
    sample_throughput: 1933.643
    train_throughput: 19800.506
  iterations_since_restore: 11
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3654707365927315
    mean_inference_ms: 1.0877852465456626
    mean_processing_ms: 0.24180244190683398
  time_since_restore: 332.49646496772766
  time_this_iter_s: 30.236111640930176
  time_total_s: 332.49646496772766
  timestamp: 1563911814
  timesteps_since_restore: 371900
  timesteps_this_iter: 31050
  timesteps_total: 371900
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 332 s, 11 iter, 371900 ts, 11.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-57-24
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.29986116805491
  episode_reward_mean: 12.715989979161446
  episode_reward_min: -11.429301148040745
  episodes_this_iter: 114
  episodes_total: 1355
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 44.422210693359375
        mean_q: 17.35125732421875
        min_q: -3.4106497764587402
    learner_queue:
      size_count: 82550
      size_mean: 0.6
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5291502622129182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 860
    num_steps_sampled: 405950
    num_steps_trained: 6900224
    num_target_updates: 137
    num_weight_syncs: 1014
    replay_shard_0:
      add_batch_time_ms: 3.082
      policy_default_policy:
        added_count: 101300
        est_size_bytes: 34543300
        num_entries: 101300
        sampled_count: 1730560
      replay_time_ms: 19.237
      update_priorities_time_ms: 54.54
    sample_throughput: 0.0
    train_throughput: 35952.582
  iterations_since_restore: 12
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36541897176874527
    mean_inference_ms: 1.0866827760934366
    mean_processing_ms: 0.24208502238300866
  time_since_restore: 362.75367498397827
  time_this_iter_s: 30.25721001625061
  time_total_s: 362.75367498397827
  timestamp: 1563911844
  timesteps_since_restore: 405950
  timesteps_this_iter: 34050
  timesteps_total: 405950
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 362 s, 12 iter, 405950 ts, 12.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-57-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.92583922745072
  episode_reward_mean: 16.240404407517214
  episode_reward_min: -4.793337619922694
  episodes_this_iter: 104
  episodes_total: 1459
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.66111373901367
        mean_q: 16.23444366455078
        min_q: 4.090310573577881
    learner_queue:
      size_count: 83727
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4963869458396343
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 873
    num_steps_sampled: 437050
    num_steps_trained: 7502848
    num_target_updates: 149
    num_weight_syncs: 1091
    replay_shard_0:
      add_batch_time_ms: 5.264
      policy_default_policy:
        added_count: 109050
        est_size_bytes: 37186050
        num_entries: 109050
        sampled_count: 1880576
      replay_time_ms: 22.803
      update_priorities_time_ms: 56.87
    sample_throughput: 0.0
    train_throughput: 23716.784
  iterations_since_restore: 13
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.366810944499656
    mean_inference_ms: 1.0943448742202588
    mean_processing_ms: 0.2429776411532679
  time_since_restore: 392.9935088157654
  time_this_iter_s: 30.23983383178711
  time_total_s: 392.9935088157654
  timestamp: 1563911875
  timesteps_since_restore: 437050
  timesteps_this_iter: 31100
  timesteps_total: 437050
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 392 s, 13 iter, 437050 ts, 16.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-58-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.44797772308748
  episode_reward_mean: 12.362106255295728
  episode_reward_min: -18.567370979649954
  episodes_this_iter: 113
  episodes_total: 1572
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 46.05279541015625
        mean_q: 17.196041107177734
        min_q: 4.131362438201904
    learner_queue:
      size_count: 84968
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5571355310873648
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 885
    num_steps_sampled: 471150
    num_steps_trained: 8138752
    num_target_updates: 162
    num_weight_syncs: 1177
    replay_shard_0:
      add_batch_time_ms: 4.133
      policy_default_policy:
        added_count: 117450
        est_size_bytes: 40050450
        num_entries: 117450
        sampled_count: 2039296
      replay_time_ms: 22.939
      update_priorities_time_ms: 54.867
    sample_throughput: 0.0
    train_throughput: 61087.889
  iterations_since_restore: 14
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3668023071010161
    mean_inference_ms: 1.093929955194129
    mean_processing_ms: 0.24289807008590103
  time_since_restore: 423.2513165473938
  time_this_iter_s: 30.257807731628418
  time_total_s: 423.2513165473938
  timestamp: 1563911905
  timesteps_since_restore: 471150
  timesteps_this_iter: 34100
  timesteps_total: 471150
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 8.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 423 s, 14 iter, 471150 ts, 12.4 rew

[2m[36m(pid=24445)[0m 2019-07-23 21:58:55,717	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-58-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.11673767483861
  episode_reward_mean: 12.60706863811819
  episode_reward_min: -5.057486961237391
  episodes_this_iter: 105
  episodes_total: 1677
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 31.675222536599396
    episode_reward_mean: 11.51322917753123
    episode_reward_min: -2.6523104598056904
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.17214715331817662
      mean_inference_ms: 0.4136837277684961
      mean_processing_ms: 0.0987508221082619
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.97871017456055
        mean_q: 16.528257369995117
        min_q: -4.207121849060059
    learner_queue:
      size_count: 86138
      size_mean: 1.32
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 3.0
      - 4.0
      size_std: 0.947417542586161
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 899
    num_steps_sampled: 502800
    num_steps_trained: 8737280
    num_target_updates: 174
    num_weight_syncs: 1256
    replay_shard_0:
      add_batch_time_ms: 4.674
      policy_default_policy:
        added_count: 124650
        est_size_bytes: 42505650
        num_entries: 124650
        sampled_count: 2190848
      replay_time_ms: 27.806
      update_priorities_time_ms: 78.714
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 15
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3678381219581199
    mean_inference_ms: 1.0996859417053189
    mean_processing_ms: 0.2436315239793944
  time_since_restore: 453.58498978614807
  time_this_iter_s: 30.333673238754272
  time_total_s: 453.58498978614807
  timestamp: 1563911935
  timesteps_since_restore: 502800
  timesteps_this_iter: 31650
  timesteps_total: 502800
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 453 s, 15 iter, 502800 ts, 12.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-59-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.39161577394405
  episode_reward_mean: 14.300431735747418
  episode_reward_min: -17.727595590413415
  episodes_this_iter: 114
  episodes_total: 1791
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 44.0724983215332
        mean_q: 16.472942352294922
        min_q: -29.192045211791992
    learner_queue:
      size_count: 87372
      size_mean: 0.84
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.88
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 912
    num_steps_sampled: 537000
    num_steps_trained: 9369600
    num_target_updates: 186
    num_weight_syncs: 1342
    replay_shard_0:
      add_batch_time_ms: 3.443
      policy_default_policy:
        added_count: 133700
        est_size_bytes: 45591700
        num_entries: 133700
        sampled_count: 2350080
      replay_time_ms: 20.215
      update_priorities_time_ms: 50.929
    sample_throughput: 2493.167
    train_throughput: 25530.026
  iterations_since_restore: 16
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3678372594323891
    mean_inference_ms: 1.0980122156416279
    mean_processing_ms: 0.2434944780007674
  time_since_restore: 483.8336446285248
  time_this_iter_s: 30.24865484237671
  time_total_s: 483.8336446285248
  timestamp: 1563911967
  timesteps_since_restore: 537000
  timesteps_this_iter: 34200
  timesteps_total: 537000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 483 s, 16 iter, 537000 ts, 14.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_21-59-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.64945673841979
  episode_reward_mean: 14.740639768407902
  episode_reward_min: -14.1823453331578
  episodes_this_iter: 103
  episodes_total: 1894
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.182838439941406
        mean_q: 15.46605396270752
        min_q: -7.295671463012695
    learner_queue:
      size_count: 88548
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5919459434779496
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 923
    num_steps_sampled: 568050
    num_steps_trained: 9971200
    num_target_updates: 198
    num_weight_syncs: 1420
    replay_shard_0:
      add_batch_time_ms: 4.145
      policy_default_policy:
        added_count: 141200
        est_size_bytes: 48149200
        num_entries: 141200
        sampled_count: 2504192
      replay_time_ms: 23.997
      update_priorities_time_ms: 66.142
    sample_throughput: 785.2
    train_throughput: 16080.9
  iterations_since_restore: 17
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.368850928786919
    mean_inference_ms: 1.1042421555680288
    mean_processing_ms: 0.2443668504184527
  time_since_restore: 514.1122868061066
  time_this_iter_s: 30.278642177581787
  time_total_s: 514.1122868061066
  timestamp: 1563911997
  timesteps_since_restore: 568050
  timesteps_this_iter: 31050
  timesteps_total: 568050
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 514 s, 17 iter, 568050 ts, 14.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-00-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.92203609644083
  episode_reward_mean: 15.793140522105356
  episode_reward_min: -4.376357408201693
  episodes_this_iter: 114
  episodes_total: 2008
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 45.33251953125
        mean_q: 16.27667999267578
        min_q: -6.608433246612549
    learner_queue:
      size_count: 89787
      size_mean: 0.72
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6645299090334459
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 936
    num_steps_sampled: 602350
    num_steps_trained: 10604544
    num_target_updates: 211
    num_weight_syncs: 1505
    replay_shard_0:
      add_batch_time_ms: 3.106
      policy_default_policy:
        added_count: 149800
        est_size_bytes: 51081800
        num_entries: 149800
        sampled_count: 2663424
      replay_time_ms: 20.294
      update_priorities_time_ms: 59.47
    sample_throughput: 1664.842
    train_throughput: 0.0
  iterations_since_restore: 18
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36867212214572276
    mean_inference_ms: 1.1025563438253416
    mean_processing_ms: 0.24422152322214236
  time_since_restore: 544.363038778305
  time_this_iter_s: 30.250751972198486
  time_total_s: 544.363038778305
  timestamp: 1563912027
  timesteps_since_restore: 602350
  timesteps_this_iter: 34300
  timesteps_total: 602350
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 544 s, 18 iter, 602350 ts, 15.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-00-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.76127896540766
  episode_reward_mean: 16.056600624246236
  episode_reward_min: -12.110608828754064
  episodes_this_iter: 106
  episodes_total: 2114
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.40166473388672
        mean_q: 15.438169479370117
        min_q: 0.20854118466377258
    learner_queue:
      size_count: 90973
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5385164807134504
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 947
    num_steps_sampled: 634150
    num_steps_trained: 11212288
    num_target_updates: 223
    num_weight_syncs: 1584
    replay_shard_0:
      add_batch_time_ms: 3.34
      policy_default_policy:
        added_count: 158950
        est_size_bytes: 54201950
        num_entries: 158950
        sampled_count: 2815488
      replay_time_ms: 25.038
      update_priorities_time_ms: 72.944
    sample_throughput: 0.0
    train_throughput: 17589.781
  iterations_since_restore: 19
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3695658180016486
    mean_inference_ms: 1.105828877461752
    mean_processing_ms: 0.24470683031622112
  time_since_restore: 574.6980674266815
  time_this_iter_s: 30.335028648376465
  time_total_s: 574.6980674266815
  timestamp: 1563912057
  timesteps_since_restore: 634150
  timesteps_this_iter: 31800
  timesteps_total: 634150
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 9.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 574 s, 19 iter, 634150 ts, 16.1 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:01:28,224	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-01-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.04412654052249
  episode_reward_mean: 15.766892357986896
  episode_reward_min: -15.500489515723494
  episodes_this_iter: 114
  episodes_total: 2228
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 30.192618425346804
    episode_reward_mean: 12.512973114800849
    episode_reward_min: -13.439487810191352
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.17021436911235727
      mean_inference_ms: 0.40989582609485076
      mean_processing_ms: 0.09734594667773137
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 40.1855583190918
        mean_q: 15.493678092956543
        min_q: -22.413415908813477
    learner_queue:
      size_count: 92193
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      - 2.0
      size_std: 0.699714227381436
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 961
    num_steps_sampled: 668200
    num_steps_trained: 11837440
    num_target_updates: 235
    num_weight_syncs: 1670
    replay_shard_0:
      add_batch_time_ms: 3.52
      policy_default_policy:
        added_count: 167400
        est_size_bytes: 57083400
        num_entries: 167400
        sampled_count: 2972160
      replay_time_ms: 22.335
      update_priorities_time_ms: 60.488
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 20
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36954423114195695
    mean_inference_ms: 1.1045138863964958
    mean_processing_ms: 0.24442323007151898
  time_since_restore: 605.0030274391174
  time_this_iter_s: 30.304960012435913
  time_total_s: 605.0030274391174
  timestamp: 1563912088
  timesteps_since_restore: 668200
  timesteps_this_iter: 34050
  timesteps_total: 668200
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 605 s, 20 iter, 668200 ts, 15.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-01-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.031469093975886
  episode_reward_mean: 14.84575086941008
  episode_reward_min: -9.52846540531269
  episodes_this_iter: 105
  episodes_total: 2333
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 43.29119873046875
        mean_q: 14.885662078857422
        min_q: 3.6953375339508057
    learner_queue:
      size_count: 93370
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.596322060635023
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 973
    num_steps_sampled: 699700
    num_steps_trained: 12440064
    num_target_updates: 247
    num_weight_syncs: 1748
    replay_shard_0:
      add_batch_time_ms: 5.236
      policy_default_policy:
        added_count: 175600
        est_size_bytes: 59879600
        num_entries: 175600
        sampled_count: 3123712
      replay_time_ms: 26.45
      update_priorities_time_ms: 68.015
    sample_throughput: 0.0
    train_throughput: 16930.383
  iterations_since_restore: 21
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3700179954460418
    mean_inference_ms: 1.1081642470420885
    mean_processing_ms: 0.24494234273757107
  time_since_restore: 635.3521461486816
  time_this_iter_s: 30.34911870956421
  time_total_s: 635.3521461486816
  timestamp: 1563912119
  timesteps_since_restore: 699700
  timesteps_this_iter: 31500
  timesteps_total: 699700
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 635 s, 21 iter, 699700 ts, 14.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-02-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.61860285358098
  episode_reward_mean: 15.697788438965208
  episode_reward_min: -6.427137291820296
  episodes_this_iter: 114
  episodes_total: 2447
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.8729362487793
        mean_q: 14.811920166015625
        min_q: -2.9279367923736572
    learner_queue:
      size_count: 94592
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5741080037762929
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 986
    num_steps_sampled: 734000
    num_steps_trained: 13065728
    num_target_updates: 260
    num_weight_syncs: 1834
    replay_shard_0:
      add_batch_time_ms: 3.306
      policy_default_policy:
        added_count: 184050
        est_size_bytes: 62761050
        num_entries: 184050
        sampled_count: 3280896
      replay_time_ms: 21.961
      update_priorities_time_ms: 55.064
    sample_throughput: 1593.714
    train_throughput: 32639.258
  iterations_since_restore: 22
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3698659937823533
    mean_inference_ms: 1.1061914440182574
    mean_processing_ms: 0.24459883874050845
  time_since_restore: 665.6223850250244
  time_this_iter_s: 30.270238876342773
  time_total_s: 665.6223850250244
  timestamp: 1563912149
  timesteps_since_restore: 734000
  timesteps_this_iter: 34300
  timesteps_total: 734000
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 665 s, 22 iter, 734000 ts, 15.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-03-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.81037192050893
  episode_reward_mean: 16.205923486727894
  episode_reward_min: -12.320433081900653
  episodes_this_iter: 107
  episodes_total: 2554
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 41.80330276489258
        mean_q: 14.174539566040039
        min_q: -10.172990798950195
    learner_queue:
      size_count: 95772
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.596322060635023
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 996
    num_steps_sampled: 766100
    num_steps_trained: 13669888
    num_target_updates: 272
    num_weight_syncs: 1914
    replay_shard_0:
      add_batch_time_ms: 3.792
      policy_default_policy:
        added_count: 191900
        est_size_bytes: 65437900
        num_entries: 191900
        sampled_count: 3432448
      replay_time_ms: 27.953
      update_priorities_time_ms: 72.275
    sample_throughput: 0.0
    train_throughput: 14599.694
  iterations_since_restore: 23
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37056668985030006
    mean_inference_ms: 1.1081670980676908
    mean_processing_ms: 0.24517205953215396
  time_since_restore: 695.9957463741302
  time_this_iter_s: 30.373361349105835
  time_total_s: 695.9957463741302
  timestamp: 1563912180
  timesteps_since_restore: 766100
  timesteps_this_iter: 32100
  timesteps_total: 766100
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 695 s, 23 iter, 766100 ts, 16.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-03-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.24061967581289
  episode_reward_mean: 13.917154483429186
  episode_reward_min: -7.352991566907205
  episodes_this_iter: 114
  episodes_total: 2668
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.8415641784668
        mean_q: 13.8884916305542
        min_q: -40.748016357421875
    learner_queue:
      size_count: 96981
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6082762530298219
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1014
    num_steps_sampled: 800250
    num_steps_trained: 14288896
    num_target_updates: 284
    num_weight_syncs: 2000
    replay_shard_0:
      add_batch_time_ms: 3.358
      policy_default_policy:
        added_count: 201050
        est_size_bytes: 68558050
        num_entries: 201050
        sampled_count: 3587584
      replay_time_ms: 21.095
      update_priorities_time_ms: 53.429
    sample_throughput: 0.0
    train_throughput: 21014.411
  iterations_since_restore: 24
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3704747470459937
    mean_inference_ms: 1.1071045195365805
    mean_processing_ms: 0.24499672785885054
  time_since_restore: 726.2308359146118
  time_this_iter_s: 30.235089540481567
  time_total_s: 726.2308359146118
  timestamp: 1563912210
  timesteps_since_restore: 800250
  timesteps_this_iter: 34150
  timesteps_total: 800250
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 10.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 726 s, 24 iter, 800250 ts, 13.9 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:04:00,846	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-04-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.93064319992145
  episode_reward_mean: 16.55281810272602
  episode_reward_min: -7.548091488321744
  episodes_this_iter: 109
  episodes_total: 2777
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 34.23684983593765
    episode_reward_mean: 22.928397878676442
    episode_reward_min: 8.529265040753668
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.18772407712280562
      mean_inference_ms: 0.45471535220621373
      mean_processing_ms: 0.1061186500687478
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.76740264892578
        mean_q: 13.28104305267334
        min_q: 1.4488811492919922
    learner_queue:
      size_count: 98175
      size_mean: 0.68
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6144916598294887
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1022
    num_steps_sampled: 832950
    num_steps_trained: 14899712
    num_target_updates: 296
    num_weight_syncs: 2082
    replay_shard_0:
      add_batch_time_ms: 5.352
      policy_default_policy:
        added_count: 209400
        est_size_bytes: 71405400
        num_entries: 209400
        sampled_count: 3742208
      replay_time_ms: 28.652
      update_priorities_time_ms: 69.278
    sample_throughput: 1298.168
    train_throughput: 26586.487
  iterations_since_restore: 25
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37079499983012004
    mean_inference_ms: 1.1079572863782088
    mean_processing_ms: 0.24512688063072569
  time_since_restore: 756.5941333770752
  time_this_iter_s: 30.36329746246338
  time_total_s: 756.5941333770752
  timestamp: 1563912240
  timesteps_since_restore: 832950
  timesteps_this_iter: 32700
  timesteps_total: 832950
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 756 s, 25 iter, 832950 ts, 16.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-04-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.24383824558314
  episode_reward_mean: 15.445533468608446
  episode_reward_min: -5.333595421730588
  episodes_this_iter: 115
  episodes_total: 2892
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 42.07822036743164
        mean_q: 13.30445671081543
        min_q: -1.5342575311660767
    learner_queue:
      size_count: 99402
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.62
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1032
    num_steps_sampled: 867500
    num_steps_trained: 15527936
    num_target_updates: 309
    num_weight_syncs: 2168
    replay_shard_0:
      add_batch_time_ms: 3.368
      policy_default_policy:
        added_count: 217550
        est_size_bytes: 74184550
        num_entries: 217550
        sampled_count: 3902464
      replay_time_ms: 20.864
      update_priorities_time_ms: 55.893
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 26
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37055954827138204
    mean_inference_ms: 1.1060017546365548
    mean_processing_ms: 0.24507911002439953
  time_since_restore: 786.8470904827118
  time_this_iter_s: 30.252957105636597
  time_total_s: 786.8470904827118
  timestamp: 1563912272
  timesteps_since_restore: 867500
  timesteps_this_iter: 34550
  timesteps_total: 867500
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 786 s, 26 iter, 867500 ts, 15.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-05-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.086791037387876
  episode_reward_mean: 17.38870007744856
  episode_reward_min: -9.261966130857653
  episodes_this_iter: 107
  episodes_total: 2999
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.853057861328125
        mean_q: 12.188112258911133
        min_q: -19.403820037841797
    learner_queue:
      size_count: 100571
      size_mean: 0.78
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7011419257183241
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1042
    num_steps_sampled: 899500
    num_steps_trained: 16126976
    num_target_updates: 321
    num_weight_syncs: 2248
    replay_shard_0:
      add_batch_time_ms: 3.792
      policy_default_policy:
        added_count: 225950
        est_size_bytes: 77048950
        num_entries: 225950
        sampled_count: 4051968
      replay_time_ms: 32.293
      update_priorities_time_ms: 72.436
    sample_throughput: 0.0
    train_throughput: 14775.078
  iterations_since_restore: 27
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3709703552892802
    mean_inference_ms: 1.1077695623547974
    mean_processing_ms: 0.24539241461660255
  time_since_restore: 817.2111642360687
  time_this_iter_s: 30.364073753356934
  time_total_s: 817.2111642360687
  timestamp: 1563912303
  timesteps_since_restore: 899500
  timesteps_this_iter: 32000
  timesteps_total: 899500
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 817 s, 27 iter, 899500 ts, 17.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-05-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.8303421773945
  episode_reward_mean: 13.981264028990793
  episode_reward_min: -15.586501630478214
  episodes_this_iter: 114
  episodes_total: 3113
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.405086517333984
        mean_q: 12.419208526611328
        min_q: -9.436500549316406
    learner_queue:
      size_count: 101791
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5868560300448484
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1060
    num_steps_sampled: 933500
    num_steps_trained: 16751616
    num_target_updates: 333
    num_weight_syncs: 2333
    replay_shard_0:
      add_batch_time_ms: 3.257
      policy_default_policy:
        added_count: 234050
        est_size_bytes: 79811050
        num_entries: 234050
        sampled_count: 4210688
      replay_time_ms: 20.197
      update_priorities_time_ms: 57.532
    sample_throughput: 0.0
    train_throughput: 18300.598
  iterations_since_restore: 28
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3707905848037595
    mean_inference_ms: 1.1066598267928787
    mean_processing_ms: 0.2452503655017378
  time_since_restore: 847.4829030036926
  time_this_iter_s: 30.2717387676239
  time_total_s: 847.4829030036926
  timestamp: 1563912333
  timesteps_since_restore: 933500
  timesteps_this_iter: 34000
  timesteps_total: 933500
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 847 s, 28 iter, 933500 ts, 14 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-06-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.632016689444065
  episode_reward_mean: 17.235650927741528
  episode_reward_min: -2.3691544875497663
  episodes_this_iter: 107
  episodes_total: 3220
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.73902130126953
        mean_q: 11.466252326965332
        min_q: 2.7465133666992188
    learner_queue:
      size_count: 102966
      size_mean: 0.88
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6823488843692793
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1085
    num_steps_sampled: 965400
    num_steps_trained: 17353216
    num_target_updates: 345
    num_weight_syncs: 2413
    replay_shard_0:
      add_batch_time_ms: 4.298
      policy_default_policy:
        added_count: 242100
        est_size_bytes: 82556100
        num_entries: 242100
        sampled_count: 4364800
      replay_time_ms: 27.378
      update_priorities_time_ms: 70.125
    sample_throughput: 0.0
    train_throughput: 21451.24
  iterations_since_restore: 29
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3710244105769639
    mean_inference_ms: 1.107832705956241
    mean_processing_ms: 0.2453772176686056
  time_since_restore: 877.8634223937988
  time_this_iter_s: 30.3805193901062
  time_total_s: 877.8634223937988
  timestamp: 1563912363
  timesteps_since_restore: 965400
  timesteps_this_iter: 31900
  timesteps_total: 965400
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 877 s, 29 iter, 965400 ts, 17.2 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:06:34,127	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-06-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.317681793868175
  episode_reward_mean: 15.88522413115261
  episode_reward_min: -11.739990140139644
  episodes_this_iter: 111
  episodes_total: 3331
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.28017437018221
    episode_reward_mean: 15.808869494000021
    episode_reward_min: 7.326515674632204
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.18429025083868264
      mean_inference_ms: 0.44698563544775877
      mean_processing_ms: 0.10422658561559055
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.8809700012207
        mean_q: 11.585121154785156
        min_q: -7.174595832824707
    learner_queue:
      size_count: 104171
      size_mean: 0.3
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5385164807134504
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1095
    num_steps_sampled: 999100
    num_steps_trained: 17969664
    num_target_updates: 358
    num_weight_syncs: 2497
    replay_shard_0:
      add_batch_time_ms: 3.306
      policy_default_policy:
        added_count: 251850
        est_size_bytes: 85880850
        num_entries: 251850
        sampled_count: 4519936
      replay_time_ms: 23.491
      update_priorities_time_ms: 59.819
    sample_throughput: 2282.167
    train_throughput: 0.0
  iterations_since_restore: 30
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3709915431867001
    mean_inference_ms: 1.1075728482292546
    mean_processing_ms: 0.2452859268819437
  time_since_restore: 908.1519412994385
  time_this_iter_s: 30.28851890563965
  time_total_s: 908.1519412994385
  timestamp: 1563912394
  timesteps_since_restore: 999100
  timesteps_this_iter: 33700
  timesteps_total: 999100
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 908 s, 30 iter, 999100 ts, 15.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-07-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.26345579765512
  episode_reward_mean: 17.63492692546222
  episode_reward_min: -2.4629020272287963
  episodes_this_iter: 106
  episodes_total: 3437
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.75062942504883
        mean_q: 11.116065979003906
        min_q: -20.68708038330078
    learner_queue:
      size_count: 105333
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1105
    num_steps_sampled: 1031100
    num_steps_trained: 18564608
    num_target_updates: 369
    num_weight_syncs: 2576
    replay_shard_0:
      add_batch_time_ms: 4.506
      policy_default_policy:
        added_count: 259700
        est_size_bytes: 88557700
        num_entries: 259700
        sampled_count: 4668928
      replay_time_ms: 29.937
      update_priorities_time_ms: 72.769
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 31
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3713412589003514
    mean_inference_ms: 1.1096451707695996
    mean_processing_ms: 0.2455727464268686
  time_since_restore: 938.5250437259674
  time_this_iter_s: 30.37310242652893
  time_total_s: 938.5250437259674
  timestamp: 1563912425
  timesteps_since_restore: 1031100
  timesteps_this_iter: 32000
  timesteps_total: 1031100
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 938 s, 31 iter, 1031100 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-07-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.765800005787376
  episode_reward_mean: 17.901014457193607
  episode_reward_min: -12.072504825465273
  episodes_this_iter: 113
  episodes_total: 3550
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.976192474365234
        mean_q: 10.970211029052734
        min_q: -8.531702041625977
    learner_queue:
      size_count: 106554
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5919459434779497
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1116
    num_steps_sampled: 1065050
    num_steps_trained: 19190272
    num_target_updates: 382
    num_weight_syncs: 2662
    replay_shard_0:
      add_batch_time_ms: 3.352
      policy_default_policy:
        added_count: 268350
        est_size_bytes: 91507350
        num_entries: 268350
        sampled_count: 4827136
      replay_time_ms: 20.447
      update_priorities_time_ms: 54.922
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 32
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37121085808481435
    mean_inference_ms: 1.1092875025355158
    mean_processing_ms: 0.24549916822668832
  time_since_restore: 968.7679235935211
  time_this_iter_s: 30.24287986755371
  time_total_s: 968.7679235935211
  timestamp: 1563912455
  timesteps_since_restore: 1065050
  timesteps_this_iter: 33950
  timesteps_total: 1065050
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 11.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 968 s, 32 iter, 1065050 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-08-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.965791440435396
  episode_reward_mean: 17.01697528494192
  episode_reward_min: -0.5256605966052276
  episodes_this_iter: 108
  episodes_total: 3658
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.13656234741211
        mean_q: 10.355379104614258
        min_q: -10.7661771774292
    learner_queue:
      size_count: 107737
      size_mean: 0.74
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5219195340279956
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1128
    num_steps_sampled: 1097500
    num_steps_trained: 19795968
    num_target_updates: 394
    num_weight_syncs: 2743
    replay_shard_0:
      add_batch_time_ms: 3.59
      policy_default_policy:
        added_count: 276500
        est_size_bytes: 94286500
        num_entries: 276500
        sampled_count: 4979712
      replay_time_ms: 25.839
      update_priorities_time_ms: 72.848
    sample_throughput: 0.0
    train_throughput: 21493.321
  iterations_since_restore: 33
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3713852642542901
    mean_inference_ms: 1.110314416995646
    mean_processing_ms: 0.2455893640033958
  time_since_restore: 999.1060440540314
  time_this_iter_s: 30.338120460510254
  time_total_s: 999.1060440540314
  timestamp: 1563912486
  timesteps_since_restore: 1097500
  timesteps_this_iter: 32450
  timesteps_total: 1097500
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 999 s, 33 iter, 1097500 ts, 17 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-08-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.50577711638827
  episode_reward_mean: 16.865805257358872
  episode_reward_min: -1.6224646812246906
  episodes_this_iter: 110
  episodes_total: 3768
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.972904205322266
        mean_q: 10.10915756225586
        min_q: -12.94809627532959
    learner_queue:
      size_count: 108944
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6079473661428265
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1158
    num_steps_sampled: 1130450
    num_steps_trained: 20413440
    num_target_updates: 406
    num_weight_syncs: 2825
    replay_shard_0:
      add_batch_time_ms: 3.22
      policy_default_policy:
        added_count: 284800
        est_size_bytes: 97116800
        num_entries: 284800
        sampled_count: 5138432
      replay_time_ms: 21.129
      update_priorities_time_ms: 55.871
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 34
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37138136806408817
    mean_inference_ms: 1.1100086564666118
    mean_processing_ms: 0.24573532272522144
  time_since_restore: 1029.3326394557953
  time_this_iter_s: 30.226595401763916
  time_total_s: 1029.3326394557953
  timestamp: 1563912516
  timesteps_since_restore: 1130450
  timesteps_this_iter: 32950
  timesteps_total: 1130450
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1029 s, 34 iter, 1130450 ts, 16.9 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:09:06,697	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-09-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.43696059369219
  episode_reward_mean: 17.948841539760892
  episode_reward_min: -1.9411440100652053
  episodes_this_iter: 109
  episodes_total: 3877
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 32.30640649801542
    episode_reward_mean: 19.85963204127424
    episode_reward_min: 4.611460505751194
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19684263829658072
      mean_inference_ms: 0.47723230406916367
      mean_processing_ms: 0.11070429628148257
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 40.25146484375
        mean_q: 9.827754020690918
        min_q: -14.171977043151855
    learner_queue:
      size_count: 110136
      size_mean: 0.88
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.84
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1167
    num_steps_sampled: 1163350
    num_steps_trained: 21023744
    num_target_updates: 418
    num_weight_syncs: 2907
    replay_shard_0:
      add_batch_time_ms: 4.82
      policy_default_policy:
        added_count: 293050
        est_size_bytes: 99930050
        num_entries: 293050
        sampled_count: 5292032
      replay_time_ms: 29.612
      update_priorities_time_ms: 72.643
    sample_throughput: 1327.387
    train_throughput: 13592.443
  iterations_since_restore: 35
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.371443639124792
    mean_inference_ms: 1.1105815432436492
    mean_processing_ms: 0.24593759659681025
  time_since_restore: 1059.678286075592
  time_this_iter_s: 30.345646619796753
  time_total_s: 1059.678286075592
  timestamp: 1563912546
  timesteps_since_restore: 1163350
  timesteps_this_iter: 32900
  timesteps_total: 1163350
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1059 s, 35 iter, 1163350 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-09-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.493838381063725
  episode_reward_mean: 16.69552194766408
  episode_reward_min: -18.95950537527499
  episodes_this_iter: 114
  episodes_total: 3991
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.905921936035156
        mean_q: 9.414085388183594
        min_q: -11.433839797973633
    learner_queue:
      size_count: 111360
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4935585071701226
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1180
    num_steps_sampled: 1197650
    num_steps_trained: 21651456
    num_target_updates: 431
    num_weight_syncs: 2993
    replay_shard_0:
      add_batch_time_ms: 3.43
      policy_default_policy:
        added_count: 301500
        est_size_bytes: 102811500
        num_entries: 301500
        sampled_count: 5452800
      replay_time_ms: 21.155
      update_priorities_time_ms: 57.398
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 36
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3712453813827657
    mean_inference_ms: 1.109268439494373
    mean_processing_ms: 0.24585401332493997
  time_since_restore: 1089.9473240375519
  time_this_iter_s: 30.26903796195984
  time_total_s: 1089.9473240375519
  timestamp: 1563912578
  timesteps_since_restore: 1197650
  timesteps_this_iter: 34300
  timesteps_total: 1197650
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1089 s, 36 iter, 1197650 ts, 16.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-10-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.22918190572717
  episode_reward_mean: 17.367854902439024
  episode_reward_min: -1.8193644013933286
  episodes_this_iter: 108
  episodes_total: 4099
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.829490661621094
        mean_q: 9.339798927307129
        min_q: 0.52422696352005
    learner_queue:
      size_count: 112529
      size_mean: 0.94
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.6755738301621814
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1195
    num_steps_sampled: 1229800
    num_steps_trained: 22248448
    num_target_updates: 443
    num_weight_syncs: 3073
    replay_shard_0:
      add_batch_time_ms: 4.109
      policy_default_policy:
        added_count: 310350
        est_size_bytes: 105829350
        num_entries: 310350
        sampled_count: 5603328
      replay_time_ms: 28.893
      update_priorities_time_ms: 77.53
    sample_throughput: 1085.825
    train_throughput: 11118.85
  iterations_since_restore: 37
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3715378082999603
    mean_inference_ms: 1.1103484776815316
    mean_processing_ms: 0.24610337692522777
  time_since_restore: 1120.3316802978516
  time_this_iter_s: 30.384356260299683
  time_total_s: 1120.3316802978516
  timestamp: 1563912609
  timesteps_since_restore: 1229800
  timesteps_this_iter: 32150
  timesteps_total: 1229800
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1120 s, 37 iter, 1229800 ts, 17.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-10-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.116289048842035
  episode_reward_mean: 16.44454642241945
  episode_reward_min: -6.401710752582946
  episodes_this_iter: 113
  episodes_total: 4212
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.00442123413086
        mean_q: 9.122066497802734
        min_q: -13.207045555114746
    learner_queue:
      size_count: 113742
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5741080037762929
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1212
    num_steps_sampled: 1263850
    num_steps_trained: 22870016
    num_target_updates: 455
    num_weight_syncs: 3159
    replay_shard_0:
      add_batch_time_ms: 3.694
      policy_default_policy:
        added_count: 318550
        est_size_bytes: 108625550
        num_entries: 318550
        sampled_count: 5760512
      replay_time_ms: 22.033
      update_priorities_time_ms: 57.919
    sample_throughput: 1357.257
    train_throughput: 27796.622
  iterations_since_restore: 38
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3715220429481488
    mean_inference_ms: 1.109426999977359
    mean_processing_ms: 0.24603036962978775
  time_since_restore: 1150.5926055908203
  time_this_iter_s: 30.26092529296875
  time_total_s: 1150.5926055908203
  timestamp: 1563912639
  timesteps_since_restore: 1263850
  timesteps_this_iter: 34050
  timesteps_total: 1263850
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1150 s, 38 iter, 1263850 ts, 16.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-11-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.470309062078435
  episode_reward_mean: 15.9747147245806
  episode_reward_min: -10.66992792883141
  episodes_this_iter: 108
  episodes_total: 4320
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.88492202758789
        mean_q: 9.18673038482666
        min_q: -25.03335189819336
    learner_queue:
      size_count: 114918
      size_mean: 0.78
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6415605972938176
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1219
    num_steps_sampled: 1296350
    num_steps_trained: 23472640
    num_target_updates: 467
    num_weight_syncs: 3240
    replay_shard_0:
      add_batch_time_ms: 4.103
      policy_default_policy:
        added_count: 326500
        est_size_bytes: 111336500
        num_entries: 326500
        sampled_count: 5910528
      replay_time_ms: 29.53
      update_priorities_time_ms: 69.121
    sample_throughput: 0.0
    train_throughput: 19344.782
  iterations_since_restore: 39
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3716620696681128
    mean_inference_ms: 1.1102734422152645
    mean_processing_ms: 0.24620321332263273
  time_since_restore: 1180.9724078178406
  time_this_iter_s: 30.379802227020264
  time_total_s: 1180.9724078178406
  timestamp: 1563912669
  timesteps_since_restore: 1296350
  timesteps_this_iter: 32500
  timesteps_total: 1296350
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1180 s, 39 iter, 1296350 ts, 16 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:11:40,020	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-11-40
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.610089427171516
  episode_reward_mean: 16.58451595891421
  episode_reward_min: -10.678105727635682
  episodes_this_iter: 110
  episodes_total: 4430
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 27.967719023556064
    episode_reward_mean: 17.255218746145395
    episode_reward_min: 4.729485121179057
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19282133047178612
      mean_inference_ms: 0.4675873261311788
      mean_processing_ms: 0.108620491957419
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.46268844604492
        mean_q: 9.123289108276367
        min_q: -15.406172752380371
    learner_queue:
      size_count: 116116
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6082762530298219
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1245
    num_steps_sampled: 1329450
    num_steps_trained: 24085504
    num_target_updates: 480
    num_weight_syncs: 3323
    replay_shard_0:
      add_batch_time_ms: 2.979
      policy_default_policy:
        added_count: 335600
        est_size_bytes: 114439600
        num_entries: 335600
        sampled_count: 6068224
      replay_time_ms: 21.474
      update_priorities_time_ms: 58.191
    sample_throughput: 0.0
    train_throughput: 16728.859
  iterations_since_restore: 40
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3716088899646391
    mean_inference_ms: 1.1100062025584612
    mean_processing_ms: 0.2461259389560419
  time_since_restore: 1211.2354173660278
  time_this_iter_s: 30.263009548187256
  time_total_s: 1211.2354173660278
  timestamp: 1563912700
  timesteps_since_restore: 1329450
  timesteps_this_iter: 33100
  timesteps_total: 1329450
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1211 s, 40 iter, 1329450 ts, 16.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-12-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.69526357127256
  episode_reward_mean: 16.49785170358706
  episode_reward_min: -2.2845878506665556
  episodes_this_iter: 107
  episodes_total: 4537
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.47658157348633
        mean_q: 8.937626838684082
        min_q: -2.8421924114227295
    learner_queue:
      size_count: 117285
      size_mean: 0.88
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7110555533852472
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1256
    num_steps_sampled: 1361400
    num_steps_trained: 24684032
    num_target_updates: 491
    num_weight_syncs: 3403
    replay_shard_0:
      add_batch_time_ms: 3.787
      policy_default_policy:
        added_count: 343300
        est_size_bytes: 117065300
        num_entries: 343300
        sampled_count: 6218752
      replay_time_ms: 30.553
      update_priorities_time_ms: 71.591
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 41
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718266515307198
    mean_inference_ms: 1.1112017612200877
    mean_processing_ms: 0.24623425512662708
  time_since_restore: 1241.5728840827942
  time_this_iter_s: 30.337466716766357
  time_total_s: 1241.5728840827942
  timestamp: 1563912731
  timesteps_since_restore: 1361400
  timesteps_this_iter: 31950
  timesteps_total: 1361400
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1241 s, 41 iter, 1361400 ts, 16.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-12-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.42471555813746
  episode_reward_mean: 16.656904210466397
  episode_reward_min: -2.592036425632449
  episodes_this_iter: 114
  episodes_total: 4651
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.58538055419922
        mean_q: 9.048103332519531
        min_q: -1.5428661108016968
    learner_queue:
      size_count: 118495
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6069596362197408
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1266
    num_steps_sampled: 1395600
    num_steps_trained: 25303040
    num_target_updates: 504
    num_weight_syncs: 3489
    replay_shard_0:
      add_batch_time_ms: 3.707
      policy_default_policy:
        added_count: 352200
        est_size_bytes: 120100200
        num_entries: 352200
        sampled_count: 6374400
      replay_time_ms: 22.374
      update_priorities_time_ms: 55.693
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 42
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3717213488546607
    mean_inference_ms: 1.1101766606470673
    mean_processing_ms: 0.24612014803083324
  time_since_restore: 1271.8429443836212
  time_this_iter_s: 30.270060300827026
  time_total_s: 1271.8429443836212
  timestamp: 1563912761
  timesteps_since_restore: 1395600
  timesteps_this_iter: 34200
  timesteps_total: 1395600
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1271 s, 42 iter, 1395600 ts, 16.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-13-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.56936451609314
  episode_reward_mean: 18.039890102906355
  episode_reward_min: -1.2619975356505486
  episodes_this_iter: 109
  episodes_total: 4760
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.58013153076172
        mean_q: 8.252918243408203
        min_q: -0.3301507532596588
    learner_queue:
      size_count: 119663
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4853864439804639
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1274
    num_steps_sampled: 1428200
    num_steps_trained: 25902592
    num_target_updates: 516
    num_weight_syncs: 3569
    replay_shard_0:
      add_batch_time_ms: 4.865
      policy_default_policy:
        added_count: 361350
        est_size_bytes: 123220350
        num_entries: 361350
        sampled_count: 6523392
      replay_time_ms: 27.561
      update_priorities_time_ms: 71.996
    sample_throughput: 2432.411
    train_throughput: 24907.891
  iterations_since_restore: 43
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718277044056435
    mean_inference_ms: 1.1107391303806238
    mean_processing_ms: 0.2462236031200985
  time_since_restore: 1302.1940937042236
  time_this_iter_s: 30.351149320602417
  time_total_s: 1302.1940937042236
  timestamp: 1563912791
  timesteps_since_restore: 1428200
  timesteps_this_iter: 32600
  timesteps_total: 1428200
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1302 s, 43 iter, 1428200 ts, 18 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-13-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.71377162495154
  episode_reward_mean: 17.83291313219067
  episode_reward_min: -1.666443634219523
  episodes_this_iter: 112
  episodes_total: 4872
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.758052825927734
        mean_q: 8.427501678466797
        min_q: -8.609938621520996
    learner_queue:
      size_count: 120868
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.532541078227774
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1290
    num_steps_sampled: 1461850
    num_steps_trained: 26518528
    num_target_updates: 528
    num_weight_syncs: 3653
    replay_shard_0:
      add_batch_time_ms: 3.231
      policy_default_policy:
        added_count: 368550
        est_size_bytes: 125675550
        num_entries: 368550
        sampled_count: 6680576
      replay_time_ms: 22.095
      update_priorities_time_ms: 56.981
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 44
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37183698159841144
    mean_inference_ms: 1.1103343490342346
    mean_processing_ms: 0.2462025372322287
  time_since_restore: 1332.5064661502838
  time_this_iter_s: 30.31237244606018
  time_total_s: 1332.5064661502838
  timestamp: 1563912822
  timesteps_since_restore: 1461850
  timesteps_this_iter: 33650
  timesteps_total: 1461850
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1332 s, 44 iter, 1461850 ts, 17.8 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:14:12,693	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-14-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.232229862730534
  episode_reward_mean: 17.95756562423665
  episode_reward_min: -6.105547971592544
  episodes_this_iter: 109
  episodes_total: 4981
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.438758226916185
    episode_reward_mean: 21.220112077999413
    episode_reward_min: 5.864344343625958
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.20063078393142114
      mean_inference_ms: 0.4878639976196818
      mean_processing_ms: 0.11256152602420093
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.12654495239258
        mean_q: 8.087257385253906
        min_q: 0.12006325274705887
    learner_queue:
      size_count: 122046
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5617828762075255
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1297
    num_steps_sampled: 1494650
    num_steps_trained: 27121664
    num_target_updates: 540
    num_weight_syncs: 3735
    replay_shard_0:
      add_batch_time_ms: 3.826
      policy_default_policy:
        added_count: 376750
        est_size_bytes: 128471750
        num_entries: 376750
        sampled_count: 6833152
      replay_time_ms: 31.238
      update_priorities_time_ms: 71.292
    sample_throughput: 1191.34
    train_throughput: 0.0
  iterations_since_restore: 45
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37193184108396904
    mean_inference_ms: 1.111000721129549
    mean_processing_ms: 0.2462248690053173
  time_since_restore: 1362.8768577575684
  time_this_iter_s: 30.370391607284546
  time_total_s: 1362.8768577575684
  timestamp: 1563912852
  timesteps_since_restore: 1494650
  timesteps_this_iter: 32800
  timesteps_total: 1494650
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1362 s, 45 iter, 1494650 ts, 18 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-14-44
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.118732019264584
  episode_reward_mean: 17.845458241201285
  episode_reward_min: -2.5552696718029058
  episodes_this_iter: 114
  episodes_total: 5095
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.06547164916992
        mean_q: 7.167631149291992
        min_q: -6.044303894042969
    learner_queue:
      size_count: 123251
      size_mean: 0.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4737087712930804
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1322
    num_steps_sampled: 1528950
    num_steps_trained: 27739136
    num_target_updates: 552
    num_weight_syncs: 3821
    replay_shard_0:
      add_batch_time_ms: 3.541
      policy_default_policy:
        added_count: 386600
        est_size_bytes: 131830600
        num_entries: 386600
        sampled_count: 6988800
      replay_time_ms: 25.358
      update_priorities_time_ms: 60.027
    sample_throughput: 0.0
    train_throughput: 26448.472
  iterations_since_restore: 46
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37171691430928616
    mean_inference_ms: 1.1098152359594484
    mean_processing_ms: 0.24606309165309181
  time_since_restore: 1393.1574952602386
  time_this_iter_s: 30.280637502670288
  time_total_s: 1393.1574952602386
  timestamp: 1563912884
  timesteps_since_restore: 1528950
  timesteps_this_iter: 34300
  timesteps_total: 1528950
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1393 s, 46 iter, 1528950 ts, 17.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-15-14
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.812660531185664
  episode_reward_mean: 16.868379998653236
  episode_reward_min: -0.8500683418801086
  episodes_this_iter: 106
  episodes_total: 5201
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.286827087402344
        mean_q: 8.054295539855957
        min_q: 0.0673108696937561
    learner_queue:
      size_count: 124408
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5919459434779497
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1332
    num_steps_sampled: 1560750
    num_steps_trained: 28331008
    num_target_updates: 564
    num_weight_syncs: 3901
    replay_shard_0:
      add_batch_time_ms: 3.954
      policy_default_policy:
        added_count: 394150
        est_size_bytes: 134405150
        num_entries: 394150
        sampled_count: 7138816
      replay_time_ms: 27.875
      update_priorities_time_ms: 71.612
    sample_throughput: 3132.556
    train_throughput: 0.0
  iterations_since_restore: 47
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3719658195761678
    mean_inference_ms: 1.111183239644307
    mean_processing_ms: 0.24613256605576522
  time_since_restore: 1423.510511636734
  time_this_iter_s: 30.35301637649536
  time_total_s: 1423.510511636734
  timestamp: 1563912914
  timesteps_since_restore: 1560750
  timesteps_this_iter: 31800
  timesteps_total: 1560750
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1423 s, 47 iter, 1560750 ts, 16.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-15-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.02795813328681
  episode_reward_mean: 18.63728239268558
  episode_reward_min: -1.1621512142344217
  episodes_this_iter: 115
  episodes_total: 5316
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.88003158569336
        mean_q: 8.037836074829102
        min_q: -0.704338550567627
    learner_queue:
      size_count: 125620
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5291502622129182
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1346
    num_steps_sampled: 1595100
    num_steps_trained: 28952064
    num_target_updates: 576
    num_weight_syncs: 3987
    replay_shard_0:
      add_batch_time_ms: 4.193
      policy_default_policy:
        added_count: 403100
        est_size_bytes: 137457100
        num_entries: 403100
        sampled_count: 7296512
      replay_time_ms: 21.672
      update_priorities_time_ms: 56.357
    sample_throughput: 0.0
    train_throughput: 32708.11
  iterations_since_restore: 48
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3717418346928047
    mean_inference_ms: 1.1102671626524694
    mean_processing_ms: 0.24599278269355462
  time_since_restore: 1453.7862949371338
  time_this_iter_s: 30.27578330039978
  time_total_s: 1453.7862949371338
  timestamp: 1563912945
  timesteps_since_restore: 1595100
  timesteps_this_iter: 34350
  timesteps_total: 1595100
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1453 s, 48 iter, 1595100 ts, 18.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-16-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.973082574920106
  episode_reward_mean: 17.4227528178653
  episode_reward_min: -5.227205341396747
  episodes_this_iter: 108
  episodes_total: 5424
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.817726135253906
        mean_q: 7.955689907073975
        min_q: -1.8869808912277222
    learner_queue:
      size_count: 126786
      size_mean: 0.8
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.66332495807108
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1358
    num_steps_sampled: 1627450
    num_steps_trained: 29548032
    num_target_updates: 588
    num_weight_syncs: 4067
    replay_shard_0:
      add_batch_time_ms: 4.764
      policy_default_policy:
        added_count: 410450
        est_size_bytes: 139963450
        num_entries: 410450
        sampled_count: 7447040
      replay_time_ms: 27.184
      update_priorities_time_ms: 69.569
    sample_throughput: 0.0
    train_throughput: 9442.851
  iterations_since_restore: 49
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718881258301522
    mean_inference_ms: 1.110928971866523
    mean_processing_ms: 0.2461325696333961
  time_since_restore: 1484.1543698310852
  time_this_iter_s: 30.368074893951416
  time_total_s: 1484.1543698310852
  timestamp: 1563912975
  timesteps_since_restore: 1627450
  timesteps_this_iter: 32350
  timesteps_total: 1627450
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1484 s, 49 iter, 1627450 ts, 17.4 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:16:45,938	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-16-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.90475301918831
  episode_reward_mean: 17.5137167662547
  episode_reward_min: -4.568317693714344
  episodes_this_iter: 114
  episodes_total: 5538
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 38.71228532809194
    episode_reward_mean: 23.19317510781378
    episode_reward_min: 9.093142338236172
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19697897087898436
      mean_inference_ms: 0.4790869852057602
      mean_processing_ms: 0.11064642003489786
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 39.371849060058594
        mean_q: 7.228435516357422
        min_q: 0.0991072803735733
    learner_queue:
      size_count: 127989
      size_mean: 0.52
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5741080037762929
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1371
    num_steps_sampled: 1661750
    num_steps_trained: 30164992
    num_target_updates: 601
    num_weight_syncs: 4153
    replay_shard_0:
      add_batch_time_ms: 3.644
      policy_default_policy:
        added_count: 418200
        est_size_bytes: 142606200
        num_entries: 418200
        sampled_count: 7601664
      replay_time_ms: 21.323
      update_priorities_time_ms: 58.677
    sample_throughput: 2838.861
    train_throughput: 0.0
  iterations_since_restore: 50
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718218545892197
    mean_inference_ms: 1.1098336912372648
    mean_processing_ms: 0.2460239644975522
  time_since_restore: 1514.4229538440704
  time_this_iter_s: 30.26858401298523
  time_total_s: 1514.4229538440704
  timestamp: 1563913005
  timesteps_since_restore: 1661750
  timesteps_this_iter: 34300
  timesteps_total: 1661750
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1514 s, 50 iter, 1661750 ts, 17.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-17-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.51296843599239
  episode_reward_mean: 17.482259602288615
  episode_reward_min: -1.0704524906474826
  episodes_this_iter: 104
  episodes_total: 5642
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.87888717651367
        mean_q: 7.0409955978393555
        min_q: -3.8090267181396484
    learner_queue:
      size_count: 129132
      size_mean: 0.76
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7088018058667741
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1391
    num_steps_sampled: 1692950
    num_steps_trained: 30749696
    num_target_updates: 612
    num_weight_syncs: 4231
    replay_shard_0:
      add_batch_time_ms: 4.231
      policy_default_policy:
        added_count: 425350
        est_size_bytes: 145044350
        num_entries: 425350
        sampled_count: 7749632
      replay_time_ms: 27.882
      update_priorities_time_ms: 70.601
    sample_throughput: 1547.257
    train_throughput: 15843.911
  iterations_since_restore: 51
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37202055789817207
    mean_inference_ms: 1.1112136598661237
    mean_processing_ms: 0.2461580866051736
  time_since_restore: 1544.7091948986053
  time_this_iter_s: 30.286241054534912
  time_total_s: 1544.7091948986053
  timestamp: 1563913037
  timesteps_since_restore: 1692950
  timesteps_this_iter: 31200
  timesteps_total: 1692950
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1544 s, 51 iter, 1692950 ts, 17.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-17-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.45230875981384
  episode_reward_mean: 15.603566207239433
  episode_reward_min: -0.5391859562170077
  episodes_this_iter: 116
  episodes_total: 5758
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.0631217956543
        mean_q: 7.349373817443848
        min_q: -13.32936954498291
    learner_queue:
      size_count: 130347
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5730619512757762
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1401
    num_steps_sampled: 1727450
    num_steps_trained: 31372800
    num_target_updates: 625
    num_weight_syncs: 4318
    replay_shard_0:
      add_batch_time_ms: 3.358
      policy_default_policy:
        added_count: 434250
        est_size_bytes: 148079250
        num_entries: 434250
        sampled_count: 7906816
      replay_time_ms: 21.764
      update_priorities_time_ms: 57.954
    sample_throughput: 7804.227
    train_throughput: 0.0
  iterations_since_restore: 52
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37183028286845776
    mean_inference_ms: 1.109960528010223
    mean_processing_ms: 0.24603918576188338
  time_since_restore: 1574.9878265857697
  time_this_iter_s: 30.278631687164307
  time_total_s: 1574.9878265857697
  timestamp: 1563913067
  timesteps_since_restore: 1727450
  timesteps_this_iter: 34500
  timesteps_total: 1727450
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.6/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1574 s, 52 iter, 1727450 ts, 15.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-18-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.14383433663011
  episode_reward_mean: 17.168925023895046
  episode_reward_min: -1.9864550340288156
  episodes_this_iter: 108
  episodes_total: 5866
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 31.64511489868164
        mean_q: 6.58873176574707
        min_q: 0.4123402535915375
    learner_queue:
      size_count: 131505
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5919459434779497
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1413
    num_steps_sampled: 1759700
    num_steps_trained: 31964672
    num_target_updates: 637
    num_weight_syncs: 4398
    replay_shard_0:
      add_batch_time_ms: 5.172
      policy_default_policy:
        added_count: 443600
        est_size_bytes: 151267600
        num_entries: 443600
        sampled_count: 8056832
      replay_time_ms: 28.069
      update_priorities_time_ms: 78.937
    sample_throughput: 0.0
    train_throughput: 8868.109
  iterations_since_restore: 53
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37196217372224444
    mean_inference_ms: 1.110707104932734
    mean_processing_ms: 0.2461450520728047
  time_since_restore: 1605.3450083732605
  time_this_iter_s: 30.357181787490845
  time_total_s: 1605.3450083732605
  timestamp: 1563913097
  timesteps_since_restore: 1759700
  timesteps_this_iter: 32250
  timesteps_total: 1759700
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1605 s, 53 iter, 1759700 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-18-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.25982996071546
  episode_reward_mean: 16.974549683086032
  episode_reward_min: -2.790872046004926
  episodes_this_iter: 114
  episodes_total: 5980
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.8914794921875
        mean_q: 6.393411159515381
        min_q: 0.14189042150974274
    learner_queue:
      size_count: 132711
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4898979485566356
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1425
    num_steps_sampled: 1793950
    num_steps_trained: 32582656
    num_target_updates: 649
    num_weight_syncs: 4484
    replay_shard_0:
      add_batch_time_ms: 4.743
      policy_default_policy:
        added_count: 452300
        est_size_bytes: 154234300
        num_entries: 452300
        sampled_count: 8210944
      replay_time_ms: 22.066
      update_priorities_time_ms: 56.038
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 54
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718190810491272
    mean_inference_ms: 1.1098108426411655
    mean_processing_ms: 0.24606261173590044
  time_since_restore: 1635.6044442653656
  time_this_iter_s: 30.259435892105103
  time_total_s: 1635.6044442653656
  timestamp: 1563913128
  timesteps_since_restore: 1793950
  timesteps_this_iter: 34250
  timesteps_total: 1793950
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1635 s, 54 iter, 1793950 ts, 17 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:19:18,465	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-19-18
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.62162048990436
  episode_reward_mean: 19.183244044574785
  episode_reward_min: -10.224772358265856
  episodes_this_iter: 108
  episodes_total: 6088
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.44232288406528
    episode_reward_mean: 16.508176824396102
    episode_reward_min: 3.1143773492619444
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1989382451444551
      mean_inference_ms: 0.48430815887917394
      mean_processing_ms: 0.11140803126293872
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.39049530029297
        mean_q: 7.747340202331543
        min_q: -0.6563093662261963
    learner_queue:
      size_count: 133871
      size_mean: 0.94
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.7323933369440221
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1435
    num_steps_sampled: 1826200
    num_steps_trained: 33176064
    num_target_updates: 661
    num_weight_syncs: 4565
    replay_shard_0:
      add_batch_time_ms: 4.735
      policy_default_policy:
        added_count: 459950
        est_size_bytes: 156842950
        num_entries: 459950
        sampled_count: 8362496
      replay_time_ms: 27.465
      update_priorities_time_ms: 66.562
    sample_throughput: 0.0
    train_throughput: 16799.922
  iterations_since_restore: 55
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37195234741418043
    mean_inference_ms: 1.1103244463642032
    mean_processing_ms: 0.2462205435420156
  time_since_restore: 1665.9325268268585
  time_this_iter_s: 30.32808256149292
  time_total_s: 1665.9325268268585
  timestamp: 1563913158
  timesteps_since_restore: 1826200
  timesteps_this_iter: 32250
  timesteps_total: 1826200
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1665 s, 55 iter, 1826200 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-19-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.154487277161394
  episode_reward_mean: 17.741342329889676
  episode_reward_min: -5.218528958751652
  episodes_this_iter: 116
  episodes_total: 6204
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.32957458496094
        mean_q: 7.013882637023926
        min_q: -11.710726737976074
    learner_queue:
      size_count: 135083
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5744562646538028
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1448
    num_steps_sampled: 1860950
    num_steps_trained: 33797120
    num_target_updates: 673
    num_weight_syncs: 4652
    replay_shard_0:
      add_batch_time_ms: 3.509
      policy_default_policy:
        added_count: 468300
        est_size_bytes: 159690300
        num_entries: 468300
        sampled_count: 8520192
      replay_time_ms: 19.861
      update_priorities_time_ms: 56.397
    sample_throughput: 2643.33
    train_throughput: 27067.7
  iterations_since_restore: 56
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3718628680181036
    mean_inference_ms: 1.1093764406922906
    mean_processing_ms: 0.24606513022147739
  time_since_restore: 1696.1881136894226
  time_this_iter_s: 30.255586862564087
  time_total_s: 1696.1881136894226
  timestamp: 1563913190
  timesteps_since_restore: 1860950
  timesteps_this_iter: 34750
  timesteps_total: 1860950
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1696 s, 56 iter, 1860950 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-20-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.19061845793865
  episode_reward_mean: 17.5903336563894
  episode_reward_min: -7.839492557367799
  episodes_this_iter: 103
  episodes_total: 6307
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.960086822509766
        mean_q: 6.830564498901367
        min_q: -11.912138938903809
    learner_queue:
      size_count: 136220
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5713142742834281
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1473
    num_steps_sampled: 1891950
    num_steps_trained: 34378752
    num_target_updates: 685
    num_weight_syncs: 4729
    replay_shard_0:
      add_batch_time_ms: 3.708
      policy_default_policy:
        added_count: 476000
        est_size_bytes: 162316000
        num_entries: 476000
        sampled_count: 8670720
      replay_time_ms: 22.603
      update_priorities_time_ms: 55.718
    sample_throughput: 2998.845
    train_throughput: 30708.169
  iterations_since_restore: 57
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37207026029140117
    mean_inference_ms: 1.1105379137642537
    mean_processing_ms: 0.24624432993706852
  time_since_restore: 1726.435467004776
  time_this_iter_s: 30.247353315353394
  time_total_s: 1726.435467004776
  timestamp: 1563913220
  timesteps_since_restore: 1891950
  timesteps_this_iter: 31000
  timesteps_total: 1891950
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1726 s, 57 iter, 1891950 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-20-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.04768399716554
  episode_reward_mean: 18.095582074347092
  episode_reward_min: -3.6822585142291757
  episodes_this_iter: 116
  episodes_total: 6423
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.965965270996094
        mean_q: 7.016605377197266
        min_q: -2.8046116828918457
    learner_queue:
      size_count: 137428
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5351635264103861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1483
    num_steps_sampled: 1926750
    num_steps_trained: 34997760
    num_target_updates: 697
    num_weight_syncs: 4816
    replay_shard_0:
      add_batch_time_ms: 3.963
      policy_default_policy:
        added_count: 484050
        est_size_bytes: 165061050
        num_entries: 484050
        sampled_count: 8827392
      replay_time_ms: 21.344
      update_priorities_time_ms: 58.214
    sample_throughput: 2276.84
    train_throughput: 0.0
  iterations_since_restore: 58
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37194444366244345
    mean_inference_ms: 1.1094638587420944
    mean_processing_ms: 0.24610198616813364
  time_since_restore: 1756.691307067871
  time_this_iter_s: 30.255840063095093
  time_total_s: 1756.691307067871
  timestamp: 1563913250
  timesteps_since_restore: 1926750
  timesteps_this_iter: 34800
  timesteps_total: 1926750
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.8/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1756 s, 58 iter, 1926750 ts, 18.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-21-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.09386752922461
  episode_reward_mean: 17.713347764676733
  episode_reward_min: -1.3065884342152194
  episodes_this_iter: 106
  episodes_total: 6529
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.56032943725586
        mean_q: 6.095197677612305
        min_q: -1.2714498043060303
    learner_queue:
      size_count: 138567
      size_mean: 0.76
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.68
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1490
    num_steps_sampled: 1958650
    num_steps_trained: 35580416
    num_target_updates: 709
    num_weight_syncs: 4896
    replay_shard_0:
      add_batch_time_ms: 4.142
      policy_default_policy:
        added_count: 492400
        est_size_bytes: 167908400
        num_entries: 492400
        sampled_count: 8974848
      replay_time_ms: 22.892
      update_priorities_time_ms: 66.545
    sample_throughput: 982.001
    train_throughput: 20111.385
  iterations_since_restore: 59
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3721337988455167
    mean_inference_ms: 1.1102924101789517
    mean_processing_ms: 0.24625202633084503
  time_since_restore: 1786.9575774669647
  time_this_iter_s: 30.266270399093628
  time_total_s: 1786.9575774669647
  timestamp: 1563913280
  timesteps_since_restore: 1958650
  timesteps_this_iter: 31900
  timesteps_total: 1958650
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1786 s, 59 iter, 1958650 ts, 17.7 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:21:51,146	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-21-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 40.09521993004067
  episode_reward_mean: 17.387770185573835
  episode_reward_min: -3.0130850512256275
  episodes_this_iter: 115
  episodes_total: 6644
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 25.95150967020458
    episode_reward_mean: 12.426383428910807
    episode_reward_min: -0.35768520203142756
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19611924020188093
      mean_inference_ms: 0.4772517651901766
      mean_processing_ms: 0.10988262517471434
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.21540832519531
        mean_q: 6.951353073120117
        min_q: -6.351816654205322
    learner_queue:
      size_count: 139773
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5713142742834281
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1497
    num_steps_sampled: 1993200
    num_steps_trained: 36197888
    num_target_updates: 721
    num_weight_syncs: 4982
    replay_shard_0:
      add_batch_time_ms: 3.534
      policy_default_policy:
        added_count: 501250
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9128960
      replay_time_ms: 20.885
      update_priorities_time_ms: 62.418
    sample_throughput: 2890.71
    train_throughput: 29600.866
  iterations_since_restore: 60
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3719524718910325
    mean_inference_ms: 1.1094447983609539
    mean_processing_ms: 0.24615949705854273
  time_since_restore: 1817.2259085178375
  time_this_iter_s: 30.268331050872803
  time_total_s: 1817.2259085178375
  timestamp: 1563913311
  timesteps_since_restore: 1993200
  timesteps_this_iter: 34550
  timesteps_total: 1993200
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1817 s, 60 iter, 1993200 ts, 17.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-22-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.52700145725992
  episode_reward_mean: 17.233363090468135
  episode_reward_min: -3.1956731078023854
  episodes_this_iter: 107
  episodes_total: 6751
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.79865264892578
        mean_q: 6.885658264160156
        min_q: 0.09526005387306213
    learner_queue:
      size_count: 140927
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1507
    num_steps_sampled: 2024900
    num_steps_trained: 36788736
    num_target_updates: 733
    num_weight_syncs: 5061
    replay_shard_0:
      add_batch_time_ms: 4.194
      policy_default_policy:
        added_count: 508850
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9278464
      replay_time_ms: 20.312
      update_priorities_time_ms: 56.572
    sample_throughput: 3213.189
    train_throughput: 0.0
  iterations_since_restore: 61
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3720787311347073
    mean_inference_ms: 1.1102190961824123
    mean_processing_ms: 0.24634204364205078
  time_since_restore: 1847.484091758728
  time_this_iter_s: 30.258183240890503
  time_total_s: 1847.484091758728
  timestamp: 1563913342
  timesteps_since_restore: 2024900
  timesteps_this_iter: 31700
  timesteps_total: 2024900
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1847 s, 61 iter, 2024900 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-22-52
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.46094960151587
  episode_reward_mean: 17.717374813809418
  episode_reward_min: -0.9754751974954656
  episodes_this_iter: 112
  episodes_total: 6863
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.54032516479492
        mean_q: 5.983819007873535
        min_q: -0.21780052781105042
    learner_queue:
      size_count: 142148
      size_mean: 8.68
      size_quantiles:
      - 0.0
      - 1.0
      - 10.0
      - 14.0
      - 15.0
      size_std: 4.649473088426257
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1524
    num_steps_sampled: 2058750
    num_steps_trained: 37414400
    num_target_updates: 745
    num_weight_syncs: 5146
    replay_shard_0:
      add_batch_time_ms: 3.461
      policy_default_policy:
        added_count: 517600
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9438208
      replay_time_ms: 22.413
      update_priorities_time_ms: 51.504
    sample_throughput: 0.0
    train_throughput: 19338.859
  iterations_since_restore: 62
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3719506806142467
    mean_inference_ms: 1.1096923269687655
    mean_processing_ms: 0.24626945456308072
  time_since_restore: 1877.868507385254
  time_this_iter_s: 30.38441562652588
  time_total_s: 1877.868507385254
  timestamp: 1563913372
  timesteps_since_restore: 2058750
  timesteps_this_iter: 33850
  timesteps_total: 2058750
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 12.9/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1877 s, 62 iter, 2058750 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-23-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.40026242080196
  episode_reward_mean: 19.159556112792338
  episode_reward_min: -8.991206086596405
  episodes_this_iter: 107
  episodes_total: 6970
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.698123931884766
        mean_q: 6.18931245803833
        min_q: -0.2192234843969345
    learner_queue:
      size_count: 143300
      size_mean: 0.78
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 3.0
      size_std: 0.855336191213724
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1539
    num_steps_sampled: 2090400
    num_steps_trained: 38004736
    num_target_updates: 757
    num_weight_syncs: 5225
    replay_shard_0:
      add_batch_time_ms: 4.126
      policy_default_policy:
        added_count: 524300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9589248
      replay_time_ms: 22.599
      update_priorities_time_ms: 59.813
    sample_throughput: 0.0
    train_throughput: 60101.415
  iterations_since_restore: 63
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37211361215135985
    mean_inference_ms: 1.1104805193141487
    mean_processing_ms: 0.24640443061765466
  time_since_restore: 1908.1446740627289
  time_this_iter_s: 30.276166677474976
  time_total_s: 1908.1446740627289
  timestamp: 1563913403
  timesteps_since_restore: 2090400
  timesteps_this_iter: 31650
  timesteps_total: 2090400
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1908 s, 63 iter, 2090400 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-23-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.578142733400746
  episode_reward_mean: 18.23389760703322
  episode_reward_min: -5.456580362162035
  episodes_this_iter: 115
  episodes_total: 7085
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.020057678222656
        mean_q: 5.675605773925781
        min_q: 0.09465824067592621
    learner_queue:
      size_count: 144521
      size_mean: 0.62
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.596322060635023
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1551
    num_steps_sampled: 2124950
    num_steps_trained: 38629376
    num_target_updates: 769
    num_weight_syncs: 5311
    replay_shard_0:
      add_batch_time_ms: 3.082
      policy_default_policy:
        added_count: 533900
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9746944
      replay_time_ms: 21.093
      update_priorities_time_ms: 56.916
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 64
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3720269964576891
    mean_inference_ms: 1.1095790906754621
    mean_processing_ms: 0.24627251580603238
  time_since_restore: 1938.415817975998
  time_this_iter_s: 30.271143913269043
  time_total_s: 1938.415817975998
  timestamp: 1563913433
  timesteps_since_restore: 2124950
  timesteps_this_iter: 34550
  timesteps_total: 2124950
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1938 s, 64 iter, 2124950 ts, 18.2 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:24:23,705	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-24-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.409183644873615
  episode_reward_mean: 16.834436020227066
  episode_reward_min: -11.768240019230241
  episodes_this_iter: 106
  episodes_total: 7191
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 28.050674623218303
    episode_reward_mean: 18.87151098176924
    episode_reward_min: 5.709077372632418
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19714251159912097
      mean_inference_ms: 0.47913664131242656
      mean_processing_ms: 0.11043031807939392
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.040245056152344
        mean_q: 5.683622360229492
        min_q: 0.27986350655555725
    learner_queue:
      size_count: 145687
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1561
    num_steps_sampled: 2156800
    num_steps_trained: 39225856
    num_target_updates: 781
    num_weight_syncs: 5391
    replay_shard_0:
      add_batch_time_ms: 4.89
      policy_default_policy:
        added_count: 542550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 9896448
      replay_time_ms: 28.777
      update_priorities_time_ms: 65.957
    sample_throughput: 1275.679
    train_throughput: 13062.95
  iterations_since_restore: 65
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37217222834717145
    mean_inference_ms: 1.1103846095162258
    mean_processing_ms: 0.24639615770333562
  time_since_restore: 1968.7659089565277
  time_this_iter_s: 30.350090980529785
  time_total_s: 1968.7659089565277
  timestamp: 1563913463
  timesteps_since_restore: 2156800
  timesteps_this_iter: 31850
  timesteps_total: 2156800
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1968 s, 65 iter, 2156800 ts, 16.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-24-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.21794252809079
  episode_reward_mean: 16.855758283882988
  episode_reward_min: -7.43459726688599
  episodes_this_iter: 115
  episodes_total: 7306
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.691287994384766
        mean_q: 5.771275520324707
        min_q: -0.286031574010849
    learner_queue:
      size_count: 146908
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.52
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1572
    num_steps_sampled: 2191300
    num_steps_trained: 39851520
    num_target_updates: 794
    num_weight_syncs: 5477
    replay_shard_0:
      add_batch_time_ms: 3.461
      policy_default_policy:
        added_count: 551550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10053120
      replay_time_ms: 23.281
      update_priorities_time_ms: 58.745
    sample_throughput: 1899.044
    train_throughput: 19446.208
  iterations_since_restore: 66
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3720240267998407
    mean_inference_ms: 1.10959521262758
    mean_processing_ms: 0.24634320300028234
  time_since_restore: 1999.0247230529785
  time_this_iter_s: 30.258814096450806
  time_total_s: 1999.0247230529785
  timestamp: 1563913495
  timesteps_since_restore: 2191300
  timesteps_this_iter: 34500
  timesteps_total: 2191300
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 1999 s, 66 iter, 2191300 ts, 16.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-25-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.990497180996606
  episode_reward_mean: 19.192570046978457
  episode_reward_min: 1.0623129630628474
  episodes_this_iter: 106
  episodes_total: 7412
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.17548370361328
        mean_q: 5.950734615325928
        min_q: -0.7400939464569092
    learner_queue:
      size_count: 148061
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.656048778674269
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1584
    num_steps_sampled: 2223000
    num_steps_trained: 40441856
    num_target_updates: 805
    num_weight_syncs: 5557
    replay_shard_0:
      add_batch_time_ms: 4.578
      policy_default_policy:
        added_count: 558600
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10204160
      replay_time_ms: 19.274
      update_priorities_time_ms: 58.696
    sample_throughput: 1414.653
    train_throughput: 14486.044
  iterations_since_restore: 67
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3721541740097572
    mean_inference_ms: 1.1105604769132675
    mean_processing_ms: 0.24650485531542643
  time_since_restore: 2029.2496526241302
  time_this_iter_s: 30.224929571151733
  time_total_s: 2029.2496526241302
  timestamp: 1563913525
  timesteps_since_restore: 2223000
  timesteps_this_iter: 31700
  timesteps_total: 2223000
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2029 s, 67 iter, 2223000 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-25-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.091217207237634
  episode_reward_mean: 19.208471096381803
  episode_reward_min: -3.7353709934709283
  episodes_this_iter: 113
  episodes_total: 7525
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.02925109863281
        mean_q: 5.739947319030762
        min_q: 0.08044074475765228
    learner_queue:
      size_count: 149275
      size_mean: 0.46
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6069596362197407
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1603
    num_steps_sampled: 2257050
    num_steps_trained: 41063424
    num_target_updates: 818
    num_weight_syncs: 5641
    replay_shard_0:
      add_batch_time_ms: 3.538
      policy_default_policy:
        added_count: 566250
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10360832
      replay_time_ms: 23.431
      update_priorities_time_ms: 54.465
    sample_throughput: 0.0
    train_throughput: 38584.597
  iterations_since_restore: 68
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37203311488886126
    mean_inference_ms: 1.1098321417637353
    mean_processing_ms: 0.24639963380850818
  time_since_restore: 2059.5299813747406
  time_this_iter_s: 30.28032875061035
  time_total_s: 2059.5299813747406
  timestamp: 1563913555
  timesteps_since_restore: 2257050
  timesteps_this_iter: 34050
  timesteps_total: 2257050
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2059 s, 68 iter, 2257050 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-26-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.20612795731273
  episode_reward_mean: 18.066969541867604
  episode_reward_min: -12.932142980576492
  episodes_this_iter: 105
  episodes_total: 7630
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 38.185752868652344
        mean_q: 5.590841770172119
        min_q: -0.27300986647605896
    learner_queue:
      size_count: 150435
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5713142742834281
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1614
    num_steps_sampled: 2288600
    num_steps_trained: 41656832
    num_target_updates: 830
    num_weight_syncs: 5721
    replay_shard_0:
      add_batch_time_ms: 4.046
      policy_default_policy:
        added_count: 574500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10509824
      replay_time_ms: 26.197
      update_priorities_time_ms: 75.697
    sample_throughput: 1996.251
    train_throughput: 10220.808
  iterations_since_restore: 69
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37223141129406867
    mean_inference_ms: 1.1108510468305273
    mean_processing_ms: 0.24655451831158523
  time_since_restore: 2089.8850355148315
  time_this_iter_s: 30.355054140090942
  time_total_s: 2089.8850355148315
  timestamp: 1563913586
  timesteps_since_restore: 2288600
  timesteps_this_iter: 31550
  timesteps_total: 2288600
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.0/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2089 s, 69 iter, 2288600 ts, 18.1 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:26:56,430	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-26-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.02603012401253
  episode_reward_mean: 16.970233815325987
  episode_reward_min: -19.919350391445832
  episodes_this_iter: 116
  episodes_total: 7746
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 34.72637926751143
    episode_reward_mean: 20.661149509736592
    episode_reward_min: 4.006977817446312
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19436037056732486
      mean_inference_ms: 0.4722672268303917
      mean_processing_ms: 0.1090544339556317
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.275753021240234
        mean_q: 5.3474602699279785
        min_q: -0.19516339898109436
    learner_queue:
      size_count: 151655
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4935585071701226
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1622
    num_steps_sampled: 2323200
    num_steps_trained: 42281984
    num_target_updates: 842
    num_weight_syncs: 5807
    replay_shard_0:
      add_batch_time_ms: 4.348
      policy_default_policy:
        added_count: 583050
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10667008
      replay_time_ms: 20.989
      update_priorities_time_ms: 61.806
    sample_throughput: 2665.911
    train_throughput: 27298.926
  iterations_since_restore: 70
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3721311536154172
    mean_inference_ms: 1.1099539125087483
    mean_processing_ms: 0.2464349113254451
  time_since_restore: 2120.1864449977875
  time_this_iter_s: 30.301409482955933
  time_total_s: 2120.1864449977875
  timestamp: 1563913616
  timesteps_since_restore: 2323200
  timesteps_this_iter: 34600
  timesteps_total: 2323200
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2120 s, 70 iter, 2323200 ts, 17 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-27-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.32170109853213
  episode_reward_mean: 19.370397583277775
  episode_reward_min: -3.3615908402418913
  episodes_this_iter: 105
  episodes_total: 7851
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.94302749633789
        mean_q: 4.914103031158447
        min_q: -0.5080655813217163
    learner_queue:
      size_count: 152808
      size_mean: 0.44
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4963869458396343
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1634
    num_steps_sampled: 2354650
    num_steps_trained: 42872320
    num_target_updates: 854
    num_weight_syncs: 5885
    replay_shard_0:
      add_batch_time_ms: 3.483
      policy_default_policy:
        added_count: 590700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10815488
      replay_time_ms: 20.693
      update_priorities_time_ms: 58.347
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 71
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37228406485905846
    mean_inference_ms: 1.1109680399739243
    mean_processing_ms: 0.246567069342379
  time_since_restore: 2150.434470653534
  time_this_iter_s: 30.24802565574646
  time_total_s: 2150.434470653534
  timestamp: 1563913647
  timesteps_since_restore: 2354650
  timesteps_this_iter: 31450
  timesteps_total: 2354650
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2150 s, 71 iter, 2354650 ts, 19.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-27-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.827696618830444
  episode_reward_mean: 17.92473302101998
  episode_reward_min: 1.0009506754996957
  episodes_this_iter: 115
  episodes_total: 7966
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.691104888916016
        mean_q: 4.744714260101318
        min_q: -0.24554148316383362
    learner_queue:
      size_count: 154028
      size_mean: 0.54
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5370288632839021
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1645
    num_steps_sampled: 2389100
    num_steps_trained: 43496960
    num_target_updates: 866
    num_weight_syncs: 5972
    replay_shard_0:
      add_batch_time_ms: 3.221
      policy_default_policy:
        added_count: 599400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 10972160
      replay_time_ms: 22.452
      update_priorities_time_ms: 61.553
    sample_throughput: 1191.543
    train_throughput: 24402.807
  iterations_since_restore: 72
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37217218293790205
    mean_inference_ms: 1.11026890142675
    mean_processing_ms: 0.24649271260179206
  time_since_restore: 2180.727319717407
  time_this_iter_s: 30.29284906387329
  time_total_s: 2180.727319717407
  timestamp: 1563913677
  timesteps_since_restore: 2389100
  timesteps_this_iter: 34450
  timesteps_total: 2389100
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2180 s, 72 iter, 2389100 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-28-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.970736605756365
  episode_reward_mean: 17.00271334404183
  episode_reward_min: -7.520110742418108
  episodes_this_iter: 104
  episodes_total: 8070
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.708770751953125
        mean_q: 5.11493444442749
        min_q: -0.11650453507900238
    learner_queue:
      size_count: 155186
      size_mean: 0.64
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6248199740725324
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1653
    num_steps_sampled: 2420550
    num_steps_trained: 44089856
    num_target_updates: 878
    num_weight_syncs: 6051
    replay_shard_0:
      add_batch_time_ms: 3.467
      policy_default_policy:
        added_count: 607300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11121664
      replay_time_ms: 25.318
      update_priorities_time_ms: 71.347
    sample_throughput: 1211.715
    train_throughput: 12407.965
  iterations_since_restore: 73
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3722886385127841
    mean_inference_ms: 1.111544467077207
    mean_processing_ms: 0.2465552286082168
  time_since_restore: 2211.0038573741913
  time_this_iter_s: 30.276537656784058
  time_total_s: 2211.0038573741913
  timestamp: 1563913708
  timesteps_since_restore: 2420550
  timesteps_this_iter: 31450
  timesteps_total: 2420550
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2211 s, 73 iter, 2420550 ts, 17 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-28-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.28873199921758
  episode_reward_mean: 19.29962770175563
  episode_reward_min: -14.478806434029105
  episodes_this_iter: 114
  episodes_total: 8184
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.358917236328125
        mean_q: 4.719845771789551
        min_q: -0.24089787900447845
    learner_queue:
      size_count: 156404
      size_mean: 0.42
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6029925372672535
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1674
    num_steps_sampled: 2454500
    num_steps_trained: 44713472
    num_target_updates: 891
    num_weight_syncs: 6135
    replay_shard_0:
      add_batch_time_ms: 3.257
      policy_default_policy:
        added_count: 615700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11279360
      replay_time_ms: 21.959
      update_priorities_time_ms: 55.47
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 74
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3721683037911714
    mean_inference_ms: 1.1107746089530917
    mean_processing_ms: 0.24647685755453835
  time_since_restore: 2241.2777168750763
  time_this_iter_s: 30.27385950088501
  time_total_s: 2241.2777168750763
  timestamp: 1563913738
  timesteps_since_restore: 2454500
  timesteps_this_iter: 33950
  timesteps_total: 2454500
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2241 s, 74 iter, 2454500 ts, 19.3 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:29:28,835	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-29-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.97898671134048
  episode_reward_mean: 20.971240890062326
  episode_reward_min: 0.3027600791044425
  episodes_this_iter: 106
  episodes_total: 8290
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 36.64755061887722
    episode_reward_mean: 19.65517557246525
    episode_reward_min: 2.0532629411622536
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19506195039432456
      mean_inference_ms: 0.4743639764515173
      mean_processing_ms: 0.10935255231611343
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.01404571533203
        mean_q: 3.951483726501465
        min_q: -0.46965619921684265
    learner_queue:
      size_count: 157565
      size_mean: 0.58
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.6029925372672534
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1683
    num_steps_sampled: 2486200
    num_steps_trained: 45308416
    num_target_updates: 902
    num_weight_syncs: 6215
    replay_shard_0:
      add_batch_time_ms: 5.063
      policy_default_policy:
        added_count: 623500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11429376
      replay_time_ms: 28.567
      update_priorities_time_ms: 72.091
    sample_throughput: 0.0
    train_throughput: 26274.377
  iterations_since_restore: 75
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37234861960154053
    mean_inference_ms: 1.1116036976867125
    mean_processing_ms: 0.2465818645891242
  time_since_restore: 2271.6075580120087
  time_this_iter_s: 30.329841136932373
  time_total_s: 2271.6075580120087
  timestamp: 1563913768
  timesteps_since_restore: 2486200
  timesteps_this_iter: 31700
  timesteps_total: 2486200
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2271 s, 75 iter, 2486200 ts, 21 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-30-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.99000507048881
  episode_reward_mean: 18.878780359518533
  episode_reward_min: -0.8210967988253731
  episodes_this_iter: 115
  episodes_total: 8405
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.919761657714844
        mean_q: 3.969158172607422
        min_q: -0.3139934241771698
    learner_queue:
      size_count: 158785
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5249761899362675
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1695
    num_steps_sampled: 2520800
    num_steps_trained: 45932544
    num_target_updates: 915
    num_weight_syncs: 6301
    replay_shard_0:
      add_batch_time_ms: 3.447
      policy_default_policy:
        added_count: 632600
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11586560
      replay_time_ms: 23.653
      update_priorities_time_ms: 59.03
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 76
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37222970551803003
    mean_inference_ms: 1.1108359971746162
    mean_processing_ms: 0.24644727494088367
  time_since_restore: 2301.87127327919
  time_this_iter_s: 30.263715267181396
  time_total_s: 2301.87127327919
  timestamp: 1563913800
  timesteps_since_restore: 2520800
  timesteps_this_iter: 34600
  timesteps_total: 2520800
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2301 s, 76 iter, 2520800 ts, 18.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-30-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.55492959178947
  episode_reward_mean: 17.9888723074201
  episode_reward_min: 2.30315579535369
  episodes_this_iter: 106
  episodes_total: 8511
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.31610870361328
        mean_q: 4.729150295257568
        min_q: -0.048795185983181
    learner_queue:
      size_count: 159937
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4853864439804639
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1707
    num_steps_sampled: 2552350
    num_steps_trained: 46522368
    num_target_updates: 927
    num_weight_syncs: 6380
    replay_shard_0:
      add_batch_time_ms: 4.072
      policy_default_policy:
        added_count: 640400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11735552
      replay_time_ms: 23.8
      update_priorities_time_ms: 55.53
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 77
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3723761161230102
    mean_inference_ms: 1.1115913354975644
    mean_processing_ms: 0.2464950616657609
  time_since_restore: 2332.1377573013306
  time_this_iter_s: 30.266484022140503
  time_total_s: 2332.1377573013306
  timestamp: 1563913830
  timesteps_since_restore: 2552350
  timesteps_this_iter: 31550
  timesteps_total: 2552350
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2332 s, 77 iter, 2552350 ts, 18 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-31-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.05039456222545
  episode_reward_mean: 17.383808070945083
  episode_reward_min: -14.250488014397467
  episodes_this_iter: 116
  episodes_total: 8627
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.84368896484375
        mean_q: 4.349454879760742
        min_q: -0.39372432231903076
    learner_queue:
      size_count: 161158
      size_mean: 0.24
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4270831300812525
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1717
    num_steps_sampled: 2587050
    num_steps_trained: 47147520
    num_target_updates: 939
    num_weight_syncs: 6467
    replay_shard_0:
      add_batch_time_ms: 3.656
      policy_default_policy:
        added_count: 649750
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 11892224
      replay_time_ms: 23.777
      update_priorities_time_ms: 58.937
    sample_throughput: 1329.297
    train_throughput: 27224.001
  iterations_since_restore: 78
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37229053969182785
    mean_inference_ms: 1.1108174521708651
    mean_processing_ms: 0.24636111973308072
  time_since_restore: 2362.428180217743
  time_this_iter_s: 30.290422916412354
  time_total_s: 2362.428180217743
  timestamp: 1563913860
  timesteps_since_restore: 2587050
  timesteps_this_iter: 34700
  timesteps_total: 2587050
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2362 s, 78 iter, 2587050 ts, 17.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-31-31
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.03877941690965
  episode_reward_mean: 19.910728733212597
  episode_reward_min: -6.039941644262093
  episodes_this_iter: 105
  episodes_total: 8732
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.13485336303711
        mean_q: 4.092067718505859
        min_q: -2.3467137813568115
    learner_queue:
      size_count: 162315
      size_mean: 0.8
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7483314773547883
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1723
    num_steps_sampled: 2618850
    num_steps_trained: 47739904
    num_target_updates: 951
    num_weight_syncs: 6546
    replay_shard_0:
      add_batch_time_ms: 4.063
      policy_default_policy:
        added_count: 658700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12039680
      replay_time_ms: 26.151
      update_priorities_time_ms: 73.65
    sample_throughput: 0.0
    train_throughput: 24942.897
  iterations_since_restore: 79
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3724157594480664
    mean_inference_ms: 1.1116299614442917
    mean_processing_ms: 0.24648625140677008
  time_since_restore: 2392.819976091385
  time_this_iter_s: 30.391795873641968
  time_total_s: 2392.819976091385
  timestamp: 1563913891
  timesteps_since_restore: 2618850
  timesteps_this_iter: 31800
  timesteps_total: 2618850
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2392 s, 79 iter, 2618850 ts, 19.9 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:32:01,667	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-32-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.37350018309183
  episode_reward_mean: 20.26629184405492
  episode_reward_min: -0.7103411696054736
  episodes_this_iter: 116
  episodes_total: 8848
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 24.968285240439425
    episode_reward_mean: 18.158500170907836
    episode_reward_min: 7.61037369217467
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.1929345296778439
      mean_inference_ms: 0.46935144496765285
      mean_processing_ms: 0.10830447008215134
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 37.41813278198242
        mean_q: 4.488944053649902
        min_q: -0.26127034425735474
    learner_queue:
      size_count: 163533
      size_mean: 0.4
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.4898979485566356
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1734
    num_steps_sampled: 2653400
    num_steps_trained: 48363520
    num_target_updates: 963
    num_weight_syncs: 6632
    replay_shard_0:
      add_batch_time_ms: 3.219
      policy_default_policy:
        added_count: 668600
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12195840
      replay_time_ms: 22.658
      update_priorities_time_ms: 59.15
    sample_throughput: 0.0
    train_throughput: 27561.877
  iterations_since_restore: 80
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37231771725827734
    mean_inference_ms: 1.1108492502109455
    mean_processing_ms: 0.24638463273616598
  time_since_restore: 2423.107108592987
  time_this_iter_s: 30.287132501602173
  time_total_s: 2423.107108592987
  timestamp: 1563913921
  timesteps_since_restore: 2653400
  timesteps_this_iter: 34550
  timesteps_total: 2653400
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2423 s, 80 iter, 2653400 ts, 20.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-32-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.613805814322596
  episode_reward_mean: 17.54258684170603
  episode_reward_min: 0.08277978544072744
  episodes_this_iter: 106
  episodes_total: 8954
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.45423126220703
        mean_q: 4.7068281173706055
        min_q: -0.18763820827007294
    learner_queue:
      size_count: 164689
      size_mean: 0.56
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.0
      - 2.0
      size_std: 0.6053098380168622
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1746
    num_steps_sampled: 2685100
    num_steps_trained: 48955392
    num_target_updates: 975
    num_weight_syncs: 6712
    replay_shard_0:
      add_batch_time_ms: 3.715
      policy_default_policy:
        added_count: 676500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12345344
      replay_time_ms: 21.409
      update_priorities_time_ms: 58.33
    sample_throughput: 1773.79
    train_throughput: 36327.221
  iterations_since_restore: 81
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37247586593289006
    mean_inference_ms: 1.1114183583689725
    mean_processing_ms: 0.24646731613666933
  time_since_restore: 2453.343160867691
  time_this_iter_s: 30.23605227470398
  time_total_s: 2453.343160867691
  timestamp: 1563913952
  timesteps_since_restore: 2685100
  timesteps_this_iter: 31700
  timesteps_total: 2685100
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2453 s, 81 iter, 2685100 ts, 17.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-33-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.75663756013205
  episode_reward_mean: 18.90390675963531
  episode_reward_min: -1.3170636596932412
  episodes_this_iter: 117
  episodes_total: 9071
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.871177673339844
        mean_q: 4.73671817779541
        min_q: -0.3060028553009033
    learner_queue:
      size_count: 165909
      size_mean: 0.48
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6079473661428265
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1759
    num_steps_sampled: 2719650
    num_steps_trained: 49579520
    num_target_updates: 988
    num_weight_syncs: 6798
    replay_shard_0:
      add_batch_time_ms: 3.985
      policy_default_policy:
        added_count: 684550
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12502528
      replay_time_ms: 21.931
      update_priorities_time_ms: 56.019
    sample_throughput: 2256.07
    train_throughput: 0.0
  iterations_since_restore: 82
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3723305711658247
    mean_inference_ms: 1.1105394496678618
    mean_processing_ms: 0.2464212040510887
  time_since_restore: 2483.581000328064
  time_this_iter_s: 30.237839460372925
  time_total_s: 2483.581000328064
  timestamp: 1563913983
  timesteps_since_restore: 2719650
  timesteps_this_iter: 34550
  timesteps_total: 2719650
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.2/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2483 s, 82 iter, 2719650 ts, 18.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-33-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.96253284956417
  episode_reward_mean: 18.446521404718
  episode_reward_min: -0.6146034686580897
  episodes_this_iter: 104
  episodes_total: 9175
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.337059020996094
        mean_q: 4.405329704284668
        min_q: -0.5837810635566711
    learner_queue:
      size_count: 167064
      size_mean: 0.7
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.1000000000000014
      - 2.0
      size_std: 0.6403124237432849
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1769
    num_steps_sampled: 2751100
    num_steps_trained: 50171392
    num_target_updates: 999
    num_weight_syncs: 6877
    replay_shard_0:
      add_batch_time_ms: 4.111
      policy_default_policy:
        added_count: 693100
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12652032
      replay_time_ms: 22.102
      update_priorities_time_ms: 62.616
    sample_throughput: 0.0
    train_throughput: 20991.815
  iterations_since_restore: 83
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37245663374991983
    mean_inference_ms: 1.1114654792159615
    mean_processing_ms: 0.2465442736877215
  time_since_restore: 2513.8446278572083
  time_this_iter_s: 30.263627529144287
  time_total_s: 2513.8446278572083
  timestamp: 1563914013
  timesteps_since_restore: 2751100
  timesteps_this_iter: 31450
  timesteps_total: 2751100
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2513 s, 83 iter, 2751100 ts, 18.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-34-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.695436575766834
  episode_reward_mean: 18.004760016515394
  episode_reward_min: -4.938478567428711
  episodes_this_iter: 115
  episodes_total: 9290
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.54686737060547
        mean_q: 4.653749465942383
        min_q: -0.21030959486961365
    learner_queue:
      size_count: 168286
      size_mean: 0.38
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5249761899362675
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1778
    num_steps_sampled: 2785400
    num_steps_trained: 50796544
    num_target_updates: 1012
    num_weight_syncs: 6962
    replay_shard_0:
      add_batch_time_ms: 3.156
      policy_default_policy:
        added_count: 701800
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12810752
      replay_time_ms: 21.328
      update_priorities_time_ms: 58.371
    sample_throughput: 1703.547
    train_throughput: 17444.325
  iterations_since_restore: 84
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37232772664278996
    mean_inference_ms: 1.1108749124622224
    mean_processing_ms: 0.24646934196267356
  time_since_restore: 2544.114739894867
  time_this_iter_s: 30.27011203765869
  time_total_s: 2544.114739894867
  timestamp: 1563914043
  timesteps_since_restore: 2785400
  timesteps_this_iter: 34300
  timesteps_total: 2785400
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2544 s, 84 iter, 2785400 ts, 18 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:34:34,038	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-34-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.258459733044745
  episode_reward_mean: 18.32907602390455
  episode_reward_min: -1.5117520005778233
  episodes_this_iter: 103
  episodes_total: 9393
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.363351703177926
    episode_reward_mean: 19.055612849171766
    episode_reward_min: 6.899268527037733
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19253691427487188
      mean_inference_ms: 0.4684785212292891
      mean_processing_ms: 0.10805913048458779
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.09090805053711
        mean_q: 3.998289108276367
        min_q: -0.23827692866325378
    learner_queue:
      size_count: 169437
      size_mean: 0.82
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7922120928135344
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1799
    num_steps_sampled: 2816450
    num_steps_trained: 51385856
    num_target_updates: 1024
    num_weight_syncs: 7040
    replay_shard_0:
      add_batch_time_ms: 5.281
      policy_default_policy:
        added_count: 709300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 12959744
      replay_time_ms: 25.941
      update_priorities_time_ms: 74.349
    sample_throughput: 0.0
    train_throughput: 26788.295
  iterations_since_restore: 85
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3724608256828828
    mean_inference_ms: 1.1117392994187267
    mean_processing_ms: 0.24654996554076436
  time_since_restore: 2574.464494943619
  time_this_iter_s: 30.34975504875183
  time_total_s: 2574.464494943619
  timestamp: 1563914074
  timesteps_since_restore: 2816450
  timesteps_this_iter: 31050
  timesteps_total: 2816450
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2574 s, 85 iter, 2816450 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-35-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.79913369682357
  episode_reward_mean: 20.100766248022328
  episode_reward_min: -1.6220074827685371
  episodes_this_iter: 115
  episodes_total: 9508
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.22782516479492
        mean_q: 4.243585586547852
        min_q: -0.20459839701652527
    learner_queue:
      size_count: 170659
      size_mean: 0.5
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.6403124237432849
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1810
    num_steps_sampled: 2850950
    num_steps_trained: 52012032
    num_target_updates: 1036
    num_weight_syncs: 7127
    replay_shard_0:
      add_batch_time_ms: 4.073
      policy_default_policy:
        added_count: 717500
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13117440
      replay_time_ms: 22.328
      update_priorities_time_ms: 57.164
    sample_throughput: 0.0
    train_throughput: 25829.107
  iterations_since_restore: 86
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37235296925000094
    mean_inference_ms: 1.1112048853413121
    mean_processing_ms: 0.24643272414517045
  time_since_restore: 2604.711921453476
  time_this_iter_s: 30.247426509857178
  time_total_s: 2604.711921453476
  timestamp: 1563914105
  timesteps_since_restore: 2850950
  timesteps_this_iter: 34500
  timesteps_total: 2850950
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2604 s, 86 iter, 2850950 ts, 20.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-35-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.247558798842014
  episode_reward_mean: 19.24082603440852
  episode_reward_min: 0.9720456434474579
  episodes_this_iter: 105
  episodes_total: 9613
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.666236877441406
        mean_q: 3.7821290493011475
        min_q: -0.8028912544250488
    learner_queue:
      size_count: 171810
      size_mean: 0.78
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7820485918406861
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1821
    num_steps_sampled: 2882700
    num_steps_trained: 52601344
    num_target_updates: 1048
    num_weight_syncs: 7206
    replay_shard_0:
      add_batch_time_ms: 3.073
      policy_default_policy:
        added_count: 725200
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13266432
      replay_time_ms: 21.427
      update_priorities_time_ms: 56.042
    sample_throughput: 1341.302
    train_throughput: 13734.929
  iterations_since_restore: 87
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3724895223632743
    mean_inference_ms: 1.1119502731593816
    mean_processing_ms: 0.2465235571494794
  time_since_restore: 2634.9555053710938
  time_this_iter_s: 30.243583917617798
  time_total_s: 2634.9555053710938
  timestamp: 1563914135
  timesteps_since_restore: 2882700
  timesteps_this_iter: 31750
  timesteps_total: 2882700
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2634 s, 87 iter, 2882700 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-36-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.87433170045091
  episode_reward_mean: 17.690740946902807
  episode_reward_min: -0.7892326359025451
  episodes_this_iter: 114
  episodes_total: 9727
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 31.818279266357422
        mean_q: 4.188379764556885
        min_q: -0.3354160785675049
    learner_queue:
      size_count: 173031
      size_mean: 0.58
      size_quantiles:
      - 0.0
      - 0.0
      - 0.5
      - 1.0
      - 2.0
      size_std: 0.6352952069707437
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1834
    num_steps_sampled: 2917100
    num_steps_trained: 53226496
    num_target_updates: 1060
    num_weight_syncs: 7292
    replay_shard_0:
      add_batch_time_ms: 3.262
      policy_default_policy:
        added_count: 733700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13422592
      replay_time_ms: 21.858
      update_priorities_time_ms: 57.527
    sample_throughput: 1674.654
    train_throughput: 17148.453
  iterations_since_restore: 88
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3723654423626881
    mean_inference_ms: 1.1115000188611748
    mean_processing_ms: 0.24641898039951327
  time_since_restore: 2665.176661491394
  time_this_iter_s: 30.221156120300293
  time_total_s: 2665.176661491394
  timestamp: 1563914165
  timesteps_since_restore: 2917100
  timesteps_this_iter: 34400
  timesteps_total: 2917100
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2665 s, 88 iter, 2917100 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-36-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.865655563780116
  episode_reward_mean: 20.222242011381383
  episode_reward_min: 0.3029036645486403
  episodes_this_iter: 106
  episodes_total: 9833
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.79121780395508
        mean_q: 3.7009925842285156
        min_q: -0.5296810865402222
    learner_queue:
      size_count: 174190
      size_mean: 0.76
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.68
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1843
    num_steps_sampled: 2948650
    num_steps_trained: 53819392
    num_target_updates: 1072
    num_weight_syncs: 7371
    replay_shard_0:
      add_batch_time_ms: 3.55
      policy_default_policy:
        added_count: 742000
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13571072
      replay_time_ms: 25.588
      update_priorities_time_ms: 75.663
    sample_throughput: 0.0
    train_throughput: 20713.511
  iterations_since_restore: 89
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3724916676054613
    mean_inference_ms: 1.1122264965164246
    mean_processing_ms: 0.2465692935785427
  time_since_restore: 2695.531903028488
  time_this_iter_s: 30.355241537094116
  time_total_s: 2695.531903028488
  timestamp: 1563914196
  timesteps_since_restore: 2948650
  timesteps_this_iter: 31550
  timesteps_total: 2948650
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2695 s, 89 iter, 2948650 ts, 20.2 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:37:06,508	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-37-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.67046900122815
  episode_reward_mean: 18.914637239072263
  episode_reward_min: -1.1224921115795683
  episodes_this_iter: 115
  episodes_total: 9948
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 35.10207172363831
    episode_reward_mean: 19.749394908199953
    episode_reward_min: 3.1444578439477144
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19096947566220093
      mean_inference_ms: 0.4645491109798299
      mean_processing_ms: 0.10719962180453406
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 32.0539436340332
        mean_q: 3.5974225997924805
        min_q: -0.38491663336753845
    learner_queue:
      size_count: 175410
      size_mean: 0.32
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5455272678794342
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1852
    num_steps_sampled: 2983250
    num_steps_trained: 54444544
    num_target_updates: 1085
    num_weight_syncs: 7457
    replay_shard_0:
      add_batch_time_ms: 3.62
      policy_default_policy:
        added_count: 751300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13728256
      replay_time_ms: 19.908
      update_priorities_time_ms: 55.006
    sample_throughput: 0.0
    train_throughput: 0.0
  iterations_since_restore: 90
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3723914106124596
    mean_inference_ms: 1.111603169305958
    mean_processing_ms: 0.2464893936928841
  time_since_restore: 2725.7653636932373
  time_this_iter_s: 30.233460664749146
  time_total_s: 2725.7653636932373
  timestamp: 1563914226
  timesteps_since_restore: 2983250
  timesteps_this_iter: 34600
  timesteps_total: 2983250
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2725 s, 90 iter, 2983250 ts, 18.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-37-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.70084751700512
  episode_reward_mean: 18.48618660884188
  episode_reward_min: -2.5588298811791255
  episodes_this_iter: 102
  episodes_total: 10050
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.643646240234375
        mean_q: 4.2696428298950195
        min_q: -0.40243569016456604
    learner_queue:
      size_count: 176555
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7102112361825881
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1874
    num_steps_sampled: 3014000
    num_steps_trained: 55030272
    num_target_updates: 1096
    num_weight_syncs: 7534
    replay_shard_0:
      add_batch_time_ms: 2.833
      policy_default_policy:
        added_count: 759350
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 13875200
      replay_time_ms: 23.051
      update_priorities_time_ms: 55.987
    sample_throughput: 2739.549
    train_throughput: 28052.98
  iterations_since_restore: 91
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37256112421393717
    mean_inference_ms: 1.1124272930590087
    mean_processing_ms: 0.24659184881324808
  time_since_restore: 2756.0081667900085
  time_this_iter_s: 30.24280309677124
  time_total_s: 2756.0081667900085
  timestamp: 1563914257
  timesteps_since_restore: 3014000
  timesteps_this_iter: 30750
  timesteps_total: 3014000
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2756 s, 91 iter, 3014000 ts, 18.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-38-08
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.184405863319476
  episode_reward_mean: 20.58466732363488
  episode_reward_min: -4.098118343774222
  episodes_this_iter: 116
  episodes_total: 10166
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.455711364746094
        mean_q: 4.644218444824219
        min_q: -0.7168872356414795
    learner_queue:
      size_count: 177776
      size_mean: 0.36
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.48
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1880
    num_steps_sampled: 3048550
    num_steps_trained: 55655936
    num_target_updates: 1109
    num_weight_syncs: 7621
    replay_shard_0:
      add_batch_time_ms: 3.512
      policy_default_policy:
        added_count: 766750
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14033920
      replay_time_ms: 20.097
      update_priorities_time_ms: 55.765
    sample_throughput: 2188.66
    train_throughput: 22411.877
  iterations_since_restore: 92
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3724811820721045
    mean_inference_ms: 1.1117741487467345
    mean_processing_ms: 0.24655937247217793
  time_since_restore: 2786.288350343704
  time_this_iter_s: 30.28018355369568
  time_total_s: 2786.288350343704
  timestamp: 1563914288
  timesteps_since_restore: 3048550
  timesteps_this_iter: 34550
  timesteps_total: 3048550
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2786 s, 92 iter, 3048550 ts, 20.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-38-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.167937557179705
  episode_reward_mean: 17.78511171331373
  episode_reward_min: -0.26004679353196763
  episodes_this_iter: 104
  episodes_total: 10270
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 36.330596923828125
        mean_q: 4.576789855957031
        min_q: -0.4265137314796448
    learner_queue:
      size_count: 178932
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      - 2.0
      size_std: 0.5517245689653488
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1889
    num_steps_sampled: 3079900
    num_steps_trained: 56247296
    num_target_updates: 1120
    num_weight_syncs: 7699
    replay_shard_0:
      add_batch_time_ms: 4.068
      policy_default_policy:
        added_count: 774400
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14182912
      replay_time_ms: 23.749
      update_priorities_time_ms: 69.304
    sample_throughput: 1571.489
    train_throughput: 16092.047
  iterations_since_restore: 93
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3726465683264149
    mean_inference_ms: 1.1125790673954437
    mean_processing_ms: 0.2466630366795202
  time_since_restore: 2816.5860710144043
  time_this_iter_s: 30.297720670700073
  time_total_s: 2816.5860710144043
  timestamp: 1563914318
  timesteps_since_restore: 3079900
  timesteps_this_iter: 31350
  timesteps_total: 3079900
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2816 s, 93 iter, 3079900 ts, 17.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-39-08
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.05733793033965
  episode_reward_mean: 17.492841124095992
  episode_reward_min: -8.223643479577825
  episodes_this_iter: 115
  episodes_total: 10385
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.28725814819336
        mean_q: 3.572723388671875
        min_q: -0.42136818170547485
    learner_queue:
      size_count: 180153
      size_mean: 0.66
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.7102112361825881
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1899
    num_steps_sampled: 3114450
    num_steps_trained: 56872960
    num_target_updates: 1133
    num_weight_syncs: 7785
    replay_shard_0:
      add_batch_time_ms: 3.221
      policy_default_policy:
        added_count: 782700
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14340096
      replay_time_ms: 25.191
      update_priorities_time_ms: 57.698
    sample_throughput: 4895.313
    train_throughput: 25064.001
  iterations_since_restore: 94
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3725662959256662
    mean_inference_ms: 1.112025512418317
    mean_processing_ms: 0.24659686050878493
  time_since_restore: 2846.838622570038
  time_this_iter_s: 30.252551555633545
  time_total_s: 2846.838622570038
  timestamp: 1563914348
  timesteps_since_restore: 3114450
  timesteps_this_iter: 34550
  timesteps_total: 3114450
  training_iteration: 94
  2019-07-23 22:40:40,691	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_DDPG_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2846 s, 94 iter, 3114450 ts, 17.5 rew

[2m[36m(pid=24445)[0m 2019-07-23 22:39:38,965	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-39-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.21105021905728
  episode_reward_mean: 19.842168171742287
  episode_reward_min: -0.12501379429933382
  episodes_this_iter: 106
  episodes_total: 10491
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.64945273645308
    episode_reward_mean: 19.648965964669408
    episode_reward_min: 6.352501324456639
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.19066278380015103
      mean_inference_ms: 0.4639352807553306
      mean_processing_ms: 0.1070563075804781
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 35.71024703979492
        mean_q: 3.561309814453125
        min_q: -0.38030269742012024
    learner_queue:
      size_count: 181319
      size_mean: 0.76
      size_quantiles:
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      - 2.0
      size_std: 0.6499230723708769
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1906
    num_steps_sampled: 3146250
    num_steps_trained: 57469440
    num_target_updates: 1145
    num_weight_syncs: 7865
    replay_shard_0:
      add_batch_time_ms: 4.383
      policy_default_policy:
        added_count: 790300
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14491648
      replay_time_ms: 26.781
      update_priorities_time_ms: 71.613
    sample_throughput: 0.0
    train_throughput: 21559.566
  iterations_since_restore: 95
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3726572791141338
    mean_inference_ms: 1.1125256719019792
    mean_processing_ms: 0.2467310913993096
  time_since_restore: 2877.199773311615
  time_this_iter_s: 30.36115074157715
  time_total_s: 2877.199773311615
  timestamp: 1563914378
  timesteps_since_restore: 3146250
  timesteps_this_iter: 31800
  timesteps_total: 3146250
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.4/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2877 s, 95 iter, 3146250 ts, 19.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-40-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.888368245444454
  episode_reward_mean: 20.303123144031197
  episode_reward_min: -0.5223804215096832
  episodes_this_iter: 113
  episodes_total: 10604
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 34.31448745727539
        mean_q: 3.484691619873047
        min_q: -0.8881548047065735
    learner_queue:
      size_count: 182537
      size_mean: 8.78
      size_quantiles:
      - 0.0
      - 0.0
      - 10.5
      - 16.0
      - 16.0
      size_std: 6.697133715254608
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1929
    num_steps_sampled: 3180150
    num_steps_trained: 58085888
    num_target_updates: 1157
    num_weight_syncs: 7949
    replay_shard_0:
      add_batch_time_ms: 3.565
      policy_default_policy:
        added_count: 798800
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14651392
      replay_time_ms: 25.658
      update_priorities_time_ms: 60.995
    sample_throughput: 0.0
    train_throughput: 30421.494
  iterations_since_restore: 96
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37256311624738714
    mean_inference_ms: 1.1120349894265993
    mean_processing_ms: 0.2466714692256478
  time_since_restore: 2907.48867726326
  time_this_iter_s: 30.288903951644897
  time_total_s: 2907.48867726326
  timestamp: 1563914410
  timesteps_since_restore: 3180150
  timesteps_this_iter: 33900
  timesteps_total: 3180150
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 3/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [3 CPUs, 0 GPUs], [pid=24445], 2907 s, 96 iter, 3180150 ts, 20.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-23_22-40-40
  done: true
  episode_len_mean: 150.0
  episode_reward_max: 38.92749103020837
  episode_reward_mean: 21.207317270254467
  episode_reward_min: 1.17816614553496
  episodes_this_iter: 105
  episodes_total: 10709
  experiment_id: 2ccdb3d6fb284df79bc8327b6164ddef
  hostname: navel-notebook-1
  info:
    learner:
      default_policy:
        max_q: 33.54045104980469
        mean_q: 3.466187000274658
        min_q: -0.41810768842697144
    learner_queue:
      size_count: 183686
      size_mean: 0.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.47370877129308037
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 1934
    num_steps_sampled: 3211750
    num_steps_trained: 58681856
    num_target_updates: 1169
    num_weight_syncs: 8028
    replay_shard_0:
      add_batch_time_ms: 3.156
      policy_default_policy:
        added_count: 806050
        est_size_bytes: 170500000
        num_entries: 500000
        sampled_count: 14797824
      replay_time_ms: 21.046
      update_priorities_time_ms: 54.169
    sample_throughput: 3052.667
    train_throughput: 31259.315
  iterations_since_restore: 97
  node_ip: 10.16.128.38
  num_healthy_workers: 2
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 24445
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3726915314228662
    mean_inference_ms: 1.1126714085515754
    mean_processing_ms: 0.24677302390112243
  time_since_restore: 2937.763751745224
  time_this_iter_s: 30.27507448196411
  time_total_s: 2937.763751745224
  timestamp: 1563914440
  timesteps_since_restore: 3211750
  timesteps_this_iter: 31600
  timesteps_total: 3211750
  training_iteration: 97
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	TERMINATED, [3 CPUs, 0 GPUs], [pid=24445], 2937 s, 97 iter, 3211750 ts, 21.2 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 13.5/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	TERMINATED, [3 CPUs, 0 GPUs], [pid=24445], 2937 s, 97 iter, 3211750 ts, 21.2 rew

[32m [  2968.09740s,  INFO] Experiment took 2967.85190 seconds | 49.46420 minutes | 0.82440 hours [0m

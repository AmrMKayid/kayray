2019-07-15 19:07:08,260	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-15_19-07-08_258708_73966/logs.
2019-07-15 19:07:08,375	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:65340 to respond...
2019-07-15 19:07:08,506	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:35247 to respond...
2019-07-15 19:07:08,509	INFO services.py:806 -- Starting Redis shard with 1.72 GB max memory.
2019-07-15 19:07:08,575	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-15_19-07-08_258708_73966/logs.
2019-07-15 19:07:08,576	INFO services.py:1446 -- Starting the Plasma object store with 2.58 GB memory using /tmp.
2019-07-15 19:07:08,732	INFO tune.py:65 -- Did not find checkpoint file in /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg.
2019-07-15 19:07:08,732	INFO tune.py:233 -- Starting a new experiment.
2019-07-15 19:07:11,252	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-15 19:07:34,740	ERROR worker.py:1672 -- WARNING: 12 workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.
[32m [     0.06792s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.06875s,  INFO] Experiment configs: 
 {
  "gym-reacher-apex-ddpg": {
    "env": "RoboschoolReacher-v1",
    "run": "APEX_DDPG",
    "local_dir": "~/kayray_results/local",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "episode_reward_mean": 21,
      "training_iteration": 500
    },
    "config": {
      "use_huber": true,
      "clip_rewards": false,
      "num_gpus": 0,
      "num_workers": 3,
      "n_step": 3,
      "exploration_ou_noise_scale": 1.0,
      "target_network_update_freq": 50000,
      "tau": 1.0,
      "evaluation_interval": 5,
      "evaluation_num_episodes": 10
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=73987)[0m [32m [     0.10395s,  INFO] TimeLimit:
[2m[36m(pid=73987)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=73987)[0m - action_space = Box(2,)
[2m[36m(pid=73987)[0m - observation_space = Box(9,)
[2m[36m(pid=73987)[0m - reward_range = (-inf, inf)
[2m[36m(pid=73987)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=73987)[0m - _max_episode_steps = 150
[2m[36m(pid=73987)[0m - _elapsed_steps = None [0m
[2m[36m(pid=73987)[0m 2019-07-15 19:07:14,892	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=73987)[0m 2019-07-15 19:07:14.893425: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=73987)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=73987)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=73987)[0m 2019-07-15 19:07:17,193	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x1d8bc6358>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:17,194	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x1d8707208>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:17,194	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x1d86fc400>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:17,202	INFO actors.py:108 -- Trying to create 4 colocated actors
[2m[36m(pid=73987)[0m 2019-07-15 19:07:24,281	INFO actors.py:101 -- Got 4 colocated actors of 4
[2m[36m(pid=73987)[0m [32m [    10.17393s,  INFO] TimeLimit:
[2m[36m(pid=73987)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=73987)[0m - action_space = Box(2,)
[2m[36m(pid=73987)[0m - observation_space = Box(9,)
[2m[36m(pid=73987)[0m - reward_range = (-inf, inf)
[2m[36m(pid=73987)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=73987)[0m - _max_episode_steps = 150
[2m[36m(pid=73987)[0m - _elapsed_steps = None [0m
[2m[36m(pid=73987)[0m 2019-07-15 19:07:24,962	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,566	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.agents.ddpg.ddpg_policy.DDPGTFPolicy object at 0x1d9809780>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,567	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x1d9809160>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,567	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': <ray.rllib.utils.filter.NoFilter object at 0x1d9809400>}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,572	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,675	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,707	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.907, max=0.985, mean=-0.016)}}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,709	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,710	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.907, max=0.985, mean=-0.016)
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,710	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.907, max=0.985, mean=-0.016)
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,711	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=73987)[0m                                   'env_id': 0,
[2m[36m(pid=73987)[0m                                   'info': None,
[2m[36m(pid=73987)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.907, max=0.985, mean=-0.016),
[2m[36m(pid=73987)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=73987)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=73987)[0m                                   'rnn_state': []},
[2m[36m(pid=73987)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,711	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=73987)[0m 2019-07-15 19:07:27,961	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-0.139, max=0.258, mean=0.059),
[2m[36m(pid=73987)[0m                       [],
[2m[36m(pid=73987)[0m                       {})}
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m 2019-07-15 19:07:29,041	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'agent0': { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.04),
[2m[36m(pid=73987)[0m                         'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=73987)[0m                         'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.02),
[2m[36m(pid=73987)[0m                         'eps_id': np.ndarray((150,), dtype=int64, min=1397681526.0, max=1397681526.0, mean=1397681526.0),
[2m[36m(pid=73987)[0m                         'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=73987)[0m                         'new_obs': np.ndarray((150, 9), dtype=float32, min=-6.283, max=5.923, mean=0.332),
[2m[36m(pid=73987)[0m                         'obs': np.ndarray((150, 9), dtype=float32, min=-6.283, max=5.923, mean=0.32),
[2m[36m(pid=73987)[0m                         'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.04),
[2m[36m(pid=73987)[0m                         'prev_rewards': np.ndarray((150,), dtype=float32, min=-10.689, max=9.568, mean=-0.442),
[2m[36m(pid=73987)[0m                         'rewards': np.ndarray((150,), dtype=float32, min=-24.144, max=22.322, mean=-1.294),
[2m[36m(pid=73987)[0m                         't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=73987)[0m                         'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=73987)[0m                         'weights': np.ndarray((150,), dtype=float32, min=0.073, max=24.28, mean=8.948)},
[2m[36m(pid=73987)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m 2019-07-15 19:07:29,051	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'data': { 'actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.04),
[2m[36m(pid=73987)[0m             'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=73987)[0m             'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.02),
[2m[36m(pid=73987)[0m             'eps_id': np.ndarray((150,), dtype=int64, min=1397681526.0, max=1397681526.0, mean=1397681526.0),
[2m[36m(pid=73987)[0m             'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=73987)[0m             'new_obs': np.ndarray((150, 9), dtype=float32, min=-6.283, max=5.923, mean=0.332),
[2m[36m(pid=73987)[0m             'obs': np.ndarray((150, 9), dtype=float32, min=-6.283, max=5.923, mean=0.32),
[2m[36m(pid=73987)[0m             'prev_actions': np.ndarray((150, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.04),
[2m[36m(pid=73987)[0m             'prev_rewards': np.ndarray((150,), dtype=float32, min=-10.689, max=9.568, mean=-0.442),
[2m[36m(pid=73987)[0m             'rewards': np.ndarray((150,), dtype=float32, min=-24.144, max=22.322, mean=-1.294),
[2m[36m(pid=73987)[0m             't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=73987)[0m             'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=73987)[0m             'weights': np.ndarray((150,), dtype=float32, min=0.073, max=24.28, mean=8.948)},
[2m[36m(pid=73987)[0m   'type': 'SampleBatch'}
[2m[36m(pid=73987)[0m 
[2m[36m(pid=74117)[0m 2019-07-15 19:07:30,555	INFO rollout_worker.py:301 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=74117)[0m 2019-07-15 19:07:30.557736: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=74117)[0m [32m [     0.08520s,  INFO] TimeLimit:
[2m[36m(pid=74117)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=74117)[0m - action_space = Box(2,)
[2m[36m(pid=74117)[0m - observation_space = Box(9,)
[2m[36m(pid=74117)[0m - reward_range = (-inf, inf)
[2m[36m(pid=74117)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=74117)[0m - _max_episode_steps = 150
[2m[36m(pid=74117)[0m - _elapsed_steps = None [0m
[2m[36m(pid=74103)[0m [32m [     0.06700s,  INFO] TimeLimit:
[2m[36m(pid=74103)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=74103)[0m - action_space = Box(2,)
[2m[36m(pid=74103)[0m - observation_space = Box(9,)
[2m[36m(pid=74103)[0m - reward_range = (-inf, inf)
[2m[36m(pid=74103)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=74103)[0m - _max_episode_steps = 150
[2m[36m(pid=74103)[0m - _elapsed_steps = None [0m
[2m[36m(pid=74103)[0m 2019-07-15 19:07:30,584	INFO rollout_worker.py:301 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=74103)[0m 2019-07-15 19:07:30.585048: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=74103)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=74103)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=74117)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=74117)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,687	INFO rollout_worker.py:428 -- Generating sample batch of size 50
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,749	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.724, max=0.69, mean=0.035)}}
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,749	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,751	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.724, max=0.69, mean=0.035)
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,752	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=-0.724, max=0.69, mean=0.035)
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,753	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=74117)[0m                                   'env_id': 0,
[2m[36m(pid=74117)[0m                                   'info': None,
[2m[36m(pid=74117)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=-0.724, max=0.69, mean=0.035),
[2m[36m(pid=74117)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=74117)[0m                                   'rnn_state': []},
[2m[36m(pid=74117)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,753	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=74117)[0m 2019-07-15 19:07:34,980	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-0.48, max=-0.295, mean=-0.388),
[2m[36m(pid=74117)[0m                       [],
[2m[36m(pid=74117)[0m                       {})}
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m 2019-07-15 19:07:35,433	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m { 'agent0': { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.303),
[2m[36m(pid=74117)[0m                         'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m                         'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m                         'eps_id': np.ndarray((50,), dtype=int64, min=1870398441.0, max=1870398441.0, mean=1870398441.0),
[2m[36m(pid=74117)[0m                         'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=74117)[0m                         'new_obs': np.ndarray((50, 9), dtype=float32, min=-5.354, max=1.37, mean=-0.033),
[2m[36m(pid=74117)[0m                         'obs': np.ndarray((50, 9), dtype=float32, min=-5.354, max=1.37, mean=-0.031),
[2m[36m(pid=74117)[0m                         'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.303),
[2m[36m(pid=74117)[0m                         'prev_rewards': np.ndarray((50,), dtype=float32, min=-2.987, max=2.182, mean=0.236),
[2m[36m(pid=74117)[0m                         'rewards': np.ndarray((50,), dtype=float32, min=-6.144, max=6.239, mean=0.699),
[2m[36m(pid=74117)[0m                         't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=74117)[0m                         'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m                         'weights': np.ndarray((50,), dtype=float32, min=0.002, max=6.135, mean=1.96)},
[2m[36m(pid=74117)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m 2019-07-15 19:07:35,435	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74117)[0m { 'data': { 'actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.303),
[2m[36m(pid=74117)[0m             'agent_index': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m             'dones': np.ndarray((50,), dtype=bool, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m             'eps_id': np.ndarray((50,), dtype=int64, min=1870398441.0, max=1870398441.0, mean=1870398441.0),
[2m[36m(pid=74117)[0m             'infos': np.ndarray((50,), dtype=object, head={}),
[2m[36m(pid=74117)[0m             'new_obs': np.ndarray((50, 9), dtype=float32, min=-5.354, max=1.37, mean=-0.033),
[2m[36m(pid=74117)[0m             'obs': np.ndarray((50, 9), dtype=float32, min=-5.354, max=1.37, mean=-0.031),
[2m[36m(pid=74117)[0m             'prev_actions': np.ndarray((50, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.303),
[2m[36m(pid=74117)[0m             'prev_rewards': np.ndarray((50,), dtype=float32, min=-2.987, max=2.182, mean=0.236),
[2m[36m(pid=74117)[0m             'rewards': np.ndarray((50,), dtype=float32, min=-6.144, max=6.239, mean=0.699),
[2m[36m(pid=74117)[0m             't': np.ndarray((50,), dtype=int64, min=0.0, max=49.0, mean=24.5),
[2m[36m(pid=74117)[0m             'unroll_id': np.ndarray((50,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=74117)[0m             'weights': np.ndarray((50,), dtype=float32, min=0.002, max=6.135, mean=1.96)},
[2m[36m(pid=74117)[0m   'type': 'SampleBatch'}
[2m[36m(pid=74117)[0m 
[2m[36m(pid=74149)[0m [32m [     0.78027s,  INFO] TimeLimit:
[2m[36m(pid=74149)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=74149)[0m - action_space = Box(2,)
[2m[36m(pid=74149)[0m - observation_space = Box(9,)
[2m[36m(pid=74149)[0m - reward_range = (-inf, inf)
[2m[36m(pid=74149)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=74149)[0m - _max_episode_steps = 150
[2m[36m(pid=74149)[0m - _elapsed_steps = None [0m
[2m[36m(pid=74149)[0m 2019-07-15 19:08:02,337	INFO rollout_worker.py:301 -- Creating policy evaluation worker 3 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=74149)[0m 2019-07-15 19:08:02.338573: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=74149)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=74149)[0m WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
[2m[36m(pid=73988)[0m /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.
[2m[36m(pid=73988)[0m   out=out, **kwargs)
[2m[36m(pid=73988)[0m /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars
[2m[36m(pid=73988)[0m   ret = ret.dtype.type(ret / rcount)
[2m[36m(pid=73987)[0m /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.
[2m[36m(pid=73987)[0m   out=out, **kwargs)
[2m[36m(pid=73987)[0m /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars
[2m[36m(pid=73987)[0m   ret = ret.dtype.type(ret / rcount)
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-08-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 9.452891272390136
  episode_reward_mean: -12.504609348526802
  episode_reward_min: -44.001864963582705
  episodes_this_iter: 37
  episodes_total: 37
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner_queue:
      size_count: 24299
      size_mean: 0.0
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      size_std: 0.0
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 0
    num_steps_sampled: 25000
    num_steps_trained: 0
    num_target_updates: 0
    num_weight_syncs: 61
    replay_shard_0:
      add_batch_time_ms: 4.624
      policy_default_policy:
        added_count: 6550
        est_size_bytes: 2233550
        num_entries: 6550
        sampled_count: 0
      replay_time_ms: .nan
      update_priorities_time_ms: .nan
    sample_throughput: 967.602
    train_throughput: 0.0
  iterations_since_restore: 1
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9088179954906124
    mean_inference_ms: 2.959220202091315
    mean_processing_ms: 0.7700434839527556
  time_since_restore: 73.73497605323792
  time_this_iter_s: 73.73497605323792
  time_total_s: 73.73497605323792
  timestamp: 1563210525
  timesteps_since_restore: 25000
  timesteps_this_iter: 25000
  timesteps_total: 25000
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 73 s, 1 iter, 25000 ts, -12.5 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:09:18,729	INFO rollout_worker.py:552 -- Training on concatenated sample batches:
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'count': 512,
[2m[36m(pid=73987)[0m   'policy_batches': { 'default_policy': { 'data': { 'actions': np.ndarray((512, 2), dtype=float32, min=-1.0, max=1.0, mean=-0.008),
[2m[36m(pid=73987)[0m                                                     'batch_indexes': np.ndarray((512,), dtype=int64, min=3.0, max=12482.0, mean=5615.701),
[2m[36m(pid=73987)[0m                                                     'dones': np.ndarray((512,), dtype=bool, min=0.0, max=1.0, mean=0.02),
[2m[36m(pid=73987)[0m                                                     'new_obs': np.ndarray((512, 9), dtype=float32, min=-4.317, max=3.857, mean=-0.017),
[2m[36m(pid=73987)[0m                                                     'obs': np.ndarray((512, 9), dtype=float32, min=-3.312, max=3.887, mean=-0.018),
[2m[36m(pid=73987)[0m                                                     'rewards': np.ndarray((512,), dtype=float32, min=-12.854, max=9.994, mean=-0.176),
[2m[36m(pid=73987)[0m                                                     'weights': np.ndarray((512,), dtype=float64, min=0.052, max=0.182, mean=0.085)},
[2m[36m(pid=73987)[0m                                           'type': 'SampleBatch'}},
[2m[36m(pid=73987)[0m   'type': 'MultiAgentBatch'}
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m 2019-07-15 19:09:19,962	INFO rollout_worker.py:574 -- Training output:
[2m[36m(pid=73987)[0m 
[2m[36m(pid=73987)[0m { 'default_policy': { 'learner_stats': { 'max_q': 0.22524892,
[2m[36m(pid=73987)[0m                                          'mean_q': 0.02805673,
[2m[36m(pid=73987)[0m                                          'min_q': -0.20999464},
[2m[36m(pid=73987)[0m                       'td_error': np.ndarray((512,), dtype=float32, min=-10.0, max=12.913, mean=0.176)}}
[2m[36m(pid=73987)[0m 
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-09-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 20.214721303022973
  episode_reward_mean: -5.629854304443774
  episode_reward_min: -44.001864963582705
  episodes_this_iter: 55
  episodes_total: 92
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 2.1073241233825684
        mean_q: -0.29449790716171265
        min_q: -2.3489511013031006
    learner_queue:
      size_count: 43280
      size_mean: 2.9
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 11.100000000000001
      - 16.0
      size_std: 4.809365862564419
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 489
    num_steps_sampled: 50000
    num_steps_trained: 12800
    num_target_updates: 0
    num_weight_syncs: 124
    replay_shard_0:
      add_batch_time_ms: 4.328
      policy_default_policy:
        added_count: 13200
        est_size_bytes: 4501200
        num_entries: 13200
        sampled_count: 13824
      replay_time_ms: 79.853
      update_priorities_time_ms: 206.782
    sample_throughput: 354.426
    train_throughput: 1814.66
  iterations_since_restore: 2
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.8949457658756821
    mean_inference_ms: 2.9833027697400483
    mean_processing_ms: 0.7226833016449234
  time_since_restore: 113.57296371459961
  time_this_iter_s: 39.837987661361694
  time_total_s: 113.57296371459961
  timestamp: 1563210565
  timesteps_since_restore: 50000
  timesteps_this_iter: 25000
  timesteps_total: 50000
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 113 s, 2 iter, 50000 ts, -5.63 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-10-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 17.65861374265335
  episode_reward_mean: -13.016683243515313
  episode_reward_min: -126.03561036755063
  episodes_this_iter: 56
  episodes_total: 148
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 26.986772537231445
        mean_q: 1.2350643873214722
        min_q: -14.557327270507812
    learner_queue:
      size_count: 45814
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 709
    num_steps_sampled: 75000
    num_steps_trained: 212992
    num_target_updates: 4
    num_weight_syncs: 186
    replay_shard_0:
      add_batch_time_ms: 13.856
      policy_default_policy:
        added_count: 19800
        est_size_bytes: 6751800
        num_entries: 19800
        sampled_count: 66560
      replay_time_ms: 78.412
      update_priorities_time_ms: 307.575
    sample_throughput: 644.383
    train_throughput: 6598.485
  iterations_since_restore: 3
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9204600745283193
    mean_inference_ms: 3.1979196273774106
    mean_processing_ms: 0.7131993549167557
  time_since_restore: 165.539404630661
  time_this_iter_s: 51.9664409160614
  time_total_s: 165.539404630661
  timestamp: 1563210617
  timesteps_since_restore: 75000
  timesteps_this_iter: 25000
  timesteps_total: 75000
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 165 s, 3 iter, 75000 ts, -13 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-11-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 15.014379441239809
  episode_reward_mean: -8.371169421463104
  episode_reward_min: -81.39354803188112
  episodes_this_iter: 55
  episodes_total: 203
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 29.726318359375
        mean_q: 1.4230303764343262
        min_q: -18.979581832885742
    learner_queue:
      size_count: 46217
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 709
    num_steps_sampled: 100000
    num_steps_trained: 419840
    num_target_updates: 8
    num_weight_syncs: 249
    replay_shard_0:
      add_batch_time_ms: 7.973
      policy_default_policy:
        added_count: 26250
        est_size_bytes: 8951250
        num_entries: 26250
        sampled_count: 117760
      replay_time_ms: 102.055
      update_priorities_time_ms: 253.726
    sample_throughput: 1116.433
    train_throughput: 11432.272
  iterations_since_restore: 4
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9584783879416428
    mean_inference_ms: 3.4477952814158765
    mean_processing_ms: 0.7492923359349235
  time_since_restore: 217.77808570861816
  time_this_iter_s: 52.23868107795715
  time_total_s: 217.77808570861816
  timestamp: 1563210670
  timesteps_since_restore: 100000
  timesteps_this_iter: 25000
  timesteps_total: 100000
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 217 s, 4 iter, 100000 ts, -8.37 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:12:00,563	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-12-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.94240165974045
  episode_reward_mean: 5.325445276907066
  episode_reward_min: -31.362941626086176
  episodes_this_iter: 56
  episodes_total: 259
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 29.566155607127413
    episode_reward_mean: 18.583942889205346
    episode_reward_min: 8.64193533231724
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.4744094357971985
      mean_inference_ms: 1.271620943958622
      mean_processing_ms: 0.4441699199937098
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 30.986818313598633
        mean_q: 3.390516519546509
        min_q: -17.395601272583008
    learner_queue:
      size_count: 46617
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 709
    num_steps_sampled: 125000
    num_steps_trained: 624640
    num_target_updates: 12
    num_weight_syncs: 311
    replay_shard_0:
      add_batch_time_ms: 4.747
      policy_default_policy:
        added_count: 33050
        est_size_bytes: 11270050
        num_entries: 33050
        sampled_count: 168448
      replay_time_ms: 129.612
      update_priorities_time_ms: 228.322
    sample_throughput: 3927.361
    train_throughput: 0.0
  iterations_since_restore: 5
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9667434991248449
    mean_inference_ms: 3.580277704460312
    mean_processing_ms: 0.7538161540815186
  time_since_restore: 268.2163736820221
  time_this_iter_s: 50.43828797340393
  time_total_s: 268.2163736820221
  timestamp: 1563210720
  timesteps_since_restore: 125000
  timesteps_this_iter: 25000
  timesteps_total: 125000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 268 s, 5 iter, 125000 ts, 5.33 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-12-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.21506681812396
  episode_reward_mean: 15.708413402336667
  episode_reward_min: -7.543174197490832
  episodes_this_iter: 56
  episodes_total: 315
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 27.540931701660156
        mean_q: 5.477644920349121
        min_q: -21.409425735473633
    learner_queue:
      size_count: 47020
      size_mean: 0.14
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.4004996878900157
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 710
    num_steps_sampled: 150000
    num_steps_trained: 830976
    num_target_updates: 16
    num_weight_syncs: 374
    replay_shard_0:
      add_batch_time_ms: 7.693
      policy_default_policy:
        added_count: 39100
        est_size_bytes: 13333100
        num_entries: 39100
        sampled_count: 220672
      replay_time_ms: 118.24
      update_priorities_time_ms: 263.734
    sample_throughput: 1224.0
    train_throughput: 0.0
  iterations_since_restore: 6
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9594679644246437
    mean_inference_ms: 3.6644190109607795
    mean_processing_ms: 0.7530951982471111
  time_since_restore: 319.23443269729614
  time_this_iter_s: 51.01805901527405
  time_total_s: 319.23443269729614
  timestamp: 1563210773
  timesteps_since_restore: 150000
  timesteps_this_iter: 25000
  timesteps_total: 150000
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 319 s, 6 iter, 150000 ts, 15.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-13-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.21506681812396
  episode_reward_mean: 15.872359158131449
  episode_reward_min: -8.095804035609873
  episodes_this_iter: 55
  episodes_total: 370
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 30.08417510986328
        mean_q: 7.295644283294678
        min_q: -34.80046844482422
    learner_queue:
      size_count: 47416
      size_mean: 0.1
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      size_std: 0.3605551275463989
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 710
    num_steps_sampled: 175000
    num_steps_trained: 1033728
    num_target_updates: 20
    num_weight_syncs: 436
    replay_shard_0:
      add_batch_time_ms: 20.249
      policy_default_policy:
        added_count: 44950
        est_size_bytes: 15327950
        num_entries: 44950
        sampled_count: 271360
      replay_time_ms: 122.616
      update_priorities_time_ms: 301.411
    sample_throughput: 1926.184
    train_throughput: 0.0
  iterations_since_restore: 7
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9458901251404797
    mean_inference_ms: 3.724593714919166
    mean_processing_ms: 0.7581501437652953
  time_since_restore: 368.9830048084259
  time_this_iter_s: 49.74857211112976
  time_total_s: 368.9830048084259
  timestamp: 1563210823
  timesteps_since_restore: 175000
  timesteps_this_iter: 25000
  timesteps_total: 175000
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 368 s, 7 iter, 175000 ts, 15.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-14-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.07903099934851
  episode_reward_mean: 16.19236948733411
  episode_reward_min: -8.095804035609873
  episodes_this_iter: 56
  episodes_total: 426
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.9674186706543
        mean_q: 8.736536979675293
        min_q: -36.108421325683594
    learner_queue:
      size_count: 47810
      size_mean: 0.12
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.32496153618543844
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 710
    num_steps_sampled: 200000
    num_steps_trained: 1235456
    num_target_updates: 24
    num_weight_syncs: 498
    replay_shard_0:
      add_batch_time_ms: 5.177
      policy_default_policy:
        added_count: 51800
        est_size_bytes: 17663800
        num_entries: 51800
        sampled_count: 321536
      replay_time_ms: 79.136
      update_priorities_time_ms: 257.524
    sample_throughput: 2776.14
    train_throughput: 0.0
  iterations_since_restore: 8
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9477296712421687
    mean_inference_ms: 3.755579547713162
    mean_processing_ms: 0.7612912309784836
  time_since_restore: 419.02593088150024
  time_this_iter_s: 50.04292607307434
  time_total_s: 419.02593088150024
  timestamp: 1563210873
  timesteps_since_restore: 200000
  timesteps_this_iter: 25000
  timesteps_total: 200000
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 419 s, 8 iter, 200000 ts, 16.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-15-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.07903099934851
  episode_reward_mean: 14.182980973680701
  episode_reward_min: -15.59464089026189
  episodes_this_iter: 56
  episodes_total: 482
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.205867767333984
        mean_q: 8.376091003417969
        min_q: -20.052021026611328
    learner_queue:
      size_count: 48201
      size_mean: 0.12
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.10000000000000142
      - 2.0
      size_std: 0.38157568056677826
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 710
    num_steps_sampled: 225000
    num_steps_trained: 1435648
    num_target_updates: 28
    num_weight_syncs: 561
    replay_shard_0:
      add_batch_time_ms: 7.098
      policy_default_policy:
        added_count: 57450
        est_size_bytes: 19590450
        num_entries: 57450
        sampled_count: 371200
      replay_time_ms: 130.465
      update_priorities_time_ms: 275.194
    sample_throughput: 1027.98
    train_throughput: 0.0
  iterations_since_restore: 9
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9620010181714507
    mean_inference_ms: 3.7760183355202166
    mean_processing_ms: 0.7663261871800792
  time_since_restore: 471.6099247932434
  time_this_iter_s: 52.583993911743164
  time_total_s: 471.6099247932434
  timestamp: 1563210926
  timesteps_since_restore: 225000
  timesteps_this_iter: 25000
  timesteps_total: 225000
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 471 s, 9 iter, 225000 ts, 14.2 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:16:17,279	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-16-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.43407547927959
  episode_reward_mean: 14.09526076149799
  episode_reward_min: -15.59464089026189
  episodes_this_iter: 56
  episodes_total: 538
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 32.878231099668945
    episode_reward_mean: 17.976870337440573
    episode_reward_min: 3.443032709658234
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.4371814371823894
      mean_inference_ms: 1.1716790528754026
      mean_processing_ms: 0.3818077289960141
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 29.75722312927246
        mean_q: 7.954738140106201
        min_q: -26.798891067504883
    learner_queue:
      size_count: 48587
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 710
    num_steps_sampled: 250000
    num_steps_trained: 1633280
    num_target_updates: 32
    num_weight_syncs: 623
    replay_shard_0:
      add_batch_time_ms: 4.727
      policy_default_policy:
        added_count: 63600
        est_size_bytes: 21687600
        num_entries: 63600
        sampled_count: 420352
      replay_time_ms: 117.216
      update_priorities_time_ms: 255.44
    sample_throughput: 3028.597
    train_throughput: 0.0
  iterations_since_restore: 10
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.966050519347361
    mean_inference_ms: 3.801012469307639
    mean_processing_ms: 0.7663817186599272
  time_since_restore: 522.5867328643799
  time_this_iter_s: 50.976808071136475
  time_total_s: 522.5867328643799
  timestamp: 1563210977
  timesteps_since_restore: 250000
  timesteps_this_iter: 25000
  timesteps_total: 250000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 522 s, 10 iter, 250000 ts, 14.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-17-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.69958990917156
  episode_reward_mean: 17.175742049221164
  episode_reward_min: -8.41512606033605
  episodes_this_iter: 55
  episodes_total: 593
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.21949768066406
        mean_q: 8.496953964233398
        min_q: -16.9738826751709
    learner_queue:
      size_count: 48990
      size_mean: 0.1
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 2.0
      size_std: 0.3605551275463989
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 275000
    num_steps_trained: 1839616
    num_target_updates: 36
    num_weight_syncs: 686
    replay_shard_0:
      add_batch_time_ms: 5.446
      policy_default_policy:
        added_count: 70050
        est_size_bytes: 23887050
        num_entries: 70050
        sampled_count: 471552
      replay_time_ms: 115.686
      update_priorities_time_ms: 245.095
    sample_throughput: 903.571
    train_throughput: 9252.566
  iterations_since_restore: 11
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9640397422551952
    mean_inference_ms: 3.8103130751630556
    mean_processing_ms: 0.7739576505661759
  time_since_restore: 572.8547897338867
  time_this_iter_s: 50.268056869506836
  time_total_s: 572.8547897338867
  timestamp: 1563211029
  timesteps_since_restore: 275000
  timesteps_this_iter: 25000
  timesteps_total: 275000
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 572 s, 11 iter, 275000 ts, 17.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-18-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.991113745456914
  episode_reward_mean: 17.338234258998135
  episode_reward_min: -7.764934501790963
  episodes_this_iter: 56
  episodes_total: 649
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.386558532714844
        mean_q: 9.304903030395508
        min_q: -3.886969804763794
    learner_queue:
      size_count: 49387
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 300000
    num_steps_trained: 2042880
    num_target_updates: 40
    num_weight_syncs: 749
    replay_shard_0:
      add_batch_time_ms: 4.668
      policy_default_policy:
        added_count: 76850
        est_size_bytes: 26205850
        num_entries: 76850
        sampled_count: 522240
      replay_time_ms: 93.658
      update_priorities_time_ms: 258.92
    sample_throughput: 3049.183
    train_throughput: 0.0
  iterations_since_restore: 12
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.96223830652777
    mean_inference_ms: 3.8255280339916795
    mean_processing_ms: 0.7814190012853994
  time_since_restore: 624.4083178043365
  time_this_iter_s: 51.55352807044983
  time_total_s: 624.4083178043365
  timestamp: 1563211081
  timesteps_since_restore: 300000
  timesteps_this_iter: 25000
  timesteps_total: 300000
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 624 s, 12 iter, 300000 ts, 17.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-18-52
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.71058608415943
  episode_reward_mean: 17.90374637750683
  episode_reward_min: -2.5794401911825333
  episodes_this_iter: 56
  episodes_total: 705
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.895095825195312
        mean_q: 8.68973159790039
        min_q: -11.246755599975586
    learner_queue:
      size_count: 49786
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 325000
    num_steps_trained: 2247168
    num_target_updates: 44
    num_weight_syncs: 811
    replay_shard_0:
      add_batch_time_ms: 5.083
      policy_default_policy:
        added_count: 83150
        est_size_bytes: 28354150
        num_entries: 83150
        sampled_count: 573440
      replay_time_ms: 114.719
      update_priorities_time_ms: 301.358
    sample_throughput: 965.637
    train_throughput: 9888.127
  iterations_since_restore: 13
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9674923583551781
    mean_inference_ms: 3.841338726681895
    mean_processing_ms: 0.7770760408795147
  time_since_restore: 675.1569306850433
  time_this_iter_s: 50.74861288070679
  time_total_s: 675.1569306850433
  timestamp: 1563211132
  timesteps_since_restore: 325000
  timesteps_this_iter: 25000
  timesteps_total: 325000
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 675 s, 13 iter, 325000 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-19-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.71058608415943
  episode_reward_mean: 17.470088781600666
  episode_reward_min: -2.5794401911825333
  episodes_this_iter: 55
  episodes_total: 760
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.94461441040039
        mean_q: 8.55221939086914
        min_q: -14.907094955444336
    learner_queue:
      size_count: 50179
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 350000
    num_steps_trained: 2448384
    num_target_updates: 48
    num_weight_syncs: 873
    replay_shard_0:
      add_batch_time_ms: 5.467
      policy_default_policy:
        added_count: 89100
        est_size_bytes: 30383100
        num_entries: 89100
        sampled_count: 623616
      replay_time_ms: 104.497
      update_priorities_time_ms: 203.245
    sample_throughput: 3291.767
    train_throughput: 0.0
  iterations_since_restore: 14
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9699101925472466
    mean_inference_ms: 3.8440562547266577
    mean_processing_ms: 0.7757138456774052
  time_since_restore: 724.9381067752838
  time_this_iter_s: 49.78117609024048
  time_total_s: 724.9381067752838
  timestamp: 1563211182
  timesteps_since_restore: 350000
  timesteps_this_iter: 25000
  timesteps_total: 350000
  training_iteration: 14
  2019-07-15 19:23:18,913	WARNING util.py:64 -- The `process_trial` operation took 0.2854161262512207 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 724 s, 14 iter, 350000 ts, 17.5 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:20:40,855	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-20-40
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.652446834558056
  episode_reward_mean: 17.38423710506998
  episode_reward_min: -3.547445720684044
  episodes_this_iter: 55
  episodes_total: 815
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 37.022328367868006
    episode_reward_mean: 25.634274903680552
    episode_reward_min: 3.744084631028712
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.4053425339932561
      mean_inference_ms: 1.1001610195730114
      mean_processing_ms: 0.3393886685669373
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.17525863647461
        mean_q: 8.034867286682129
        min_q: -33.66524124145508
    learner_queue:
      size_count: 50587
      size_mean: 0.22
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.5015974481593781
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 375000
    num_steps_trained: 2657280
    num_target_updates: 52
    num_weight_syncs: 936
    replay_shard_0:
      add_batch_time_ms: 4.6
      policy_default_policy:
        added_count: 95300
        est_size_bytes: 32497300
        num_entries: 95300
        sampled_count: 676352
      replay_time_ms: 108.455
      update_priorities_time_ms: 213.104
    sample_throughput: 2599.668
    train_throughput: 0.0
  iterations_since_restore: 15
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9714498262357847
    mean_inference_ms: 3.8701915741856077
    mean_processing_ms: 0.7848704280383934
  time_since_restore: 783.656965970993
  time_this_iter_s: 58.71885919570923
  time_total_s: 783.656965970993
  timestamp: 1563211240
  timesteps_since_restore: 375000
  timesteps_this_iter: 25000
  timesteps_total: 375000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 783 s, 15 iter, 375000 ts, 17.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-21-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.860409247831804
  episode_reward_mean: 17.810224447493827
  episode_reward_min: -3.547445720684044
  episodes_this_iter: 56
  episodes_total: 871
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.86380386352539
        mean_q: 8.170422554016113
        min_q: -31.43358039855957
    learner_queue:
      size_count: 50967
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265426
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 400000
    num_steps_trained: 2851840
    num_target_updates: 56
    num_weight_syncs: 998
    replay_shard_0:
      add_batch_time_ms: 6.904
      policy_default_policy:
        added_count: 101250
        est_size_bytes: 34526250
        num_entries: 101250
        sampled_count: 723456
      replay_time_ms: 91.756
      update_priorities_time_ms: 246.495
    sample_throughput: 2522.01
    train_throughput: 0.0
  iterations_since_restore: 16
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9706216739733169
    mean_inference_ms: 3.8932578658193115
    mean_processing_ms: 0.7891280110210432
  time_since_restore: 833.5435197353363
  time_this_iter_s: 49.88655376434326
  time_total_s: 833.5435197353363
  timestamp: 1563211292
  timesteps_since_restore: 400000
  timesteps_this_iter: 25000
  timesteps_total: 400000
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 833 s, 16 iter, 400000 ts, 17.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-22-24
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.329161314089866
  episode_reward_mean: 17.45368612649388
  episode_reward_min: -1.027897932596961
  episodes_this_iter: 56
  episodes_total: 927
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.01621627807617
        mean_q: 8.398216247558594
        min_q: -8.341402053833008
    learner_queue:
      size_count: 51351
      size_mean: 0.1
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.10000000000000142
      - 1.0
      size_std: 0.3
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 425050
    num_steps_trained: 3048448
    num_target_updates: 60
    num_weight_syncs: 1061
    replay_shard_0:
      add_batch_time_ms: 4.726
      policy_default_policy:
        added_count: 106900
        est_size_bytes: 36452900
        num_entries: 106900
        sampled_count: 774144
      replay_time_ms: 101.321
      update_priorities_time_ms: 205.723
    sample_throughput: 3537.915
    train_throughput: 0.0
  iterations_since_restore: 17
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9645086709208992
    mean_inference_ms: 3.8964042225962547
    mean_processing_ms: 0.7842029710345386
  time_since_restore: 885.0066406726837
  time_this_iter_s: 51.46312093734741
  time_total_s: 885.0066406726837
  timestamp: 1563211344
  timesteps_since_restore: 425050
  timesteps_this_iter: 25050
  timesteps_total: 425050
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 885 s, 17 iter, 425050 ts, 17.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-23-18
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.329161314089866
  episode_reward_mean: 17.283161554261007
  episode_reward_min: -10.596227225249736
  episodes_this_iter: 55
  episodes_total: 982
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.94469451904297
        mean_q: 8.162275314331055
        min_q: -23.63291358947754
    learner_queue:
      size_count: 51743
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 450050
    num_steps_trained: 3249152
    num_target_updates: 64
    num_weight_syncs: 1124
    replay_shard_0:
      add_batch_time_ms: 5.476
      policy_default_policy:
        added_count: 113250
        est_size_bytes: 38618250
        num_entries: 113250
        sampled_count: 824320
      replay_time_ms: 102.271
      update_priorities_time_ms: 282.147
    sample_throughput: 2006.364
    train_throughput: 0.0
  iterations_since_restore: 18
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9594601998990027
    mean_inference_ms: 3.8962300591730887
    mean_processing_ms: 0.779177228767804
  time_since_restore: 938.7328104972839
  time_this_iter_s: 53.72616982460022
  time_total_s: 938.7328104972839
  timestamp: 1563211398
  timesteps_since_restore: 450050
  timesteps_this_iter: 25000
  timesteps_total: 450050
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 938 s, 18 iter, 450050 ts, 17.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-24-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.17781981859552
  episode_reward_mean: 16.279869220526532
  episode_reward_min: -10.596227225249736
  episodes_this_iter: 56
  episodes_total: 1038
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.57111358642578
        mean_q: 8.177403450012207
        min_q: -20.665645599365234
    learner_queue:
      size_count: 52143
      size_mean: 0.0
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      size_std: 0.0
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 475050
    num_steps_trained: 3453440
    num_target_updates: 68
    num_weight_syncs: 1186
    replay_shard_0:
      add_batch_time_ms: 7.154
      policy_default_policy:
        added_count: 119850
        est_size_bytes: 40868850
        num_entries: 119850
        sampled_count: 874496
      replay_time_ms: 89.582
      update_priorities_time_ms: 280.711
    sample_throughput: 309.303
    train_throughput: 3167.259
  iterations_since_restore: 19
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9577011362103065
    mean_inference_ms: 3.898053641618558
    mean_processing_ms: 0.775715931667933
  time_since_restore: 995.8676748275757
  time_this_iter_s: 57.13486433029175
  time_total_s: 995.8676748275757
  timestamp: 1563211455
  timesteps_since_restore: 475050
  timesteps_this_iter: 25000
  timesteps_total: 475050
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.1/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 995 s, 19 iter, 475050 ts, 16.3 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:25:11,886	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-25-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.17781981859552
  episode_reward_mean: 17.107709476502727
  episode_reward_min: -9.644633093671555
  episodes_this_iter: 55
  episodes_total: 1093
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 26.679501433226502
    episode_reward_mean: 13.598856604284014
    episode_reward_min: 0.058813704770747696
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.3858171070659817
      mean_inference_ms: 1.050914260422829
      mean_processing_ms: 0.3219853240861017
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.92302322387695
        mean_q: 8.020889282226562
        min_q: -4.341240406036377
    learner_queue:
      size_count: 52536
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 500050
    num_steps_trained: 3655168
    num_target_updates: 72
    num_weight_syncs: 1248
    replay_shard_0:
      add_batch_time_ms: 6.723
      policy_default_policy:
        added_count: 125850
        est_size_bytes: 42914850
        num_entries: 125850
        sampled_count: 924672
      replay_time_ms: 90.109
      update_priorities_time_ms: 251.615
    sample_throughput: 2997.13
    train_throughput: 0.0
  iterations_since_restore: 20
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9587179305891681
    mean_inference_ms: 3.9004830353220337
    mean_processing_ms: 0.7755348462146315
  time_since_restore: 1052.1987037658691
  time_this_iter_s: 56.33102893829346
  time_total_s: 1052.1987037658691
  timestamp: 1563211511
  timesteps_since_restore: 500050
  timesteps_this_iter: 25000
  timesteps_total: 500050
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.1/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1052 s, 20 iter, 500050 ts, 17.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-26-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.55946862190678
  episode_reward_mean: 17.103938978693968
  episode_reward_min: -1.3284328019436664
  episodes_this_iter: 55
  episodes_total: 1148
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.60619354248047
        mean_q: 7.98281717300415
        min_q: -33.7457389831543
    learner_queue:
      size_count: 52925
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 525050
    num_steps_trained: 3853824
    num_target_updates: 76
    num_weight_syncs: 1312
    replay_shard_0:
      add_batch_time_ms: 4.889
      policy_default_policy:
        added_count: 131850
        est_size_bytes: 44960850
        num_entries: 131850
        sampled_count: 974336
      replay_time_ms: 147.021
      update_priorities_time_ms: 222.936
    sample_throughput: 1026.295
    train_throughput: 0.0
  iterations_since_restore: 21
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9596327789712007
    mean_inference_ms: 3.9063943227217095
    mean_processing_ms: 0.7801253535900304
  time_since_restore: 1105.8152856826782
  time_this_iter_s: 53.61658191680908
  time_total_s: 1105.8152856826782
  timestamp: 1563211567
  timesteps_since_restore: 525050
  timesteps_this_iter: 25000
  timesteps_total: 525050
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1105 s, 21 iter, 525050 ts, 17.1 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-26-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.55946862190678
  episode_reward_mean: 17.48443502873934
  episode_reward_min: -12.000091789024882
  episodes_this_iter: 56
  episodes_total: 1204
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.44784927368164
        mean_q: 7.961325645446777
        min_q: -37.74532699584961
    learner_queue:
      size_count: 53328
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 550050
    num_steps_trained: 4060672
    num_target_updates: 80
    num_weight_syncs: 1373
    replay_shard_0:
      add_batch_time_ms: 8.206
      policy_default_policy:
        added_count: 137750
        est_size_bytes: 46972750
        num_entries: 137750
        sampled_count: 1026048
      replay_time_ms: 99.746
      update_priorities_time_ms: 251.661
    sample_throughput: 2322.788
    train_throughput: 0.0
  iterations_since_restore: 22
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9576515453924549
    mean_inference_ms: 3.9166822639207495
    mean_processing_ms: 0.7811299656092736
  time_since_restore: 1157.2974426746368
  time_this_iter_s: 51.48215699195862
  time_total_s: 1157.2974426746368
  timestamp: 1563211619
  timesteps_since_restore: 550050
  timesteps_this_iter: 25000
  timesteps_total: 550050
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1157 s, 22 iter, 550050 ts, 17.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-27-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.496148112866976
  episode_reward_mean: 18.47964116199121
  episode_reward_min: -12.000091789024882
  episodes_this_iter: 56
  episodes_total: 1260
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.04158401489258
        mean_q: 7.792593955993652
        min_q: -28.88115119934082
    learner_queue:
      size_count: 53711
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 575050
    num_steps_trained: 4256768
    num_target_updates: 84
    num_weight_syncs: 1437
    replay_shard_0:
      add_batch_time_ms: 6.978
      policy_default_policy:
        added_count: 144600
        est_size_bytes: 49308600
        num_entries: 144600
        sampled_count: 1074688
      replay_time_ms: 113.598
      update_priorities_time_ms: 244.919
    sample_throughput: 1705.473
    train_throughput: 0.0
  iterations_since_restore: 23
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9532204942105015
    mean_inference_ms: 3.925638102819148
    mean_processing_ms: 0.7797864690702632
  time_since_restore: 1207.5875346660614
  time_this_iter_s: 50.29009199142456
  time_total_s: 1207.5875346660614
  timestamp: 1563211669
  timesteps_since_restore: 575050
  timesteps_this_iter: 25000
  timesteps_total: 575050
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1207 s, 23 iter, 575050 ts, 18.5 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-28-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.86861750519332
  episode_reward_mean: 19.494939589515624
  episode_reward_min: -4.655890889262708
  episodes_this_iter: 56
  episodes_total: 1316
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.994232177734375
        mean_q: 7.320140838623047
        min_q: -23.940343856811523
    learner_queue:
      size_count: 54104
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 600050
    num_steps_trained: 4457472
    num_target_updates: 88
    num_weight_syncs: 1499
    replay_shard_0:
      add_batch_time_ms: 7.899
      policy_default_policy:
        added_count: 150600
        est_size_bytes: 51354600
        num_entries: 150600
        sampled_count: 1124864
      replay_time_ms: 105.889
      update_priorities_time_ms: 254.696
    sample_throughput: 841.753
    train_throughput: 0.0
  iterations_since_restore: 24
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9522630182996644
    mean_inference_ms: 3.9257923324910298
    mean_processing_ms: 0.7799006861047028
  time_since_restore: 1257.6801857948303
  time_this_iter_s: 50.09265112876892
  time_total_s: 1257.6801857948303
  timestamp: 1563211719
  timesteps_since_restore: 600050
  timesteps_this_iter: 25000
  timesteps_total: 600050
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1257 s, 24 iter, 600050 ts, 19.5 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:29:29,003	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-29-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.67488505974826
  episode_reward_mean: 17.89743299247853
  episode_reward_min: -2.2968623329037654
  episodes_this_iter: 55
  episodes_total: 1371
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 35.926114525643825
    episode_reward_mean: 21.597990741922057
    episode_reward_min: 12.41882614059537
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.3727443906124824
      mean_inference_ms: 1.0206455681644775
      mean_processing_ms: 0.3045704507546986
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 37.23734664916992
        mean_q: 6.815858840942383
        min_q: -38.36699295043945
    learner_queue:
      size_count: 54489
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 625050
    num_steps_trained: 4655104
    num_target_updates: 92
    num_weight_syncs: 1562
    replay_shard_0:
      add_batch_time_ms: 4.904
      policy_default_policy:
        added_count: 156900
        est_size_bytes: 53502900
        num_entries: 156900
        sampled_count: 1174016
      replay_time_ms: 85.9
      update_priorities_time_ms: 246.74
    sample_throughput: 323.928
    train_throughput: 0.0
  iterations_since_restore: 25
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9520688215013163
    mean_inference_ms: 3.92091288915967
    mean_processing_ms: 0.7808745204148753
  time_since_restore: 1307.049561738968
  time_this_iter_s: 49.36937594413757
  time_total_s: 1307.049561738968
  timestamp: 1563211769
  timesteps_since_restore: 625050
  timesteps_this_iter: 25000
  timesteps_total: 625050
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1307 s, 25 iter, 625050 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-30-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.67488505974826
  episode_reward_mean: 18.2462026140219
  episode_reward_min: -3.579889385590747
  episodes_this_iter: 56
  episodes_total: 1427
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.02803421020508
        mean_q: 6.948934555053711
        min_q: -39.254215240478516
    learner_queue:
      size_count: 54872
      size_mean: 0.02
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.13999999999999999
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 650050
    num_steps_trained: 4851200
    num_target_updates: 96
    num_weight_syncs: 1625
    replay_shard_0:
      add_batch_time_ms: 5.469
      policy_default_policy:
        added_count: 163950
        est_size_bytes: 55906950
        num_entries: 163950
        sampled_count: 1223168
      replay_time_ms: 100.286
      update_priorities_time_ms: 246.134
    sample_throughput: 1202.548
    train_throughput: 4104.698
  iterations_since_restore: 26
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9523767200700177
    mean_inference_ms: 3.919936040499996
    mean_processing_ms: 0.7816079002413312
  time_since_restore: 1358.2844488620758
  time_this_iter_s: 51.23488712310791
  time_total_s: 1358.2844488620758
  timestamp: 1563211822
  timesteps_since_restore: 650050
  timesteps_this_iter: 25000
  timesteps_total: 650050
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1358 s, 26 iter, 650050 ts, 18.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-31-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.2386436158782
  episode_reward_mean: 18.332344723299503
  episode_reward_min: -3.579889385590747
  episodes_this_iter: 56
  episodes_total: 1483
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.94529724121094
        mean_q: 6.5391998291015625
        min_q: -14.565292358398438
    learner_queue:
      size_count: 55255
      size_mean: 0.02
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.13999999999999999
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 675050
    num_steps_trained: 5047296
    num_target_updates: 100
    num_weight_syncs: 1686
    replay_shard_0:
      add_batch_time_ms: 5.279
      policy_default_policy:
        added_count: 170200
        est_size_bytes: 58038200
        num_entries: 170200
        sampled_count: 1272320
      replay_time_ms: 113.27
      update_priorities_time_ms: 235.975
    sample_throughput: 4518.556
    train_throughput: 0.0
  iterations_since_restore: 27
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9534452036946096
    mean_inference_ms: 3.922265317726796
    mean_processing_ms: 0.7785238355131986
  time_since_restore: 1407.7358858585358
  time_this_iter_s: 49.45143699645996
  time_total_s: 1407.7358858585358
  timestamp: 1563211871
  timesteps_since_restore: 675050
  timesteps_this_iter: 25000
  timesteps_total: 675050
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1407 s, 27 iter, 675050 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-32-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.8216563332523
  episode_reward_mean: 17.598187550515235
  episode_reward_min: -1.9542907575003043
  episodes_this_iter: 56
  episodes_total: 1539
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.54957389831543
        mean_q: 6.431333541870117
        min_q: -19.363834381103516
    learner_queue:
      size_count: 55646
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 700050
    num_steps_trained: 5247488
    num_target_updates: 104
    num_weight_syncs: 1748
    replay_shard_0:
      add_batch_time_ms: 10.867
      policy_default_policy:
        added_count: 176350
        est_size_bytes: 60135350
        num_entries: 176350
        sampled_count: 1321984
      replay_time_ms: 85.929
      update_priorities_time_ms: 245.941
    sample_throughput: 2818.298
    train_throughput: 0.0
  iterations_since_restore: 28
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9523017732582223
    mean_inference_ms: 3.91996175568575
    mean_processing_ms: 0.7791747278238986
  time_since_restore: 1457.9002380371094
  time_this_iter_s: 50.16435217857361
  time_total_s: 1457.9002380371094
  timestamp: 1563211922
  timesteps_since_restore: 700050
  timesteps_this_iter: 25000
  timesteps_total: 700050
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1457 s, 28 iter, 700050 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-32-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.79699074817416
  episode_reward_mean: 16.707548186001002
  episode_reward_min: -1.9542907575003043
  episodes_this_iter: 56
  episodes_total: 1595
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.94969177246094
        mean_q: 6.923501014709473
        min_q: -6.651500225067139
    learner_queue:
      size_count: 56031
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 725050
    num_steps_trained: 5444608
    num_target_updates: 108
    num_weight_syncs: 1812
    replay_shard_0:
      add_batch_time_ms: 4.798
      policy_default_policy:
        added_count: 182850
        est_size_bytes: 62351850
        num_entries: 182850
        sampled_count: 1371648
      replay_time_ms: 104.848
      update_priorities_time_ms: 242.753
    sample_throughput: 990.33
    train_throughput: 0.0
  iterations_since_restore: 29
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9499810629736349
    mean_inference_ms: 3.917265647074135
    mean_processing_ms: 0.7814024594668133
  time_since_restore: 1507.7267670631409
  time_this_iter_s: 49.826529026031494
  time_total_s: 1507.7267670631409
  timestamp: 1563211971
  timesteps_since_restore: 725050
  timesteps_this_iter: 25000
  timesteps_total: 725050
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1507 s, 29 iter, 725050 ts, 16.7 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:33:42,096	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-33-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.3525842468515
  episode_reward_mean: 15.416938694353561
  episode_reward_min: -2.639013489515254
  episodes_this_iter: 56
  episodes_total: 1651
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 35.37855471073354
    episode_reward_mean: 14.934973482506066
    episode_reward_min: 4.637700153575658
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.367028090445476
      mean_inference_ms: 1.0232715626669298
      mean_processing_ms: 0.2953287601788808
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.436073303222656
        mean_q: 6.387557029724121
        min_q: -0.54147869348526
    learner_queue:
      size_count: 56415
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 750050
    num_steps_trained: 5641216
    num_target_updates: 112
    num_weight_syncs: 1874
    replay_shard_0:
      add_batch_time_ms: 5.006
      policy_default_policy:
        added_count: 189000
        est_size_bytes: 64449000
        num_entries: 189000
        sampled_count: 1421312
      replay_time_ms: 112.429
      update_priorities_time_ms: 248.257
    sample_throughput: 3146.491
    train_throughput: 0.0
  iterations_since_restore: 30
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9486133820414021
    mean_inference_ms: 3.9169924253374804
    mean_processing_ms: 0.78115614187744
  time_since_restore: 1557.9095630645752
  time_this_iter_s: 50.182796001434326
  time_total_s: 1557.9095630645752
  timestamp: 1563212022
  timesteps_since_restore: 750050
  timesteps_this_iter: 25000
  timesteps_total: 750050
  training_iteration: 30
  2019-07-15 19:39:21,784	WARNING util.py:64 -- The `experiment_checkpoint` operation took 0.41585516929626465 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1557 s, 30 iter, 750050 ts, 15.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-34-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.86385999999436
  episode_reward_mean: 16.3858631480719
  episode_reward_min: -2.639013489515254
  episodes_this_iter: 56
  episodes_total: 1707
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.13703155517578
        mean_q: 7.827396392822266
        min_q: -4.954081058502197
    learner_queue:
      size_count: 56796
      size_mean: 0.0
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      size_std: 0.0
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 775050
    num_steps_trained: 5836288
    num_target_updates: 116
    num_weight_syncs: 1936
    replay_shard_0:
      add_batch_time_ms: 9.177
      policy_default_policy:
        added_count: 195000
        est_size_bytes: 66495000
        num_entries: 195000
        sampled_count: 1470464
      replay_time_ms: 103.119
      update_priorities_time_ms: 231.932
    sample_throughput: 1517.674
    train_throughput: 0.0
  iterations_since_restore: 31
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9491506605567898
    mean_inference_ms: 3.916226826861272
    mean_processing_ms: 0.779562936073784
  time_since_restore: 1607.6880769729614
  time_this_iter_s: 49.77851390838623
  time_total_s: 1607.6880769729614
  timestamp: 1563212074
  timesteps_since_restore: 775050
  timesteps_this_iter: 25000
  timesteps_total: 775050
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1607 s, 31 iter, 775050 ts, 16.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-35-24
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.865311358557854
  episode_reward_mean: 17.941077808482994
  episode_reward_min: -2.382822594027608
  episodes_this_iter: 56
  episodes_total: 1763
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.4508056640625
        mean_q: 6.888722896575928
        min_q: -7.774051666259766
    learner_queue:
      size_count: 57180
      size_mean: 0.12
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.3249615361854384
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 800050
    num_steps_trained: 6032896
    num_target_updates: 120
    num_weight_syncs: 1998
    replay_shard_0:
      add_batch_time_ms: 4.676
      policy_default_policy:
        added_count: 201800
        est_size_bytes: 68813800
        num_entries: 201800
        sampled_count: 1519104
      replay_time_ms: 123.07
      update_priorities_time_ms: 283.793
    sample_throughput: 841.819
    train_throughput: 4310.113
  iterations_since_restore: 32
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9506813319981817
    mean_inference_ms: 3.915443581431953
    mean_processing_ms: 0.7759483286164681
  time_since_restore: 1657.4417288303375
  time_this_iter_s: 49.7536518573761
  time_total_s: 1657.4417288303375
  timestamp: 1563212124
  timesteps_since_restore: 800050
  timesteps_this_iter: 25000
  timesteps_total: 800050
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1657 s, 32 iter, 800050 ts, 17.9 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-36-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.2410567064488
  episode_reward_mean: 20.285039876235274
  episode_reward_min: 0.2510372351673442
  episodes_this_iter: 56
  episodes_total: 1819
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.63103485107422
        mean_q: 6.945940971374512
        min_q: -15.463885307312012
    learner_queue:
      size_count: 57564
      size_mean: 0.14
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.4004996878900157
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 825050
    num_steps_trained: 6229504
    num_target_updates: 123
    num_weight_syncs: 2061
    replay_shard_0:
      add_batch_time_ms: 5.1
      policy_default_policy:
        added_count: 207850
        est_size_bytes: 70876850
        num_entries: 207850
        sampled_count: 1568256
      replay_time_ms: 146.959
      update_priorities_time_ms: 272.656
    sample_throughput: 369.284
    train_throughput: 0.0
  iterations_since_restore: 33
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9511492597623094
    mean_inference_ms: 3.9157739863399037
    mean_processing_ms: 0.773214247635964
  time_since_restore: 1707.1676437854767
  time_this_iter_s: 49.72591495513916
  time_total_s: 1707.1676437854767
  timestamp: 1563212173
  timesteps_since_restore: 825050
  timesteps_this_iter: 25000
  timesteps_total: 825050
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1707 s, 33 iter, 825050 ts, 20.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-37-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.911122097099344
  episode_reward_mean: 18.483553001423836
  episode_reward_min: -1.4714592658819305
  episodes_this_iter: 56
  episodes_total: 1875
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.92850875854492
        mean_q: 7.361089706420898
        min_q: -19.544387817382812
    learner_queue:
      size_count: 57950
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265426
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 850050
    num_steps_trained: 6427136
    num_target_updates: 127
    num_weight_syncs: 2124
    replay_shard_0:
      add_batch_time_ms: 4.945
      policy_default_policy:
        added_count: 214150
        est_size_bytes: 73025150
        num_entries: 214150
        sampled_count: 1617408
      replay_time_ms: 99.263
      update_priorities_time_ms: 293.103
    sample_throughput: 978.809
    train_throughput: 5011.502
  iterations_since_restore: 34
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9504704394781497
    mean_inference_ms: 3.913164571491894
    mean_processing_ms: 0.7738044804338925
  time_since_restore: 1756.3302087783813
  time_this_iter_s: 49.16256499290466
  time_total_s: 1756.3302087783813
  timestamp: 1563212223
  timesteps_since_restore: 850050
  timesteps_this_iter: 25000
  timesteps_total: 850050
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1756 s, 34 iter, 850050 ts, 18.5 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:38:12,163	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-38-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.55837737621388
  episode_reward_mean: 19.30876288200967
  episode_reward_min: -1.4714592658819305
  episodes_this_iter: 55
  episodes_total: 1930
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 36.133020589448485
    episode_reward_mean: 20.156776617990626
    episode_reward_min: 5.821595364357517
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.37194728732119003
      mean_inference_ms: 1.0460826438940045
      mean_processing_ms: 0.311940742049572
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.67689514160156
        mean_q: 6.86200475692749
        min_q: -3.595071315765381
    learner_queue:
      size_count: 58318
      size_mean: 0.02
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.13999999999999999
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 875050
    num_steps_trained: 6615552
    num_target_updates: 131
    num_weight_syncs: 2186
    replay_shard_0:
      add_batch_time_ms: 4.419
      policy_default_policy:
        added_count: 220450
        est_size_bytes: 75173450
        num_entries: 220450
        sampled_count: 1664512
      replay_time_ms: 116.25
      update_priorities_time_ms: 280.409
    sample_throughput: 1217.257
    train_throughput: 0.0
  iterations_since_restore: 35
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9561592926646716
    mean_inference_ms: 3.92940564856607
    mean_processing_ms: 0.7798699960428513
  time_since_restore: 1825.4389386177063
  time_this_iter_s: 69.10872983932495
  time_total_s: 1825.4389386177063
  timestamp: 1563212292
  timesteps_since_restore: 875050
  timesteps_this_iter: 25000
  timesteps_total: 875050
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1825 s, 35 iter, 875050 ts, 19.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-39-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.55837737621388
  episode_reward_mean: 19.73272133386933
  episode_reward_min: -1.4057861375314515
  episodes_this_iter: 55
  episodes_total: 1985
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.402587890625
        mean_q: 6.831655502319336
        min_q: -22.619529724121094
    learner_queue:
      size_count: 58685
      size_mean: 0.1
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.10000000000000142
      - 1.0
      size_std: 0.3
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 900050
    num_steps_trained: 6803456
    num_target_updates: 135
    num_weight_syncs: 2248
    replay_shard_0:
      add_batch_time_ms: 5.718
      policy_default_policy:
        added_count: 226900
        est_size_bytes: 77372900
        num_entries: 226900
        sampled_count: 1711616
      replay_time_ms: 122.006
      update_priorities_time_ms: 298.67
    sample_throughput: 1857.498
    train_throughput: 0.0
  iterations_since_restore: 36
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9612816683144806
    mean_inference_ms: 3.948228642722569
    mean_processing_ms: 0.7851124715544415
  time_since_restore: 1891.4702634811401
  time_this_iter_s: 66.03132486343384
  time_total_s: 1891.4702634811401
  timestamp: 1563212361
  timesteps_since_restore: 900050
  timesteps_this_iter: 25000
  timesteps_total: 900050
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1891 s, 36 iter, 900050 ts, 19.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-40-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.92162182521592
  episode_reward_mean: 18.605183207628286
  episode_reward_min: -0.5372181124612663
  episodes_this_iter: 56
  episodes_total: 2041
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.305416107177734
        mean_q: 6.827603340148926
        min_q: -2.9338648319244385
    learner_queue:
      size_count: 59077
      size_mean: 0.22
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 3.0
      size_std: 0.5758472019555188
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 925050
    num_steps_trained: 7004160
    num_target_updates: 139
    num_weight_syncs: 2311
    replay_shard_0:
      add_batch_time_ms: 4.902
      policy_default_policy:
        added_count: 232550
        est_size_bytes: 79299550
        num_entries: 232550
        sampled_count: 1759232
      replay_time_ms: 86.008
      update_priorities_time_ms: 272.208
    sample_throughput: 4213.348
    train_throughput: 0.0
  iterations_since_restore: 37
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9594961549079645
    mean_inference_ms: 3.9534087123879247
    mean_processing_ms: 0.7852293483141954
  time_since_restore: 1945.4711394309998
  time_this_iter_s: 54.00087594985962
  time_total_s: 1945.4711394309998
  timestamp: 1563212415
  timesteps_since_restore: 925050
  timesteps_this_iter: 25000
  timesteps_total: 925050
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1945 s, 37 iter, 925050 ts, 18.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-41-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.880042108061104
  episode_reward_mean: 17.60317247978031
  episode_reward_min: -0.5848374220978955
  episodes_this_iter: 55
  episodes_total: 2096
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.701316833496094
        mean_q: 5.398898124694824
        min_q: -15.50886058807373
    learner_queue:
      size_count: 59472
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 711
    num_steps_sampled: 950050
    num_steps_trained: 7206400
    num_target_updates: 143
    num_weight_syncs: 2374
    replay_shard_0:
      add_batch_time_ms: 4.355
      policy_default_policy:
        added_count: 239550
        est_size_bytes: 81686550
        num_entries: 239550
        sampled_count: 1809408
      replay_time_ms: 134.168
      update_priorities_time_ms: 281.142
    sample_throughput: 926.594
    train_throughput: 0.0
  iterations_since_restore: 38
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9584636573651616
    mean_inference_ms: 3.954367079472497
    mean_processing_ms: 0.7831829448702985
  time_since_restore: 1999.087352514267
  time_this_iter_s: 53.61621308326721
  time_total_s: 1999.087352514267
  timestamp: 1563212469
  timesteps_since_restore: 950050
  timesteps_this_iter: 25000
  timesteps_total: 950050
  training_iteration: 38
  2019-07-15 19:48:48,532	WARNING util.py:64 -- The `process_trial` operation took 0.11751103401184082 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 1999 s, 38 iter, 950050 ts, 17.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-42-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.880042108061104
  episode_reward_mean: 18.13320085104333
  episode_reward_min: -0.5848374220978955
  episodes_this_iter: 55
  episodes_total: 2151
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.911792755126953
        mean_q: 6.213062763214111
        min_q: -0.5438801646232605
    learner_queue:
      size_count: 59856
      size_mean: 0.16
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.41761226035642196
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 975050
    num_steps_trained: 7403008
    num_target_updates: 147
    num_weight_syncs: 2436
    replay_shard_0:
      add_batch_time_ms: 18.918
      policy_default_policy:
        added_count: 245750
        est_size_bytes: 83800750
        num_entries: 245750
        sampled_count: 1858048
      replay_time_ms: 134.67
      update_priorities_time_ms: 197.95
    sample_throughput: 1127.95
    train_throughput: 0.0
  iterations_since_restore: 39
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9580977655262631
    mean_inference_ms: 3.9531549482284345
    mean_processing_ms: 0.7800819349307053
  time_since_restore: 2056.88126039505
  time_this_iter_s: 57.79390788078308
  time_total_s: 2056.88126039505
  timestamp: 1563212526
  timesteps_since_restore: 975050
  timesteps_this_iter: 25000
  timesteps_total: 975050
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2056 s, 39 iter, 975050 ts, 18.1 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:42:59,234	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-42-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.14009986495346
  episode_reward_mean: 19.267239164839182
  episode_reward_min: -4.97877556444311
  episodes_this_iter: 56
  episodes_total: 2207
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 36.53248575032623
    episode_reward_mean: 21.02930580982094
    episode_reward_min: 4.54749367342902
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.3689051857613412
      mean_inference_ms: 1.0352642233659053
      mean_processing_ms: 0.3081131101528739
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.47138595581055
        mean_q: 6.22935676574707
        min_q: -2.8088197708129883
    learner_queue:
      size_count: 60228
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1000050
    num_steps_trained: 7593472
    num_target_updates: 151
    num_weight_syncs: 2499
    replay_shard_0:
      add_batch_time_ms: 10.077
      policy_default_policy:
        added_count: 251100
        est_size_bytes: 85625100
        num_entries: 251100
        sampled_count: 1906176
      replay_time_ms: 133.946
      update_priorities_time_ms: 290.709
    sample_throughput: 1591.609
    train_throughput: 0.0
  iterations_since_restore: 40
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9555770281314174
    mean_inference_ms: 3.9524528271980377
    mean_processing_ms: 0.7791566676298983
  time_since_restore: 2109.285257101059
  time_this_iter_s: 52.40399670600891
  time_total_s: 2109.285257101059
  timestamp: 1563212579
  timesteps_since_restore: 1000050
  timesteps_this_iter: 25000
  timesteps_total: 1000050
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2109 s, 40 iter, 1000050 ts, 19.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-44-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.14009986495346
  episode_reward_mean: 18.345397452071023
  episode_reward_min: -4.97877556444311
  episodes_this_iter: 55
  episodes_total: 2262
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 37.613494873046875
        mean_q: 6.486997604370117
        min_q: -0.989274799823761
    learner_queue:
      size_count: 60595
      size_mean: 2.82
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 10.0
      - 13.0
      size_std: 4.102145779954681
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1025050
    num_steps_trained: 7775744
    num_target_updates: 154
    num_weight_syncs: 2562
    replay_shard_0:
      add_batch_time_ms: 8.759
      policy_default_policy:
        added_count: 257600
        est_size_bytes: 87841600
        num_entries: 257600
        sampled_count: 1952768
      replay_time_ms: 123.328
      update_priorities_time_ms: 205.602
    sample_throughput: 2567.271
    train_throughput: 0.0
  iterations_since_restore: 41
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9578165739910648
    mean_inference_ms: 3.963009703541908
    mean_processing_ms: 0.7823392374688345
  time_since_restore: 2172.2047140598297
  time_this_iter_s: 62.91945695877075
  time_total_s: 2172.2047140598297
  timestamp: 1563212644
  timesteps_since_restore: 1025050
  timesteps_this_iter: 25000
  timesteps_total: 1025050
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2172 s, 41 iter, 1025050 ts, 18.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-44-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.802295966592595
  episode_reward_mean: 18.615682508147444
  episode_reward_min: -9.260994489175209
  episodes_this_iter: 55
  episodes_total: 2317
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.880985260009766
        mean_q: 5.473382949829102
        min_q: -2.721811294555664
    learner_queue:
      size_count: 60985
      size_mean: 1.28
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 6.0
      - 8.0
      size_std: 2.383610706470333
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1050050
    num_steps_trained: 7981056
    num_target_updates: 158
    num_weight_syncs: 2623
    replay_shard_0:
      add_batch_time_ms: 4.604
      policy_default_policy:
        added_count: 264300
        est_size_bytes: 90126300
        num_entries: 264300
        sampled_count: 2001920
      replay_time_ms: 120.326
      update_priorities_time_ms: 273.84
    sample_throughput: 2505.558
    train_throughput: 0.0
  iterations_since_restore: 42
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9603491988496918
    mean_inference_ms: 3.969674766777341
    mean_processing_ms: 0.7841769683074926
  time_since_restore: 2223.773181915283
  time_this_iter_s: 51.56846785545349
  time_total_s: 2223.773181915283
  timestamp: 1563212696
  timesteps_since_restore: 1050050
  timesteps_this_iter: 25000
  timesteps_total: 1050050
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2223 s, 42 iter, 1050050 ts, 18.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-45-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.60211444121968
  episode_reward_mean: 19.045546967422652
  episode_reward_min: -9.260994489175209
  episodes_this_iter: 55
  episodes_total: 2372
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.99474334716797
        mean_q: 6.111196517944336
        min_q: -0.4909731149673462
    learner_queue:
      size_count: 61382
      size_mean: 4.6
      size_quantiles:
      - 0.0
      - 0.0
      - 5.0
      - 10.100000000000001
      - 14.0
      size_std: 4.404543109109048
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1075050
    num_steps_trained: 8183808
    num_target_updates: 162
    num_weight_syncs: 2686
    replay_shard_0:
      add_batch_time_ms: 5.136
      policy_default_policy:
        added_count: 269600
        est_size_bytes: 91933600
        num_entries: 269600
        sampled_count: 2054656
      replay_time_ms: 113.6
      update_priorities_time_ms: 288.728
    sample_throughput: 1120.429
    train_throughput: 0.0
  iterations_since_restore: 43
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9602537340451761
    mean_inference_ms: 3.971258692764297
    mean_processing_ms: 0.783699587759281
  time_since_restore: 2278.1512768268585
  time_this_iter_s: 54.37809491157532
  time_total_s: 2278.1512768268585
  timestamp: 1563212750
  timesteps_since_restore: 1075050
  timesteps_this_iter: 25000
  timesteps_total: 1075050
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2278 s, 43 iter, 1075050 ts, 19 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-46-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.191306468369646
  episode_reward_mean: 17.66087847956274
  episode_reward_min: -7.110441127608232
  episodes_this_iter: 55
  episodes_total: 2427
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.18532180786133
        mean_q: 5.69331169128418
        min_q: -32.90503692626953
    learner_queue:
      size_count: 61765
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1100050
    num_steps_trained: 8380416
    num_target_updates: 166
    num_weight_syncs: 2749
    replay_shard_0:
      add_batch_time_ms: 8.902
      policy_default_policy:
        added_count: 275650
        est_size_bytes: 93996650
        num_entries: 275650
        sampled_count: 2103808
      replay_time_ms: 205.711
      update_priorities_time_ms: 407.291
    sample_throughput: 470.913
    train_throughput: 4822.154
  iterations_since_restore: 44
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9618548303909565
    mean_inference_ms: 3.9767600470198636
    mean_processing_ms: 0.7844984628020338
  time_since_restore: 2333.281665802002
  time_this_iter_s: 55.13038897514343
  time_total_s: 2333.281665802002
  timestamp: 1563212805
  timesteps_since_restore: 1100050
  timesteps_this_iter: 25000
  timesteps_total: 1100050
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.1/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2333 s, 44 iter, 1100050 ts, 17.7 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:48:25,911	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-48-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.40649617624488
  episode_reward_mean: 18.696017158463604
  episode_reward_min: -7.110441127608232
  episodes_this_iter: 54
  episodes_total: 2481
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 38.853939286422836
    episode_reward_mean: 21.628939321697583
    episode_reward_min: 4.191810605532423
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.5872212889257904
      mean_inference_ms: 1.6515958739093093
      mean_processing_ms: 0.7492153575107119
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.778045654296875
        mean_q: 5.395412445068359
        min_q: -5.6261162757873535
    learner_queue:
      size_count: 62122
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265426
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1125050
    num_steps_trained: 8563200
    num_target_updates: 170
    num_weight_syncs: 2811
    replay_shard_0:
      add_batch_time_ms: 16.384
      policy_default_policy:
        added_count: 281500
        est_size_bytes: 95991500
        num_entries: 281500
        sampled_count: 2149376
      replay_time_ms: 458.992
      update_priorities_time_ms: 1020.792
    sample_throughput: 498.273
    train_throughput: 0.0
  iterations_since_restore: 45
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9669651642638394
    mean_inference_ms: 4.016794363500132
    mean_processing_ms: 0.7900020107139285
  time_since_restore: 2433.3951609134674
  time_this_iter_s: 100.11349511146545
  time_total_s: 2433.3951609134674
  timestamp: 1563212905
  timesteps_since_restore: 1125050
  timesteps_this_iter: 25000
  timesteps_total: 1125050
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 7.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2433 s, 45 iter, 1125050 ts, 18.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-50-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.584244906168
  episode_reward_mean: 18.588566316629723
  episode_reward_min: -2.0937646154406058
  episodes_this_iter: 56
  episodes_total: 2537
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 35.06283187866211
        mean_q: 5.598398208618164
        min_q: -18.748605728149414
    learner_queue:
      size_count: 62473
      size_mean: 0.16
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.36660605559646714
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1150050
    num_steps_trained: 8742912
    num_target_updates: 173
    num_weight_syncs: 2874
    replay_shard_0:
      add_batch_time_ms: 12.827
      policy_default_policy:
        added_count: 288350
        est_size_bytes: 98327350
        num_entries: 288350
        sampled_count: 2194432
      replay_time_ms: 189.003
      update_priorities_time_ms: 413.897
    sample_throughput: 1960.45
    train_throughput: 0.0
  iterations_since_restore: 46
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9760192282526196
    mean_inference_ms: 4.066557668308065
    mean_processing_ms: 0.8010699378011633
  time_since_restore: 2511.8543899059296
  time_this_iter_s: 78.45922899246216
  time_total_s: 2511.8543899059296
  timestamp: 1563213007
  timesteps_since_restore: 1150050
  timesteps_this_iter: 25000
  timesteps_total: 1150050
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.2/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2511 s, 46 iter, 1150050 ts, 18.6 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-51-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.439344766860415
  episode_reward_mean: 20.019294288333263
  episode_reward_min: -6.263143793898631
  episodes_this_iter: 56
  episodes_total: 2593
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.0416374206543
        mean_q: 5.9948225021362305
        min_q: -3.547858238220215
    learner_queue:
      size_count: 62917
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1175050
    num_steps_trained: 8970240
    num_target_updates: 178
    num_weight_syncs: 2937
    replay_shard_0:
      add_batch_time_ms: 5.41
      policy_default_policy:
        added_count: 295450
        est_size_bytes: 100748450
        num_entries: 295450
        sampled_count: 2251264
      replay_time_ms: 115.628
      update_priorities_time_ms: 347.884
    sample_throughput: 2231.725
    train_throughput: 0.0
  iterations_since_restore: 47
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9858100567101259
    mean_inference_ms: 4.094457476544407
    mean_processing_ms: 0.8081208724463766
  time_since_restore: 2585.312299966812
  time_this_iter_s: 73.45791006088257
  time_total_s: 2585.312299966812
  timestamp: 1563213080
  timesteps_since_restore: 1175050
  timesteps_this_iter: 25000
  timesteps_total: 1175050
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2585 s, 47 iter, 1175050 ts, 20 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-52-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.439344766860415
  episode_reward_mean: 19.193501190031217
  episode_reward_min: -6.263143793898631
  episodes_this_iter: 55
  episodes_total: 2648
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.99153137207031
        mean_q: 6.035674095153809
        min_q: -10.899458885192871
    learner_queue:
      size_count: 63326
      size_mean: 0.0
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      size_std: 0.0
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1200050
    num_steps_trained: 9179136
    num_target_updates: 182
    num_weight_syncs: 2999
    replay_shard_0:
      add_batch_time_ms: 6.632
      policy_default_policy:
        added_count: 301800
        est_size_bytes: 102913800
        num_entries: 301800
        sampled_count: 2304000
      replay_time_ms: 160.481
      update_priorities_time_ms: 407.87
    sample_throughput: 221.789
    train_throughput: 0.0
  iterations_since_restore: 48
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.9943571366522883
    mean_inference_ms: 4.1104272552603645
    mean_processing_ms: 0.8120058307205028
  time_since_restore: 2647.7476699352264
  time_this_iter_s: 62.43536996841431
  time_total_s: 2647.7476699352264
  timestamp: 1563213142
  timesteps_since_restore: 1200050
  timesteps_this_iter: 25000
  timesteps_total: 1200050
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2647 s, 48 iter, 1200050 ts, 19.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-53-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.461986181776695
  episode_reward_mean: 19.37685395527104
  episode_reward_min: -0.6745814323028352
  episodes_this_iter: 56
  episodes_total: 2704
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.350486755371094
        mean_q: 6.199825763702393
        min_q: -22.735671997070312
    learner_queue:
      size_count: 63723
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1225050
    num_steps_trained: 9382912
    num_target_updates: 186
    num_weight_syncs: 3061
    replay_shard_0:
      add_batch_time_ms: 10.29
      policy_default_policy:
        added_count: 307900
        est_size_bytes: 104993900
        num_entries: 307900
        sampled_count: 2355200
      replay_time_ms: 100.506
      update_priorities_time_ms: 221.992
    sample_throughput: 1329.154
    train_throughput: 0.0
  iterations_since_restore: 49
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.001135563882596
    mean_inference_ms: 4.121688722295839
    mean_processing_ms: 0.815560456076966
  time_since_restore: 2710.0273649692535
  time_this_iter_s: 62.2796950340271
  time_total_s: 2710.0273649692535
  timestamp: 1563213205
  timesteps_since_restore: 1225050
  timesteps_this_iter: 25000
  timesteps_total: 1225050
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2710 s, 49 iter, 1225050 ts, 19.4 rew

[2m[36m(pid=73987)[0m 2019-07-15 19:54:24,262	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-54-24
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.461986181776695
  episode_reward_mean: 20.33478471845513
  episode_reward_min: 1.513446776458172
  episodes_this_iter: 56
  episodes_total: 2760
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 33.53124179626694
    episode_reward_mean: 19.88844867467196
    episode_reward_min: 1.4641997915618188
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.559002072527498
      mean_inference_ms: 1.5733737626528568
      mean_processing_ms: 0.7012606779666867
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.93379592895508
        mean_q: 5.1227946281433105
        min_q: -30.829313278198242
    learner_queue:
      size_count: 64128
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1250050
    num_steps_trained: 9590272
    num_target_updates: 190
    num_weight_syncs: 3123
    replay_shard_0:
      add_batch_time_ms: 8.255
      policy_default_policy:
        added_count: 314800
        est_size_bytes: 107346800
        num_entries: 314800
        sampled_count: 2406912
      replay_time_ms: 72.931
      update_priorities_time_ms: 234.802
    sample_throughput: 1533.763
    train_throughput: 15705.729
  iterations_since_restore: 50
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0045313847806798
    mean_inference_ms: 4.129311885850375
    mean_processing_ms: 0.8204700987393645
  time_since_restore: 2768.934638977051
  time_this_iter_s: 58.90727400779724
  time_total_s: 2768.934638977051
  timestamp: 1563213264
  timesteps_since_restore: 1250050
  timesteps_this_iter: 25000
  timesteps_total: 1250050
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2768 s, 50 iter, 1250050 ts, 20.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-55-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.41923717025752
  episode_reward_mean: 20.16557918530936
  episode_reward_min: 1.3645784479209437
  episodes_this_iter: 56
  episodes_total: 2816
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.506534576416016
        mean_q: 6.116917610168457
        min_q: -9.130998611450195
    learner_queue:
      size_count: 64530
      size_mean: 0.12
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 1.0
      size_std: 0.32496153618543844
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1275050
    num_steps_trained: 9796096
    num_target_updates: 194
    num_weight_syncs: 3186
    replay_shard_0:
      add_batch_time_ms: 6.171
      policy_default_policy:
        added_count: 321400
        est_size_bytes: 109597400
        num_entries: 321400
        sampled_count: 2458624
      replay_time_ms: 118.583
      update_priorities_time_ms: 310.377
    sample_throughput: 2039.595
    train_throughput: 0.0
  iterations_since_restore: 51
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.006591926909811
    mean_inference_ms: 4.1366730819432105
    mean_processing_ms: 0.8253718309187933
  time_since_restore: 2831.728869199753
  time_this_iter_s: 62.794230222702026
  time_total_s: 2831.728869199753
  timestamp: 1563213329
  timesteps_since_restore: 1275050
  timesteps_this_iter: 25000
  timesteps_total: 1275050
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2831 s, 51 iter, 1275050 ts, 20.2 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-56-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.86715808942521
  episode_reward_mean: 20.27313460417332
  episode_reward_min: -1.0788028720101193
  episodes_this_iter: 55
  episodes_total: 2871
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.96717834472656
        mean_q: 5.876543045043945
        min_q: -8.331846237182617
    learner_queue:
      size_count: 64941
      size_mean: 0.1
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.10000000000000142
      - 1.0
      size_std: 0.3
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1300050
    num_steps_trained: 10006528
    num_target_updates: 199
    num_weight_syncs: 3248
    replay_shard_0:
      add_batch_time_ms: 5.546
      policy_default_policy:
        added_count: 327050
        est_size_bytes: 111524050
        num_entries: 327050
        sampled_count: 2511360
      replay_time_ms: 128.019
      update_priorities_time_ms: 305.303
    sample_throughput: 453.901
    train_throughput: 4647.941
  iterations_since_restore: 52
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0097775191921567
    mean_inference_ms: 4.153088801565799
    mean_processing_ms: 0.831572593615038
  time_since_restore: 2902.1569521427155
  time_this_iter_s: 70.42808294296265
  time_total_s: 2902.1569521427155
  timestamp: 1563213399
  timesteps_since_restore: 1300050
  timesteps_this_iter: 25000
  timesteps_total: 1300050
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2902 s, 52 iter, 1300050 ts, 20.3 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-57-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.86715808942521
  episode_reward_mean: 18.74934442361388
  episode_reward_min: -1.0788028720101193
  episodes_this_iter: 56
  episodes_total: 2927
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.8807430267334
        mean_q: 5.565756797790527
        min_q: -4.349078178405762
    learner_queue:
      size_count: 65372
      size_mean: 4.86
      size_quantiles:
      - 0.0
      - 0.0
      - 5.0
      - 10.0
      - 12.0
      size_std: 3.805312076558242
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1325050
    num_steps_trained: 10226688
    num_target_updates: 203
    num_weight_syncs: 3311
    replay_shard_0:
      add_batch_time_ms: 5.226
      policy_default_policy:
        added_count: 332700
        est_size_bytes: 113450700
        num_entries: 332700
        sampled_count: 2567168
      replay_time_ms: 140.882
      update_priorities_time_ms: 75.69
    sample_throughput: 2059.767
    train_throughput: 0.0
  iterations_since_restore: 53
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0143523307939475
    mean_inference_ms: 4.171821316622506
    mean_processing_ms: 0.838555285216042
  time_since_restore: 2971.5756390094757
  time_this_iter_s: 69.41868686676025
  time_total_s: 2971.5756390094757
  timestamp: 1563213468
  timesteps_since_restore: 1325050
  timesteps_this_iter: 25000
  timesteps_total: 1325050
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 2971 s, 53 iter, 1325050 ts, 18.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_19-58-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.94232134111837
  episode_reward_mean: 19.351258998054067
  episode_reward_min: 0.022328711645801566
  episodes_this_iter: 56
  episodes_total: 2983
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 31.630027770996094
        mean_q: 5.426261901855469
        min_q: -12.205948829650879
    learner_queue:
      size_count: 65800
      size_mean: 2.02
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 8.100000000000001
      - 13.0
      size_std: 3.624858617932567
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1350050
    num_steps_trained: 10446336
    num_target_updates: 207
    num_weight_syncs: 3374
    replay_shard_0:
      add_batch_time_ms: 7.603
      policy_default_policy:
        added_count: 338400
        est_size_bytes: 115394400
        num_entries: 338400
        sampled_count: 2626560
      replay_time_ms: 147.19
      update_priorities_time_ms: 262.795
    sample_throughput: 1896.622
    train_throughput: 0.0
  iterations_since_restore: 54
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0196707977313926
    mean_inference_ms: 4.187207024529841
    mean_processing_ms: 0.8417889243431627
  time_since_restore: 3039.3268191814423
  time_this_iter_s: 67.75118017196655
  time_total_s: 3039.3268191814423
  timestamp: 1563213536
  timesteps_since_restore: 1350050
  timesteps_this_iter: 25000
  timesteps_total: 1350050
  training_iteration: 54
  2019-07-15 20:07:23,549	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_DDPG_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-15 20:07:23,563	WARNING util.py:64 -- The `process_trial` operation took 0.20394182205200195 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3039 s, 54 iter, 1350050 ts, 19.4 rew

[2m[36m(pid=73987)[0m 2019-07-15 20:00:10,033	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-00-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.94232134111837
  episode_reward_mean: 19.976247955085647
  episode_reward_min: 0.022328711645801566
  episodes_this_iter: 55
  episodes_total: 3038
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 29.120918334306506
    episode_reward_mean: 18.653287397406462
    episode_reward_min: 9.84779148528164
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.5602714227481747
      mean_inference_ms: 1.5804695557252637
      mean_processing_ms: 0.6808606553531993
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.40406799316406
        mean_q: 5.933420181274414
        min_q: -26.662750244140625
    learner_queue:
      size_count: 66213
      size_mean: 0.04
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.19595917942265428
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1375050
    num_steps_trained: 10657792
    num_target_updates: 211
    num_weight_syncs: 3436
    replay_shard_0:
      add_batch_time_ms: 5.952
      policy_default_policy:
        added_count: 343900
        est_size_bytes: 117269900
        num_entries: 343900
        sampled_count: 2679808
      replay_time_ms: 244.902
      update_priorities_time_ms: 390.756
    sample_throughput: 2723.609
    train_throughput: 0.0
  iterations_since_restore: 55
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0266653669465553
    mean_inference_ms: 4.203095188258344
    mean_processing_ms: 0.8441189242033991
  time_since_restore: 3112.6059262752533
  time_this_iter_s: 73.27910709381104
  time_total_s: 3112.6059262752533
  timestamp: 1563213610
  timesteps_since_restore: 1375050
  timesteps_this_iter: 25000
  timesteps_total: 1375050
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3112 s, 55 iter, 1375050 ts, 20 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-01-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.6298580473319
  episode_reward_mean: 20.43689109328362
  episode_reward_min: -3.873042262027995
  episodes_this_iter: 57
  episodes_total: 3095
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 36.95677947998047
        mean_q: 6.142406940460205
        min_q: -5.590577602386475
    learner_queue:
      size_count: 66630
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1400050
    num_steps_trained: 10871296
    num_target_updates: 216
    num_weight_syncs: 3499
    replay_shard_0:
      add_batch_time_ms: 7.334
      policy_default_policy:
        added_count: 350450
        est_size_bytes: 119503450
        num_entries: 350450
        sampled_count: 2733056
      replay_time_ms: 137.938
      update_priorities_time_ms: 372.808
    sample_throughput: 1734.258
    train_throughput: 0.0
  iterations_since_restore: 56
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0330482576143263
    mean_inference_ms: 4.218484962045427
    mean_processing_ms: 0.8465899817251167
  time_since_restore: 3177.7498421669006
  time_this_iter_s: 65.14391589164734
  time_total_s: 3177.7498421669006
  timestamp: 1563213679
  timesteps_since_restore: 1400050
  timesteps_this_iter: 25000
  timesteps_total: 1400050
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.2/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3177 s, 56 iter, 1400050 ts, 20.4 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-02-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.6298580473319
  episode_reward_mean: 18.763765429107753
  episode_reward_min: -3.873042262027995
  episodes_this_iter: 55
  episodes_total: 3150
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 37.37792205810547
        mean_q: 5.37298583984375
        min_q: -27.381298065185547
    learner_queue:
      size_count: 67040
      size_mean: 0.16
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      - 2.0
      size_std: 0.41761226035642196
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1425050
    num_steps_trained: 11081216
    num_target_updates: 220
    num_weight_syncs: 3562
    replay_shard_0:
      add_batch_time_ms: 8.402
      policy_default_policy:
        added_count: 357250
        est_size_bytes: 121822250
        num_entries: 357250
        sampled_count: 2785792
      replay_time_ms: 122.184
      update_priorities_time_ms: 310.27
    sample_throughput: 2002.991
    train_throughput: 0.0
  iterations_since_restore: 57
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.038967646962545
    mean_inference_ms: 4.234038146418725
    mean_processing_ms: 0.8492841159277319
  time_since_restore: 3246.4488122463226
  time_this_iter_s: 68.698970079422
  time_total_s: 3246.4488122463226
  timestamp: 1563213748
  timesteps_since_restore: 1425050
  timesteps_this_iter: 25000
  timesteps_total: 1425050
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3246 s, 57 iter, 1425050 ts, 18.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-03-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.246672270838836
  episode_reward_mean: 17.730532585634457
  episode_reward_min: -15.197858149950582
  episodes_this_iter: 55
  episodes_total: 3205
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 34.37527084350586
        mean_q: 5.071316719055176
        min_q: -8.103991508483887
    learner_queue:
      size_count: 67453
      size_mean: 0.06
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.23748684174075835
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1450050
    num_steps_trained: 11291648
    num_target_updates: 224
    num_weight_syncs: 3623
    replay_shard_0:
      add_batch_time_ms: 4.876
      policy_default_policy:
        added_count: 363550
        est_size_bytes: 123970550
        num_entries: 363550
        sampled_count: 2838528
      replay_time_ms: 158.48
      update_priorities_time_ms: 401.928
    sample_throughput: 429.744
    train_throughput: 0.0
  iterations_since_restore: 58
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.046175759928771
    mean_inference_ms: 4.251204102912884
    mean_processing_ms: 0.8539164305830971
  time_since_restore: 3318.1995241642
  time_this_iter_s: 71.7507119178772
  time_total_s: 3318.1995241642
  timestamp: 1563213819
  timesteps_since_restore: 1450050
  timesteps_this_iter: 25000
  timesteps_total: 1450050
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3318 s, 58 iter, 1450050 ts, 17.7 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-04-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.246672270838836
  episode_reward_mean: 19.720711229850103
  episode_reward_min: -15.197858149950582
  episodes_this_iter: 56
  episodes_total: 3261
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 33.5789794921875
        mean_q: 5.009153366088867
        min_q: -11.613922119140625
    learner_queue:
      size_count: 67850
      size_mean: 0.08
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.2712931993250107
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1475050
    num_steps_trained: 11495936
    num_target_updates: 228
    num_weight_syncs: 3686
    replay_shard_0:
      add_batch_time_ms: 7.902
      policy_default_policy:
        added_count: 368900
        est_size_bytes: 125794900
        num_entries: 368900
        sampled_count: 2891264
      replay_time_ms: 158.428
      update_priorities_time_ms: 358.684
    sample_throughput: 1547.634
    train_throughput: 0.0
  iterations_since_restore: 59
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0504779054433602
    mean_inference_ms: 4.266401723797426
    mean_processing_ms: 0.8576691763343663
  time_since_restore: 3388.3112499713898
  time_this_iter_s: 70.11172580718994
  time_total_s: 3388.3112499713898
  timestamp: 1563213889
  timesteps_since_restore: 1475050
  timesteps_this_iter: 25000
  timesteps_total: 1475050
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3388 s, 59 iter, 1475050 ts, 19.7 rew

[2m[36m(pid=73987)[0m 2019-07-15 20:06:12,990	INFO trainer.py:507 -- Evaluating current policy for 10 episodes
Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-06-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.02863105635928
  episode_reward_mean: 20.779332829159003
  episode_reward_min: -5.0502497227317855
  episodes_this_iter: 56
  episodes_total: 3317
  evaluation:
    custom_metrics: {}
    episode_len_mean: 150.0
    episode_reward_max: 35.42416436966996
    episode_reward_mean: 18.85523270670031
    episode_reward_min: 0.09013935297378915
    episodes_this_iter: 10
    num_metric_batches_dropped: 0
    off_policy_estimator: {}
    policy_reward_mean: {}
    sampler_perf:
      mean_env_wait_ms: 0.551731450381288
      mean_inference_ms: 1.5585565192902016
      mean_processing_ms: 0.6572055141777022
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.04396438598633
        mean_q: 5.017416954040527
        min_q: -12.019206047058105
    learner_queue:
      size_count: 68240
      size_mean: 0.02
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 0.0
      - 1.0
      size_std: 0.13999999999999999
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1500050
    num_steps_trained: 11695616
    num_target_updates: 232
    num_weight_syncs: 3749
    replay_shard_0:
      add_batch_time_ms: 5.52
      policy_default_policy:
        added_count: 374800
        est_size_bytes: 127806800
        num_entries: 374800
        sampled_count: 2941952
      replay_time_ms: 197.442
      update_priorities_time_ms: 340.601
    sample_throughput: 2212.092
    train_throughput: 0.0
  iterations_since_restore: 60
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0537573978791464
    mean_inference_ms: 4.283056783399509
    mean_processing_ms: 0.8637587167498336
  time_since_restore: 3471.3406438827515
  time_this_iter_s: 83.0293939113617
  time_total_s: 3471.3406438827515
  timestamp: 1563213972
  timesteps_since_restore: 1500050
  timesteps_this_iter: 25000
  timesteps_total: 1500050
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	RUNNING, [4 CPUs, 0 GPUs], [pid=73987], 3471 s, 60 iter, 1500050 ts, 20.8 rew

Result for APEX_DDPG_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-15_20-07-23
  done: true
  episode_len_mean: 150.0
  episode_reward_max: 38.647991280711324
  episode_reward_mean: 21.036591081607767
  episode_reward_min: 0.35743129309003613
  episodes_this_iter: 55
  episodes_total: 3372
  experiment_id: 9440f3628ea5420fba633e6367590177
  hostname: KayidmacOS
  info:
    learner:
      default_policy:
        max_q: 32.466888427734375
        mean_q: 4.905846118927002
        min_q: -16.603425979614258
    learner_queue:
      size_count: 68639
      size_mean: 1.34
      size_quantiles:
      - 0.0
      - 0.0
      - 0.0
      - 5.0
      - 8.0
      size_std: 2.1504418150696383
    max_exploration: 0.4
    min_exploration: 0.0
    num_samples_dropped: 716
    num_steps_sampled: 1525050
    num_steps_trained: 11899904
    num_target_updates: 236
    num_weight_syncs: 3812
    replay_shard_0:
      add_batch_time_ms: 8.322
      policy_default_policy:
        added_count: 380650
        est_size_bytes: 129801650
        num_entries: 380650
        sampled_count: 2995712
      replay_time_ms: 221.481
      update_priorities_time_ms: 268.376
    sample_throughput: 521.449
    train_throughput: 5339.635
  iterations_since_restore: 61
  node_ip: 192.168.0.3
  num_healthy_workers: 3
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 73987
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 1.0568383775913242
    mean_inference_ms: 4.297919302628071
    mean_processing_ms: 0.8706386868103254
  time_since_restore: 3538.4328966140747
  time_this_iter_s: 67.09225273132324
  time_total_s: 3538.4328966140747
  timestamp: 1563214043
  timesteps_since_restore: 1525050
  timesteps_this_iter: 25000
  timesteps_total: 1525050
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	TERMINATED, [4 CPUs, 0 GPUs], [pid=73987], 3538 s, 61 iter, 1525050 ts, 21 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.4/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/local/gym-reacher-apex-ddpg
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - APEX_DDPG_RoboschoolReacher-v1_0:	TERMINATED, [4 CPUs, 0 GPUs], [pid=73987], 3538 s, 61 iter, 1525050 ts, 21 rew

[32m [  3615.43639s,  INFO] Experiment took 3615.36955 seconds | 60.25616 minutes | 1.00427 hours [0m

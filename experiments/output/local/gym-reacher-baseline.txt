2019-07-22 00:56:32,782	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-22_00-56-32_781836_31782/logs.
2019-07-22 00:56:32,886	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-22 00:56:32,999	WARNING services.py:763 -- Redis failed to start, retrying now.
2019-07-22 00:56:33,113	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:59673 to respond...
2019-07-22 00:56:33,233	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:37562 to respond...
2019-07-22 00:56:33,237	INFO services.py:806 -- Starting Redis shard with 3.33 GB max memory.
2019-07-22 00:56:33,266	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-22_00-56-32_781836_31782/logs.
2019-07-22 00:56:33,266	INFO services.py:1446 -- Starting the Plasma object store with 5.0 GB memory using /dev/shm.
2019-07-22 00:56:33,342	INFO tune.py:65 -- Did not find checkpoint file in /home/amr/kayray_results/local/gym-reacher-ppo-baseline.
2019-07-22 00:56:33,342	INFO tune.py:233 -- Starting a new experiment.
2019-07-22 00:56:33,355	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-22 00:56:33,497	WARNING util.py:64 -- The `start_trial` operation took 0.147416353225708 seconds to complete, which may be a performance bottleneck.
[32m [     0.20865s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.20895s,  INFO] Experiment configs: 
 {
  "gym-reacher-ppo-baseline": {
    "env": "RoboschoolReacher-v1",
    "run": "PPO",
    "local_dir": "~/kayray_results/local",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "episode_reward_mean": 21,
      "timesteps_total": 10000000
    },
    "config": {
      "env_config": {
        "env_type": "openai"
      },
      "gamma": 0.995,
      "kl_coeff": 1.0,
      "num_sgd_iter": 20,
      "lr": 0.0001,
      "sgd_minibatch_size": 1000,
      "train_batch_size": 25000,
      "model": {
        "free_log_std": true
      },
      "num_gpus": 0,
      "num_workers": 0,
      "batch_mode": "complete_episodes",
      "observation_filter": "MeanStdFilter"
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 1.1/16.7 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 1.1/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,293	WARNING ppo.py:151 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,295	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35.295877: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=31829)[0m [32m [     0.01567s,  INFO] TimeLimit:
[2m[36m(pid=31829)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=31829)[0m - action_space = Box(2,)
[2m[36m(pid=31829)[0m - observation_space = Box(9,)
[2m[36m(pid=31829)[0m - reward_range = (-inf, inf)
[2m[36m(pid=31829)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=31829)[0m - _max_episode_steps = 150
[2m[36m(pid=31829)[0m - _elapsed_steps = None [0m
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,382	INFO dynamic_tf_policy.py:313 -- Initializing loss function with dummy input:
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=31829)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=31829)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=31829)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=31829)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=31829)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=31829)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m /home/amr/anaconda3/envs/kayray/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=31829)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,911	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x7f1074ba45f8>}
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,911	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x7f10751ca198>}
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,911	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': MeanStdFilter((9,), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}
[2m[36m(pid=31829)[0m 2019-07-22 00:56:35,913	INFO multi_gpu_optimizer.py:79 -- LocalMultiGPUOptimizer devices ['/cpu:0']
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,337	INFO rollout_worker.py:428 -- Generating sample batch of size 200
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,343	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.675, max=0.947, mean=0.107)}}
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,343	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,343	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.675, max=0.947, mean=0.107)
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,343	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=0.0, max=0.0, mean=0.0)
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,344	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=31829)[0m                                   'env_id': 0,
[2m[36m(pid=31829)[0m                                   'info': None,
[2m[36m(pid=31829)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=31829)[0m                                   'rnn_state': []},
[2m[36m(pid=31829)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,344	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,368	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-1.046, max=-0.281, mean=-0.664),
[2m[36m(pid=31829)[0m                       [],
[2m[36m(pid=31829)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.089, max=0.089, mean=0.089),
[2m[36m(pid=31829)[0m                         'behaviour_logits': np.ndarray((1, 4), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,469	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((150,), dtype=float32, min=0.0, max=0.159, mean=0.074),
[2m[36m(pid=31829)[0m                         'actions': np.ndarray((150, 2), dtype=float32, min=-3.372, max=3.972, mean=-0.0),
[2m[36m(pid=31829)[0m                         'advantages': np.ndarray((150,), dtype=float32, min=-25.466, max=11.887, mean=-5.257),
[2m[36m(pid=31829)[0m                         'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m                         'behaviour_logits': np.ndarray((150, 4), dtype=float32, min=-0.009, max=0.013, mean=0.001),
[2m[36m(pid=31829)[0m                         'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=31829)[0m                         'eps_id': np.ndarray((150,), dtype=int64, min=1876925959.0, max=1876925959.0, mean=1876925959.0),
[2m[36m(pid=31829)[0m                         'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=31829)[0m                         'new_obs': np.ndarray((150, 9), dtype=float32, min=-3.684, max=3.705, mean=0.111),
[2m[36m(pid=31829)[0m                         'obs': np.ndarray((150, 9), dtype=float32, min=-3.684, max=3.705, mean=0.109),
[2m[36m(pid=31829)[0m                         'prev_actions': np.ndarray((150, 2), dtype=float32, min=-3.372, max=3.972, mean=0.003),
[2m[36m(pid=31829)[0m                         'prev_rewards': np.ndarray((150,), dtype=float32, min=-3.032, max=2.682, mean=-0.128),
[2m[36m(pid=31829)[0m                         'rewards': np.ndarray((150,), dtype=float32, min=-3.032, max=2.682, mean=-0.129),
[2m[36m(pid=31829)[0m                         't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=31829)[0m                         'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m                         'value_targets': np.ndarray((150,), dtype=float32, min=-25.464, max=11.886, mean=-5.257),
[2m[36m(pid=31829)[0m                         'vf_preds': np.ndarray((150,), dtype=float32, min=-0.01, max=0.005, mean=-0.001)},
[2m[36m(pid=31829)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m 2019-07-22 00:56:37,576	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'data': { 'action_prob': np.ndarray((300,), dtype=float32, min=0.0, max=0.159, mean=0.08),
[2m[36m(pid=31829)[0m             'actions': np.ndarray((300, 2), dtype=float32, min=-3.372, max=3.972, mean=0.001),
[2m[36m(pid=31829)[0m             'advantages': np.ndarray((300,), dtype=float32, min=-25.466, max=11.887, mean=-9.796),
[2m[36m(pid=31829)[0m             'agent_index': np.ndarray((300,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=31829)[0m             'behaviour_logits': np.ndarray((300, 4), dtype=float32, min=-0.013, max=0.014, mean=0.0),
[2m[36m(pid=31829)[0m             'dones': np.ndarray((300,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=31829)[0m             'eps_id': np.ndarray((300,), dtype=int64, min=178999698.0, max=1876925959.0, mean=1027962828.5),
[2m[36m(pid=31829)[0m             'infos': np.ndarray((300,), dtype=object, head={}),
[2m[36m(pid=31829)[0m             'new_obs': np.ndarray((300, 9), dtype=float32, min=-8.661, max=8.661, mean=0.03),
[2m[36m(pid=31829)[0m             'obs': np.ndarray((300, 9), dtype=float32, min=-12.248, max=12.248, mean=0.028),
[2m[36m(pid=31829)[0m             'prev_actions': np.ndarray((300, 2), dtype=float32, min=-3.372, max=3.972, mean=0.003),
[2m[36m(pid=31829)[0m             'prev_rewards': np.ndarray((300,), dtype=float32, min=-3.117, max=4.3, mean=-0.178),
[2m[36m(pid=31829)[0m             'rewards': np.ndarray((300,), dtype=float32, min=-3.117, max=4.3, mean=-0.174),
[2m[36m(pid=31829)[0m             't': np.ndarray((300,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=31829)[0m             'unroll_id': np.ndarray((300,), dtype=int64, min=0.0, max=1.0, mean=0.5),
[2m[36m(pid=31829)[0m             'value_targets': np.ndarray((300,), dtype=float32, min=-25.464, max=11.886, mean=-9.797),
[2m[36m(pid=31829)[0m             'vf_preds': np.ndarray((300,), dtype=float32, min=-0.01, max=0.005, mean=-0.001)},
[2m[36m(pid=31829)[0m   'type': 'SampleBatch'}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m 2019-07-22 00:56:55,129	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m { 'inputs': [ np.ndarray((25200, 2), dtype=float32, min=-4.326, max=4.228, mean=-0.003),
[2m[36m(pid=31829)[0m               np.ndarray((25200,), dtype=float32, min=-5.757, max=6.523, mean=-0.102),
[2m[36m(pid=31829)[0m               np.ndarray((25200, 9), dtype=float32, min=-12.248, max=12.248, mean=-0.013),
[2m[36m(pid=31829)[0m               np.ndarray((25200, 2), dtype=float32, min=-4.326, max=4.228, mean=-0.003),
[2m[36m(pid=31829)[0m               np.ndarray((25200,), dtype=float32, min=-3.564, max=3.783, mean=-0.0),
[2m[36m(pid=31829)[0m               np.ndarray((25200, 4), dtype=float32, min=-0.016, max=0.016, mean=-0.0),
[2m[36m(pid=31829)[0m               np.ndarray((25200,), dtype=float32, min=-43.078, max=32.448, mean=-6.438),
[2m[36m(pid=31829)[0m               np.ndarray((25200,), dtype=float32, min=-0.01, max=0.01, mean=0.0)],
[2m[36m(pid=31829)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=31829)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=31829)[0m   'state_inputs': []}
[2m[36m(pid=31829)[0m 
[2m[36m(pid=31829)[0m 2019-07-22 00:56:55,129	INFO multi_gpu_impl.py:191 -- Divided 25200 rollout sequences, each of length 1, among 1 devices.
Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-56-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 23.025761044017585
  episode_reward_mean: -15.384808766571123
  episode_reward_min: -56.883641230298856
  episodes_this_iter: 168
  episodes_total: 168
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4022.339
    learner:
      default_policy:
        cur_kl_coeff: 1.0
        cur_lr: 9.999999747378752e-05
        entropy: 2.837611436843872
        kl: 0.0010658659739419818
        policy_loss: -0.0036960330326110125
        total_loss: 93.99359130859375
        vf_explained_var: 0.14469939470291138
        vf_loss: 93.99622344970703
    load_time_ms: 19.516
    num_steps_sampled: 25200
    num_steps_trained: 25000
    sample_time_ms: 17786.343
    update_time_ms: 0.002
  iterations_since_restore: 1
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14152666305881664
    mean_inference_ms: 0.4336977850789613
    mean_processing_ms: 0.1234755828822304
  time_since_restore: 21.85423707962036
  time_this_iter_s: 21.85423707962036
  time_total_s: 21.85423707962036
  timestamp: 1563749819
  timesteps_since_restore: 25200
  timesteps_this_iter: 25200
  timesteps_total: 25200
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 1.7/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 21 s, 1 iter, 25200 ts, -15.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-57-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 19.785861645450908
  episode_reward_mean: -13.301506404793486
  episode_reward_min: -54.318645802172085
  episodes_this_iter: 168
  episodes_total: 336
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 3875.383
    learner:
      default_policy:
        cur_kl_coeff: 0.5
        cur_lr: 9.999999747378752e-05
        entropy: 2.83487606048584
        kl: 0.0034021828323602676
        policy_loss: -0.005334812216460705
        total_loss: 70.0938491821289
        vf_explained_var: 0.29681092500686646
        vf_loss: 70.09748840332031
    load_time_ms: 10.145
    num_steps_sampled: 50400
    num_steps_trained: 50000
    sample_time_ms: 18801.489
    update_time_ms: 0.003
  iterations_since_restore: 2
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1470199149458307
    mean_inference_ms: 0.4644422965760161
    mean_processing_ms: 0.12832641488032095
  time_since_restore: 45.40713453292847
  time_this_iter_s: 23.552897453308105
  time_total_s: 45.40713453292847
  timestamp: 1563749842
  timesteps_since_restore: 50400
  timesteps_this_iter: 25200
  timesteps_total: 50400
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 45 s, 2 iter, 50400 ts, -13.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-57-44
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 14.116524084906194
  episode_reward_mean: -14.402652423123568
  episode_reward_min: -57.81428925031664
  episodes_this_iter: 168
  episodes_total: 504
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4034.933
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.8313350677490234
        kl: 0.004409048706293106
        policy_loss: -0.005371693521738052
        total_loss: 61.29804611206055
        vf_explained_var: 0.38150328397750854
        vf_loss: 61.30232238769531
    load_time_ms: 7.014
    num_steps_sampled: 75600
    num_steps_trained: 75000
    sample_time_ms: 18477.931
    update_time_ms: 0.002
  iterations_since_restore: 3
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14545912748985104
    mean_inference_ms: 0.4551199822464884
    mean_processing_ms: 0.1267430088548149
  time_since_restore: 67.60007309913635
  time_this_iter_s: 22.192938566207886
  time_total_s: 67.60007309913635
  timestamp: 1563749864
  timesteps_since_restore: 75600
  timesteps_this_iter: 25200
  timesteps_total: 75600
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 67 s, 3 iter, 75600 ts, -14.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-58-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 24.63201206004697
  episode_reward_mean: -12.742943508254685
  episode_reward_min: -55.42256607030437
  episodes_this_iter: 168
  episodes_total: 672
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4249.69
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.818638324737549
        kl: 0.006865321192890406
        policy_loss: -0.007800546940416098
        total_loss: 58.70438003540039
        vf_explained_var: 0.359559565782547
        vf_loss: 58.71132278442383
    load_time_ms: 5.456
    num_steps_sampled: 100800
    num_steps_trained: 100000
    sample_time_ms: 18276.008
    update_time_ms: 0.002
  iterations_since_restore: 4
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14430087179956977
    mean_inference_ms: 0.44950533395243963
    mean_processing_ms: 0.12569482079978583
  time_since_restore: 90.17274117469788
  time_this_iter_s: 22.572668075561523
  time_total_s: 90.17274117469788
  timestamp: 1563749887
  timesteps_since_restore: 100800
  timesteps_this_iter: 25200
  timesteps_total: 100800
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 90 s, 4 iter, 100800 ts, -12.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-58-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 19.248466919449278
  episode_reward_mean: -11.41107307446318
  episode_reward_min: -46.02264770873381
  episodes_this_iter: 168
  episodes_total: 840
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4421.87
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.8063669204711914
        kl: 0.0077140009962022305
        policy_loss: -0.007718312554061413
        total_loss: 52.08719253540039
        vf_explained_var: 0.3574114143848419
        vf_loss: 52.09394073486328
    load_time_ms: 4.512
    num_steps_sampled: 126000
    num_steps_trained: 125000
    sample_time_ms: 18158.513
    update_time_ms: 0.002
  iterations_since_restore: 5
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14383730756404955
    mean_inference_ms: 0.4458019074396035
    mean_processing_ms: 0.12531135651057887
  time_since_restore: 112.98069286346436
  time_this_iter_s: 22.80795168876648
  time_total_s: 112.98069286346436
  timestamp: 1563749910
  timesteps_since_restore: 126000
  timesteps_this_iter: 25200
  timesteps_total: 126000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 112 s, 5 iter, 126000 ts, -11.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-58-52
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 17.15196722986118
  episode_reward_mean: -9.366304781780324
  episode_reward_min: -40.904789993817914
  episodes_this_iter: 168
  episodes_total: 1008
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4342.287
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7907700538635254
        kl: 0.0070053404197096825
        policy_loss: -0.008402821607887745
        total_loss: 39.033592224121094
        vf_explained_var: 0.3996419906616211
        vf_loss: 39.04112243652344
    load_time_ms: 3.886
    num_steps_sampled: 151200
    num_steps_trained: 150000
    sample_time_ms: 18098.275
    update_time_ms: 0.002
  iterations_since_restore: 6
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1436263899753618
    mean_inference_ms: 0.4438894927068445
    mean_processing_ms: 0.12511006620565554
  time_since_restore: 134.7302052974701
  time_this_iter_s: 21.749512434005737
  time_total_s: 134.7302052974701
  timestamp: 1563749932
  timesteps_since_restore: 151200
  timesteps_this_iter: 25200
  timesteps_total: 151200
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 134 s, 6 iter, 151200 ts, -9.37 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-59-14
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 26.188376924650346
  episode_reward_mean: -9.010646905991731
  episode_reward_min: -31.968348553448315
  episodes_this_iter: 168
  episodes_total: 1176
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4451.277
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7851028442382812
        kl: 0.007916031405329704
        policy_loss: -0.00825595110654831
        total_loss: 30.751161575317383
        vf_explained_var: 0.4384823143482208
        vf_loss: 30.7584285736084
    load_time_ms: 3.44
    num_steps_sampled: 176400
    num_steps_trained: 175000
    sample_time_ms: 18032.286
    update_time_ms: 0.002
  iterations_since_restore: 7
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14317710852633933
    mean_inference_ms: 0.4421439145346763
    mean_processing_ms: 0.1247368780874791
  time_since_restore: 157.48064708709717
  time_this_iter_s: 22.750441789627075
  time_total_s: 157.48064708709717
  timestamp: 1563749954
  timesteps_since_restore: 176400
  timesteps_this_iter: 25200
  timesteps_total: 176400
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 157 s, 7 iter, 176400 ts, -9.01 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-59-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 22.665506549576868
  episode_reward_mean: -4.623254313489723
  episode_reward_min: -38.51680958223618
  episodes_this_iter: 168
  episodes_total: 1344
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4533.776
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.778134346008301
        kl: 0.007561780046671629
        policy_loss: -0.008388676680624485
        total_loss: 23.923070907592773
        vf_explained_var: 0.4720350503921509
        vf_loss: 23.930517196655273
    load_time_ms: 3.098
    num_steps_sampled: 201600
    num_steps_trained: 200000
    sample_time_ms: 18008.543
    update_time_ms: 0.002
  iterations_since_restore: 8
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14301269910787792
    mean_inference_ms: 0.4415370205322767
    mean_processing_ms: 0.12460655442569742
  time_since_restore: 180.4433925151825
  time_this_iter_s: 22.962745428085327
  time_total_s: 180.4433925151825
  timestamp: 1563749977
  timesteps_since_restore: 201600
  timesteps_this_iter: 25200
  timesteps_total: 201600
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 180 s, 8 iter, 201600 ts, -4.62 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_00-59-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 23.446762297949576
  episode_reward_mean: -5.0091660525702615
  episode_reward_min: -31.712830434040427
  episodes_this_iter: 168
  episodes_total: 1512
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4484.022
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7668912410736084
        kl: 0.008581562899053097
        policy_loss: -0.008532613515853882
        total_loss: 19.87641143798828
        vf_explained_var: 0.5486514568328857
        vf_loss: 19.883872985839844
    load_time_ms: 2.833
    num_steps_sampled: 226800
    num_steps_trained: 225000
    sample_time_ms: 17968.478
    update_time_ms: 0.002
  iterations_since_restore: 9
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1427458006245723
    mean_inference_ms: 0.4404733447180102
    mean_processing_ms: 0.12437861465932519
  time_since_restore: 202.1855549812317
  time_this_iter_s: 21.742162466049194
  time_total_s: 202.1855549812317
  timestamp: 1563749999
  timesteps_since_restore: 226800
  timesteps_this_iter: 25200
  timesteps_total: 226800
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 202 s, 9 iter, 226800 ts, -5.01 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-00-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 20.0691092734153
  episode_reward_mean: -4.542026426551452
  episode_reward_min: -36.54299313047073
  episodes_this_iter: 168
  episodes_total: 1680
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4445.825
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7536067962646484
        kl: 0.0074290321208536625
        policy_loss: -0.010394478216767311
        total_loss: 21.892040252685547
        vf_explained_var: 0.5558788776397705
        vf_loss: 21.901506423950195
    load_time_ms: 2.63
    num_steps_sampled: 252000
    num_steps_trained: 250000
    sample_time_ms: 17946.542
    update_time_ms: 0.002
  iterations_since_restore: 10
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1426111742100844
    mean_inference_ms: 0.4398682458616977
    mean_processing_ms: 0.12426727611419389
  time_since_restore: 224.0458071231842
  time_this_iter_s: 21.860252141952515
  time_total_s: 224.0458071231842
  timestamp: 1563750021
  timesteps_since_restore: 252000
  timesteps_this_iter: 25200
  timesteps_total: 252000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 224 s, 10 iter, 252000 ts, -4.54 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-00-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 26.77476037048389
  episode_reward_mean: -3.192124077445588
  episode_reward_min: -28.45416290242674
  episodes_this_iter: 168
  episodes_total: 1848
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4424.99
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7461163997650146
        kl: 0.006296057254076004
        policy_loss: -0.00865345448255539
        total_loss: 18.373777389526367
        vf_explained_var: 0.6108589768409729
        vf_loss: 18.38164520263672
    load_time_ms: 0.759
    num_steps_sampled: 277200
    num_steps_trained: 275000
    sample_time_ms: 17940.994
    update_time_ms: 0.002
  iterations_since_restore: 11
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14244760831491826
    mean_inference_ms: 0.4394046319368724
    mean_processing_ms: 0.12413812520267034
  time_since_restore: 245.5986201763153
  time_this_iter_s: 21.552813053131104
  time_total_s: 245.5986201763153
  timestamp: 1563750043
  timesteps_since_restore: 277200
  timesteps_this_iter: 25200
  timesteps_total: 277200
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 245 s, 11 iter, 277200 ts, -3.19 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-01-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 19.467461992186752
  episode_reward_mean: -1.705293019640538
  episode_reward_min: -30.335865408613454
  episodes_this_iter: 168
  episodes_total: 2016
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4541.106
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7386934757232666
        kl: 0.008897069841623306
        policy_loss: -0.010143935680389404
        total_loss: 15.312042236328125
        vf_explained_var: 0.6335920691490173
        vf_loss: 15.321074485778809
    load_time_ms: 0.752
    num_steps_sampled: 302400
    num_steps_trained: 300000
    sample_time_ms: 17733.923
    update_time_ms: 0.002
  iterations_since_restore: 12
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1423262020587932
    mean_inference_ms: 0.4390272053354289
    mean_processing_ms: 0.124059753644781
  time_since_restore: 268.24274158477783
  time_this_iter_s: 22.644121408462524
  time_total_s: 268.24274158477783
  timestamp: 1563750065
  timesteps_since_restore: 302400
  timesteps_this_iter: 25200
  timesteps_total: 302400
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 268 s, 12 iter, 302400 ts, -1.71 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-01-27
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 28.685661649815522
  episode_reward_mean: -0.08471989762902983
  episode_reward_min: -31.148354742444003
  episodes_this_iter: 168
  episodes_total: 2184
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4527.289
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.729696750640869
        kl: 0.008036335930228233
        policy_loss: -0.009567680768668652
        total_loss: 16.476490020751953
        vf_explained_var: 0.6746843457221985
        vf_loss: 16.48505401611328
    load_time_ms: 0.759
    num_steps_sampled: 327600
    num_steps_trained: 325000
    sample_time_ms: 17748.777
    update_time_ms: 0.002
  iterations_since_restore: 13
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14237251098805712
    mean_inference_ms: 0.4391477054736133
    mean_processing_ms: 0.12410875892911054
  time_since_restore: 290.44649505615234
  time_this_iter_s: 22.20375347137451
  time_total_s: 290.44649505615234
  timestamp: 1563750087
  timesteps_since_restore: 327600
  timesteps_this_iter: 25200
  timesteps_total: 327600
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 290 s, 13 iter, 327600 ts, -0.0847 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-01-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 28.401862587606054
  episode_reward_mean: 0.8105470861866996
  episode_reward_min: -26.724471896107858
  episodes_this_iter: 168
  episodes_total: 2352
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4421.718
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.7144789695739746
        kl: 0.008312231861054897
        policy_loss: -0.010925313457846642
        total_loss: 16.496822357177734
        vf_explained_var: 0.6792222857475281
        vf_loss: 16.5067081451416
    load_time_ms: 0.76
    num_steps_sampled: 352800
    num_steps_trained: 350000
    sample_time_ms: 17754.222
    update_time_ms: 0.002
  iterations_since_restore: 14
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14228161380651727
    mean_inference_ms: 0.4387631023647595
    mean_processing_ms: 0.12404935545073362
  time_since_restore: 312.01756954193115
  time_this_iter_s: 21.57107448577881
  time_total_s: 312.01756954193115
  timestamp: 1563750109
  timesteps_since_restore: 352800
  timesteps_this_iter: 25200
  timesteps_total: 352800
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 312 s, 14 iter, 352800 ts, 0.811 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-02-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 28.146677610819097
  episode_reward_mean: 3.439101221569535
  episode_reward_min: -27.32169611830169
  episodes_this_iter: 168
  episodes_total: 2520
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4421.221
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.702676773071289
        kl: 0.009437079541385174
        policy_loss: -0.01205353531986475
        total_loss: 14.766595840454102
        vf_explained_var: 0.7051349878311157
        vf_loss: 14.777470588684082
    load_time_ms: 0.783
    num_steps_sampled: 378000
    num_steps_trained: 375000
    sample_time_ms: 17768.583
    update_time_ms: 0.002
  iterations_since_restore: 15
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1422385856639337
    mean_inference_ms: 0.43860578559315316
    mean_processing_ms: 0.1240674835180212
  time_since_restore: 334.96572279930115
  time_this_iter_s: 22.948153257369995
  time_total_s: 334.96572279930115
  timestamp: 1563750132
  timesteps_since_restore: 378000
  timesteps_this_iter: 25200
  timesteps_total: 378000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 334 s, 15 iter, 378000 ts, 3.44 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-02-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.126846995624366
  episode_reward_mean: 5.419195655233898
  episode_reward_min: -26.048926727185318
  episodes_this_iter: 168
  episodes_total: 2688
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4537.717
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.685206890106201
        kl: 0.008477049879729748
        policy_loss: -0.009948044084012508
        total_loss: 13.150609970092773
        vf_explained_var: 0.7220467329025269
        vf_loss: 13.15949821472168
    load_time_ms: 0.782
    num_steps_sampled: 403200
    num_steps_trained: 400000
    sample_time_ms: 17761.379
    update_time_ms: 0.002
  iterations_since_restore: 16
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14217445814721968
    mean_inference_ms: 0.4382836284767682
    mean_processing_ms: 0.12403309508891638
  time_since_restore: 357.8088002204895
  time_this_iter_s: 22.843077421188354
  time_total_s: 357.8088002204895
  timestamp: 1563750155
  timesteps_since_restore: 403200
  timesteps_this_iter: 25200
  timesteps_total: 403200
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 357 s, 16 iter, 403200 ts, 5.42 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-02-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 28.890568049360454
  episode_reward_mean: 6.855210067213453
  episode_reward_min: -13.790700942334041
  episodes_this_iter: 168
  episodes_total: 2856
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4541.63
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.6747498512268066
        kl: 0.007423068396747112
        policy_loss: -0.009956277906894684
        total_loss: 9.998435974121094
        vf_explained_var: 0.7636840343475342
        vf_loss: 10.007465362548828
    load_time_ms: 0.778
    num_steps_sampled: 428400
    num_steps_trained: 425000
    sample_time_ms: 17767.557
    update_time_ms: 0.002
  iterations_since_restore: 17
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14212884036345774
    mean_inference_ms: 0.43791154089087103
    mean_processing_ms: 0.12401626882436652
  time_since_restore: 380.6600706577301
  time_this_iter_s: 22.8512704372406
  time_total_s: 380.6600706577301
  timestamp: 1563750178
  timesteps_since_restore: 428400
  timesteps_this_iter: 25200
  timesteps_total: 428400
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 380 s, 17 iter, 428400 ts, 6.86 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-03-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.94716271507818
  episode_reward_mean: 7.575696833546439
  episode_reward_min: -19.491062731476184
  episodes_this_iter: 168
  episodes_total: 3024
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4544.155
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.6645658016204834
        kl: 0.008441840298473835
        policy_loss: -0.012346174567937851
        total_loss: 7.364132881164551
        vf_explained_var: 0.8248276710510254
        vf_loss: 7.375423431396484
    load_time_ms: 0.78
    num_steps_sampled: 453600
    num_steps_trained: 450000
    sample_time_ms: 17752.132
    update_time_ms: 0.002
  iterations_since_restore: 18
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14209355575089666
    mean_inference_ms: 0.43754736045962483
    mean_processing_ms: 0.12400864286505417
  time_since_restore: 403.4936578273773
  time_this_iter_s: 22.833587169647217
  time_total_s: 403.4936578273773
  timestamp: 1563750200
  timesteps_since_restore: 453600
  timesteps_this_iter: 25200
  timesteps_total: 453600
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 403 s, 18 iter, 453600 ts, 7.58 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-03-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.377294474302936
  episode_reward_mean: 8.124886116905213
  episode_reward_min: -25.287645221610813
  episodes_this_iter: 168
  episodes_total: 3192
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4648.3
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.6511871814727783
        kl: 0.008913763798773289
        policy_loss: -0.01235520001500845
        total_loss: 6.139726161956787
        vf_explained_var: 0.8550505042076111
        vf_loss: 6.150967597961426
    load_time_ms: 0.788
    num_steps_sampled: 478800
    num_steps_trained: 475000
    sample_time_ms: 17757.437
    update_time_ms: 0.002
  iterations_since_restore: 19
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14202768406907645
    mean_inference_ms: 0.4373030205508878
    mean_processing_ms: 0.123978859696558
  time_since_restore: 426.33099365234375
  time_this_iter_s: 22.83733582496643
  time_total_s: 426.33099365234375
  timestamp: 1563750223
  timesteps_since_restore: 478800
  timesteps_this_iter: 25200
  timesteps_total: 478800
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 426 s, 19 iter, 478800 ts, 8.12 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-04-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.20443572312926
  episode_reward_mean: 8.79769483337507
  episode_reward_min: -15.640194843297616
  episodes_this_iter: 168
  episodes_total: 3360
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4751.077
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.634173631668091
        kl: 0.008149810135364532
        policy_loss: -0.011580479331314564
        total_loss: 5.271044731140137
        vf_explained_var: 0.8685007691383362
        vf_loss: 5.281606674194336
    load_time_ms: 0.777
    num_steps_sampled: 504000
    num_steps_trained: 500000
    sample_time_ms: 17754.477
    update_time_ms: 0.002
  iterations_since_restore: 20
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14195066530352388
    mean_inference_ms: 0.4371442626790728
    mean_processing_ms: 0.12394786265397066
  time_since_restore: 449.18898129463196
  time_this_iter_s: 22.857987642288208
  time_total_s: 449.18898129463196
  timestamp: 1563750246
  timesteps_since_restore: 504000
  timesteps_this_iter: 25200
  timesteps_total: 504000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 449 s, 20 iter, 504000 ts, 8.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-04-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.456867231551985
  episode_reward_mean: 9.985763690589335
  episode_reward_min: -26.749888453562
  episodes_this_iter: 168
  episodes_total: 3528
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4789.963
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.624992609024048
        kl: 0.007958143949508667
        policy_loss: -0.012108133174479008
        total_loss: 4.416919231414795
        vf_explained_var: 0.8980010151863098
        vf_loss: 4.428032875061035
    load_time_ms: 0.771
    num_steps_sampled: 529200
    num_steps_trained: 525000
    sample_time_ms: 17760.22
    update_time_ms: 0.002
  iterations_since_restore: 21
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141912798210509
    mean_inference_ms: 0.4370878706536127
    mean_processing_ms: 0.12393015861837411
  time_since_restore: 471.18836736679077
  time_this_iter_s: 21.999386072158813
  time_total_s: 471.18836736679077
  timestamp: 1563750268
  timesteps_since_restore: 529200
  timesteps_this_iter: 25200
  timesteps_total: 529200
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 471 s, 21 iter, 529200 ts, 9.99 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-04-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.779226324865824
  episode_reward_mean: 8.244172789608724
  episode_reward_min: -17.141974925512727
  episodes_this_iter: 168
  episodes_total: 3696
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4719.767
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.6147654056549072
        kl: 0.008143909275531769
        policy_loss: -0.011085723526775837
        total_loss: 3.803834915161133
        vf_explained_var: 0.8916678428649902
        vf_loss: 3.8139023780822754
    load_time_ms: 0.777
    num_steps_sampled: 554400
    num_steps_trained: 550000
    sample_time_ms: 17771.168
    update_time_ms: 0.002
  iterations_since_restore: 22
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14192519237924528
    mean_inference_ms: 0.43706392907348635
    mean_processing_ms: 0.12395819160744789
  time_since_restore: 493.2399251461029
  time_this_iter_s: 22.051557779312134
  time_total_s: 493.2399251461029
  timestamp: 1563750290
  timesteps_since_restore: 554400
  timesteps_this_iter: 25200
  timesteps_total: 554400
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 493 s, 22 iter, 554400 ts, 8.24 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-05-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.11964368329912
  episode_reward_mean: 10.372053674398495
  episode_reward_min: -13.840341089425399
  episodes_this_iter: 168
  episodes_total: 3864
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4813.337
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.5976827144622803
        kl: 0.008677477017045021
        policy_loss: -0.012881777249276638
        total_loss: 3.4949257373809814
        vf_explained_var: 0.9105004668235779
        vf_loss: 3.506722927093506
    load_time_ms: 0.773
    num_steps_sampled: 579600
    num_steps_trained: 575000
    sample_time_ms: 17748.758
    update_time_ms: 0.002
  iterations_since_restore: 23
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14188862154448714
    mean_inference_ms: 0.4369566847287634
    mean_processing_ms: 0.12394626364849891
  time_since_restore: 516.1556489467621
  time_this_iter_s: 22.91572380065918
  time_total_s: 516.1556489467621
  timestamp: 1563750313
  timesteps_since_restore: 579600
  timesteps_this_iter: 25200
  timesteps_total: 579600
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 516 s, 23 iter, 579600 ts, 10.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-05-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.124702667433404
  episode_reward_mean: 10.982636441315805
  episode_reward_min: -16.67938921955912
  episodes_this_iter: 168
  episodes_total: 4032
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4812.434
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.592222213745117
        kl: 0.007781171705573797
        policy_loss: -0.011754533275961876
        total_loss: 2.8582348823547363
        vf_explained_var: 0.9178454875946045
        vf_loss: 2.869016647338867
    load_time_ms: 0.763
    num_steps_sampled: 604800
    num_steps_trained: 600000
    sample_time_ms: 17757.998
    update_time_ms: 0.002
  iterations_since_restore: 24
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14188790797516312
    mean_inference_ms: 0.43692251220509465
    mean_processing_ms: 0.12394173717320435
  time_since_restore: 537.809671163559
  time_this_iter_s: 21.654022216796875
  time_total_s: 537.809671163559
  timestamp: 1563750335
  timesteps_since_restore: 604800
  timesteps_this_iter: 25200
  timesteps_total: 604800
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 537 s, 24 iter, 604800 ts, 11 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-05-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.02659411142776
  episode_reward_mean: 11.307914386357359
  episode_reward_min: -8.319474890444917
  episodes_this_iter: 168
  episodes_total: 4200
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4815.336
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.5853819847106934
        kl: 0.007317402865737677
        policy_loss: -0.009842628613114357
        total_loss: 2.3409383296966553
        vf_explained_var: 0.940646231174469
        vf_loss: 2.3498663902282715
    load_time_ms: 0.747
    num_steps_sampled: 630000
    num_steps_trained: 625000
    sample_time_ms: 17752.699
    update_time_ms: 0.002
  iterations_since_restore: 25
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14186635773120163
    mean_inference_ms: 0.4368432384622127
    mean_processing_ms: 0.12394488506372878
  time_since_restore: 560.7325460910797
  time_this_iter_s: 22.922874927520752
  time_total_s: 560.7325460910797
  timestamp: 1563750358
  timesteps_since_restore: 630000
  timesteps_this_iter: 25200
  timesteps_total: 630000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 560 s, 25 iter, 630000 ts, 11.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-06-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.880879386082583
  episode_reward_mean: 11.585153847455459
  episode_reward_min: -12.381160916898368
  episodes_this_iter: 168
  episodes_total: 4368
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4679.649
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.567981481552124
        kl: 0.009472247213125229
        policy_loss: -0.01077944040298462
        total_loss: 1.8881635665893555
        vf_explained_var: 0.9504544734954834
        vf_loss: 1.897758960723877
    load_time_ms: 0.747
    num_steps_sampled: 655200
    num_steps_trained: 650000
    sample_time_ms: 17750.334
    update_time_ms: 0.002
  iterations_since_restore: 26
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14181214854712088
    mean_inference_ms: 0.43672381421423634
    mean_processing_ms: 0.12391153792225137
  time_since_restore: 582.1942102909088
  time_this_iter_s: 21.4616641998291
  time_total_s: 582.1942102909088
  timestamp: 1563750379
  timesteps_since_restore: 655200
  timesteps_this_iter: 25200
  timesteps_total: 655200
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 582 s, 26 iter, 655200 ts, 11.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-06-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.01002307893485
  episode_reward_mean: 11.551233539793271
  episode_reward_min: -8.76073446211746
  episodes_this_iter: 168
  episodes_total: 4536
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4549.511
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.5547423362731934
        kl: 0.008573471568524837
        policy_loss: -0.010530748404562473
        total_loss: 1.6962802410125732
        vf_explained_var: 0.9549993276596069
        vf_loss: 1.7057392597198486
    load_time_ms: 0.753
    num_steps_sampled: 680400
    num_steps_trained: 675000
    sample_time_ms: 17747.43
    update_time_ms: 0.002
  iterations_since_restore: 27
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14175515131267846
    mean_inference_ms: 0.436576060260374
    mean_processing_ms: 0.12387653767401809
  time_since_restore: 603.7140061855316
  time_this_iter_s: 21.519795894622803
  time_total_s: 603.7140061855316
  timestamp: 1563750401
  timesteps_since_restore: 680400
  timesteps_this_iter: 25200
  timesteps_total: 680400
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 603 s, 27 iter, 680400 ts, 11.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-07-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.913566707404414
  episode_reward_mean: 12.167095000274216
  episode_reward_min: -10.048074549352146
  episodes_this_iter: 168
  episodes_total: 4704
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4412.227
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.544457197189331
        kl: 0.008697464130818844
        policy_loss: -0.013624467886984348
        total_loss: 1.7054709196090698
        vf_explained_var: 0.9538149237632751
        vf_loss: 1.7180079221725464
    load_time_ms: 0.751
    num_steps_sampled: 705600
    num_steps_trained: 700000
    sample_time_ms: 17733.672
    update_time_ms: 0.002
  iterations_since_restore: 28
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1417017860408651
    mean_inference_ms: 0.43627803866192766
    mean_processing_ms: 0.1238373745016246
  time_since_restore: 625.035995721817
  time_this_iter_s: 21.3219895362854
  time_total_s: 625.035995721817
  timestamp: 1563750422
  timesteps_since_restore: 705600
  timesteps_this_iter: 25200
  timesteps_total: 705600
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 625 s, 28 iter, 705600 ts, 12.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-07-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.775512041930796
  episode_reward_mean: 13.569973313256826
  episode_reward_min: -14.777971499884258
  episodes_this_iter: 168
  episodes_total: 4872
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4413.744
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.536741018295288
        kl: 0.008997932076454163
        policy_loss: -0.01228108536452055
        total_loss: 1.1687389612197876
        vf_explained_var: 0.9695538282394409
        vf_loss: 1.179895281791687
    load_time_ms: 0.746
    num_steps_sampled: 730800
    num_steps_trained: 725000
    sample_time_ms: 17732.334
    update_time_ms: 0.002
  iterations_since_restore: 29
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14169780285302921
    mean_inference_ms: 0.43609005082474267
    mean_processing_ms: 0.12385085739977629
  time_since_restore: 647.8750288486481
  time_this_iter_s: 22.839033126831055
  time_total_s: 647.8750288486481
  timestamp: 1563750445
  timesteps_since_restore: 730800
  timesteps_this_iter: 25200
  timesteps_total: 730800
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 647 s, 29 iter, 730800 ts, 13.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-07-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.171797344403394
  episode_reward_mean: 11.956230917867853
  episode_reward_min: -10.661935935509666
  episodes_this_iter: 168
  episodes_total: 5040
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4340.894
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.5242249965667725
        kl: 0.010261261835694313
        policy_loss: -0.01140658836811781
        total_loss: 1.4487359523773193
        vf_explained_var: 0.9580605030059814
        vf_loss: 1.4588596820831299
    load_time_ms: 0.751
    num_steps_sampled: 756000
    num_steps_trained: 750000
    sample_time_ms: 17735.578
    update_time_ms: 0.002
  iterations_since_restore: 30
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14169361878131687
    mean_inference_ms: 0.4360006490336315
    mean_processing_ms: 0.12386370571768587
  time_since_restore: 670.0365188121796
  time_this_iter_s: 22.161489963531494
  time_total_s: 670.0365188121796
  timestamp: 1563750467
  timesteps_since_restore: 756000
  timesteps_this_iter: 25200
  timesteps_total: 756000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 670 s, 30 iter, 756000 ts, 12 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-08-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.72176171486093
  episode_reward_mean: 12.168256525759436
  episode_reward_min: -8.573610535566925
  episodes_this_iter: 168
  episodes_total: 5208
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4430.447
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.504267454147339
        kl: 0.008283864706754684
        policy_loss: -0.010760975070297718
        total_loss: 1.2117220163345337
        vf_explained_var: 0.9654810428619385
        vf_loss: 1.221447467803955
    load_time_ms: 0.754
    num_steps_sampled: 781200
    num_steps_trained: 775000
    sample_time_ms: 17733.067
    update_time_ms: 0.002
  iterations_since_restore: 31
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14167037970684018
    mean_inference_ms: 0.43597413812118513
    mean_processing_ms: 0.12385368027323687
  time_since_restore: 692.9069273471832
  time_this_iter_s: 22.870408535003662
  time_total_s: 692.9069273471832
  timestamp: 1563750490
  timesteps_since_restore: 781200
  timesteps_this_iter: 25200
  timesteps_total: 781200
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 692 s, 31 iter, 781200 ts, 12.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-08-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.4173982049628
  episode_reward_mean: 11.852809969301063
  episode_reward_min: -13.373736356976208
  episodes_this_iter: 168
  episodes_total: 5376
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4463.439
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.4939396381378174
        kl: 0.008278779685497284
        policy_loss: -0.012182128615677357
        total_loss: 1.0455615520477295
        vf_explained_var: 0.9695821404457092
        vf_loss: 1.056708812713623
    load_time_ms: 0.751
    num_steps_sampled: 806400
    num_steps_trained: 800000
    sample_time_ms: 17722.21
    update_time_ms: 0.002
  iterations_since_restore: 32
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14164253002244617
    mean_inference_ms: 0.4359453592841574
    mean_processing_ms: 0.12383466278979774
  time_since_restore: 715.1796016693115
  time_this_iter_s: 22.272674322128296
  time_total_s: 715.1796016693115
  timestamp: 1563750512
  timesteps_since_restore: 806400
  timesteps_this_iter: 25200
  timesteps_total: 806400
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 715 s, 32 iter, 806400 ts, 11.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-08-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.98215258491299
  episode_reward_mean: 14.996833766144267
  episode_reward_min: -7.4654122915039265
  episodes_this_iter: 168
  episodes_total: 5544
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4331.802
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.4821953773498535
        kl: 0.008706456981599331
        policy_loss: -0.012448136694729328
        total_loss: 0.9775674939155579
        vf_explained_var: 0.9772789478302002
        vf_loss: 0.9889274835586548
    load_time_ms: 0.747
    num_steps_sampled: 831600
    num_steps_trained: 825000
    sample_time_ms: 17730.755
    update_time_ms: 0.002
  iterations_since_restore: 33
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1416404689134729
    mean_inference_ms: 0.43598698914252526
    mean_processing_ms: 0.12383582805167806
  time_since_restore: 736.8634181022644
  time_this_iter_s: 21.68381643295288
  time_total_s: 736.8634181022644
  timestamp: 1563750534
  timesteps_since_restore: 831600
  timesteps_this_iter: 25200
  timesteps_total: 831600
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 736 s, 33 iter, 831600 ts, 15 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-09-16
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.18321757167604
  episode_reward_mean: 12.128385867091888
  episode_reward_min: -8.09767762964971
  episodes_this_iter: 168
  episodes_total: 5712
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4344.042
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.473794937133789
        kl: 0.0080169178545475
        policy_loss: -0.0101797329261899
        total_loss: 1.3425652980804443
        vf_explained_var: 0.9664840698242188
        vf_loss: 1.3517428636550903
    load_time_ms: 0.75
    num_steps_sampled: 856800
    num_steps_trained: 850000
    sample_time_ms: 17722.616
    update_time_ms: 0.002
  iterations_since_restore: 34
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14161451914332046
    mean_inference_ms: 0.4359368671189544
    mean_processing_ms: 0.12382831048854762
  time_since_restore: 758.5585277080536
  time_this_iter_s: 21.695109605789185
  time_total_s: 758.5585277080536
  timestamp: 1563750556
  timesteps_since_restore: 856800
  timesteps_this_iter: 25200
  timesteps_total: 856800
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 758 s, 34 iter, 856800 ts, 12.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-09-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.570965808090214
  episode_reward_mean: 12.567437283270273
  episode_reward_min: -8.508225677168847
  episodes_this_iter: 168
  episodes_total: 5880
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4212.957
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.458723783493042
        kl: 0.009227573871612549
        policy_loss: -0.01256282813847065
        total_loss: 0.8867043256759644
        vf_explained_var: 0.9763882160186768
        vf_loss: 0.8981137871742249
    load_time_ms: 0.747
    num_steps_sampled: 882000
    num_steps_trained: 875000
    sample_time_ms: 17708.914
    update_time_ms: 0.002
  iterations_since_restore: 35
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157076736403815
    mean_inference_ms: 0.4358204141054277
    mean_processing_ms: 0.1238029253815023
  time_since_restore: 780.0321674346924
  time_this_iter_s: 21.473639726638794
  time_total_s: 780.0321674346924
  timestamp: 1563750577
  timesteps_since_restore: 882000
  timesteps_this_iter: 25200
  timesteps_total: 882000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 780 s, 35 iter, 882000 ts, 12.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-09-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.71985737621523
  episode_reward_mean: 12.638135107719839
  episode_reward_min: -5.203617974060763
  episodes_this_iter: 168
  episodes_total: 6048
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4232.622
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.4450042247772217
        kl: 0.00875120423734188
        policy_loss: -0.01234553661197424
        total_loss: 0.8299347162246704
        vf_explained_var: 0.9767738580703735
        vf_loss: 0.8411862850189209
    load_time_ms: 0.752
    num_steps_sampled: 907200
    num_steps_trained: 900000
    sample_time_ms: 17728.92
    update_time_ms: 0.002
  iterations_since_restore: 36
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415868392964503
    mean_inference_ms: 0.435886007179863
    mean_processing_ms: 0.12383080075867199
  time_since_restore: 801.8906862735748
  time_this_iter_s: 21.858518838882446
  time_total_s: 801.8906862735748
  timestamp: 1563750599
  timesteps_since_restore: 907200
  timesteps_this_iter: 25200
  timesteps_total: 907200
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 801 s, 36 iter, 907200 ts, 12.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-10-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.52957285241517
  episode_reward_mean: 13.363501180776955
  episode_reward_min: -10.751356478295316
  episodes_this_iter: 168
  episodes_total: 6216
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4358.155
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.4339096546173096
        kl: 0.009375866502523422
        policy_loss: -0.0121949203312397
        total_loss: 0.9375125169754028
        vf_explained_var: 0.9764652848243713
        vf_loss: 0.9485353827476501
    load_time_ms: 0.751
    num_steps_sampled: 932400
    num_steps_trained: 925000
    sample_time_ms: 17754.499
    update_time_ms: 0.002
  iterations_since_restore: 37
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141606431122856
    mean_inference_ms: 0.43597105295165844
    mean_processing_ms: 0.12385514469677347
  time_since_restore: 824.9228827953339
  time_this_iter_s: 23.032196521759033
  time_total_s: 824.9228827953339
  timestamp: 1563750622
  timesteps_since_restore: 932400
  timesteps_this_iter: 25200
  timesteps_total: 932400
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 824 s, 37 iter, 932400 ts, 13.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-10-44
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.06293897592167
  episode_reward_mean: 12.775367342349014
  episode_reward_min: -8.983983763469658
  episodes_this_iter: 168
  episodes_total: 6384
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4361.735
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.425027370452881
        kl: 0.009540406055748463
        policy_loss: -0.01347433403134346
        total_loss: 0.7654415965080261
        vf_explained_var: 0.9793504476547241
        vf_loss: 0.777723491191864
    load_time_ms: 0.758
    num_steps_sampled: 957600
    num_steps_trained: 950000
    sample_time_ms: 17774.849
    update_time_ms: 0.002
  iterations_since_restore: 38
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1416039028836431
    mean_inference_ms: 0.4359117931225701
    mean_processing_ms: 0.12386096038950775
  time_since_restore: 846.484313249588
  time_this_iter_s: 21.56143045425415
  time_total_s: 846.484313249588
  timestamp: 1563750644
  timesteps_since_restore: 957600
  timesteps_this_iter: 25200
  timesteps_total: 957600
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 846 s, 38 iter, 957600 ts, 12.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-11-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.12722472580834
  episode_reward_mean: 13.410303771352083
  episode_reward_min: -7.141483660672043
  episodes_this_iter: 168
  episodes_total: 6552
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4357.161
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.416590690612793
        kl: 0.008035991340875626
        policy_loss: -0.01220053993165493
        total_loss: 0.826719343662262
        vf_explained_var: 0.9771502614021301
        vf_loss: 0.8379154205322266
    load_time_ms: 0.758
    num_steps_sampled: 982800
    num_steps_trained: 975000
    sample_time_ms: 17777.405
    update_time_ms: 0.002
  iterations_since_restore: 39
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14158957755858417
    mean_inference_ms: 0.43582930354296917
    mean_processing_ms: 0.12386419045229644
  time_since_restore: 869.3030943870544
  time_this_iter_s: 22.81878113746643
  time_total_s: 869.3030943870544
  timestamp: 1563750666
  timesteps_since_restore: 982800
  timesteps_this_iter: 25200
  timesteps_total: 982800
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 869 s, 39 iter, 982800 ts, 13.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-11-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.660169080401424
  episode_reward_mean: 13.841188831657917
  episode_reward_min: -6.163488618186918
  episodes_this_iter: 168
  episodes_total: 6720
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4311.298
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.4027512073516846
        kl: 0.010046372190117836
        policy_loss: -0.012995684519410133
        total_loss: 0.7471910119056702
        vf_explained_var: 0.979510486125946
        vf_loss: 0.7589309215545654
    load_time_ms: 0.758
    num_steps_sampled: 1008000
    num_steps_trained: 1000000
    sample_time_ms: 17767.7
    update_time_ms: 0.002
  iterations_since_restore: 40
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141576491931401
    mean_inference_ms: 0.4356889144267929
    mean_processing_ms: 0.12387028228914441
  time_since_restore: 890.9085969924927
  time_this_iter_s: 21.605502605438232
  time_total_s: 890.9085969924927
  timestamp: 1563750688
  timesteps_since_restore: 1008000
  timesteps_this_iter: 25200
  timesteps_total: 1008000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 890 s, 40 iter, 1008000 ts, 13.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-11-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.665201488999415
  episode_reward_mean: 13.40989190443293
  episode_reward_min: -8.402688722598983
  episodes_this_iter: 168
  episodes_total: 6888
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4312.752
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.3830955028533936
        kl: 0.009432355873286724
        policy_loss: -0.01255212351679802
        total_loss: 0.6969670057296753
        vf_explained_var: 0.9798135161399841
        vf_loss: 0.708340048789978
    load_time_ms: 0.753
    num_steps_sampled: 1033200
    num_steps_trained: 1025000
    sample_time_ms: 17768.36
    update_time_ms: 0.002
  iterations_since_restore: 41
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415821742977599
    mean_inference_ms: 0.43563545507385715
    mean_processing_ms: 0.12388835993898507
  time_since_restore: 913.7999722957611
  time_this_iter_s: 22.891375303268433
  time_total_s: 913.7999722957611
  timestamp: 1563750711
  timesteps_since_restore: 1033200
  timesteps_this_iter: 25200
  timesteps_total: 1033200
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 913 s, 41 iter, 1033200 ts, 13.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-12-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.392019794520678
  episode_reward_mean: 13.55530931338227
  episode_reward_min: -5.7443557074198
  episodes_this_iter: 168
  episodes_total: 7056
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4235.307
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.3725109100341797
        kl: 0.011280820704996586
        policy_loss: -0.012577617540955544
        total_loss: 0.7083232998847961
        vf_explained_var: 0.9780087471008301
        vf_loss: 0.7194908261299133
    load_time_ms: 0.749
    num_steps_sampled: 1058400
    num_steps_trained: 1050000
    sample_time_ms: 17775.67
    update_time_ms: 0.002
  iterations_since_restore: 42
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14159364993006096
    mean_inference_ms: 0.4356326001356435
    mean_processing_ms: 0.12389962597663332
  time_since_restore: 935.3707008361816
  time_this_iter_s: 21.570728540420532
  time_total_s: 935.3707008361816
  timestamp: 1563750733
  timesteps_since_restore: 1058400
  timesteps_this_iter: 25200
  timesteps_total: 1058400
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 935 s, 42 iter, 1058400 ts, 13.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-12-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.96429130771667
  episode_reward_mean: 13.581432061190023
  episode_reward_min: -7.29076629287187
  episodes_this_iter: 168
  episodes_total: 7224
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4363.852
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.3584210872650146
        kl: 0.010569112375378609
        policy_loss: -0.01497775036841631
        total_loss: 0.6571347117424011
        vf_explained_var: 0.9805250763893127
        vf_loss: 0.6707913279533386
    load_time_ms: 0.752
    num_steps_sampled: 1083600
    num_steps_trained: 1075000
    sample_time_ms: 17763.715
    update_time_ms: 0.002
  iterations_since_restore: 43
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415732132633627
    mean_inference_ms: 0.4355904454455449
    mean_processing_ms: 0.12389015173794139
  time_since_restore: 958.2214567661285
  time_this_iter_s: 22.8507559299469
  time_total_s: 958.2214567661285
  timestamp: 1563750755
  timesteps_since_restore: 1083600
  timesteps_this_iter: 25200
  timesteps_total: 1083600
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 958 s, 43 iter, 1083600 ts, 13.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-12-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.157123710107335
  episode_reward_mean: 13.949362881699198
  episode_reward_min: -7.7975003129301035
  episodes_this_iter: 168
  episodes_total: 7392
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4343.203
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.340273380279541
        kl: 0.010253277607262135
        policy_loss: -0.014718578197062016
        total_loss: 0.5984034538269043
        vf_explained_var: 0.983242392539978
        vf_loss: 0.6118404269218445
    load_time_ms: 0.754
    num_steps_sampled: 1108800
    num_steps_trained: 1100000
    sample_time_ms: 17771.885
    update_time_ms: 0.002
  iterations_since_restore: 44
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415729030730676
    mean_inference_ms: 0.43560219446473425
    mean_processing_ms: 0.12389686981898528
  time_since_restore: 979.7918968200684
  time_this_iter_s: 21.57044005393982
  time_total_s: 979.7918968200684
  timestamp: 1563750777
  timesteps_since_restore: 1108800
  timesteps_this_iter: 25200
  timesteps_total: 1108800
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 979 s, 44 iter, 1108800 ts, 13.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-13-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.552414127580185
  episode_reward_mean: 14.58581515510339
  episode_reward_min: -13.48445213120669
  episodes_this_iter: 168
  episodes_total: 7560
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4367.502
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.3233580589294434
        kl: 0.010668568313121796
        policy_loss: -0.014669597148895264
        total_loss: 0.609327495098114
        vf_explained_var: 0.982210099697113
        vf_loss: 0.6226634383201599
    load_time_ms: 0.751
    num_steps_sampled: 1134000
    num_steps_trained: 1125000
    sample_time_ms: 17764.392
    update_time_ms: 0.002
  iterations_since_restore: 45
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415245979557198
    mean_inference_ms: 0.4354825870182661
    mean_processing_ms: 0.12386278300517321
  time_since_restore: 1001.4339535236359
  time_this_iter_s: 21.642056703567505
  time_total_s: 1001.4339535236359
  timestamp: 1563750799
  timesteps_since_restore: 1134000
  timesteps_this_iter: 25200
  timesteps_total: 1134000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1001 s, 45 iter, 1134000 ts, 14.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-13-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.73979755277041
  episode_reward_mean: 13.257718881574089
  episode_reward_min: -10.871657824413623
  episodes_this_iter: 168
  episodes_total: 7728
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4477.851
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.307852029800415
        kl: 0.010713365860283375
        policy_loss: -0.014244580641388893
        total_loss: 0.5580649375915527
        vf_explained_var: 0.9806067943572998
        vf_loss: 0.570970356464386
    load_time_ms: 0.747
    num_steps_sampled: 1159200
    num_steps_trained: 1150000
    sample_time_ms: 17742.58
    update_time_ms: 0.002
  iterations_since_restore: 46
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14149870078415464
    mean_inference_ms: 0.4354313206534188
    mean_processing_ms: 0.12384617315305778
  time_since_restore: 1024.1783254146576
  time_this_iter_s: 22.74437189102173
  time_total_s: 1024.1783254146576
  timestamp: 1563750821
  timesteps_since_restore: 1159200
  timesteps_this_iter: 25200
  timesteps_total: 1159200
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1024 s, 46 iter, 1159200 ts, 13.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-14-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.60079468291751
  episode_reward_mean: 14.677660211667828
  episode_reward_min: -6.409909833092964
  episodes_this_iter: 168
  episodes_total: 7896
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4404.278
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2893757820129395
        kl: 0.010309288278222084
        policy_loss: -0.01452438160777092
        total_loss: 0.48560795187950134
        vf_explained_var: 0.9862422943115234
        vf_loss: 0.4988437294960022
    load_time_ms: 0.744
    num_steps_sampled: 1184400
    num_steps_trained: 1175000
    sample_time_ms: 17723.492
    update_time_ms: 0.002
  iterations_since_restore: 47
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147874444111913
    mean_inference_ms: 0.435411925202731
    mean_processing_ms: 0.12383876290175234
  time_since_restore: 1046.283239364624
  time_this_iter_s: 22.10491394996643
  time_total_s: 1046.283239364624
  timestamp: 1563750844
  timesteps_since_restore: 1184400
  timesteps_this_iter: 25200
  timesteps_total: 1184400
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1046 s, 47 iter, 1184400 ts, 14.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-14-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.74976463694175
  episode_reward_mean: 13.648119192688476
  episode_reward_min: -6.381388630504594
  episodes_this_iter: 168
  episodes_total: 8064
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4457.846
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2707157135009766
        kl: 0.010090917348861694
        policy_loss: -0.01584479957818985
        total_loss: 0.5308338403701782
        vf_explained_var: 0.9828929901123047
        vf_loss: 0.545417308807373
    load_time_ms: 0.737
    num_steps_sampled: 1209600
    num_steps_trained: 1200000
    sample_time_ms: 17723.239
    update_time_ms: 0.002
  iterations_since_restore: 48
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145976349844427
    mean_inference_ms: 0.43541265774714333
    mean_processing_ms: 0.12382595186596095
  time_since_restore: 1068.3781187534332
  time_this_iter_s: 22.094879388809204
  time_total_s: 1068.3781187534332
  timestamp: 1563750866
  timesteps_since_restore: 1209600
  timesteps_this_iter: 25200
  timesteps_total: 1209600
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1068 s, 48 iter, 1209600 ts, 13.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-14-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.60168942836026
  episode_reward_mean: 13.072575364947966
  episode_reward_min: -9.346059605416874
  episodes_this_iter: 168
  episodes_total: 8232
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4384.583
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2538437843322754
        kl: 0.010034075938165188
        policy_loss: -0.014938180334866047
        total_loss: 0.5113598704338074
        vf_explained_var: 0.9824273586273193
        vf_loss: 0.525043785572052
    load_time_ms: 0.738
    num_steps_sampled: 1234800
    num_steps_trained: 1225000
    sample_time_ms: 17742.818
    update_time_ms: 0.002
  iterations_since_restore: 49
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414775662257052
    mean_inference_ms: 0.4354679656938108
    mean_processing_ms: 0.12384998333726752
  time_since_restore: 1090.6597485542297
  time_this_iter_s: 22.28162980079651
  time_total_s: 1090.6597485542297
  timestamp: 1563750888
  timesteps_since_restore: 1234800
  timesteps_this_iter: 25200
  timesteps_total: 1234800
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1090 s, 49 iter, 1234800 ts, 13.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-15-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.44350745268811
  episode_reward_mean: 14.828613607996068
  episode_reward_min: -6.589452917079625
  episodes_this_iter: 168
  episodes_total: 8400
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4481.067
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2389721870422363
        kl: 0.011016210541129112
        policy_loss: -0.01478556264191866
        total_loss: 0.4660160541534424
        vf_explained_var: 0.9859763979911804
        vf_loss: 0.4794245958328247
    load_time_ms: 0.739
    num_steps_sampled: 1260000
    num_steps_trained: 1250000
    sample_time_ms: 17752.613
    update_time_ms: 0.002
  iterations_since_restore: 50
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147048595023062
    mean_inference_ms: 0.4354438254977448
    mean_processing_ms: 0.12385127062459222
  time_since_restore: 1113.328652381897
  time_this_iter_s: 22.668903827667236
  time_total_s: 1113.328652381897
  timestamp: 1563750911
  timesteps_since_restore: 1260000
  timesteps_this_iter: 25200
  timesteps_total: 1260000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1113 s, 50 iter, 1260000 ts, 14.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-15-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.67826634679428
  episode_reward_mean: 16.6070527291134
  episode_reward_min: -4.329110471922695
  episodes_this_iter: 168
  episodes_total: 8568
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4344.979
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2338809967041016
        kl: 0.010140782222151756
        policy_loss: -0.014422047883272171
        total_loss: 0.4334591329097748
        vf_explained_var: 0.9892292022705078
        vf_loss: 0.446613609790802
    load_time_ms: 0.736
    num_steps_sampled: 1285200
    num_steps_trained: 1275000
    sample_time_ms: 17743.673
    update_time_ms: 0.002
  iterations_since_restore: 51
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146335572044788
    mean_inference_ms: 0.43535806068926336
    mean_processing_ms: 0.12385850573412956
  time_since_restore: 1134.7688829898834
  time_this_iter_s: 21.44023060798645
  time_total_s: 1134.7688829898834
  timestamp: 1563750932
  timesteps_since_restore: 1285200
  timesteps_this_iter: 25200
  timesteps_total: 1285200
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1134 s, 51 iter, 1285200 ts, 16.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-15-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.33132672099157
  episode_reward_mean: 13.893146632838274
  episode_reward_min: -11.017785401358022
  episodes_this_iter: 168
  episodes_total: 8736
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4409.111
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.2176947593688965
        kl: 0.011151847429573536
        policy_loss: -0.01465550996363163
        total_loss: 0.4672022759914398
        vf_explained_var: 0.9856835007667542
        vf_loss: 0.48046380281448364
    load_time_ms: 0.737
    num_steps_sampled: 1310400
    num_steps_trained: 1300000
    sample_time_ms: 17731.264
    update_time_ms: 0.002
  iterations_since_restore: 52
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414604233356296
    mean_inference_ms: 0.4352841609574322
    mean_processing_ms: 0.1238650078943255
  time_since_restore: 1156.8573927879333
  time_this_iter_s: 22.088509798049927
  time_total_s: 1156.8573927879333
  timestamp: 1563750954
  timesteps_since_restore: 1310400
  timesteps_this_iter: 25200
  timesteps_total: 1310400
  training_iteration: 52
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1156 s, 52 iter, 1310400 ts, 13.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-16-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.14514973737555
  episode_reward_mean: 13.737218380778142
  episode_reward_min: -6.7812877671110074
  episodes_this_iter: 168
  episodes_total: 8904
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4409.356
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.206569194793701
        kl: 0.010590363293886185
        policy_loss: -0.015152870677411556
        total_loss: 0.4032648205757141
        vf_explained_var: 0.9875823259353638
        vf_loss: 0.4170938730239868
    load_time_ms: 0.733
    num_steps_sampled: 1335600
    num_steps_trained: 1325000
    sample_time_ms: 17737.169
    update_time_ms: 0.002
  iterations_since_restore: 53
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146325252985695
    mean_inference_ms: 0.4352648862586307
    mean_processing_ms: 0.12387650700311512
  time_since_restore: 1179.7694294452667
  time_this_iter_s: 22.912036657333374
  time_total_s: 1179.7694294452667
  timestamp: 1563750977
  timesteps_since_restore: 1335600
  timesteps_this_iter: 25200
  timesteps_total: 1335600
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1179 s, 53 iter, 1335600 ts, 13.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-16-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.57464894404629
  episode_reward_mean: 14.149949857572839
  episode_reward_min: -3.855618382580851
  episodes_this_iter: 168
  episodes_total: 9072
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4442.808
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.1975672245025635
        kl: 0.011392639949917793
        policy_loss: -0.015853075310587883
        total_loss: 0.41299450397491455
        vf_explained_var: 0.9879515171051025
        vf_loss: 0.42742347717285156
    load_time_ms: 0.736
    num_steps_sampled: 1360800
    num_steps_trained: 1350000
    sample_time_ms: 17730.354
    update_time_ms: 0.002
  iterations_since_restore: 54
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414451924188679
    mean_inference_ms: 0.4352662311311447
    mean_processing_ms: 0.12386674453923764
  time_since_restore: 1201.6064286231995
  time_this_iter_s: 21.83699917793274
  time_total_s: 1201.6064286231995
  timestamp: 1563750999
  timesteps_since_restore: 1360800
  timesteps_this_iter: 25200
  timesteps_total: 1360800
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1201 s, 54 iter, 1360800 ts, 14.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-17-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.39586492082753
  episode_reward_mean: 14.120924399429354
  episode_reward_min: -3.871959855569276
  episodes_this_iter: 168
  episodes_total: 9240
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4505.97
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.181715488433838
        kl: 0.012270020321011543
        policy_loss: -0.015160931274294853
        total_loss: 0.44487637281417847
        vf_explained_var: 0.9858165979385376
        vf_loss: 0.4585035741329193
    load_time_ms: 0.736
    num_steps_sampled: 1386000
    num_steps_trained: 1375000
    sample_time_ms: 17742.925
    update_time_ms: 0.002
  iterations_since_restore: 55
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14142854867485052
    mean_inference_ms: 0.43522224101937923
    mean_processing_ms: 0.12386133754888078
  time_since_restore: 1224.0063190460205
  time_this_iter_s: 22.399890422821045
  time_total_s: 1224.0063190460205
  timestamp: 1563751021
  timesteps_since_restore: 1386000
  timesteps_this_iter: 25200
  timesteps_total: 1386000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1224 s, 55 iter, 1386000 ts, 14.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-17-24
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.38411162133324
  episode_reward_mean: 13.129133562858224
  episode_reward_min: -4.8609077282095505
  episodes_this_iter: 168
  episodes_total: 9408
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4512.311
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.1648483276367188
        kl: 0.011759405955672264
        policy_loss: -0.014165555126965046
        total_loss: 0.40389472246170044
        vf_explained_var: 0.9847061038017273
        vf_loss: 0.41659030318260193
    load_time_ms: 0.734
    num_steps_sampled: 1411200
    num_steps_trained: 1400000
    sample_time_ms: 17755.958
    update_time_ms: 0.002
  iterations_since_restore: 56
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414250203711091
    mean_inference_ms: 0.4352413600172015
    mean_processing_ms: 0.12386637792071581
  time_since_restore: 1246.9447858333588
  time_this_iter_s: 22.938466787338257
  time_total_s: 1246.9447858333588
  timestamp: 1563751044
  timesteps_since_restore: 1411200
  timesteps_this_iter: 25200
  timesteps_total: 1411200
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1246 s, 56 iter, 1411200 ts, 13.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-17-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.06522251226341
  episode_reward_mean: 13.432372444664344
  episode_reward_min: -4.327100497111246
  episodes_this_iter: 168
  episodes_total: 9576
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4513.436
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.1432032585144043
        kl: 0.01206922996789217
        policy_loss: -0.01784846931695938
        total_loss: 0.3562018871307373
        vf_explained_var: 0.9871948957443237
        vf_loss: 0.3725416958332062
    load_time_ms: 0.743
    num_steps_sampled: 1436400
    num_steps_trained: 1425000
    sample_time_ms: 17761.878
    update_time_ms: 0.002
  iterations_since_restore: 57
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414234650873658
    mean_inference_ms: 0.4352425042483813
    mean_processing_ms: 0.1238728320554924
  time_since_restore: 1269.1200768947601
  time_this_iter_s: 22.175291061401367
  time_total_s: 1269.1200768947601
  timestamp: 1563751066
  timesteps_since_restore: 1436400
  timesteps_this_iter: 25200
  timesteps_total: 1436400
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1269 s, 57 iter, 1436400 ts, 13.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-18-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.95336895411014
  episode_reward_mean: 15.518051181927794
  episode_reward_min: -5.038333265548759
  episodes_this_iter: 168
  episodes_total: 9744
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4593.671
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.1296815872192383
        kl: 0.012891411781311035
        policy_loss: -0.015886692330241203
        total_loss: 0.35194528102874756
        vf_explained_var: 0.9900110363960266
        vf_loss: 0.3662205636501312
    load_time_ms: 0.75
    num_steps_sampled: 1461600
    num_steps_trained: 1450000
    sample_time_ms: 17770.148
    update_time_ms: 0.002
  iterations_since_restore: 58
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414314432412878
    mean_inference_ms: 0.43525336483218313
    mean_processing_ms: 0.12388740990982414
  time_since_restore: 1292.100839138031
  time_this_iter_s: 22.980762243270874
  time_total_s: 1292.100839138031
  timestamp: 1563751089
  timesteps_since_restore: 1461600
  timesteps_this_iter: 25200
  timesteps_total: 1461600
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1292 s, 58 iter, 1461600 ts, 15.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-18-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.80602844331742
  episode_reward_mean: 15.034111944290435
  episode_reward_min: -5.419304924852222
  episodes_this_iter: 168
  episodes_total: 9912
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4593.439
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.112912893295288
        kl: 0.012568676844239235
        policy_loss: -0.015043255873024464
        total_loss: 0.3136537969112396
        vf_explained_var: 0.9905359148979187
        vf_loss: 0.3271259665489197
    load_time_ms: 0.747
    num_steps_sampled: 1486800
    num_steps_trained: 1475000
    sample_time_ms: 17765.893
    update_time_ms: 0.002
  iterations_since_restore: 59
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14143994295149384
    mean_inference_ms: 0.43528359717701004
    mean_processing_ms: 0.12390244403440323
  time_since_restore: 1314.3377141952515
  time_this_iter_s: 22.23687505722046
  time_total_s: 1314.3377141952515
  timestamp: 1563751112
  timesteps_since_restore: 1486800
  timesteps_this_iter: 25200
  timesteps_total: 1486800
  training_iteration: 59
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1314 s, 59 iter, 1486800 ts, 15 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-18-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.0234840111441
  episode_reward_mean: 14.924431864121228
  episode_reward_min: -5.533301754385576
  episodes_this_iter: 168
  episodes_total: 10080
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4541.846
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.097323417663574
        kl: 0.012166578322649002
        policy_loss: -0.0179245974868536
        total_loss: 0.32983702421188354
        vf_explained_var: 0.9904731512069702
        vf_loss: 0.3462408185005188
    load_time_ms: 0.746
    num_steps_sampled: 1512000
    num_steps_trained: 1500000
    sample_time_ms: 17767.884
    update_time_ms: 0.002
  iterations_since_restore: 60
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14143271543806127
    mean_inference_ms: 0.43528040270667645
    mean_processing_ms: 0.12390375851795946
  time_since_restore: 1336.5103831291199
  time_this_iter_s: 22.172668933868408
  time_total_s: 1336.5103831291199
  timestamp: 1563751134
  timesteps_since_restore: 1512000
  timesteps_this_iter: 25200
  timesteps_total: 1512000
  training_iteration: 60
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1336 s, 60 iter, 1512000 ts, 14.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-19-15
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.298173842491394
  episode_reward_mean: 14.601956356421775
  episode_reward_min: -4.734271497668702
  episodes_this_iter: 168
  episodes_total: 10248
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4549.135
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.0794131755828857
        kl: 0.011846107430756092
        policy_loss: -0.017024697735905647
        total_loss: 0.2907576858997345
        vf_explained_var: 0.991400957107544
        vf_loss: 0.30630162358283997
    load_time_ms: 0.748
    num_steps_sampled: 1537200
    num_steps_trained: 1525000
    sample_time_ms: 17765.67
    update_time_ms: 0.002
  iterations_since_restore: 61
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14141129167478428
    mean_inference_ms: 0.4352289780268465
    mean_processing_ms: 0.1238938891312813
  time_since_restore: 1358.0012376308441
  time_this_iter_s: 21.490854501724243
  time_total_s: 1358.0012376308441
  timestamp: 1563751155
  timesteps_since_restore: 1537200
  timesteps_this_iter: 25200
  timesteps_total: 1537200
  training_iteration: 61
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1358 s, 61 iter, 1537200 ts, 14.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-19-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.97510030267432
  episode_reward_mean: 15.806387908415294
  episode_reward_min: -4.200054888066557
  episodes_this_iter: 168
  episodes_total: 10416
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4625.954
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.0652647018432617
        kl: 0.010430552065372467
        policy_loss: -0.01575397327542305
        total_loss: 0.295759916305542
        vf_explained_var: 0.9906167387962341
        vf_loss: 0.31021004915237427
    load_time_ms: 0.755
    num_steps_sampled: 1562400
    num_steps_trained: 1550000
    sample_time_ms: 17758.594
    update_time_ms: 0.002
  iterations_since_restore: 62
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14140474721606291
    mean_inference_ms: 0.43513101548829963
    mean_processing_ms: 0.12389678976734772
  time_since_restore: 1380.7878515720367
  time_this_iter_s: 22.786613941192627
  time_total_s: 1380.7878515720367
  timestamp: 1563751178
  timesteps_since_restore: 1562400
  timesteps_this_iter: 25200
  timesteps_total: 1562400
  training_iteration: 62
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1380 s, 62 iter, 1562400 ts, 15.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-20-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.805566149446435
  episode_reward_mean: 14.956010435806382
  episode_reward_min: -5.084908975230209
  episodes_this_iter: 168
  episodes_total: 10584
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4568.25
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.0460891723632812
        kl: 0.012948760762810707
        policy_loss: -0.017581336200237274
        total_loss: 0.2895331084728241
        vf_explained_var: 0.9904212951660156
        vf_loss: 0.30549582839012146
    load_time_ms: 0.758
    num_steps_sampled: 1587600
    num_steps_trained: 1575000
    sample_time_ms: 17763.283
    update_time_ms: 0.002
  iterations_since_restore: 63
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414200034844232
    mean_inference_ms: 0.4351248070397587
    mean_processing_ms: 0.12391524494216803
  time_since_restore: 1403.169646024704
  time_this_iter_s: 22.381794452667236
  time_total_s: 1403.169646024704
  timestamp: 1563751201
  timesteps_since_restore: 1587600
  timesteps_this_iter: 25200
  timesteps_total: 1587600
  training_iteration: 63
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1403 s, 63 iter, 1587600 ts, 15 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-20-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.35899090327933
  episode_reward_mean: 16.450760504428974
  episode_reward_min: -3.578395838424755
  episodes_this_iter: 168
  episodes_total: 10752
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4596.687
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.0263030529022217
        kl: 0.011591878719627857
        policy_loss: -0.016047224402427673
        total_loss: 0.26914677023887634
        vf_explained_var: 0.9925438761711121
        vf_loss: 0.2837449610233307
    load_time_ms: 0.75
    num_steps_sampled: 1612800
    num_steps_trained: 1600000
    sample_time_ms: 17779.936
    update_time_ms: 0.002
  iterations_since_restore: 64
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414408813798276
    mean_inference_ms: 0.4351650396902311
    mean_processing_ms: 0.12393648842212034
  time_since_restore: 1425.457664012909
  time_this_iter_s: 22.288017988204956
  time_total_s: 1425.457664012909
  timestamp: 1563751223
  timesteps_since_restore: 1612800
  timesteps_this_iter: 25200
  timesteps_total: 1612800
  training_iteration: 64
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1425 s, 64 iter, 1612800 ts, 16.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-20-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.31638753390624
  episode_reward_mean: 14.920053174638873
  episode_reward_min: -5.077487503842161
  episodes_this_iter: 168
  episodes_total: 10920
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4520.587
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 2.008009433746338
        kl: 0.011902115307748318
        policy_loss: -0.017778780311346054
        total_loss: 0.272254079580307
        vf_explained_var: 0.991075336933136
        vf_loss: 0.28854507207870483
    load_time_ms: 0.753
    num_steps_sampled: 1638000
    num_steps_trained: 1625000
    sample_time_ms: 17787.043
    update_time_ms: 0.002
  iterations_since_restore: 65
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141429769221469
    mean_inference_ms: 0.4351580538614087
    mean_processing_ms: 0.12394168251030982
  time_since_restore: 1447.167032957077
  time_this_iter_s: 21.70936894416809
  time_total_s: 1447.167032957077
  timestamp: 1563751245
  timesteps_since_restore: 1638000
  timesteps_this_iter: 25200
  timesteps_total: 1638000
  training_iteration: 65
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1447 s, 65 iter, 1638000 ts, 14.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-21-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.205266540956075
  episode_reward_mean: 15.911620979337624
  episode_reward_min: -3.6646324767796776
  episodes_this_iter: 168
  episodes_total: 11088
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4402.211
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.9888404607772827
        kl: 0.011315311305224895
        policy_loss: -0.01651027984917164
        total_loss: 0.26660409569740295
        vf_explained_var: 0.9911497235298157
        vf_loss: 0.2816999554634094
    load_time_ms: 0.757
    num_steps_sampled: 1663200
    num_steps_trained: 1650000
    sample_time_ms: 17794.034
    update_time_ms: 0.002
  iterations_since_restore: 66
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414354241967767
    mean_inference_ms: 0.4352036873418465
    mean_processing_ms: 0.1239498102413821
  time_since_restore: 1468.990695476532
  time_this_iter_s: 21.823662519454956
  time_total_s: 1468.990695476532
  timestamp: 1563751266
  timesteps_since_restore: 1663200
  timesteps_this_iter: 25200
  timesteps_total: 1663200
  training_iteration: 66
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1468 s, 66 iter, 1663200 ts, 15.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-21-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.378967110938575
  episode_reward_mean: 14.934881790376085
  episode_reward_min: -4.136990123514911
  episodes_this_iter: 168
  episodes_total: 11256
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4385.95
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.9639155864715576
        kl: 0.012905863113701344
        policy_loss: -0.018948817625641823
        total_loss: 0.2552163004875183
        vf_explained_var: 0.9921196103096008
        vf_loss: 0.27255189418792725
    load_time_ms: 0.746
    num_steps_sampled: 1688400
    num_steps_trained: 1675000
    sample_time_ms: 17797.384
    update_time_ms: 0.002
  iterations_since_restore: 67
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414346101554936
    mean_inference_ms: 0.4352251423918227
    mean_processing_ms: 0.12395349394190128
  time_since_restore: 1491.0369911193848
  time_this_iter_s: 22.046295642852783
  time_total_s: 1491.0369911193848
  timestamp: 1563751288
  timesteps_since_restore: 1688400
  timesteps_this_iter: 25200
  timesteps_total: 1688400
  training_iteration: 67
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1491 s, 67 iter, 1688400 ts, 14.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-21-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.43792195807766
  episode_reward_mean: 17.493243103352377
  episode_reward_min: -2.701574215642675
  episodes_this_iter: 168
  episodes_total: 11424
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4295.424
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.9500246047973633
        kl: 0.0120631018653512
        policy_loss: -0.019120780751109123
        total_loss: 0.23630136251449585
        vf_explained_var: 0.9936670064926147
        vf_loss: 0.2539142668247223
    load_time_ms: 0.75
    num_steps_sampled: 1713600
    num_steps_trained: 1700000
    sample_time_ms: 17801.445
    update_time_ms: 0.002
  iterations_since_restore: 68
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14144432947352417
    mean_inference_ms: 0.43525432204819753
    mean_processing_ms: 0.12396570278401649
  time_since_restore: 1513.1528282165527
  time_this_iter_s: 22.11583709716797
  time_total_s: 1513.1528282165527
  timestamp: 1563751311
  timesteps_since_restore: 1713600
  timesteps_this_iter: 25200
  timesteps_total: 1713600
  training_iteration: 68
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1513 s, 68 iter, 1713600 ts, 17.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-22-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.84886553279381
  episode_reward_mean: 16.37115174410285
  episode_reward_min: -4.566756151110522
  episodes_this_iter: 168
  episodes_total: 11592
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4296.76
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.9296824932098389
        kl: 0.010804014280438423
        policy_loss: -0.01671341434121132
        total_loss: 0.24295760691165924
        vf_explained_var: 0.9924408793449402
        vf_loss: 0.25832051038742065
    load_time_ms: 0.754
    num_steps_sampled: 1738800
    num_steps_trained: 1725000
    sample_time_ms: 17799.608
    update_time_ms: 0.002
  iterations_since_restore: 69
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414478366398517
    mean_inference_ms: 0.4352745014532503
    mean_processing_ms: 0.12397701421642807
  time_since_restore: 1535.3845012187958
  time_this_iter_s: 22.231673002243042
  time_total_s: 1535.3845012187958
  timestamp: 1563751333
  timesteps_since_restore: 1738800
  timesteps_this_iter: 25200
  timesteps_total: 1738800
  training_iteration: 69
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1535 s, 69 iter, 1738800 ts, 16.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-22-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.67928350962893
  episode_reward_mean: 15.801944144497394
  episode_reward_min: -3.6806693264159027
  episodes_this_iter: 168
  episodes_total: 11760
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4370.327
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.9083904027938843
        kl: 0.014402867294847965
        policy_loss: -0.019872941076755524
        total_loss: 0.18867690861225128
        vf_explained_var: 0.9939380884170532
        vf_loss: 0.20674948394298553
    load_time_ms: 0.755
    num_steps_sampled: 1764000
    num_steps_trained: 1750000
    sample_time_ms: 17808.055
    update_time_ms: 0.002
  iterations_since_restore: 70
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145542133056663
    mean_inference_ms: 0.4352922073638024
    mean_processing_ms: 0.1239903467781139
  time_since_restore: 1558.3781652450562
  time_this_iter_s: 22.993664026260376
  time_total_s: 1558.3781652450562
  timestamp: 1563751356
  timesteps_since_restore: 1764000
  timesteps_this_iter: 25200
  timesteps_total: 1764000
  training_iteration: 70
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1558 s, 70 iter, 1764000 ts, 15.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-22-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.80970504011832
  episode_reward_mean: 14.370483052547202
  episode_reward_min: -3.827095688577564
  episodes_this_iter: 168
  episodes_total: 11928
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4392.768
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.890769600868225
        kl: 0.013569793663918972
        policy_loss: -0.01760013960301876
        total_loss: 0.2077503353357315
        vf_explained_var: 0.9927045702934265
        vf_loss: 0.22365422546863556
    load_time_ms: 0.763
    num_steps_sampled: 1789200
    num_steps_trained: 1775000
    sample_time_ms: 17824.25
    update_time_ms: 0.002
  iterations_since_restore: 71
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146077303373034
    mean_inference_ms: 0.4352973019747327
    mean_processing_ms: 0.12399708360127579
  time_since_restore: 1580.2559597492218
  time_this_iter_s: 21.87779450416565
  time_total_s: 1580.2559597492218
  timestamp: 1563751378
  timesteps_since_restore: 1789200
  timesteps_this_iter: 25200
  timesteps_total: 1789200
  training_iteration: 71
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1580 s, 71 iter, 1789200 ts, 14.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-23-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.335349902543406
  episode_reward_mean: 16.20040926343315
  episode_reward_min: -3.0384161539533006
  episodes_this_iter: 168
  episodes_total: 12096
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4272.616
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.870723009109497
        kl: 0.013399477116763592
        policy_loss: -0.01884063333272934
        total_loss: 0.18451234698295593
        vf_explained_var: 0.9939563274383545
        vf_loss: 0.2016780525445938
    load_time_ms: 0.759
    num_steps_sampled: 1814400
    num_steps_trained: 1800000
    sample_time_ms: 17839.514
    update_time_ms: 0.002
  iterations_since_restore: 72
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414590722718839
    mean_inference_ms: 0.4352869208099675
    mean_processing_ms: 0.12400266051070939
  time_since_restore: 1601.9926543235779
  time_this_iter_s: 21.73669457435608
  time_total_s: 1601.9926543235779
  timestamp: 1563751399
  timesteps_since_restore: 1814400
  timesteps_this_iter: 25200
  timesteps_total: 1814400
  training_iteration: 72
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1601 s, 72 iter, 1814400 ts, 16.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-23-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.70161199190622
  episode_reward_mean: 16.42521388305776
  episode_reward_min: -3.914972231663359
  episodes_this_iter: 168
  episodes_total: 12264
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4213.6
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.85384202003479
        kl: 0.013042938895523548
        policy_loss: -0.019547924399375916
        total_loss: 0.192214235663414
        vf_explained_var: 0.994253933429718
        vf_loss: 0.21013182401657104
    load_time_ms: 0.764
    num_steps_sampled: 1839600
    num_steps_trained: 1825000
    sample_time_ms: 17831.953
    update_time_ms: 0.002
  iterations_since_restore: 73
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145554196713442
    mean_inference_ms: 0.4352659871410417
    mean_processing_ms: 0.12400643244380204
  time_since_restore: 1623.7080142498016
  time_this_iter_s: 21.715359926223755
  time_total_s: 1623.7080142498016
  timestamp: 1563751421
  timesteps_since_restore: 1839600
  timesteps_this_iter: 25200
  timesteps_total: 1839600
  training_iteration: 73
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1623 s, 73 iter, 1839600 ts, 16.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-24-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.85255783392612
  episode_reward_mean: 16.46115630360921
  episode_reward_min: -2.1524415014238474
  episodes_this_iter: 168
  episodes_total: 12432
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4213.707
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.838525414466858
        kl: 0.013834232464432716
        policy_loss: -0.01848248764872551
        total_loss: 0.16961941123008728
        vf_explained_var: 0.9952698349952698
        vf_loss: 0.1863725781440735
    load_time_ms: 0.766
    num_steps_sampled: 1864800
    num_steps_trained: 1850000
    sample_time_ms: 17816.982
    update_time_ms: 0.002
  iterations_since_restore: 74
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146194886895094
    mean_inference_ms: 0.4352317547176425
    mean_processing_ms: 0.12402086680598015
  time_since_restore: 1645.8474090099335
  time_this_iter_s: 22.139394760131836
  time_total_s: 1645.8474090099335
  timestamp: 1563751443
  timesteps_since_restore: 1864800
  timesteps_this_iter: 25200
  timesteps_total: 1864800
  training_iteration: 74
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1645 s, 74 iter, 1864800 ts, 16.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-24-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.24138819371081
  episode_reward_mean: 16.24537066951388
  episode_reward_min: -2.7715560101768126
  episodes_this_iter: 168
  episodes_total: 12600
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4201.852
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.8193135261535645
        kl: 0.014842166565358639
        policy_loss: -0.019382167607545853
        total_loss: 0.14797793328762054
        vf_explained_var: 0.9947476983070374
        vf_loss: 0.1655048429965973
    load_time_ms: 0.788
    num_steps_sampled: 1890000
    num_steps_trained: 1875000
    sample_time_ms: 17823.227
    update_time_ms: 0.002
  iterations_since_restore: 75
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414691476765623
    mean_inference_ms: 0.43522902790417095
    mean_processing_ms: 0.12403519062247906
  time_since_restore: 1667.5021171569824
  time_this_iter_s: 21.65470814704895
  time_total_s: 1667.5021171569824
  timestamp: 1563751465
  timesteps_since_restore: 1890000
  timesteps_this_iter: 25200
  timesteps_total: 1890000
  training_iteration: 75
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1667 s, 75 iter, 1890000 ts, 16.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-24-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.632001746943516
  episode_reward_mean: 17.274462173503903
  episode_reward_min: -2.590864980292773
  episodes_this_iter: 168
  episodes_total: 12768
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4244.715
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.80006742477417
        kl: 0.013633147813379765
        policy_loss: -0.0170903280377388
        total_loss: 0.16983643174171448
        vf_explained_var: 0.9954609870910645
        vf_loss: 0.18522261083126068
    load_time_ms: 0.788
    num_steps_sampled: 1915200
    num_steps_trained: 1900000
    sample_time_ms: 17818.386
    update_time_ms: 0.002
  iterations_since_restore: 76
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146810892527378
    mean_inference_ms: 0.4352470329184318
    mean_processing_ms: 0.1240415211025824
  time_since_restore: 1689.7065072059631
  time_this_iter_s: 22.204390048980713
  time_total_s: 1689.7065072059631
  timestamp: 1563751487
  timesteps_since_restore: 1915200
  timesteps_this_iter: 25200
  timesteps_total: 1915200
  training_iteration: 76
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1689 s, 76 iter, 1915200 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-25-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.66961040846032
  episode_reward_mean: 17.243153029384654
  episode_reward_min: -1.580415991613315
  episodes_this_iter: 168
  episodes_total: 12936
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4262.056
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.7863329648971558
        kl: 0.013309701345860958
        policy_loss: -0.020021731033921242
        total_loss: 0.13275079429149628
        vf_explained_var: 0.9956416487693787
        vf_loss: 0.15110881626605988
    load_time_ms: 0.814
    num_steps_sampled: 1940400
    num_steps_trained: 1925000
    sample_time_ms: 17815.225
    update_time_ms: 0.002
  iterations_since_restore: 77
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146552428570436
    mean_inference_ms: 0.43524394960489954
    mean_processing_ms: 0.12404905151182673
  time_since_restore: 1711.897747039795
  time_this_iter_s: 22.191239833831787
  time_total_s: 1711.897747039795
  timestamp: 1563751509
  timesteps_since_restore: 1940400
  timesteps_this_iter: 25200
  timesteps_total: 1940400
  training_iteration: 77
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1711 s, 77 iter, 1940400 ts, 17.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-25-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.22541440223101
  episode_reward_mean: 16.269499693419466
  episode_reward_min: -3.0825918198372566
  episodes_this_iter: 168
  episodes_total: 13104
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4350.225
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.7707505226135254
        kl: 0.014012293890118599
        policy_loss: -0.020478179678320885
        total_loss: 0.17551639676094055
        vf_explained_var: 0.9945804476737976
        vf_loss: 0.19424301385879517
    load_time_ms: 0.81
    num_steps_sampled: 1965600
    num_steps_trained: 1950000
    sample_time_ms: 17800.745
    update_time_ms: 0.002
  iterations_since_restore: 78
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145693847482427
    mean_inference_ms: 0.4352240179555126
    mean_processing_ms: 0.12404764415513195
  time_since_restore: 1734.7507758140564
  time_this_iter_s: 22.853028774261475
  time_total_s: 1734.7507758140564
  timestamp: 1563751532
  timesteps_since_restore: 1965600
  timesteps_this_iter: 25200
  timesteps_total: 1965600
  training_iteration: 78
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1734 s, 78 iter, 1965600 ts, 16.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-25-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.32737304064397
  episode_reward_mean: 17.443121377101303
  episode_reward_min: -3.563621990592913
  episodes_this_iter: 168
  episodes_total: 13272
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4295.12
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.754610300064087
        kl: 0.012887089513242245
        policy_loss: -0.01907261088490486
        total_loss: 0.14676745235919952
        vf_explained_var: 0.9959819912910461
        vf_loss: 0.16422918438911438
    load_time_ms: 0.812
    num_steps_sampled: 1990800
    num_steps_trained: 1975000
    sample_time_ms: 17807.844
    update_time_ms: 0.002
  iterations_since_restore: 79
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146566698175936
    mean_inference_ms: 0.43526436845304856
    mean_processing_ms: 0.1240634200418598
  time_since_restore: 1756.5020878314972
  time_this_iter_s: 21.751312017440796
  time_total_s: 1756.5020878314972
  timestamp: 1563751554
  timesteps_since_restore: 1990800
  timesteps_this_iter: 25200
  timesteps_total: 1990800
  training_iteration: 79
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1756 s, 79 iter, 1990800 ts, 17.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-26-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 35.79656381444524
  episode_reward_mean: 18.192127503209505
  episode_reward_min: -3.80513738544214
  episodes_this_iter: 168
  episodes_total: 13440
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4294.738
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.7335448265075684
        kl: 0.012739371508359909
        policy_loss: -0.016288453713059425
        total_loss: 0.13626687228679657
        vf_explained_var: 0.9963476657867432
        vf_loss: 0.15096288919448853
    load_time_ms: 0.816
    num_steps_sampled: 2016000
    num_steps_trained: 2000000
    sample_time_ms: 17806.859
    update_time_ms: 0.002
  iterations_since_restore: 80
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146822450171154
    mean_inference_ms: 0.4352800956442898
    mean_processing_ms: 0.12407333304469584
  time_since_restore: 1779.4819750785828
  time_this_iter_s: 22.97988724708557
  time_total_s: 1779.4819750785828
  timestamp: 1563751577
  timesteps_since_restore: 2016000
  timesteps_this_iter: 25200
  timesteps_total: 2016000
  training_iteration: 80
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1779 s, 80 iter, 2016000 ts, 18.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-26-40
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.10512310095424
  episode_reward_mean: 18.287290182836397
  episode_reward_min: -1.7032872557307301
  episodes_this_iter: 168
  episodes_total: 13608
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4401.645
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.7115716934204102
        kl: 0.012362267822027206
        policy_loss: -0.017451148480176926
        total_loss: 0.13369643688201904
        vf_explained_var: 0.9962121844291687
        vf_loss: 0.14960229396820068
    load_time_ms: 0.818
    num_steps_sampled: 2041200
    num_steps_trained: 2025000
    sample_time_ms: 17804.494
    update_time_ms: 0.002
  iterations_since_restore: 81
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146904613603709
    mean_inference_ms: 0.43527643905749
    mean_processing_ms: 0.12407867851668267
  time_since_restore: 1802.405982017517
  time_this_iter_s: 22.924006938934326
  time_total_s: 1802.405982017517
  timestamp: 1563751600
  timesteps_since_restore: 2041200
  timesteps_this_iter: 25200
  timesteps_total: 2041200
  training_iteration: 81
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1802 s, 81 iter, 2041200 ts, 18.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-27-01
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.865549844775906
  episode_reward_mean: 16.896519989221588
  episode_reward_min: -2.5782235912621148
  episodes_this_iter: 168
  episodes_total: 13776
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4381.121
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.6964313983917236
        kl: 0.013574939221143723
        policy_loss: -0.017296388745307922
        total_loss: 0.1410760134458542
        vf_explained_var: 0.9958893060684204
        vf_loss: 0.1566755324602127
    load_time_ms: 0.821
    num_steps_sampled: 2066400
    num_steps_trained: 2050000
    sample_time_ms: 17797.12
    update_time_ms: 0.002
  iterations_since_restore: 82
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145416523224028
    mean_inference_ms: 0.4352562012853308
    mean_processing_ms: 0.12407151117353955
  time_since_restore: 1823.8638269901276
  time_this_iter_s: 21.457844972610474
  time_total_s: 1823.8638269901276
  timestamp: 1563751621
  timesteps_since_restore: 2066400
  timesteps_this_iter: 25200
  timesteps_total: 2066400
  training_iteration: 82
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1823 s, 82 iter, 2066400 ts, 16.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-27-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.29935965944762
  episode_reward_mean: 17.230194381656723
  episode_reward_min: -1.7674722850076685
  episodes_this_iter: 168
  episodes_total: 13944
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4360.222
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.675947666168213
        kl: 0.015232504345476627
        policy_loss: -0.021878056228160858
        total_loss: 0.10576410591602325
        vf_explained_var: 0.9968305826187134
        vf_loss: 0.12573809921741486
    load_time_ms: 0.814
    num_steps_sampled: 2091600
    num_steps_trained: 2075000
    sample_time_ms: 17800.198
    update_time_ms: 0.002
  iterations_since_restore: 83
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14144873463154645
    mean_inference_ms: 0.4352522807609623
    mean_processing_ms: 0.12407696933123862
  time_since_restore: 1845.4009809494019
  time_this_iter_s: 21.537153959274292
  time_total_s: 1845.4009809494019
  timestamp: 1563751643
  timesteps_since_restore: 2091600
  timesteps_this_iter: 25200
  timesteps_total: 2091600
  training_iteration: 83
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1845 s, 83 iter, 2091600 ts, 17.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-27-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.067751621936694
  episode_reward_mean: 16.699556879677484
  episode_reward_min: -1.702332380935121
  episodes_this_iter: 168
  episodes_total: 14112
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4372.544
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.662832498550415
        kl: 0.014242539182305336
        policy_loss: -0.018621983006596565
        total_loss: 0.09998304396867752
        vf_explained_var: 0.9964215755462646
        vf_loss: 0.11682470142841339
    load_time_ms: 0.821
    num_steps_sampled: 2116800
    num_steps_trained: 2100000
    sample_time_ms: 17803.191
    update_time_ms: 0.002
  iterations_since_restore: 84
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414581133892284
    mean_inference_ms: 0.4352320260454391
    mean_processing_ms: 0.12408972603415662
  time_since_restore: 1867.6938858032227
  time_this_iter_s: 22.2929048538208
  time_total_s: 1867.6938858032227
  timestamp: 1563751665
  timesteps_since_restore: 2116800
  timesteps_this_iter: 25200
  timesteps_total: 2116800
  training_iteration: 84
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1867 s, 84 iter, 2116800 ts, 16.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-28-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.51072983198855
  episode_reward_mean: 17.655491849399272
  episode_reward_min: -3.0056136719579656
  episodes_this_iter: 168
  episodes_total: 14280
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4365.471
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.651252031326294
        kl: 0.014061182737350464
        policy_loss: -0.019782161340117455
        total_loss: 0.09964112937450409
        vf_explained_var: 0.9968671202659607
        vf_loss: 0.11766563355922699
    load_time_ms: 0.794
    num_steps_sampled: 2142000
    num_steps_trained: 2125000
    sample_time_ms: 17792.004
    update_time_ms: 0.002
  iterations_since_restore: 85
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145549902980892
    mean_inference_ms: 0.4351968868386463
    mean_processing_ms: 0.12409181115353697
  time_since_restore: 1889.1643362045288
  time_this_iter_s: 21.470450401306152
  time_total_s: 1889.1643362045288
  timestamp: 1563751687
  timesteps_since_restore: 2142000
  timesteps_this_iter: 25200
  timesteps_total: 2142000
  training_iteration: 85
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1889 s, 85 iter, 2142000 ts, 17.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-28-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.703200536432014
  episode_reward_mean: 17.286859787678075
  episode_reward_min: -2.641739108550919
  episodes_this_iter: 168
  episodes_total: 14448
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4301.609
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.6328346729278564
        kl: 0.013066879473626614
        policy_loss: -0.017963672056794167
        total_loss: 0.08914391696453094
        vf_explained_var: 0.9972144961357117
        vf_loss: 0.10547423362731934
    load_time_ms: 0.795
    num_steps_sampled: 2167200
    num_steps_trained: 2150000
    sample_time_ms: 17791.97
    update_time_ms: 0.002
  iterations_since_restore: 86
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147015456996279
    mean_inference_ms: 0.4351880307795489
    mean_processing_ms: 0.12410644770062754
  time_since_restore: 1910.7295429706573
  time_this_iter_s: 21.56520676612854
  time_total_s: 1910.7295429706573
  timestamp: 1563751708
  timesteps_since_restore: 2167200
  timesteps_this_iter: 25200
  timesteps_total: 2167200
  training_iteration: 86
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1910 s, 86 iter, 2167200 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-28-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.28623951463047
  episode_reward_mean: 18.24355622522888
  episode_reward_min: 0.20741127264473685
  episodes_this_iter: 168
  episodes_total: 14616
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4247.355
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.6123768091201782
        kl: 0.014711686410009861
        policy_loss: -0.01958095096051693
        total_loss: 0.08339923620223999
        vf_explained_var: 0.9975360035896301
        vf_loss: 0.10114123672246933
    load_time_ms: 0.771
    num_steps_sampled: 2192400
    num_steps_trained: 2175000
    sample_time_ms: 17801.764
    update_time_ms: 0.002
  iterations_since_restore: 87
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147710717544393
    mean_inference_ms: 0.43521605292799087
    mean_processing_ms: 0.12411821145278058
  time_since_restore: 1932.4724605083466
  time_this_iter_s: 21.74291753768921
  time_total_s: 1932.4724605083466
  timestamp: 1563751730
  timesteps_since_restore: 2192400
  timesteps_this_iter: 25200
  timesteps_total: 2192400
  training_iteration: 87
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1932 s, 87 iter, 2192400 ts, 18.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-29-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.4348707420771
  episode_reward_mean: 15.646407867239532
  episode_reward_min: -2.574083540162405
  episodes_this_iter: 168
  episodes_total: 14784
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4247.009
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.5921547412872314
        kl: 0.014988354407250881
        policy_loss: -0.02062346413731575
        total_loss: 0.08703981339931488
        vf_explained_var: 0.996865451335907
        vf_loss: 0.10578973591327667
    load_time_ms: 0.769
    num_steps_sampled: 2217600
    num_steps_trained: 2200000
    sample_time_ms: 17813.199
    update_time_ms: 0.002
  iterations_since_restore: 88
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147675738399496
    mean_inference_ms: 0.43523452170721116
    mean_processing_ms: 0.1241241604461231
  time_since_restore: 1955.4362969398499
  time_this_iter_s: 22.963836431503296
  time_total_s: 1955.4362969398499
  timestamp: 1563751753
  timesteps_since_restore: 2217600
  timesteps_this_iter: 25200
  timesteps_total: 2217600
  training_iteration: 88
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1955 s, 88 iter, 2217600 ts, 15.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-29-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.69012969691291
  episode_reward_mean: 18.274735959006847
  episode_reward_min: -2.228310957777978
  episodes_this_iter: 168
  episodes_total: 14952
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4301.387
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.5737239122390747
        kl: 0.015130081214010715
        policy_loss: -0.02125605195760727
        total_loss: 0.07148788869380951
        vf_explained_var: 0.9977332949638367
        vf_loss: 0.09085267782211304
    load_time_ms: 0.773
    num_steps_sampled: 2242800
    num_steps_trained: 2225000
    sample_time_ms: 17799.088
    update_time_ms: 0.002
  iterations_since_restore: 89
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147407751050964
    mean_inference_ms: 0.4352289606758025
    mean_processing_ms: 0.12412596745798442
  time_since_restore: 1977.5907835960388
  time_this_iter_s: 22.154486656188965
  time_total_s: 1977.5907835960388
  timestamp: 1563751775
  timesteps_since_restore: 2242800
  timesteps_this_iter: 25200
  timesteps_total: 2242800
  training_iteration: 89
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 1977 s, 89 iter, 2242800 ts, 18.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-29-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.925088381071276
  episode_reward_mean: 18.395350029567
  episode_reward_min: -1.8667568646031922
  episodes_this_iter: 168
  episodes_total: 15120
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4298.911
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.5577141046524048
        kl: 0.01513532642275095
        policy_loss: -0.018492374569177628
        total_loss: 0.08733674883842468
        vf_explained_var: 0.9974563121795654
        vf_loss: 0.10393720865249634
    load_time_ms: 0.769
    num_steps_sampled: 2268000
    num_steps_trained: 2250000
    sample_time_ms: 17782.328
    update_time_ms: 0.002
  iterations_since_restore: 90
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145920586513325
    mean_inference_ms: 0.43520436459544193
    mean_processing_ms: 0.12411666173121173
  time_since_restore: 2000.3782949447632
  time_this_iter_s: 22.787511348724365
  time_total_s: 2000.3782949447632
  timestamp: 1563751798
  timesteps_since_restore: 2268000
  timesteps_this_iter: 25200
  timesteps_total: 2268000
  training_iteration: 90
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2000 s, 90 iter, 2268000 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-30-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.90329238327285
  episode_reward_mean: 18.059998207186965
  episode_reward_min: -2.445199962491534
  episodes_this_iter: 168
  episodes_total: 15288
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4182.01
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.5419387817382812
        kl: 0.014966257847845554
        policy_loss: -0.02083207294344902
        total_loss: 0.0840383842587471
        vf_explained_var: 0.9973326325416565
        vf_loss: 0.10299967974424362
    load_time_ms: 0.772
    num_steps_sampled: 2293200
    num_steps_trained: 2275000
    sample_time_ms: 17781.256
    update_time_ms: 0.002
  iterations_since_restore: 91
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14145580181993211
    mean_inference_ms: 0.43520451326260134
    mean_processing_ms: 0.12411776629625806
  time_since_restore: 2022.1214599609375
  time_this_iter_s: 21.743165016174316
  time_total_s: 2022.1214599609375
  timestamp: 1563751820
  timesteps_since_restore: 2293200
  timesteps_this_iter: 25200
  timesteps_total: 2293200
  training_iteration: 91
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2022 s, 91 iter, 2293200 ts, 18.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-30-41
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.330583005712185
  episode_reward_mean: 17.256143680081863
  episode_reward_min: -2.701107581244504
  episodes_this_iter: 168
  episodes_total: 15456
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4193.004
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.527432918548584
        kl: 0.01424160972237587
        policy_loss: -0.019151251763105392
        total_loss: 0.08302589505910873
        vf_explained_var: 0.9974233508110046
        vf_loss: 0.10039696097373962
    load_time_ms: 0.771
    num_steps_sampled: 2318400
    num_steps_trained: 2300000
    sample_time_ms: 17781.314
    update_time_ms: 0.002
  iterations_since_restore: 92
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14144752477740657
    mean_inference_ms: 0.4351779426447574
    mean_processing_ms: 0.12411557445672046
  time_since_restore: 2043.6897921562195
  time_this_iter_s: 21.568332195281982
  time_total_s: 2043.6897921562195
  timestamp: 1563751841
  timesteps_since_restore: 2318400
  timesteps_this_iter: 25200
  timesteps_total: 2318400
  training_iteration: 92
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2043 s, 92 iter, 2318400 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-31-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.95695141608075
  episode_reward_mean: 19.065502281051156
  episode_reward_min: 0.04597858972116478
  episodes_this_iter: 168
  episodes_total: 15624
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4203.51
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.5164602994918823
        kl: 0.013920087367296219
        policy_loss: -0.019340772181749344
        total_loss: 0.0646006166934967
        vf_explained_var: 0.9980954527854919
        vf_loss: 0.08220138400793076
    load_time_ms: 0.778
    num_steps_sampled: 2343600
    num_steps_trained: 2325000
    sample_time_ms: 17785.357
    update_time_ms: 0.002
  iterations_since_restore: 93
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14144652050641943
    mean_inference_ms: 0.4351893480577672
    mean_processing_ms: 0.1241189926478387
  time_since_restore: 2065.3730437755585
  time_this_iter_s: 21.68325161933899
  time_total_s: 2065.3730437755585
  timestamp: 1563751863
  timesteps_since_restore: 2343600
  timesteps_this_iter: 25200
  timesteps_total: 2343600
  training_iteration: 93
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2065 s, 93 iter, 2343600 ts, 19.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-31-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.42057941112453
  episode_reward_mean: 18.033586226499068
  episode_reward_min: -1.2826273883141135
  episodes_this_iter: 168
  episodes_total: 15792
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4191.578
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.506795048713684
        kl: 0.015114380046725273
        policy_loss: -0.02069997973740101
        total_loss: 0.06216612458229065
        vf_explained_var: 0.9978231191635132
        vf_loss: 0.08097681403160095
    load_time_ms: 0.786
    num_steps_sampled: 2368800
    num_steps_trained: 2350000
    sample_time_ms: 17782.584
    update_time_ms: 0.002
  iterations_since_restore: 94
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414446943615821
    mean_inference_ms: 0.4351766091688836
    mean_processing_ms: 0.12412415855858719
  time_since_restore: 2087.5189023017883
  time_this_iter_s: 22.14585852622986
  time_total_s: 2087.5189023017883
  timestamp: 1563751885
  timesteps_since_restore: 2368800
  timesteps_this_iter: 25200
  timesteps_total: 2368800
  training_iteration: 94
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2087 s, 94 iter, 2368800 ts, 18 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-31-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.10989523725398
  episode_reward_mean: 16.904062670393113
  episode_reward_min: -2.5272599502249564
  episodes_this_iter: 168
  episodes_total: 15960
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4328.005
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4910567998886108
        kl: 0.015055153518915176
        policy_loss: -0.021689750254154205
        total_loss: 0.060414258390665054
        vf_explained_var: 0.9977185726165771
        vf_loss: 0.08022210747003555
    load_time_ms: 0.782
    num_steps_sampled: 2394000
    num_steps_trained: 2375000
    sample_time_ms: 17787.542
    update_time_ms: 0.002
  iterations_since_restore: 95
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14143881351254825
    mean_inference_ms: 0.43517394947708526
    mean_processing_ms: 0.12412247416694361
  time_since_restore: 2110.404314994812
  time_this_iter_s: 22.88541269302368
  time_total_s: 2110.404314994812
  timestamp: 1563751908
  timesteps_since_restore: 2394000
  timesteps_this_iter: 25200
  timesteps_total: 2394000
  training_iteration: 95
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2110 s, 95 iter, 2394000 ts, 16.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-32-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.92704487918941
  episode_reward_mean: 18.565773864864884
  episode_reward_min: -4.70295354886746
  episodes_this_iter: 168
  episodes_total: 16128
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4363.996
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4714972972869873
        kl: 0.016186486929655075
        policy_loss: -0.02095089852809906
        total_loss: 0.0536317303776741
        vf_explained_var: 0.9982138872146606
        vf_loss: 0.07255931943655014
    load_time_ms: 0.795
    num_steps_sampled: 2419200
    num_steps_trained: 2400000
    sample_time_ms: 17788.299
    update_time_ms: 0.002
  iterations_since_restore: 96
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414566452272815
    mean_inference_ms: 0.43515973904852717
    mean_processing_ms: 0.12413999679928207
  time_since_restore: 2132.337424516678
  time_this_iter_s: 21.933109521865845
  time_total_s: 2132.337424516678
  timestamp: 1563751930
  timesteps_since_restore: 2419200
  timesteps_this_iter: 25200
  timesteps_total: 2419200
  training_iteration: 96
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2132 s, 96 iter, 2419200 ts, 18.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-32-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.96250512929565
  episode_reward_mean: 17.293421687955856
  episode_reward_min: -1.2080990364180986
  episodes_this_iter: 168
  episodes_total: 16296
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4490.204
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4557729959487915
        kl: 0.01587251015007496
        policy_loss: -0.022203445434570312
        total_loss: 0.04978196695446968
        vf_explained_var: 0.9982580542564392
        vf_loss: 0.07000134885311127
    load_time_ms: 0.796
    num_steps_sampled: 2444400
    num_steps_trained: 2425000
    sample_time_ms: 17780.002
    update_time_ms: 0.002
  iterations_since_restore: 97
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14146496366047437
    mean_inference_ms: 0.43514622766327044
    mean_processing_ms: 0.1241531380715957
  time_since_restore: 2155.2605612277985
  time_this_iter_s: 22.923136711120605
  time_total_s: 2155.2605612277985
  timestamp: 1563751953
  timesteps_since_restore: 2444400
  timesteps_this_iter: 25200
  timesteps_total: 2444400
  training_iteration: 97
  2019-07-22 01:33:42,585	WARNING util.py:64 -- The `save_to_disk` operation took 0.20276093482971191 seconds to complete, which may be a performance bottleneck.
2019-07-22 01:33:42,587	WARNING util.py:64 -- The `process_trial` operation took 0.21079421043395996 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2155 s, 97 iter, 2444400 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-32-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.58543322698548
  episode_reward_mean: 17.286103253757524
  episode_reward_min: -2.148985865188616
  episodes_this_iter: 168
  episodes_total: 16464
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4489.203
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4395453929901123
        kl: 0.015067645348608494
        policy_loss: -0.0206402949988842
        total_loss: 0.06584532558917999
        vf_explained_var: 0.9977755546569824
        vf_loss: 0.08460217714309692
    load_time_ms: 0.8
    num_steps_sampled: 2469600
    num_steps_trained: 2450000
    sample_time_ms: 17785.825
    update_time_ms: 0.002
  iterations_since_restore: 98
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141480276083065
    mean_inference_ms: 0.43515746341476375
    mean_processing_ms: 0.12417097164169624
  time_since_restore: 2178.2725665569305
  time_this_iter_s: 23.01200532913208
  time_total_s: 2178.2725665569305
  timestamp: 1563751976
  timesteps_since_restore: 2469600
  timesteps_this_iter: 25200
  timesteps_total: 2469600
  training_iteration: 98
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2178 s, 98 iter, 2469600 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-33-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.16038043352113
  episode_reward_mean: 18.65644859979192
  episode_reward_min: -3.9607849816422864
  episodes_this_iter: 168
  episodes_total: 16632
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4565.716
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4207067489624023
        kl: 0.015773789957165718
        policy_loss: -0.018999846652150154
        total_loss: 0.06144272908568382
        vf_explained_var: 0.9980695843696594
        vf_loss: 0.0784708559513092
    load_time_ms: 0.796
    num_steps_sampled: 2494800
    num_steps_trained: 2475000
    sample_time_ms: 17794.234
    update_time_ms: 0.002
  iterations_since_restore: 99
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414883339879942
    mean_inference_ms: 0.435170258504339
    mean_processing_ms: 0.12417816985421878
  time_since_restore: 2201.276938199997
  time_this_iter_s: 23.004371643066406
  time_total_s: 2201.276938199997
  timestamp: 1563751999
  timesteps_since_restore: 2494800
  timesteps_this_iter: 25200
  timesteps_total: 2494800
  training_iteration: 99
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2201 s, 99 iter, 2494800 ts, 18.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-33-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.79061123673017
  episode_reward_mean: 18.472343748609585
  episode_reward_min: -0.9548600631998582
  episodes_this_iter: 168
  episodes_total: 16800
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4567.208
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.4077121019363403
        kl: 0.01601385325193405
        policy_loss: -0.021145647391676903
        total_loss: 0.044754758477211
        vf_explained_var: 0.9984833002090454
        vf_loss: 0.06389866769313812
    load_time_ms: 0.797
    num_steps_sampled: 2520000
    num_steps_trained: 2500000
    sample_time_ms: 17801.865
    update_time_ms: 0.002
  iterations_since_restore: 100
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414836015563885
    mean_inference_ms: 0.43516205272958974
    mean_processing_ms: 0.1241769272338982
  time_since_restore: 2224.1556208133698
  time_this_iter_s: 22.878682613372803
  time_total_s: 2224.1556208133698
  timestamp: 1563752022
  timesteps_since_restore: 2520000
  timesteps_this_iter: 25200
  timesteps_total: 2520000
  training_iteration: 100
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2224 s, 100 iter, 2520000 ts, 18.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-34-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.98057004057675
  episode_reward_mean: 17.256846440102347
  episode_reward_min: -1.7719875133022576
  episodes_this_iter: 168
  episodes_total: 16968
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4554.037
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.3863155841827393
        kl: 0.016080135479569435
        policy_loss: -0.02280447445809841
        total_loss: 0.03730931133031845
        vf_explained_var: 0.9984252452850342
        vf_loss: 0.0581037700176239
    load_time_ms: 0.793
    num_steps_sampled: 2545200
    num_steps_trained: 2525000
    sample_time_ms: 17803.165
    update_time_ms: 0.002
  iterations_since_restore: 101
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14147918615453628
    mean_inference_ms: 0.43515992915941043
    mean_processing_ms: 0.12418631346563795
  time_since_restore: 2245.78013920784
  time_this_iter_s: 21.624518394470215
  time_total_s: 2245.78013920784
  timestamp: 1563752044
  timesteps_since_restore: 2545200
  timesteps_this_iter: 25200
  timesteps_total: 2545200
  training_iteration: 101
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2245 s, 101 iter, 2545200 ts, 17.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-34-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.821145258362755
  episode_reward_mean: 17.01088027388375
  episode_reward_min: -1.7813985741146678
  episodes_this_iter: 168
  episodes_total: 17136
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4576.41
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.3730331659317017
        kl: 0.01745745725929737
        policy_loss: -0.02068343572318554
        total_loss: 0.04343266040086746
        vf_explained_var: 0.9982550144195557
        vf_loss: 0.061933908611536026
    load_time_ms: 0.792
    num_steps_sampled: 2570400
    num_steps_trained: 2550000
    sample_time_ms: 17830.445
    update_time_ms: 0.002
  iterations_since_restore: 102
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1414934632280814
    mean_inference_ms: 0.4351996612704955
    mean_processing_ms: 0.12420403301127106
  time_since_restore: 2267.845372438431
  time_this_iter_s: 22.06523323059082
  time_total_s: 2267.845372438431
  timestamp: 1563752066
  timesteps_since_restore: 2570400
  timesteps_this_iter: 25200
  timesteps_total: 2570400
  training_iteration: 102
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2267 s, 102 iter, 2570400 ts, 17 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-34-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.50977887948703
  episode_reward_mean: 18.44983239829627
  episode_reward_min: -0.6765861942622002
  episodes_this_iter: 168
  episodes_total: 17304
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4630.204
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.357303500175476
        kl: 0.015129591338336468
        policy_loss: -0.021996233612298965
        total_loss: 0.03434969484806061
        vf_explained_var: 0.998514711856842
        vf_loss: 0.054454732686281204
    load_time_ms: 0.789
    num_steps_sampled: 2595600
    num_steps_trained: 2575000
    sample_time_ms: 17834.754
    update_time_ms: 0.002
  iterations_since_restore: 103
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14150006168755797
    mean_inference_ms: 0.43520564350800667
    mean_processing_ms: 0.12421848713606734
  time_since_restore: 2290.109749317169
  time_this_iter_s: 22.264376878738403
  time_total_s: 2290.109749317169
  timestamp: 1563752088
  timesteps_since_restore: 2595600
  timesteps_this_iter: 25200
  timesteps_total: 2595600
  training_iteration: 103
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2290 s, 103 iter, 2595600 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-35-11
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.788094582785476
  episode_reward_mean: 18.95845059263814
  episode_reward_min: -0.6797567136708671
  episodes_this_iter: 168
  episodes_total: 17472
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4707.498
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.3365066051483154
        kl: 0.015729503706097603
        policy_loss: -0.020805612206459045
        total_loss: 0.030150193721055984
        vf_explained_var: 0.9986865520477295
        vf_loss: 0.048989616334438324
    load_time_ms: 0.782
    num_steps_sampled: 2620800
    num_steps_trained: 2600000
    sample_time_ms: 17842.155
    update_time_ms: 0.002
  iterations_since_restore: 104
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14149976050560695
    mean_inference_ms: 0.4352173751896502
    mean_processing_ms: 0.12422530168954635
  time_since_restore: 2313.10329413414
  time_this_iter_s: 22.993544816970825
  time_total_s: 2313.10329413414
  timestamp: 1563752111
  timesteps_since_restore: 2620800
  timesteps_this_iter: 25200
  timesteps_total: 2620800
  training_iteration: 104
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2313 s, 104 iter, 2620800 ts, 19 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-35-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.72284502163129
  episode_reward_mean: 18.612939858908664
  episode_reward_min: -1.2202988165069935
  episodes_this_iter: 168
  episodes_total: 17640
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4666.122
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.3199189901351929
        kl: 0.015299306251108646
        policy_loss: -0.020885229110717773
        total_loss: 0.031186223030090332
        vf_explained_var: 0.998782217502594
        vf_loss: 0.0501590333878994
    load_time_ms: 0.788
    num_steps_sampled: 2646000
    num_steps_trained: 2625000
    sample_time_ms: 17859.383
    update_time_ms: 0.002
  iterations_since_restore: 105
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415071487855659
    mean_inference_ms: 0.4352505143471791
    mean_processing_ms: 0.12423768487821642
  time_since_restore: 2335.747103214264
  time_this_iter_s: 22.6438090801239
  time_total_s: 2335.747103214264
  timestamp: 1563752134
  timesteps_since_restore: 2646000
  timesteps_this_iter: 25200
  timesteps_total: 2646000
  training_iteration: 105
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2335 s, 105 iter, 2646000 ts, 18.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-35-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.414278063228885
  episode_reward_mean: 17.77889891812803
  episode_reward_min: 0.4163498765372797
  episodes_this_iter: 168
  episodes_total: 17808
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4647.962
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.3056353330612183
        kl: 0.014648220501840115
        policy_loss: -0.021673865616321564
        total_loss: 0.0248919315636158
        vf_explained_var: 0.9986809492111206
        vf_loss: 0.04473476856946945
    load_time_ms: 0.804
    num_steps_sampled: 2671200
    num_steps_trained: 2650000
    sample_time_ms: 17880.144
    update_time_ms: 0.002
  iterations_since_restore: 106
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14152736662311735
    mean_inference_ms: 0.43530118747599433
    mean_processing_ms: 0.12426100078293748
  time_since_restore: 2357.7072768211365
  time_this_iter_s: 21.96017360687256
  time_total_s: 2357.7072768211365
  timestamp: 1563752156
  timesteps_since_restore: 2671200
  timesteps_this_iter: 25200
  timesteps_total: 2671200
  training_iteration: 106
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2357 s, 106 iter, 2671200 ts, 17.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-36-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.62755738406085
  episode_reward_mean: 17.904398347640093
  episode_reward_min: -0.36884199565539616
  episodes_this_iter: 168
  episodes_total: 17976
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4652.189
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2857463359832764
        kl: 0.01499843504279852
        policy_loss: -0.022797996178269386
        total_loss: 0.02341117337346077
        vf_explained_var: 0.9987651109695435
        vf_loss: 0.04433436319231987
    load_time_ms: 0.804
    num_steps_sampled: 2696400
    num_steps_trained: 2675000
    sample_time_ms: 17873.423
    update_time_ms: 0.002
  iterations_since_restore: 107
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415244300049181
    mean_inference_ms: 0.43528061288175074
    mean_processing_ms: 0.12426388339740066
  time_since_restore: 2380.60559797287
  time_this_iter_s: 22.8983211517334
  time_total_s: 2380.60559797287
  timestamp: 1563752179
  timesteps_since_restore: 2696400
  timesteps_this_iter: 25200
  timesteps_total: 2696400
  training_iteration: 107
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2380 s, 107 iter, 2696400 ts, 17.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-36-40
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.43978817900188
  episode_reward_mean: 18.35623347987743
  episode_reward_min: -0.10237854469059224
  episodes_this_iter: 168
  episodes_total: 18144
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4527.338
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2686576843261719
        kl: 0.015029259026050568
        policy_loss: -0.01882302202284336
        total_loss: 0.039725303649902344
        vf_explained_var: 0.9984754920005798
        vf_loss: 0.05666965991258621
    load_time_ms: 0.802
    num_steps_sampled: 2721600
    num_steps_trained: 2700000
    sample_time_ms: 17854.005
    update_time_ms: 0.002
  iterations_since_restore: 108
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14151694733234707
    mean_inference_ms: 0.43525395354586527
    mean_processing_ms: 0.12426509461516574
  time_since_restore: 2402.1738085746765
  time_this_iter_s: 21.56821060180664
  time_total_s: 2402.1738085746765
  timestamp: 1563752200
  timesteps_since_restore: 2721600
  timesteps_this_iter: 25200
  timesteps_total: 2721600
  training_iteration: 108
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2402 s, 108 iter, 2721600 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-37-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.55516834620768
  episode_reward_mean: 19.244605272569792
  episode_reward_min: -0.5826327319440344
  episodes_this_iter: 168
  episodes_total: 18312
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4387.267
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2562042474746704
        kl: 0.017359286546707153
        policy_loss: -0.02213406376540661
        total_loss: 0.020125865936279297
        vf_explained_var: 0.9990394115447998
        vf_loss: 0.04009002074599266
    load_time_ms: 0.799
    num_steps_sampled: 2746800
    num_steps_trained: 2725000
    sample_time_ms: 17854.451
    update_time_ms: 0.002
  iterations_since_restore: 109
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14152657673164426
    mean_inference_ms: 0.43525282616708083
    mean_processing_ms: 0.12428120663778476
  time_since_restore: 2423.7806594371796
  time_this_iter_s: 21.60685086250305
  time_total_s: 2423.7806594371796
  timestamp: 1563752222
  timesteps_since_restore: 2746800
  timesteps_this_iter: 25200
  timesteps_total: 2746800
  training_iteration: 109
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2423 s, 109 iter, 2746800 ts, 19.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-37-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.47315555309825
  episode_reward_mean: 18.071561147504944
  episode_reward_min: -3.8481437034578776
  episodes_this_iter: 168
  episodes_total: 18480
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4250.418
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2468059062957764
        kl: 0.018212055787444115
        policy_loss: -0.02256939560174942
        total_loss: 0.017944134771823883
        vf_explained_var: 0.9989888072013855
        vf_loss: 0.03823702409863472
    load_time_ms: 0.797
    num_steps_sampled: 2772000
    num_steps_trained: 2750000
    sample_time_ms: 17870.44
    update_time_ms: 0.002
  iterations_since_restore: 110
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14153936366333775
    mean_inference_ms: 0.43526573179115635
    mean_processing_ms: 0.12429751493700622
  time_since_restore: 2445.4497294425964
  time_this_iter_s: 21.66907000541687
  time_total_s: 2445.4497294425964
  timestamp: 1563752243
  timesteps_since_restore: 2772000
  timesteps_this_iter: 25200
  timesteps_total: 2772000
  training_iteration: 110
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2445 s, 110 iter, 2772000 ts, 18.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-37-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.19343807168339
  episode_reward_mean: 17.74032455833682
  episode_reward_min: -1.758276333918943
  episodes_this_iter: 168
  episodes_total: 18648
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4379.498
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2275696992874146
        kl: 0.014679298736155033
        policy_loss: -0.021723812445998192
        total_loss: 0.02106022648513317
        vf_explained_var: 0.9988279938697815
        vf_loss: 0.04094912111759186
    load_time_ms: 0.793
    num_steps_sampled: 2797200
    num_steps_trained: 2775000
    sample_time_ms: 17869.185
    update_time_ms: 0.002
  iterations_since_restore: 111
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415432850728158
    mean_inference_ms: 0.43524619758760974
    mean_processing_ms: 0.12430831123973117
  time_since_restore: 2468.3535101413727
  time_this_iter_s: 22.903780698776245
  time_total_s: 2468.3535101413727
  timestamp: 1563752266
  timesteps_since_restore: 2797200
  timesteps_this_iter: 25200
  timesteps_total: 2797200
  training_iteration: 111
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2468 s, 111 iter, 2797200 ts, 17.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-38-08
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.5712276705147
  episode_reward_mean: 18.74888113257935
  episode_reward_min: -8.716218778749814
  episodes_this_iter: 168
  episodes_total: 18816
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4354.827
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.2164939641952515
        kl: 0.01781534031033516
        policy_loss: -0.016479671001434326
        total_loss: 0.06268098205327988
        vf_explained_var: 0.9979491233825684
        vf_loss: 0.07693373411893845
    load_time_ms: 0.8
    num_steps_sampled: 2822400
    num_steps_trained: 2800000
    sample_time_ms: 17850.9
    update_time_ms: 0.002
  iterations_since_restore: 112
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14154079569430802
    mean_inference_ms: 0.435244144230147
    mean_processing_ms: 0.12431096476509247
  time_since_restore: 2489.9887516498566
  time_this_iter_s: 21.635241508483887
  time_total_s: 2489.9887516498566
  timestamp: 1563752288
  timesteps_since_restore: 2822400
  timesteps_this_iter: 25200
  timesteps_total: 2822400
  training_iteration: 112
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2489 s, 112 iter, 2822400 ts, 18.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-38-31
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.183105325676266
  episode_reward_mean: 19.059082607685916
  episode_reward_min: -0.9133229742630616
  episodes_this_iter: 168
  episodes_total: 18984
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4430.226
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.1978164911270142
        kl: 0.017816198989748955
        policy_loss: -0.021479835733771324
        total_loss: 0.023806894198060036
        vf_explained_var: 0.998930037021637
        vf_loss: 0.04305970296263695
    load_time_ms: 0.796
    num_steps_sampled: 2847600
    num_steps_trained: 2825000
    sample_time_ms: 17851.358
    update_time_ms: 0.002
  iterations_since_restore: 113
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14154530801603848
    mean_inference_ms: 0.4352546630246655
    mean_processing_ms: 0.12432081388585846
  time_since_restore: 2513.0123374462128
  time_this_iter_s: 23.0235857963562
  time_total_s: 2513.0123374462128
  timestamp: 1563752311
  timesteps_since_restore: 2847600
  timesteps_this_iter: 25200
  timesteps_total: 2847600
  training_iteration: 113
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2513 s, 113 iter, 2847600 ts, 19.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-38-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.71502588478907
  episode_reward_mean: 18.083869730104425
  episode_reward_min: -1.6710771694576239
  episodes_this_iter: 168
  episodes_total: 19152
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4427.258
    learner:
      default_policy:
        cur_kl_coeff: 0.125
        cur_lr: 9.999999747378752e-05
        entropy: 1.1939024925231934
        kl: 0.02959977649152279
        policy_loss: -0.026679882779717445
        total_loss: 0.23530352115631104
        vf_explained_var: 0.9943692684173584
        vf_loss: 0.25828343629837036
    load_time_ms: 0.792
    num_steps_sampled: 2872800
    num_steps_trained: 2850000
    sample_time_ms: 17845.506
    update_time_ms: 0.002
  iterations_since_restore: 114
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14154541722477745
    mean_inference_ms: 0.43524445028203973
    mean_processing_ms: 0.12432557445194767
  time_since_restore: 2535.9174466133118
  time_this_iter_s: 22.905109167099
  time_total_s: 2535.9174466133118
  timestamp: 1563752334
  timesteps_since_restore: 2872800
  timesteps_this_iter: 25200
  timesteps_total: 2872800
  training_iteration: 114
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2535 s, 114 iter, 2872800 ts, 18.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-39-16
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.44679093873506
  episode_reward_mean: 17.560396680232365
  episode_reward_min: -3.915154175661123
  episodes_this_iter: 168
  episodes_total: 19320
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4366.079
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1778998374938965
        kl: 0.016481474041938782
        policy_loss: -0.02008446864783764
        total_loss: 0.04389703646302223
        vf_explained_var: 0.9982037544250488
        vf_loss: 0.06089123338460922
    load_time_ms: 0.799
    num_steps_sampled: 2898000
    num_steps_trained: 2875000
    sample_time_ms: 17846.969
    update_time_ms: 0.002
  iterations_since_restore: 115
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155461750965936
    mean_inference_ms: 0.4352730239756123
    mean_processing_ms: 0.12433960023807586
  time_since_restore: 2557.963538169861
  time_this_iter_s: 22.046091556549072
  time_total_s: 2557.963538169861
  timestamp: 1563752356
  timesteps_since_restore: 2898000
  timesteps_this_iter: 25200
  timesteps_total: 2898000
  training_iteration: 115
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2557 s, 115 iter, 2898000 ts, 17.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-39-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.05156970801601
  episode_reward_mean: 17.694292804362576
  episode_reward_min: -1.3174945687816175
  episodes_this_iter: 168
  episodes_total: 19488
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4415.126
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1665217876434326
        kl: 0.016285788267850876
        policy_loss: -0.02011737786233425
        total_loss: 0.026186252012848854
        vf_explained_var: 0.9987277388572693
        vf_loss: 0.04325004667043686
    load_time_ms: 0.781
    num_steps_sampled: 2923200
    num_steps_trained: 2900000
    sample_time_ms: 17832.042
    update_time_ms: 0.002
  iterations_since_restore: 116
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155743306306687
    mean_inference_ms: 0.4352966852403245
    mean_processing_ms: 0.12434688527362245
  time_since_restore: 2580.2646594047546
  time_this_iter_s: 22.3011212348938
  time_total_s: 2580.2646594047546
  timestamp: 1563752378
  timesteps_since_restore: 2923200
  timesteps_this_iter: 25200
  timesteps_total: 2923200
  training_iteration: 116
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2580 s, 116 iter, 2923200 ts, 17.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-40-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.04237365447874
  episode_reward_mean: 19.567467440939367
  episode_reward_min: -0.9987957625056892
  episodes_this_iter: 168
  episodes_total: 19656
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4320.973
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1529957056045532
        kl: 0.015490497462451458
        policy_loss: -0.026952097192406654
        total_loss: 0.012966884300112724
        vf_explained_var: 0.9990763664245605
        vf_loss: 0.037014514207839966
    load_time_ms: 0.781
    num_steps_sampled: 2948400
    num_steps_trained: 2925000
    sample_time_ms: 17842.207
    update_time_ms: 0.002
  iterations_since_restore: 117
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155392247321316
    mean_inference_ms: 0.4353117764238776
    mean_processing_ms: 0.12434987353583361
  time_since_restore: 2602.3225512504578
  time_this_iter_s: 22.057891845703125
  time_total_s: 2602.3225512504578
  timestamp: 1563752400
  timesteps_since_restore: 2948400
  timesteps_this_iter: 25200
  timesteps_total: 2948400
  training_iteration: 117
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2602 s, 117 iter, 2948400 ts, 19.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-40-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.95390362822161
  episode_reward_mean: 18.54184680491516
  episode_reward_min: 0.4975499837826471
  episodes_this_iter: 168
  episodes_total: 19824
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4447.117
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1466701030731201
        kl: 0.014985833317041397
        policy_loss: -0.021887339651584625
        total_loss: 0.02563168853521347
        vf_explained_var: 0.9987878203392029
        vf_loss: 0.044709183275699615
    load_time_ms: 0.779
    num_steps_sampled: 2973600
    num_steps_trained: 2950000
    sample_time_ms: 17867.02
    update_time_ms: 0.002
  iterations_since_restore: 118
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156498960899272
    mean_inference_ms: 0.4353357071825935
    mean_processing_ms: 0.12436624159328773
  time_since_restore: 2625.401350736618
  time_this_iter_s: 23.07879948616028
  time_total_s: 2625.401350736618
  timestamp: 1563752423
  timesteps_since_restore: 2973600
  timesteps_this_iter: 25200
  timesteps_total: 2973600
  training_iteration: 118
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2625 s, 118 iter, 2973600 ts, 18.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-40-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.03863078214425
  episode_reward_mean: 19.604491284131498
  episode_reward_min: 1.5323772885400582
  episodes_this_iter: 168
  episodes_total: 19992
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4568.515
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.129716157913208
        kl: 0.016949884593486786
        policy_loss: -0.0217053834348917
        total_loss: 0.02432333491742611
        vf_explained_var: 0.9989665746688843
        vf_loss: 0.042850613594055176
    load_time_ms: 0.78
    num_steps_sampled: 2998800
    num_steps_trained: 2975000
    sample_time_ms: 17859.299
    update_time_ms: 0.002
  iterations_since_restore: 119
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156331091832516
    mean_inference_ms: 0.43532875573385915
    mean_processing_ms: 0.12437003725750878
  time_since_restore: 2648.1457114219666
  time_this_iter_s: 22.74436068534851
  time_total_s: 2648.1457114219666
  timestamp: 1563752446
  timesteps_since_restore: 2998800
  timesteps_this_iter: 25200
  timesteps_total: 2998800
  training_iteration: 119
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2648 s, 119 iter, 2998800 ts, 19.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-41-09
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.04217997751575
  episode_reward_mean: 18.722636964383646
  episode_reward_min: -2.6030149386463144
  episodes_this_iter: 168
  episodes_total: 20160
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4707.208
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1170110702514648
        kl: 0.016936827450990677
        policy_loss: -0.02471516653895378
        total_loss: 0.008291634730994701
        vf_explained_var: 0.9992188811302185
        vf_loss: 0.029831144958734512
    load_time_ms: 0.78
    num_steps_sampled: 3024000
    num_steps_trained: 3000000
    sample_time_ms: 17847.646
    update_time_ms: 0.002
  iterations_since_restore: 120
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415602788922929
    mean_inference_ms: 0.43532864434846225
    mean_processing_ms: 0.12437220913906148
  time_since_restore: 2671.086261510849
  time_this_iter_s: 22.940550088882446
  time_total_s: 2671.086261510849
  timestamp: 1563752469
  timesteps_since_restore: 3024000
  timesteps_this_iter: 25200
  timesteps_total: 3024000
  training_iteration: 120
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2671 s, 120 iter, 3024000 ts, 18.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-41-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.53928397691198
  episode_reward_mean: 19.468504304010274
  episode_reward_min: -0.9044648073727598
  episodes_this_iter: 168
  episodes_total: 20328
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4710.532
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.1029787063598633
        kl: 0.014941607601940632
        policy_loss: -0.01908511109650135
        total_loss: 0.02880864217877388
        vf_explained_var: 0.9989223480224609
        vf_loss: 0.045092202723026276
    load_time_ms: 0.775
    num_steps_sampled: 3049200
    num_steps_trained: 3025000
    sample_time_ms: 17855.016
    update_time_ms: 0.002
  iterations_since_restore: 121
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155880817034983
    mean_inference_ms: 0.43534100798875824
    mean_processing_ms: 0.12438002261282702
  time_since_restore: 2694.096781015396
  time_this_iter_s: 23.01051950454712
  time_total_s: 2694.096781015396
  timestamp: 1563752492
  timesteps_since_restore: 3049200
  timesteps_this_iter: 25200
  timesteps_total: 3049200
  training_iteration: 121
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2694 s, 121 iter, 3049200 ts, 19.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-41-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.884583805834815
  episode_reward_mean: 18.234064376540204
  episode_reward_min: -2.165643362778745
  episodes_this_iter: 168
  episodes_total: 20496
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4838.453
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0864988565444946
        kl: 0.014934636652469635
        policy_loss: -0.02003317140042782
        total_loss: 0.012491878122091293
        vf_explained_var: 0.9991868734359741
        vf_loss: 0.02972480282187462
    load_time_ms: 0.766
    num_steps_sampled: 3074400
    num_steps_trained: 3050000
    sample_time_ms: 17862.577
    update_time_ms: 0.002
  iterations_since_restore: 122
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415682139276833
    mean_inference_ms: 0.4353377581341499
    mean_processing_ms: 0.12439519998656216
  time_since_restore: 2717.0882070064545
  time_this_iter_s: 22.99142599105835
  time_total_s: 2717.0882070064545
  timestamp: 1563752515
  timesteps_since_restore: 3074400
  timesteps_this_iter: 25200
  timesteps_total: 3074400
  training_iteration: 122
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2717 s, 122 iter, 3074400 ts, 18.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-42-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.665852011929594
  episode_reward_mean: 19.3302327797426
  episode_reward_min: -5.461500638106843
  episodes_this_iter: 168
  episodes_total: 20664
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4706.006
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0849446058273315
        kl: 0.01525503396987915
        policy_loss: -0.021396230906248093
        total_loss: 0.012860038317739964
        vf_explained_var: 0.9992491006851196
        vf_loss: 0.03139594942331314
    load_time_ms: 0.77
    num_steps_sampled: 3099600
    num_steps_trained: 3075000
    sample_time_ms: 17858.647
    update_time_ms: 0.002
  iterations_since_restore: 123
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157166319837125
    mean_inference_ms: 0.4353336292475588
    mean_processing_ms: 0.12440424295366356
  time_since_restore: 2738.7468650341034
  time_this_iter_s: 21.658658027648926
  time_total_s: 2738.7468650341034
  timestamp: 1563752537
  timesteps_since_restore: 3099600
  timesteps_this_iter: 25200
  timesteps_total: 3099600
  training_iteration: 123
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2738 s, 123 iter, 3099600 ts, 19.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-42-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.5183962900485
  episode_reward_mean: 18.940353941019545
  episode_reward_min: 0.12182492410067473
  episodes_this_iter: 168
  episodes_total: 20832
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4570.009
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0808871984481812
        kl: 0.014239518903195858
        policy_loss: -0.021263785660266876
        total_loss: 0.03681260719895363
        vf_explained_var: 0.9985842108726501
        vf_loss: 0.05540647357702255
    load_time_ms: 0.765
    num_steps_sampled: 3124800
    num_steps_trained: 3100000
    sample_time_ms: 17861.384
    update_time_ms: 0.002
  iterations_since_restore: 124
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157277054201642
    mean_inference_ms: 0.4353282618648483
    mean_processing_ms: 0.12441063189591904
  time_since_restore: 2760.3182163238525
  time_this_iter_s: 21.571351289749146
  time_total_s: 2760.3182163238525
  timestamp: 1563752558
  timesteps_since_restore: 3124800
  timesteps_this_iter: 25200
  timesteps_total: 3124800
  training_iteration: 124
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2760 s, 124 iter, 3124800 ts, 18.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-43-00
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.71470020139673
  episode_reward_mean: 18.807123796059
  episode_reward_min: -0.1693674657723747
  episodes_this_iter: 168
  episodes_total: 21000
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4570.283
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0722651481628418
        kl: 0.016092579811811447
        policy_loss: -0.017868082970380783
        total_loss: 0.01681768149137497
        vf_explained_var: 0.9992182850837708
        vf_loss: 0.03166840597987175
    load_time_ms: 0.756
    num_steps_sampled: 3150000
    num_steps_trained: 3125000
    sample_time_ms: 17846.207
    update_time_ms: 0.002
  iterations_since_restore: 125
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156920298438042
    mean_inference_ms: 0.4353259901856967
    mean_processing_ms: 0.12441476580957762
  time_since_restore: 2782.215361595154
  time_this_iter_s: 21.89714527130127
  time_total_s: 2782.215361595154
  timestamp: 1563752580
  timesteps_since_restore: 3150000
  timesteps_this_iter: 25200
  timesteps_total: 3150000
  training_iteration: 125
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2782 s, 125 iter, 3150000 ts, 18.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-43-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.80549389043109
  episode_reward_mean: 18.656441699126592
  episode_reward_min: -1.0160158238208639
  episodes_this_iter: 168
  episodes_total: 21168
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4513.648
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.060675024986267
        kl: 0.014874338172376156
        policy_loss: -0.02011801488697529
        total_loss: 0.013981794938445091
        vf_explained_var: 0.9991827607154846
        vf_loss: 0.03131087124347687
    load_time_ms: 0.743
    num_steps_sampled: 3175200
    num_steps_trained: 3150000
    sample_time_ms: 17836.755
    update_time_ms: 0.002
  iterations_since_restore: 126
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415648288462852
    mean_inference_ms: 0.4353286104121977
    mean_processing_ms: 0.12441722002011672
  time_since_restore: 2803.854215860367
  time_this_iter_s: 21.638854265213013
  time_total_s: 2803.854215860367
  timestamp: 1563752602
  timesteps_since_restore: 3175200
  timesteps_this_iter: 25200
  timesteps_total: 3175200
  training_iteration: 126
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2803 s, 126 iter, 3175200 ts, 18.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-43-44
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.07907983033893
  episode_reward_mean: 18.831172589556264
  episode_reward_min: -1.5854467349100372
  episodes_this_iter: 168
  episodes_total: 21336
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4515.982
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0491348505020142
        kl: 0.015583071857690811
        policy_loss: -0.019970322027802467
        total_loss: 0.025501802563667297
        vf_explained_var: 0.9988741278648376
        vf_loss: 0.04255029559135437
    load_time_ms: 0.747
    num_steps_sampled: 3200400
    num_steps_trained: 3175000
    sample_time_ms: 17839.864
    update_time_ms: 0.002
  iterations_since_restore: 127
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156418792463038
    mean_inference_ms: 0.43534721654599384
    mean_processing_ms: 0.12442169838895477
  time_since_restore: 2825.9662449359894
  time_this_iter_s: 22.11202907562256
  time_total_s: 2825.9662449359894
  timestamp: 1563752624
  timesteps_since_restore: 3200400
  timesteps_this_iter: 25200
  timesteps_total: 3200400
  training_iteration: 127
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2825 s, 127 iter, 3200400 ts, 18.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-44-07
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.65679404040581
  episode_reward_mean: 19.71279357846473
  episode_reward_min: -1.987978440692109
  episodes_this_iter: 168
  episodes_total: 21504
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4477.767
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0362775325775146
        kl: 0.01723187044262886
        policy_loss: -0.023306487128138542
        total_loss: 0.008456812240183353
        vf_explained_var: 0.9992693066596985
        vf_loss: 0.028532320633530617
    load_time_ms: 0.748
    num_steps_sampled: 3225600
    num_steps_trained: 3200000
    sample_time_ms: 17816.517
    update_time_ms: 0.002
  iterations_since_restore: 128
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155604235524324
    mean_inference_ms: 0.4353297933532919
    mean_processing_ms: 0.12442213875904781
  time_since_restore: 2848.429188013077
  time_this_iter_s: 22.462943077087402
  time_total_s: 2848.429188013077
  timestamp: 1563752647
  timesteps_since_restore: 3225600
  timesteps_this_iter: 25200
  timesteps_total: 3225600
  training_iteration: 128
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2848 s, 128 iter, 3225600 ts, 19.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-44-28
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.8243322207644
  episode_reward_mean: 19.095562190677477
  episode_reward_min: -1.034360184884296
  episodes_this_iter: 168
  episodes_total: 21672
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4366.681
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0194965600967407
        kl: 0.015196060761809349
        policy_loss: -0.025344910100102425
        total_loss: 0.004202030133455992
        vf_explained_var: 0.9992939829826355
        vf_loss: 0.02669767662882805
    load_time_ms: 0.749
    num_steps_sampled: 3250800
    num_steps_trained: 3225000
    sample_time_ms: 17814.766
    update_time_ms: 0.002
  iterations_since_restore: 129
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155125281277528
    mean_inference_ms: 0.4353240145987116
    mean_processing_ms: 0.12442313351075776
  time_since_restore: 2870.0445494651794
  time_this_iter_s: 21.61536145210266
  time_total_s: 2870.0445494651794
  timestamp: 1563752668
  timesteps_since_restore: 3250800
  timesteps_this_iter: 25200
  timesteps_total: 3250800
  training_iteration: 129
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2870 s, 129 iter, 3250800 ts, 19.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-44-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.55996723637658
  episode_reward_mean: 20.25745688391427
  episode_reward_min: -0.585675410037843
  episodes_this_iter: 168
  episodes_total: 21840
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4290.788
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0176758766174316
        kl: 0.01690192148089409
        policy_loss: -0.02519022487103939
        total_loss: 0.0034689349122345448
        vf_explained_var: 0.999376118183136
        vf_loss: 0.0254900474101305
    load_time_ms: 0.75
    num_steps_sampled: 3276000
    num_steps_trained: 3250000
    sample_time_ms: 17819.507
    update_time_ms: 0.002
  iterations_since_restore: 130
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415516822394298
    mean_inference_ms: 0.4353300526678795
    mean_processing_ms: 0.12442935954850817
  time_since_restore: 2892.2728729248047
  time_this_iter_s: 22.228323459625244
  time_total_s: 2892.2728729248047
  timestamp: 1563752690
  timesteps_since_restore: 3276000
  timesteps_this_iter: 25200
  timesteps_total: 3276000
  training_iteration: 130
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2892 s, 130 iter, 3276000 ts, 20.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-45-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.55498767064174
  episode_reward_mean: 18.589873778696354
  episode_reward_min: -0.42642219349908245
  episodes_this_iter: 168
  episodes_total: 22008
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4200.713
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 1.0082173347473145
        kl: 0.016012679785490036
        policy_loss: -0.025285208597779274
        total_loss: 0.0030237503815442324
        vf_explained_var: 0.9993879795074463
        vf_loss: 0.02530658058822155
    load_time_ms: 0.763
    num_steps_sampled: 3301200
    num_steps_trained: 3275000
    sample_time_ms: 17824.404
    update_time_ms: 0.002
  iterations_since_restore: 131
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415559117750034
    mean_inference_ms: 0.435345392510649
    mean_processing_ms: 0.12444142968952573
  time_since_restore: 2914.43119764328
  time_this_iter_s: 22.158324718475342
  time_total_s: 2914.43119764328
  timestamp: 1563752713
  timesteps_since_restore: 3301200
  timesteps_this_iter: 25200
  timesteps_total: 3301200
  training_iteration: 131
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2914 s, 131 iter, 3301200 ts, 18.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-45-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.14676366642702
  episode_reward_mean: 18.484775609246178
  episode_reward_min: -4.443993257185491
  episodes_this_iter: 168
  episodes_total: 22176
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4204.266
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9966206550598145
        kl: 0.018214017152786255
        policy_loss: -0.023564625531435013
        total_loss: 0.005400103982537985
        vf_explained_var: 0.9993681311607361
        vf_loss: 0.025549598038196564
    load_time_ms: 0.768
    num_steps_sampled: 3326400
    num_steps_trained: 3300000
    sample_time_ms: 17821.194
    update_time_ms: 0.002
  iterations_since_restore: 132
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155575789816674
    mean_inference_ms: 0.43534962789287246
    mean_processing_ms: 0.1244470694300731
  time_since_restore: 2937.425676584244
  time_this_iter_s: 22.994478940963745
  time_total_s: 2937.425676584244
  timestamp: 1563752736
  timesteps_since_restore: 3326400
  timesteps_this_iter: 25200
  timesteps_total: 3326400
  training_iteration: 132
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2937 s, 132 iter, 3326400 ts, 18.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-45-58
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.762485621304485
  episode_reward_mean: 18.349762140788297
  episode_reward_min: -1.6787719381624138
  episodes_this_iter: 168
  episodes_total: 22344
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4329.703
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9887737035751343
        kl: 0.018565205857157707
        policy_loss: -0.02534162439405918
        total_loss: 0.004793839529156685
        vf_explained_var: 0.9992828369140625
        vf_loss: 0.02665448933839798
    load_time_ms: 0.766
    num_steps_sampled: 3351600
    num_steps_trained: 3325000
    sample_time_ms: 17814.034
    update_time_ms: 0.002
  iterations_since_restore: 133
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155054296524086
    mean_inference_ms: 0.43533833403753824
    mean_processing_ms: 0.12444968368263275
  time_since_restore: 2960.2679872512817
  time_this_iter_s: 22.842310667037964
  time_total_s: 2960.2679872512817
  timestamp: 1563752758
  timesteps_since_restore: 3351600
  timesteps_this_iter: 25200
  timesteps_total: 3351600
  training_iteration: 133
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2960 s, 133 iter, 3351600 ts, 18.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-46-20
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.282100591593746
  episode_reward_mean: 18.577236377272822
  episode_reward_min: -0.6102565571992009
  episodes_this_iter: 168
  episodes_total: 22512
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4337.635
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9729128479957581
        kl: 0.015148469246923923
        policy_loss: -0.02346942573785782
        total_loss: 0.001920522889122367
        vf_explained_var: 0.9994000196456909
        vf_loss: 0.02254960499703884
    load_time_ms: 0.77
    num_steps_sampled: 3376800
    num_steps_trained: 3350000
    sample_time_ms: 17815.067
    update_time_ms: 0.002
  iterations_since_restore: 134
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155707084990055
    mean_inference_ms: 0.43532297217283317
    mean_processing_ms: 0.12446300900145577
  time_since_restore: 2981.929167032242
  time_this_iter_s: 21.661179780960083
  time_total_s: 2981.929167032242
  timestamp: 1563752780
  timesteps_since_restore: 3376800
  timesteps_this_iter: 25200
  timesteps_total: 3376800
  training_iteration: 134
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 2981 s, 134 iter, 3376800 ts, 18.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-46-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.28657437413204
  episode_reward_mean: 18.291748841662063
  episode_reward_min: -2.500499661835546
  episodes_this_iter: 168
  episodes_total: 22680
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4321.53
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9618812799453735
        kl: 0.01811285689473152
        policy_loss: -0.023045208305120468
        total_loss: 0.00296037457883358
        vf_explained_var: 0.9993982911109924
        vf_loss: 0.022609420120716095
    load_time_ms: 0.771
    num_steps_sampled: 3402000
    num_steps_trained: 3375000
    sample_time_ms: 17809.359
    update_time_ms: 0.002
  iterations_since_restore: 135
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155748563713158
    mean_inference_ms: 0.4352965607378144
    mean_processing_ms: 0.124470309320699
  time_since_restore: 3003.608096599579
  time_this_iter_s: 21.678929567337036
  time_total_s: 3003.608096599579
  timestamp: 1563752802
  timesteps_since_restore: 3402000
  timesteps_this_iter: 25200
  timesteps_total: 3402000
  training_iteration: 135
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3003 s, 135 iter, 3402000 ts, 18.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-47-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.8393505031733
  episode_reward_mean: 18.795562363971992
  episode_reward_min: -12.696597417945943
  episodes_this_iter: 168
  episodes_total: 22848
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4321.603
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9558625221252441
        kl: 0.01806194894015789
        policy_loss: -0.012361832894384861
        total_loss: 0.040552183985710144
        vf_explained_var: 0.9988450407981873
        vf_loss: 0.049527402967214584
    load_time_ms: 0.768
    num_steps_sampled: 3427200
    num_steps_trained: 3400000
    sample_time_ms: 17815.764
    update_time_ms: 0.002
  iterations_since_restore: 136
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156675258228782
    mean_inference_ms: 0.43529238918828467
    mean_processing_ms: 0.1244842958741815
  time_since_restore: 3025.3117611408234
  time_this_iter_s: 21.703664541244507
  time_total_s: 3025.3117611408234
  timestamp: 1563752824
  timesteps_since_restore: 3427200
  timesteps_this_iter: 25200
  timesteps_total: 3427200
  training_iteration: 136
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3025 s, 136 iter, 3427200 ts, 18.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-47-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.87194117318791
  episode_reward_mean: 18.663668710866236
  episode_reward_min: -0.848474417453191
  episodes_this_iter: 168
  episodes_total: 23016
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4409.425
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9470213055610657
        kl: 0.018454348668456078
        policy_loss: -0.023340992629528046
        total_loss: 0.007114190608263016
        vf_explained_var: 0.9993122816085815
        vf_loss: 0.026994993910193443
    load_time_ms: 0.764
    num_steps_sampled: 3452400
    num_steps_trained: 3425000
    sample_time_ms: 17806.518
    update_time_ms: 0.002
  iterations_since_restore: 137
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156107887125371
    mean_inference_ms: 0.4352907351650245
    mean_processing_ms: 0.12448528344923712
  time_since_restore: 3048.2102484703064
  time_this_iter_s: 22.898487329483032
  time_total_s: 3048.2102484703064
  timestamp: 1563752846
  timesteps_since_restore: 3452400
  timesteps_this_iter: 25200
  timesteps_total: 3452400
  training_iteration: 137
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3048 s, 137 iter, 3452400 ts, 18.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-47-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.99986087723259
  episode_reward_mean: 18.90930585022458
  episode_reward_min: -0.6258219092842312
  episodes_this_iter: 168
  episodes_total: 23184
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4375.645
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9332380890846252
        kl: 0.016210446134209633
        policy_loss: -0.021431181579828262
        total_loss: 0.004907163791358471
        vf_explained_var: 0.9993642568588257
        vf_loss: 0.02329888753592968
    load_time_ms: 0.768
    num_steps_sampled: 3477600
    num_steps_trained: 3450000
    sample_time_ms: 17823.613
    update_time_ms: 0.002
  iterations_since_restore: 138
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156589619049864
    mean_inference_ms: 0.43530167096701466
    mean_processing_ms: 0.12449496019387665
  time_since_restore: 3070.506033182144
  time_this_iter_s: 22.29578471183777
  time_total_s: 3070.506033182144
  timestamp: 1563752869
  timesteps_since_restore: 3477600
  timesteps_this_iter: 25200
  timesteps_total: 3477600
  training_iteration: 138
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3070 s, 138 iter, 3477600 ts, 18.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-48-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.939465975821655
  episode_reward_mean: 19.027258072246532
  episode_reward_min: -4.466642296549335
  episodes_this_iter: 168
  episodes_total: 23352
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4505.5
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.924807608127594
        kl: 0.017751146107912064
        policy_loss: -0.02221955545246601
        total_loss: 0.007744614966213703
        vf_explained_var: 0.9992988109588623
        vf_loss: 0.026635833084583282
    load_time_ms: 0.769
    num_steps_sampled: 3502800
    num_steps_trained: 3475000
    sample_time_ms: 17822.406
    update_time_ms: 0.002
  iterations_since_restore: 139
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155858346450403
    mean_inference_ms: 0.4352961204603667
    mean_processing_ms: 0.12449510090627045
  time_since_restore: 3093.408735513687
  time_this_iter_s: 22.90270233154297
  time_total_s: 3093.408735513687
  timestamp: 1563752892
  timesteps_since_restore: 3502800
  timesteps_this_iter: 25200
  timesteps_total: 3502800
  training_iteration: 139
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3093 s, 139 iter, 3502800 ts, 19 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-48-33
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.36729134941132
  episode_reward_mean: 17.816191004281894
  episode_reward_min: -7.487439850268308
  episodes_this_iter: 168
  episodes_total: 23520
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4453.769
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9114530086517334
        kl: 0.018696190789341927
        policy_loss: -0.022226590663194656
        total_loss: 0.005669957958161831
        vf_explained_var: 0.999299168586731
        vf_loss: 0.024391014128923416
    load_time_ms: 0.769
    num_steps_sampled: 3528000
    num_steps_trained: 3500000
    sample_time_ms: 17815.806
    update_time_ms: 0.002
  iterations_since_restore: 140
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415541248580339
    mean_inference_ms: 0.4352907993394811
    mean_processing_ms: 0.12449809421062641
  time_since_restore: 3115.053548812866
  time_this_iter_s: 21.644813299179077
  time_total_s: 3115.053548812866
  timestamp: 1563752913
  timesteps_since_restore: 3528000
  timesteps_this_iter: 25200
  timesteps_total: 3528000
  training_iteration: 140
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3115 s, 140 iter, 3528000 ts, 17.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-48-56
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 36.72060750021545
  episode_reward_mean: 18.15146608532505
  episode_reward_min: -1.1023769088835678
  episodes_this_iter: 168
  episodes_total: 23688
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4465.054
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.9029994010925293
        kl: 0.017077064141631126
        policy_loss: -0.024452609941363335
        total_loss: 0.00041423915536142886
        vf_explained_var: 0.9994128346443176
        vf_loss: 0.021664898842573166
    load_time_ms: 0.76
    num_steps_sampled: 3553200
    num_steps_trained: 3525000
    sample_time_ms: 17806.208
    update_time_ms: 0.002
  iterations_since_restore: 141
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155251708246702
    mean_inference_ms: 0.43528990182053573
    mean_processing_ms: 0.12450260203728776
  time_since_restore: 3137.228622674942
  time_this_iter_s: 22.175073862075806
  time_total_s: 3137.228622674942
  timestamp: 1563752936
  timesteps_since_restore: 3553200
  timesteps_this_iter: 25200
  timesteps_total: 3553200
  training_iteration: 141
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3137 s, 141 iter, 3553200 ts, 18.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-49-19
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.54629465313845
  episode_reward_mean: 18.468932655415493
  episode_reward_min: -2.9178610048756544
  episodes_this_iter: 168
  episodes_total: 23856
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4460.287
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.8974892497062683
        kl: 0.016960442066192627
        policy_loss: -0.025085289031267166
        total_loss: -0.0010900432243943214
        vf_explained_var: 0.9994503855705261
        vf_loss: 0.020815160125494003
    load_time_ms: 0.784
    num_steps_sampled: 3578400
    num_steps_trained: 3550000
    sample_time_ms: 17818.122
    update_time_ms: 0.002
  iterations_since_restore: 142
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155477173959594
    mean_inference_ms: 0.4353088253875382
    mean_processing_ms: 0.12451040084943067
  time_since_restore: 3160.296903371811
  time_this_iter_s: 23.068280696868896
  time_total_s: 3160.296903371811
  timestamp: 1563752959
  timesteps_since_restore: 3578400
  timesteps_this_iter: 25200
  timesteps_total: 3578400
  training_iteration: 142
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3160 s, 142 iter, 3578400 ts, 18.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-49-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.9131427130462
  episode_reward_mean: 18.81506446221714
  episode_reward_min: -6.29455466317233
  episodes_this_iter: 168
  episodes_total: 24024
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4464.074
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.885884165763855
        kl: 0.016555745154619217
        policy_loss: -0.02342928946018219
        total_loss: 0.003651506034657359
        vf_explained_var: 0.9993759393692017
        vf_loss: 0.02397659234702587
    load_time_ms: 0.778
    num_steps_sampled: 3603600
    num_steps_trained: 3575000
    sample_time_ms: 17830.604
    update_time_ms: 0.002
  iterations_since_restore: 143
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155797490897484
    mean_inference_ms: 0.43531967468704125
    mean_processing_ms: 0.12451787443865638
  time_since_restore: 3183.301968574524
  time_this_iter_s: 23.005065202713013
  time_total_s: 3183.301968574524
  timestamp: 1563752982
  timesteps_since_restore: 3603600
  timesteps_this_iter: 25200
  timesteps_total: 3603600
  training_iteration: 143
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3183 s, 143 iter, 3603600 ts, 18.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-50-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.85836734776781
  episode_reward_mean: 18.418265291647074
  episode_reward_min: -0.47956136545845607
  episodes_this_iter: 168
  episodes_total: 24192
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4462.947
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.8782159686088562
        kl: 0.019313929602503777
        policy_loss: -0.021773897111415863
        total_loss: 0.007527979556471109
        vf_explained_var: 0.9993155002593994
        vf_loss: 0.02568051405251026
    load_time_ms: 0.781
    num_steps_sampled: 3628800
    num_steps_trained: 3600000
    sample_time_ms: 17831.738
    update_time_ms: 0.002
  iterations_since_restore: 144
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155616863999598
    mean_inference_ms: 0.4353257204352804
    mean_processing_ms: 0.12452072217365615
  time_since_restore: 3204.963084936142
  time_this_iter_s: 21.661116361618042
  time_total_s: 3204.963084936142
  timestamp: 1563753003
  timesteps_since_restore: 3628800
  timesteps_this_iter: 25200
  timesteps_total: 3628800
  training_iteration: 144
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3204 s, 144 iter, 3628800 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-50-26
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.62353040415921
  episode_reward_mean: 20.33040571031541
  episode_reward_min: -1.6649174278891707
  episodes_this_iter: 168
  episodes_total: 24360
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4583.595
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.8721547722816467
        kl: 0.01635807752609253
        policy_loss: -0.024658644571900368
        total_loss: 0.0020976888481527567
        vf_explained_var: 0.9994280934333801
        vf_loss: 0.02368919551372528
    load_time_ms: 0.781
    num_steps_sampled: 3654000
    num_steps_trained: 3625000
    sample_time_ms: 17840.709
    update_time_ms: 0.002
  iterations_since_restore: 145
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155412100538403
    mean_inference_ms: 0.43533105979994036
    mean_processing_ms: 0.12452439210729672
  time_since_restore: 3227.939168214798
  time_this_iter_s: 22.976083278656006
  time_total_s: 3227.939168214798
  timestamp: 1563753026
  timesteps_since_restore: 3654000
  timesteps_this_iter: 25200
  timesteps_total: 3654000
  training_iteration: 145
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3227 s, 145 iter, 3654000 ts, 20.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-50-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.48784180622634
  episode_reward_mean: 19.989780423536793
  episode_reward_min: 1.1947366042721272
  episodes_this_iter: 168
  episodes_total: 24528
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4621.708
    learner:
      default_policy:
        cur_kl_coeff: 0.1875
        cur_lr: 9.999999747378752e-05
        entropy: 0.8627593517303467
        kl: 0.020273452624678612
        policy_loss: -0.02624351717531681
        total_loss: -0.004380987491458654
        vf_explained_var: 0.999555230140686
        vf_loss: 0.018061256036162376
    load_time_ms: 0.792
    num_steps_sampled: 3679200
    num_steps_trained: 3650000
    sample_time_ms: 17837.19
    update_time_ms: 0.002
  iterations_since_restore: 146
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415611453439911
    mean_inference_ms: 0.43531977721678217
    mean_processing_ms: 0.12453597214164634
  time_since_restore: 3249.990039587021
  time_this_iter_s: 22.0508713722229
  time_total_s: 3249.990039587021
  timestamp: 1563753048
  timesteps_since_restore: 3679200
  timesteps_this_iter: 25200
  timesteps_total: 3679200
  training_iteration: 146
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3249 s, 146 iter, 3679200 ts, 20 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-51-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.60183334486033
  episode_reward_mean: 19.31242526487683
  episode_reward_min: -7.463400728899309
  episodes_this_iter: 168
  episodes_total: 24696
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4532.874
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.8614029884338379
        kl: 0.014283857308328152
        policy_loss: -0.0208274032920599
        total_loss: 0.03535744175314903
        vf_explained_var: 0.9986973404884338
        vf_loss: 0.05216750502586365
    load_time_ms: 0.792
    num_steps_sampled: 3704400
    num_steps_trained: 3675000
    sample_time_ms: 17849.013
    update_time_ms: 0.002
  iterations_since_restore: 147
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156879160869476
    mean_inference_ms: 0.43532502032799686
    mean_processing_ms: 0.12454792869129164
  time_since_restore: 3272.1178834438324
  time_this_iter_s: 22.127843856811523
  time_total_s: 3272.1178834438324
  timestamp: 1563753070
  timesteps_since_restore: 3704400
  timesteps_this_iter: 25200
  timesteps_total: 3704400
  training_iteration: 147
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3272 s, 147 iter, 3704400 ts, 19.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-51-32
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.417231723460354
  episode_reward_mean: 19.922638526708127
  episode_reward_min: -0.38598084243049724
  episodes_this_iter: 168
  episodes_total: 24864
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4475.523
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.8476466536521912
        kl: 0.01604853942990303
        policy_loss: -0.02187270112335682
        total_loss: 0.0009708995930850506
        vf_explained_var: 0.9995836019515991
        vf_loss: 0.018329953774809837
    load_time_ms: 0.787
    num_steps_sampled: 3729600
    num_steps_trained: 3700000
    sample_time_ms: 17852.482
    update_time_ms: 0.002
  iterations_since_restore: 148
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157513107411582
    mean_inference_ms: 0.43533828792289697
    mean_processing_ms: 0.12456056020199154
  time_since_restore: 3293.8746304512024
  time_this_iter_s: 21.756747007369995
  time_total_s: 3293.8746304512024
  timestamp: 1563753092
  timesteps_since_restore: 3729600
  timesteps_this_iter: 25200
  timesteps_total: 3729600
  training_iteration: 148
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3293 s, 148 iter, 3729600 ts, 19.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-51-54
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.33326020906238
  episode_reward_mean: 18.425856992232443
  episode_reward_min: 0.14038755340413137
  episodes_this_iter: 168
  episodes_total: 25032
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4345.586
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.837256908416748
        kl: 0.015876509249210358
        policy_loss: -0.02559933252632618
        total_loss: -0.001984070520848036
        vf_explained_var: 0.9994775652885437
        vf_loss: 0.01914999447762966
    load_time_ms: 0.782
    num_steps_sampled: 3754800
    num_steps_trained: 3725000
    sample_time_ms: 17858.054
    update_time_ms: 0.002
  iterations_since_restore: 149
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415685822930397
    mean_inference_ms: 0.4353461900423427
    mean_processing_ms: 0.12456098021120529
  time_since_restore: 3315.532957315445
  time_this_iter_s: 21.658326864242554
  time_total_s: 3315.532957315445
  timestamp: 1563753114
  timesteps_since_restore: 3754800
  timesteps_this_iter: 25200
  timesteps_total: 3754800
  training_iteration: 149
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3315 s, 149 iter, 3754800 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-52-16
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 37.62603789399728
  episode_reward_mean: 17.74455241316245
  episode_reward_min: -2.8699280466230834
  episodes_this_iter: 168
  episodes_total: 25200
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4342.159
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.8270647525787354
        kl: 0.01609829068183899
        policy_loss: -0.026125144213438034
        total_loss: -0.0032763921190053225
        vf_explained_var: 0.9995177388191223
        vf_loss: 0.01832110434770584
    load_time_ms: 0.783
    num_steps_sampled: 3780000
    num_steps_trained: 3750000
    sample_time_ms: 17867.578
    update_time_ms: 0.002
  iterations_since_restore: 150
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.141571178461978
    mean_inference_ms: 0.43535453730731566
    mean_processing_ms: 0.12456787153050246
  time_since_restore: 3337.238623380661
  time_this_iter_s: 21.705666065216064
  time_total_s: 3337.238623380661
  timestamp: 1563753136
  timesteps_since_restore: 3780000
  timesteps_this_iter: 25200
  timesteps_total: 3780000
  training_iteration: 150
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3337 s, 150 iter, 3780000 ts, 17.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-52-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.875049252332644
  episode_reward_mean: 19.111092133806498
  episode_reward_min: 1.4620116209431826
  episodes_this_iter: 168
  episodes_total: 25368
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4281.546
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.8228577375411987
        kl: 0.014882523566484451
        policy_loss: -0.027054980397224426
        total_loss: -0.0039207823574543
        vf_explained_var: 0.9994972944259644
        vf_loss: 0.018948489800095558
    load_time_ms: 0.784
    num_steps_sampled: 3805200
    num_steps_trained: 3775000
    sample_time_ms: 17881.307
    update_time_ms: 0.002
  iterations_since_restore: 151
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157823856765808
    mean_inference_ms: 0.43537331794797407
    mean_processing_ms: 0.12457887867217529
  time_since_restore: 3358.9446470737457
  time_this_iter_s: 21.706023693084717
  time_total_s: 3358.9446470737457
  timestamp: 1563753157
  timesteps_since_restore: 3805200
  timesteps_this_iter: 25200
  timesteps_total: 3805200
  training_iteration: 151
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3358 s, 151 iter, 3805200 ts, 19.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-52-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.131385822652845
  episode_reward_mean: 18.360750452784483
  episode_reward_min: -11.59586809237208
  episodes_this_iter: 168
  episodes_total: 25536
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4191.389
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.8162184953689575
        kl: 0.014504985883831978
        policy_loss: -0.01711411029100418
        total_loss: 0.02807682193815708
        vf_explained_var: 0.9989109635353088
        vf_loss: 0.04111141338944435
    load_time_ms: 0.756
    num_steps_sampled: 3830400
    num_steps_trained: 3800000
    sample_time_ms: 17869.483
    update_time_ms: 0.002
  iterations_since_restore: 152
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157896583980942
    mean_inference_ms: 0.4353715469987184
    mean_processing_ms: 0.12458745539202934
  time_since_restore: 3380.990132331848
  time_this_iter_s: 22.045485258102417
  time_total_s: 3380.990132331848
  timestamp: 1563753179
  timesteps_since_restore: 3830400
  timesteps_this_iter: 25200
  timesteps_total: 3830400
  training_iteration: 152
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3380 s, 152 iter, 3830400 ts, 18.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-53-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.34821477254593
  episode_reward_mean: 19.272969777299593
  episode_reward_min: -1.3716838297068106
  episodes_this_iter: 168
  episodes_total: 25704
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4101.217
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.81206214427948
        kl: 0.012948005460202694
        policy_loss: -0.020170550793409348
        total_loss: 0.0034765165764838457
        vf_explained_var: 0.9995130896568298
        vf_loss: 0.020005442202091217
    load_time_ms: 0.759
    num_steps_sampled: 3855600
    num_steps_trained: 3825000
    sample_time_ms: 17869.445
    update_time_ms: 0.002
  iterations_since_restore: 153
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14158120936986826
    mean_inference_ms: 0.4353802211974859
    mean_processing_ms: 0.12459566677564607
  time_since_restore: 3403.0926365852356
  time_this_iter_s: 22.10250425338745
  time_total_s: 3403.0926365852356
  timestamp: 1563753201
  timesteps_since_restore: 3855600
  timesteps_this_iter: 25200
  timesteps_total: 3855600
  training_iteration: 153
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3403 s, 153 iter, 3855600 ts, 19.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-53-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.024089117485076
  episode_reward_mean: 19.50500098047704
  episode_reward_min: -0.6560129653186004
  episodes_this_iter: 168
  episodes_total: 25872
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4101.512
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7958061099052429
        kl: 0.016708537936210632
        policy_loss: -0.023479411378502846
        total_loss: 6.073251279303804e-05
        vf_explained_var: 0.999531090259552
        vf_loss: 0.018840868026018143
    load_time_ms: 0.757
    num_steps_sampled: 3880800
    num_steps_trained: 3850000
    sample_time_ms: 17868.43
    update_time_ms: 0.002
  iterations_since_restore: 154
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157978826168563
    mean_inference_ms: 0.43538040375384124
    mean_processing_ms: 0.12460006174104568
  time_since_restore: 3424.746693611145
  time_this_iter_s: 21.654057025909424
  time_total_s: 3424.746693611145
  timestamp: 1563753223
  timesteps_since_restore: 3880800
  timesteps_this_iter: 25200
  timesteps_total: 3880800
  training_iteration: 154
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3424 s, 154 iter, 3880800 ts, 19.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-54-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.42392785187446
  episode_reward_mean: 19.274535202248373
  episode_reward_min: -0.5524815185697566
  episodes_this_iter: 168
  episodes_total: 26040
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4077.101
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7909320592880249
        kl: 0.01605728454887867
        policy_loss: -0.02361745573580265
        total_loss: -0.0019541485235095024
        vf_explained_var: 0.9995784759521484
        vf_loss: 0.01714719645678997
    load_time_ms: 0.755
    num_steps_sampled: 3906000
    num_steps_trained: 3875000
    sample_time_ms: 17865.629
    update_time_ms: 0.002
  iterations_since_restore: 155
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14157729020571658
    mean_inference_ms: 0.43537687076627746
    mean_processing_ms: 0.12460420448916096
  time_since_restore: 3447.4504582881927
  time_this_iter_s: 22.70376467704773
  time_total_s: 3447.4504582881927
  timestamp: 1563753246
  timesteps_since_restore: 3906000
  timesteps_this_iter: 25200
  timesteps_total: 3906000
  training_iteration: 155
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3447 s, 155 iter, 3906000 ts, 19.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-54-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.85672168490512
  episode_reward_mean: 20.0649666393848
  episode_reward_min: -0.21075053074274266
  episodes_this_iter: 168
  episodes_total: 26208
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4167.179
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7815690636634827
        kl: 0.016345426440238953
        policy_loss: -0.02245265431702137
        total_loss: -0.0033620698377490044
        vf_explained_var: 0.9996612668037415
        vf_loss: 0.014493432827293873
    load_time_ms: 0.746
    num_steps_sampled: 3931200
    num_steps_trained: 3900000
    sample_time_ms: 17855.622
    update_time_ms: 0.002
  iterations_since_restore: 156
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156636951289495
    mean_inference_ms: 0.43537260908655756
    mean_processing_ms: 0.12460034866061906
  time_since_restore: 3470.3016591072083
  time_this_iter_s: 22.851200819015503
  time_total_s: 3470.3016591072083
  timestamp: 1563753269
  timesteps_since_restore: 3931200
  timesteps_this_iter: 25200
  timesteps_total: 3931200
  training_iteration: 156
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3470 s, 156 iter, 3931200 ts, 20.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-54-51
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.508420334694016
  episode_reward_mean: 20.06386794248369
  episode_reward_min: 0.19678267452065362
  episodes_this_iter: 168
  episodes_total: 26376
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4183.682
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7751851677894592
        kl: 0.015919266268610954
        policy_loss: -0.02519620582461357
        total_loss: -0.005827701650559902
        vf_explained_var: 0.9996569156646729
        vf_loss: 0.014891207218170166
    load_time_ms: 0.746
    num_steps_sampled: 3956400
    num_steps_trained: 3925000
    sample_time_ms: 17850.042
    update_time_ms: 0.002
  iterations_since_restore: 157
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156421147543227
    mean_inference_ms: 0.4353820985877519
    mean_processing_ms: 0.12460218206384388
  time_since_restore: 3492.5386502742767
  time_this_iter_s: 22.23699116706848
  time_total_s: 3492.5386502742767
  timestamp: 1563753291
  timesteps_since_restore: 3956400
  timesteps_this_iter: 25200
  timesteps_total: 3956400
  training_iteration: 157
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3492 s, 157 iter, 3956400 ts, 20.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-55-14
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.181251352779974
  episode_reward_mean: 19.020198088184152
  episode_reward_min: -2.988074121134236
  episodes_this_iter: 168
  episodes_total: 26544
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4317.043
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7651967406272888
        kl: 0.01623327098786831
        policy_loss: -0.023796670138835907
        total_loss: -0.004015334881842136
        vf_explained_var: 0.9995909929275513
        vf_loss: 0.015215721912682056
    load_time_ms: 0.738
    num_steps_sampled: 3981600
    num_steps_trained: 3950000
    sample_time_ms: 17839.097
    update_time_ms: 0.002
  iterations_since_restore: 158
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156650427590686
    mean_inference_ms: 0.43537464496014794
    mean_processing_ms: 0.12460933901149819
  time_since_restore: 3515.5204331874847
  time_this_iter_s: 22.981782913208008
  time_total_s: 3515.5204331874847
  timestamp: 1563753314
  timesteps_since_restore: 3981600
  timesteps_this_iter: 25200
  timesteps_total: 3981600
  training_iteration: 158
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3515 s, 158 iter, 3981600 ts, 19 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-55-37
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.356709557409275
  episode_reward_mean: 19.58160602257793
  episode_reward_min: -0.340417692964575
  episodes_this_iter: 168
  episodes_total: 26712
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4446.565
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7497544884681702
        kl: 0.017400868237018585
        policy_loss: -0.02611033245921135
        total_loss: -0.00521504832431674
        vf_explained_var: 0.9996346235275269
        vf_loss: 0.016001293435692787
    load_time_ms: 0.739
    num_steps_sampled: 4006800
    num_steps_trained: 3975000
    sample_time_ms: 17831.254
    update_time_ms: 0.002
  iterations_since_restore: 159
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14156309517492058
    mean_inference_ms: 0.43535895037773725
    mean_processing_ms: 0.12461041494640404
  time_since_restore: 3538.396483182907
  time_this_iter_s: 22.876049995422363
  time_total_s: 3538.396483182907
  timestamp: 1563753337
  timesteps_since_restore: 4006800
  timesteps_this_iter: 25200
  timesteps_total: 4006800
  training_iteration: 159
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3538 s, 159 iter, 4006800 ts, 19.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-55-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.4271520630654
  episode_reward_mean: 18.124669745231778
  episode_reward_min: -0.901195993349111
  episodes_this_iter: 168
  episodes_total: 26880
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4460.373
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7351698279380798
        kl: 0.018675457686185837
        policy_loss: -0.025558412075042725
        total_loss: -0.005906541831791401
        vf_explained_var: 0.9996500611305237
        vf_loss: 0.014399398118257523
    load_time_ms: 0.73
    num_steps_sampled: 4032000
    num_steps_trained: 4000000
    sample_time_ms: 17825.558
    update_time_ms: 0.002
  iterations_since_restore: 160
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415606828348186
    mean_inference_ms: 0.4353591079496409
    mean_processing_ms: 0.124615054892558
  time_since_restore: 3560.183217525482
  time_this_iter_s: 21.786734342575073
  time_total_s: 3560.183217525482
  timestamp: 1563753359
  timesteps_since_restore: 4032000
  timesteps_this_iter: 25200
  timesteps_total: 4032000
  training_iteration: 160
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3560 s, 160 iter, 4032000 ts, 18.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-56-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 38.84558283855208
  episode_reward_mean: 18.218091275029423
  episode_reward_min: 0.003433265277483971
  episodes_this_iter: 168
  episodes_total: 27048
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4523.847
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7275668382644653
        kl: 0.0174007099121809
        policy_loss: -0.02671022154390812
        total_loss: -0.007944355718791485
        vf_explained_var: 0.9996232390403748
        vf_loss: 0.013871910981833935
    load_time_ms: 0.726
    num_steps_sampled: 4057200
    num_steps_trained: 4025000
    sample_time_ms: 17810.867
    update_time_ms: 0.002
  iterations_since_restore: 161
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415556439039304
    mean_inference_ms: 0.4353601323943144
    mean_processing_ms: 0.124617467445373
  time_since_restore: 3582.377272605896
  time_this_iter_s: 22.19405508041382
  time_total_s: 3582.377272605896
  timestamp: 1563753381
  timesteps_since_restore: 4057200
  timesteps_this_iter: 25200
  timesteps_total: 4057200
  training_iteration: 161
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3582 s, 161 iter, 4057200 ts, 18.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-56-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 39.45732245754324
  episode_reward_mean: 19.070233016851745
  episode_reward_min: -0.4671127030404986
  episodes_this_iter: 168
  episodes_total: 27216
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4488.817
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7264763116836548
        kl: 0.015900680795311928
        policy_loss: -0.018988754600286484
        total_loss: 0.006400780752301216
        vf_explained_var: 0.9994249939918518
        vf_loss: 0.020917469635605812
    load_time_ms: 0.72
    num_steps_sampled: 4082400
    num_steps_trained: 4050000
    sample_time_ms: 17809.608
    update_time_ms: 0.002
  iterations_since_restore: 162
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.1415552032310663
    mean_inference_ms: 0.43535919007539275
    mean_processing_ms: 0.1246226880037012
  time_since_restore: 3604.0595078468323
  time_this_iter_s: 21.68223524093628
  time_total_s: 3604.0595078468323
  timestamp: 1563753403
  timesteps_since_restore: 4082400
  timesteps_this_iter: 25200
  timesteps_total: 4082400
  training_iteration: 162
  2019-07-22 01:57:05,591	INFO ray_trial_executor.py:187 -- Destroying actor for trial PPO_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=31829], 3604 s, 162 iter, 4082400 ts, 19.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-22_01-57-05
  done: true
  episode_len_mean: 150.0
  episode_reward_max: 39.841184001927274
  episode_reward_mean: 21.05862622332213
  episode_reward_min: 0.37399617397405904
  episodes_this_iter: 168
  episodes_total: 27384
  experiment_id: a76ad5ee118c419682be5de99782b501
  hostname: navel-notebook-1
  info:
    grad_time_ms: 4540.467
    learner:
      default_policy:
        cur_kl_coeff: 0.28125
        cur_lr: 9.999999747378752e-05
        entropy: 0.7117065191268921
        kl: 0.015853697434067726
        policy_loss: -0.022721610963344574
        total_loss: -0.0030491119250655174
        vf_explained_var: 0.9996528029441833
        vf_loss: 0.015213645994663239
    load_time_ms: 0.724
    num_steps_sampled: 4107600
    num_steps_trained: 4075000
    sample_time_ms: 17801.41
    update_time_ms: 0.002
  iterations_since_restore: 163
  node_ip: 10.16.128.63
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 31829
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.14155430361909854
    mean_inference_ms: 0.43535303879119713
    mean_processing_ms: 0.12462759741592952
  time_since_restore: 3626.5966713428497
  time_this_iter_s: 22.537163496017456
  time_total_s: 3626.5966713428497
  timestamp: 1563753425
  timesteps_since_restore: 4107600
  timesteps_this_iter: 25200
  timesteps_total: 4107600
  training_iteration: 163
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_RoboschoolReacher-v1_0:	TERMINATED, [1 CPUs, 0 GPUs], [pid=31829], 3626 s, 163 iter, 4107600 ts, 21.1 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/12 CPUs, 0/1 GPUs
Memory usage on this node: 3.3/16.7 GB
Result logdir: /home/amr/kayray_results/local/gym-reacher-ppo-baseline
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_RoboschoolReacher-v1_0:	TERMINATED, [1 CPUs, 0 GPUs], [pid=31829], 3626 s, 163 iter, 4107600 ts, 21.1 rew

[32m [  3633.02135s,  INFO] Experiment took 3632.81629 seconds | 60.54694 minutes | 1.00912 hours [0m

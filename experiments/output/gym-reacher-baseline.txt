2019-07-14 02:26:12,831	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-14_02-26-12_830383_1172/logs.
2019-07-14 02:26:12,939	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:21535 to respond...
2019-07-14 02:26:13,056	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:63996 to respond...
2019-07-14 02:26:13,059	INFO services.py:806 -- Starting Redis shard with 1.72 GB max memory.
2019-07-14 02:26:13,132	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-14_02-26-12_830383_1172/logs.
2019-07-14 02:26:13,135	INFO services.py:1446 -- Starting the Plasma object store with 2.58 GB memory using /tmp.
2019-07-14 02:26:13,777	INFO tune.py:65 -- Did not find checkpoint file in /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline.
2019-07-14 02:26:13,778	INFO tune.py:233 -- Starting a new experiment.
2019-07-14 02:26:15,610	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
[32m [     0.07163s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.07227s,  INFO] Experiment configs: 
 {
  "gym-reacher-ppo-baseline": {
    "env": "RoboschoolReacher-v1",
    "run": "PPO",
    "local_dir": "~/kayray_results",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "time_total_s": 3600,
      "episode_reward_mean": 21,
      "training_iteration": 1000
    },
    "config": {
      "gamma": 0.995,
      "kl_coeff": 1.0,
      "num_sgd_iter": 20,
      "lr": 0.0001,
      "sgd_minibatch_size": 1000,
      "train_batch_size": 25000,
      "model": {
        "free_log_std": true
      },
      "num_gpus": 0,
      "num_workers": 0,
      "batch_mode": "complete_episodes",
      "observation_filter": "MeanStdFilter"
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.3/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=1196)[0m 2019-07-14 02:26:18,402	WARNING ppo.py:151 -- FYI: By default, the value function will not share layers with the policy model ('vf_share_layers': False).
[2m[36m(pid=1196)[0m [32m [     0.06179s,  INFO] TimeLimit:
[2m[36m(pid=1196)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=1196)[0m - action_space = Box(2,)
[2m[36m(pid=1196)[0m - observation_space = Box(9,)
[2m[36m(pid=1196)[0m - reward_range = (-inf, inf)
[2m[36m(pid=1196)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=1196)[0m - _max_episode_steps = 150
[2m[36m(pid=1196)[0m - _elapsed_steps = None [0m
[2m[36m(pid=1196)[0m 2019-07-14 02:26:18,424	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=1196)[0m 2019-07-14 02:26:18.429861: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=1196)[0m 2019-07-14 02:26:18,640	INFO dynamic_tf_policy.py:313 -- Initializing loss function with dummy input:
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'action_prob': <tf.Tensor 'default_policy/action_prob:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m   'actions': <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=1196)[0m   'advantages': <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m   'behaviour_logits': <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=1196)[0m   'dones': <tf.Tensor 'default_policy/dones:0' shape=(?,) dtype=bool>,
[2m[36m(pid=1196)[0m   'new_obs': <tf.Tensor 'default_policy/new_obs:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=1196)[0m   'obs': <tf.Tensor 'default_policy/observation:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=1196)[0m   'prev_actions': <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=1196)[0m   'prev_rewards': <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m   'rewards': <tf.Tensor 'default_policy/rewards:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m   'value_targets': <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m   'vf_preds': <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[2m[36m(pid=1196)[0m   "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[2m[36m(pid=1196)[0m 2019-07-14 02:26:19,765	INFO rollout_worker.py:719 -- Built policy map: {'default_policy': <ray.rllib.policy.tf_policy_template.PPOTFPolicy object at 0x1dc915278>}
[2m[36m(pid=1196)[0m 2019-07-14 02:26:19,765	INFO rollout_worker.py:720 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x1dc43e470>}
[2m[36m(pid=1196)[0m 2019-07-14 02:26:19,766	INFO rollout_worker.py:333 -- Built filter map: {'default_policy': MeanStdFilter((9,), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}
[2m[36m(pid=1196)[0m 2019-07-14 02:26:19,771	INFO multi_gpu_optimizer.py:79 -- LocalMultiGPUOptimizer devices ['/cpu:0']
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,214	INFO rollout_worker.py:428 -- Generating sample batch of size 200
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,246	INFO sampler.py:308 -- Raw obs from env: { 0: { 'agent0': np.ndarray((9,), dtype=float64, min=-0.944, max=0.551, mean=0.002)}}
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,247	INFO sampler.py:309 -- Info return from env: {0: {'agent0': None}}
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,247	INFO sampler.py:407 -- Preprocessed obs: np.ndarray((9,), dtype=float64, min=-0.944, max=0.551, mean=0.002)
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,248	INFO sampler.py:411 -- Filtered obs: np.ndarray((9,), dtype=float64, min=0.0, max=0.0, mean=0.0)
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,250	INFO sampler.py:525 -- Inputs to compute_actions():
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'default_policy': [ { 'data': { 'agent_id': 'agent0',
[2m[36m(pid=1196)[0m                                   'env_id': 0,
[2m[36m(pid=1196)[0m                                   'info': None,
[2m[36m(pid=1196)[0m                                   'obs': np.ndarray((9,), dtype=float64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m                                   'prev_action': np.ndarray((2,), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m                                   'prev_reward': 0.0,
[2m[36m(pid=1196)[0m                                   'rnn_state': []},
[2m[36m(pid=1196)[0m                         'type': 'PolicyEvalData'}]}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,250	INFO tf_run_builder.py:92 -- Executing TF run without tracing. To dump TF timeline traces to disk, set the TF_TIMELINE_DIR environment variable.
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,320	INFO sampler.py:552 -- Outputs of compute_actions():
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'default_policy': ( np.ndarray((1, 2), dtype=float32, min=-2.636, max=0.045, mean=-1.296),
[2m[36m(pid=1196)[0m                       [],
[2m[36m(pid=1196)[0m                       { 'action_prob': np.ndarray((1,), dtype=float32, min=0.005, max=0.005, mean=0.005),
[2m[36m(pid=1196)[0m                         'behaviour_logits': np.ndarray((1, 4), dtype=float32, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m                         'vf_preds': np.ndarray((1,), dtype=float32, min=0.0, max=0.0, mean=0.0)})}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,651	INFO sample_batch_builder.py:161 -- Trajectory fragment after postprocess_trajectory():
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'agent0': { 'data': { 'action_prob': np.ndarray((150,), dtype=float32, min=0.001, max=0.156, mean=0.075),
[2m[36m(pid=1196)[0m                         'actions': np.ndarray((150, 2), dtype=float32, min=-3.047, max=3.145, mean=0.122),
[2m[36m(pid=1196)[0m                         'advantages': np.ndarray((150,), dtype=float32, min=-28.341, max=6.489, mean=-7.4),
[2m[36m(pid=1196)[0m                         'agent_index': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m                         'behaviour_logits': np.ndarray((150, 4), dtype=float32, min=-0.014, max=0.015, mean=-0.0),
[2m[36m(pid=1196)[0m                         'dones': np.ndarray((150,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=1196)[0m                         'eps_id': np.ndarray((150,), dtype=int64, min=1535678044.0, max=1535678044.0, mean=1535678044.0),
[2m[36m(pid=1196)[0m                         'infos': np.ndarray((150,), dtype=object, head={}),
[2m[36m(pid=1196)[0m                         'new_obs': np.ndarray((150, 9), dtype=float32, min=-3.351, max=3.987, mean=0.035),
[2m[36m(pid=1196)[0m                         'obs': np.ndarray((150, 9), dtype=float32, min=-3.351, max=3.987, mean=0.035),
[2m[36m(pid=1196)[0m                         'prev_actions': np.ndarray((150, 2), dtype=float32, min=-3.047, max=3.145, mean=0.123),
[2m[36m(pid=1196)[0m                         'prev_rewards': np.ndarray((150,), dtype=float32, min=-2.24, max=1.473, mean=-0.215),
[2m[36m(pid=1196)[0m                         'rewards': np.ndarray((150,), dtype=float32, min=-2.24, max=1.473, mean=-0.211),
[2m[36m(pid=1196)[0m                         't': np.ndarray((150,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=1196)[0m                         'unroll_id': np.ndarray((150,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m                         'value_targets': np.ndarray((150,), dtype=float32, min=-28.343, max=6.483, mean=-7.402),
[2m[36m(pid=1196)[0m                         'vf_preds': np.ndarray((150,), dtype=float32, min=-0.012, max=0.008, mean=-0.001)},
[2m[36m(pid=1196)[0m               'type': 'SampleBatch'}}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m 2019-07-14 02:26:23,911	INFO rollout_worker.py:462 -- Completed sample batch:
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'data': { 'action_prob': np.ndarray((300,), dtype=float32, min=0.0, max=0.159, mean=0.077),
[2m[36m(pid=1196)[0m             'actions': np.ndarray((300, 2), dtype=float32, min=-3.047, max=3.145, mean=0.069),
[2m[36m(pid=1196)[0m             'advantages': np.ndarray((300,), dtype=float32, min=-28.341, max=15.17, mean=-5.648),
[2m[36m(pid=1196)[0m             'agent_index': np.ndarray((300,), dtype=int64, min=0.0, max=0.0, mean=0.0),
[2m[36m(pid=1196)[0m             'behaviour_logits': np.ndarray((300, 4), dtype=float32, min=-0.014, max=0.015, mean=-0.001),
[2m[36m(pid=1196)[0m             'dones': np.ndarray((300,), dtype=bool, min=0.0, max=1.0, mean=0.007),
[2m[36m(pid=1196)[0m             'eps_id': np.ndarray((300,), dtype=int64, min=776864642.0, max=1535678044.0, mean=1156271343.0),
[2m[36m(pid=1196)[0m             'infos': np.ndarray((300,), dtype=object, head={}),
[2m[36m(pid=1196)[0m             'new_obs': np.ndarray((300, 9), dtype=float32, min=-8.661, max=8.661, mean=0.052),
[2m[36m(pid=1196)[0m             'obs': np.ndarray((300, 9), dtype=float32, min=-12.248, max=12.248, mean=0.052),
[2m[36m(pid=1196)[0m             'prev_actions': np.ndarray((300, 2), dtype=float32, min=-3.047, max=3.145, mean=0.065),
[2m[36m(pid=1196)[0m             'prev_rewards': np.ndarray((300,), dtype=float32, min=-4.111, max=2.623, mean=-0.14),
[2m[36m(pid=1196)[0m             'rewards': np.ndarray((300,), dtype=float32, min=-4.111, max=2.623, mean=-0.137),
[2m[36m(pid=1196)[0m             't': np.ndarray((300,), dtype=int64, min=0.0, max=149.0, mean=74.5),
[2m[36m(pid=1196)[0m             'unroll_id': np.ndarray((300,), dtype=int64, min=0.0, max=1.0, mean=0.5),
[2m[36m(pid=1196)[0m             'value_targets': np.ndarray((300,), dtype=float32, min=-28.343, max=15.176, mean=-5.648),
[2m[36m(pid=1196)[0m             'vf_preds': np.ndarray((300,), dtype=float32, min=-0.012, max=0.009, mean=-0.001)},
[2m[36m(pid=1196)[0m   'type': 'SampleBatch'}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m 2019-07-14 02:27:27,959	INFO multi_gpu_impl.py:146 -- Training on concatenated sample batches:
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m { 'inputs': [ np.ndarray((25200, 2), dtype=float32, min=-3.868, max=4.625, mean=0.003),
[2m[36m(pid=1196)[0m               np.ndarray((25200,), dtype=float32, min=-11.709, max=6.482, mean=-0.098),
[2m[36m(pid=1196)[0m               np.ndarray((25200, 9), dtype=float32, min=-12.248, max=12.248, mean=-0.005),
[2m[36m(pid=1196)[0m               np.ndarray((25200, 2), dtype=float32, min=-3.868, max=4.625, mean=0.003),
[2m[36m(pid=1196)[0m               np.ndarray((25200,), dtype=float32, min=-3.419, max=3.624, mean=-0.0),
[2m[36m(pid=1196)[0m               np.ndarray((25200, 4), dtype=float32, min=-0.018, max=0.016, mean=-0.0),
[2m[36m(pid=1196)[0m               np.ndarray((25200,), dtype=float32, min=-41.359, max=30.688, mean=-6.385),
[2m[36m(pid=1196)[0m               np.ndarray((25200,), dtype=float32, min=-0.014, max=0.013, mean=-0.0)],
[2m[36m(pid=1196)[0m   'placeholders': [ <tf.Tensor 'default_policy/action:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/prev_reward:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/observation:0' shape=(?, 9) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/actions:0' shape=(?, 2) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/advantages:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/behaviour_logits:0' shape=(?, 4) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/value_targets:0' shape=(?,) dtype=float32>,
[2m[36m(pid=1196)[0m                     <tf.Tensor 'default_policy/vf_preds:0' shape=(?,) dtype=float32>],
[2m[36m(pid=1196)[0m   'state_inputs': []}
[2m[36m(pid=1196)[0m 
[2m[36m(pid=1196)[0m 2019-07-14 02:27:27,959	INFO multi_gpu_impl.py:191 -- Divided 25200 rollout sequences, each of length 1, among 1 devices.
Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-27-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 20.68840667983854
  episode_reward_mean: -14.761604224957662
  episode_reward_min: -49.22017558814105
  episodes_this_iter: 168
  episodes_total: 168
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 11864.982
    learner:
      default_policy:
        cur_kl_coeff: 1.0
        cur_lr: 9.999999747378752e-05
        entropy: 2.834421396255493
        kl: 0.001017571659758687
        policy_loss: -0.002791286213323474
        total_loss: 95.17231750488281
        vf_explained_var: 0.11256248503923416
        vf_loss: 95.1740951538086
    load_time_ms: 38.302
    num_steps_sampled: 25200
    num_steps_trained: 25000
    sample_time_ms: 64734.407
    update_time_ms: 0.007
  iterations_since_restore: 1
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5260958216889575
    mean_inference_ms: 1.57220389823025
    mean_processing_ms: 0.45609549867563326
  time_since_restore: 76.70795488357544
  time_this_iter_s: 76.70795488357544
  time_total_s: 76.70795488357544
  timestamp: 1563064059
  timesteps_since_restore: 25200
  timesteps_this_iter: 25200
  timesteps_total: 25200
  training_iteration: 1
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 76 s, 1 iter, 25200 ts, -14.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-29-03
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 19.09979874542474
  episode_reward_mean: -15.443999984672436
  episode_reward_min: -60.745172748304775
  episodes_this_iter: 168
  episodes_total: 336
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 13172.202
    learner:
      default_policy:
        cur_kl_coeff: 0.5
        cur_lr: 9.999999747378752e-05
        entropy: 2.83298921585083
        kl: 0.0022361658047884703
        policy_loss: -0.004711315501481295
        total_loss: 75.0042953491211
        vf_explained_var: 0.2950948476791382
        vf_loss: 75.00788879394531
    load_time_ms: 19.871
    num_steps_sampled: 50400
    num_steps_trained: 50000
    sample_time_ms: 66999.696
    update_time_ms: 0.005
  iterations_since_restore: 2
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5496040213375569
    mean_inference_ms: 1.6105526442215659
    mean_processing_ms: 0.4845780679738293
  time_since_restore: 160.4853367805481
  time_this_iter_s: 83.77738189697266
  time_total_s: 160.4853367805481
  timestamp: 1563064143
  timesteps_since_restore: 50400
  timesteps_this_iter: 25200
  timesteps_total: 50400
  training_iteration: 2
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 160 s, 2 iter, 50400 ts, -15.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-30-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 13.87200922298442
  episode_reward_mean: -14.03649582275422
  episode_reward_min: -64.93293628855915
  episodes_this_iter: 168
  episodes_total: 504
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 13890.412
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.8300881385803223
        kl: 0.0063309757970273495
        policy_loss: -0.007939008995890617
        total_loss: 78.66131591796875
        vf_explained_var: 0.2934817373752594
        vf_loss: 78.66767120361328
    load_time_ms: 13.889
    num_steps_sampled: 75600
    num_steps_trained: 75000
    sample_time_ms: 74567.166
    update_time_ms: 0.007
  iterations_since_restore: 3
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.6036472072049558
    mean_inference_ms: 1.7957976283182684
    mean_processing_ms: 0.5438771128466839
  time_since_restore: 265.57585072517395
  time_this_iter_s: 105.09051394462585
  time_total_s: 265.57585072517395
  timestamp: 1563064248
  timesteps_since_restore: 75600
  timesteps_this_iter: 25200
  timesteps_total: 75600
  training_iteration: 3
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 265 s, 3 iter, 75600 ts, -14 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-32-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 25.97801941117929
  episode_reward_mean: -11.051276650039117
  episode_reward_min: -51.10801747329688
  episodes_this_iter: 168
  episodes_total: 672
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 13518.742
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.818387508392334
        kl: 0.005187436938285828
        policy_loss: -0.007113281637430191
        total_loss: 54.79621124267578
        vf_explained_var: 0.36792227625846863
        vf_loss: 54.802024841308594
    load_time_ms: 10.695
    num_steps_sampled: 100800
    num_steps_trained: 100000
    sample_time_ms: 74856.295
    update_time_ms: 0.007
  iterations_since_restore: 4
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.6137052058553891
    mean_inference_ms: 1.7910681847436758
    mean_processing_ms: 0.5500465819225927
  time_since_restore: 353.7434968948364
  time_this_iter_s: 88.16764616966248
  time_total_s: 353.7434968948364
  timestamp: 1563064337
  timesteps_since_restore: 100800
  timesteps_this_iter: 25200
  timesteps_total: 100800
  training_iteration: 4
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 353 s, 4 iter, 100800 ts, -11.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-33-18
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 22.76489718591861
  episode_reward_mean: -11.35695891877119
  episode_reward_min: -44.15575214679761
  episodes_this_iter: 168
  episodes_total: 840
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12796.05
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.814119815826416
        kl: 0.00549536757171154
        policy_loss: -0.006977565120905638
        total_loss: 48.02885818481445
        vf_explained_var: 0.38196295499801636
        vf_loss: 48.03446960449219
    load_time_ms: 8.802
    num_steps_sampled: 126000
    num_steps_trained: 125000
    sample_time_ms: 70080.403
    update_time_ms: 0.006
  iterations_since_restore: 5
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5725815095959844
    mean_inference_ms: 1.6798405973454567
    mean_processing_ms: 0.5138500867505408
  time_since_restore: 414.64448261260986
  time_this_iter_s: 60.90098571777344
  time_total_s: 414.64448261260986
  timestamp: 1563064398
  timesteps_since_restore: 126000
  timesteps_this_iter: 25200
  timesteps_total: 126000
  training_iteration: 5
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 414 s, 5 iter, 126000 ts, -11.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-34-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 21.405390348077677
  episode_reward_mean: -8.38688093910296
  episode_reward_min: -38.947831152308595
  episodes_this_iter: 168
  episodes_total: 1008
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12412.593
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.8087680339813232
        kl: 0.005618008319288492
        policy_loss: -0.009571968577802181
        total_loss: 39.03968811035156
        vf_explained_var: 0.3898431658744812
        vf_loss: 39.047855377197266
    load_time_ms: 7.509
    num_steps_sampled: 151200
    num_steps_trained: 150000
    sample_time_ms: 68793.18
    update_time_ms: 0.006
  iterations_since_restore: 6
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5604851626763905
    mean_inference_ms: 1.6540500401998013
    mean_processing_ms: 0.5008212905132864
  time_since_restore: 487.5127387046814
  time_this_iter_s: 72.86825609207153
  time_total_s: 487.5127387046814
  timestamp: 1563064470
  timesteps_since_restore: 151200
  timesteps_this_iter: 25200
  timesteps_total: 151200
  training_iteration: 6
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 487 s, 6 iter, 151200 ts, -8.39 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-35-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 23.829774767639755
  episode_reward_mean: -7.14460381878922
  episode_reward_min: -37.56383106968219
  episodes_this_iter: 168
  episodes_total: 1176
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12047.449
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.8002405166625977
        kl: 0.0053234887309372425
        policy_loss: -0.006561100948601961
        total_loss: 30.356931686401367
        vf_explained_var: 0.4652181565761566
        vf_loss: 30.362163543701172
    load_time_ms: 6.59
    num_steps_sampled: 176400
    num_steps_trained: 175000
    sample_time_ms: 66736.812
    update_time_ms: 0.005
  iterations_since_restore: 7
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.54245427457906
    mean_inference_ms: 1.6062751416361905
    mean_processing_ms: 0.4855251306308945
  time_since_restore: 551.7836439609528
  time_this_iter_s: 64.27090525627136
  time_total_s: 551.7836439609528
  timestamp: 1563064535
  timesteps_since_restore: 176400
  timesteps_this_iter: 25200
  timesteps_total: 176400
  training_iteration: 7
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.1/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 551 s, 7 iter, 176400 ts, -7.14 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-36-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 18.118241283762277
  episode_reward_mean: -6.330636130721497
  episode_reward_min: -33.26536621087664
  episodes_this_iter: 168
  episodes_total: 1344
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12254.618
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.795092821121216
        kl: 0.006116660311818123
        policy_loss: -0.00831223651766777
        total_loss: 26.281627655029297
        vf_explained_var: 0.48331815004348755
        vf_loss: 26.288414001464844
    load_time_ms: 5.951
    num_steps_sampled: 201600
    num_steps_trained: 200000
    sample_time_ms: 66099.984
    update_time_ms: 0.005
  iterations_since_restore: 8
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5379360331580095
    mean_inference_ms: 1.591168065105899
    mean_processing_ms: 0.4796900553292724
  time_since_restore: 627.149659872055
  time_this_iter_s: 75.3660159111023
  time_total_s: 627.149659872055
  timestamp: 1563064610
  timesteps_since_restore: 201600
  timesteps_this_iter: 25200
  timesteps_total: 201600
  training_iteration: 8
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.1/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 627 s, 8 iter, 201600 ts, -6.33 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-39-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 23.081807943035592
  episode_reward_mean: -3.225040953970174
  episode_reward_min: -34.373234659546206
  episodes_this_iter: 168
  episodes_total: 1512
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 13134.104
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7886171340942383
        kl: 0.006091163028031588
        policy_loss: -0.008240319788455963
        total_loss: 25.107646942138672
        vf_explained_var: 0.49605751037597656
        vf_loss: 25.114362716674805
    load_time_ms: 5.787
    num_steps_sampled: 226800
    num_steps_trained: 225000
    sample_time_ms: 71489.578
    update_time_ms: 0.006
  iterations_since_restore: 9
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5843851132274959
    mean_inference_ms: 1.7176385549238944
    mean_processing_ms: 0.5190124725159203
  time_since_restore: 762.014075756073
  time_this_iter_s: 134.86441588401794
  time_total_s: 762.014075756073
  timestamp: 1563064745
  timesteps_since_restore: 226800
  timesteps_this_iter: 25200
  timesteps_total: 226800
  training_iteration: 9
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.2/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 762 s, 9 iter, 226800 ts, -3.23 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-40-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.453607203630664
  episode_reward_mean: -2.0160087982680586
  episode_reward_min: -30.04776638847403
  episodes_this_iter: 168
  episodes_total: 1680
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 13007.817
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7840137481689453
        kl: 0.005059288814663887
        policy_loss: -0.008519154042005539
        total_loss: 21.85334014892578
        vf_explained_var: 0.5409287810325623
        vf_loss: 21.860593795776367
    load_time_ms: 5.541
    num_steps_sampled: 252000
    num_steps_trained: 250000
    sample_time_ms: 71117.124
    update_time_ms: 0.005
  iterations_since_restore: 10
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.581849240639288
    mean_inference_ms: 1.7101076210195723
    mean_processing_ms: 0.5144484225217535
  time_since_restore: 841.6876757144928
  time_this_iter_s: 79.6735999584198
  time_total_s: 841.6876757144928
  timestamp: 1563064825
  timesteps_since_restore: 252000
  timesteps_this_iter: 25200
  timesteps_total: 252000
  training_iteration: 10
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 841 s, 10 iter, 252000 ts, -2.02 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-41-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.03956218357989
  episode_reward_mean: -0.8036526845616814
  episode_reward_min: -46.465252018228114
  episodes_this_iter: 168
  episodes_total: 1848
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12906.199
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7750678062438965
        kl: 0.00655427435413003
        policy_loss: -0.009579270146787167
        total_loss: 25.07187271118164
        vf_explained_var: 0.5747485756874084
        vf_loss: 25.079814910888672
    load_time_ms: 1.808
    num_steps_sampled: 277200
    num_steps_trained: 275000
    sample_time_ms: 70644.986
    update_time_ms: 0.005
  iterations_since_restore: 11
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5727743591668925
    mean_inference_ms: 1.6866395945851782
    mean_processing_ms: 0.5071522128611631
  time_since_restore: 912.567239522934
  time_this_iter_s: 70.87956380844116
  time_total_s: 912.567239522934
  timestamp: 1563064896
  timesteps_since_restore: 277200
  timesteps_this_iter: 25200
  timesteps_total: 277200
  training_iteration: 11
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 912 s, 11 iter, 277200 ts, -0.804 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-42-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 28.24430788915601
  episode_reward_mean: 0.8593188477621742
  episode_reward_min: -30.41395988655926
  episodes_this_iter: 168
  episodes_total: 2016
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12644.648
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7673089504241943
        kl: 0.006956362631171942
        policy_loss: -0.009947835467755795
        total_loss: 18.638479232788086
        vf_explained_var: 0.626995325088501
        vf_loss: 18.64668846130371
    load_time_ms: 1.759
    num_steps_sampled: 302400
    num_steps_trained: 300000
    sample_time_ms: 68526.257
    update_time_ms: 0.005
  iterations_since_restore: 12
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5571073248923445
    mean_inference_ms: 1.6424906040113834
    mean_processing_ms: 0.4945337668101023
  time_since_restore: 972.5288963317871
  time_this_iter_s: 59.96165680885315
  time_total_s: 972.5288963317871
  timestamp: 1563064956
  timesteps_since_restore: 302400
  timesteps_this_iter: 25200
  timesteps_total: 302400
  training_iteration: 12
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 972 s, 12 iter, 302400 ts, 0.859 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-43-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 27.479148253754307
  episode_reward_mean: 2.5699687828594984
  episode_reward_min: -26.638237767566185
  episodes_this_iter: 168
  episodes_total: 2184
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 12033.741
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7527520656585693
        kl: 0.00662660039961338
        policy_loss: -0.00949287973344326
        total_loss: 17.120107650756836
        vf_explained_var: 0.6903717517852783
        vf_loss: 17.127944946289062
    load_time_ms: 1.664
    num_steps_sampled: 327600
    num_steps_trained: 325000
    sample_time_ms: 63558.929
    update_time_ms: 0.004
  iterations_since_restore: 13
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5392210921254471
    mean_inference_ms: 1.5900326531446338
    mean_processing_ms: 0.4791497960778337
  time_since_restore: 1021.7927813529968
  time_this_iter_s: 49.26388502120972
  time_total_s: 1021.7927813529968
  timestamp: 1563065005
  timesteps_since_restore: 327600
  timesteps_this_iter: 25200
  timesteps_total: 327600
  training_iteration: 13
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1021 s, 13 iter, 327600 ts, 2.57 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-44-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.862253542518893
  episode_reward_mean: 2.911346833656519
  episode_reward_min: -24.503906587097553
  episodes_this_iter: 168
  episodes_total: 2352
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 11697.615
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.743739604949951
        kl: 0.006067116279155016
        policy_loss: -0.010224729776382446
        total_loss: 12.164815902709961
        vf_explained_var: 0.747708797454834
        vf_loss: 12.173523902893066
    load_time_ms: 1.658
    num_steps_sampled: 352800
    num_steps_trained: 350000
    sample_time_ms: 59611.811
    update_time_ms: 0.004
  iterations_since_restore: 14
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5216761112022562
    mean_inference_ms: 1.538569466848716
    mean_processing_ms: 0.4640494017615461
  time_since_restore: 1067.1076662540436
  time_this_iter_s: 45.31488490104675
  time_total_s: 1067.1076662540436
  timestamp: 1563065050
  timesteps_since_restore: 352800
  timesteps_this_iter: 25200
  timesteps_total: 352800
  training_iteration: 14
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1067 s, 14 iter, 352800 ts, 2.91 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-44-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.26279346264032
  episode_reward_mean: 4.9536711602454835
  episode_reward_min: -17.755420934721325
  episodes_this_iter: 168
  episodes_total: 2520
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 11609.502
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7362234592437744
        kl: 0.0073982239700853825
        policy_loss: -0.010637346655130386
        total_loss: 10.523139953613281
        vf_explained_var: 0.7457420229911804
        vf_loss: 10.531927108764648
    load_time_ms: 1.655
    num_steps_sampled: 378000
    num_steps_trained: 375000
    sample_time_ms: 58327.773
    update_time_ms: 0.004
  iterations_since_restore: 15
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.5075280926674706
    mean_inference_ms: 1.496861465209356
    mean_processing_ms: 0.4519555287141132
  time_since_restore: 1114.2856771945953
  time_this_iter_s: 47.17801094055176
  time_total_s: 1114.2856771945953
  timestamp: 1563065097
  timesteps_since_restore: 378000
  timesteps_this_iter: 25200
  timesteps_total: 378000
  training_iteration: 15
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1114 s, 15 iter, 378000 ts, 4.95 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-45-43
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.69595539595047
  episode_reward_mean: 5.624505984586308
  episode_reward_min: -21.79735915268774
  episodes_this_iter: 168
  episodes_total: 2688
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 11516.176
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7347164154052734
        kl: 0.005552347283810377
        policy_loss: -0.010778083465993404
        total_loss: 9.131138801574707
        vf_explained_var: 0.7940716743469238
        vf_loss: 9.14052963256836
    load_time_ms: 1.672
    num_steps_sampled: 403200
    num_steps_trained: 400000
    sample_time_ms: 55744.653
    update_time_ms: 0.003
  iterations_since_restore: 16
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.49427323863370193
    mean_inference_ms: 1.4582132286793785
    mean_processing_ms: 0.4404444889901163
  time_since_restore: 1160.3928101062775
  time_this_iter_s: 46.10713291168213
  time_total_s: 1160.3928101062775
  timestamp: 1563065143
  timesteps_since_restore: 403200
  timesteps_this_iter: 25200
  timesteps_total: 403200
  training_iteration: 16
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1160 s, 16 iter, 403200 ts, 5.62 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-46-29
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.11207344420649
  episode_reward_mean: 5.065415569313276
  episode_reward_min: -25.473946621644355
  episodes_this_iter: 168
  episodes_total: 2856
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 11424.205
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.7250635623931885
        kl: 0.007743793074041605
        policy_loss: -0.01057153195142746
        total_loss: 7.829821586608887
        vf_explained_var: 0.8209927082061768
        vf_loss: 7.8384575843811035
    load_time_ms: 1.662
    num_steps_sampled: 428400
    num_steps_trained: 425000
    sample_time_ms: 54009.029
    update_time_ms: 0.003
  iterations_since_restore: 17
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4831519083004029
    mean_inference_ms: 1.4244150038918926
    mean_processing_ms: 0.4305997760431867
  time_since_restore: 1206.3884599208832
  time_this_iter_s: 45.99564981460571
  time_total_s: 1206.3884599208832
  timestamp: 1563065189
  timesteps_since_restore: 428400
  timesteps_this_iter: 25200
  timesteps_total: 428400
  training_iteration: 17
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1206 s, 17 iter, 428400 ts, 5.07 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-47-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.1166857123205
  episode_reward_mean: 7.423885486443977
  episode_reward_min: -32.04693148686279
  episodes_this_iter: 168
  episodes_total: 3024
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 10934.387
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.711092233657837
        kl: 0.006972159259021282
        policy_loss: -0.01095519308000803
        total_loss: 5.001318454742432
        vf_explained_var: 0.8782281279563904
        vf_loss: 5.010530471801758
    load_time_ms: 1.625
    num_steps_sampled: 453600
    num_steps_trained: 450000
    sample_time_ms: 52116.601
    update_time_ms: 0.004
  iterations_since_restore: 18
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.47549209510712587
    mean_inference_ms: 1.4022588905938755
    mean_processing_ms: 0.42418806999989134
  time_since_restore: 1257.9296979904175
  time_this_iter_s: 51.5412380695343
  time_total_s: 1257.9296979904175
  timestamp: 1563065241
  timesteps_since_restore: 453600
  timesteps_this_iter: 25200
  timesteps_total: 453600
  training_iteration: 18
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1257 s, 18 iter, 453600 ts, 7.42 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-48-05
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.30544927827201
  episode_reward_mean: 7.771750964564476
  episode_reward_min: -14.167248767449388
  episodes_this_iter: 168
  episodes_total: 3192
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9781.016
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.708404302597046
        kl: 0.006717680487781763
        policy_loss: -0.011521058157086372
        total_loss: 3.541689395904541
        vf_explained_var: 0.9039148092269897
        vf_loss: 3.5515313148498535
    load_time_ms: 1.289
    num_steps_sampled: 478800
    num_steps_trained: 475000
    sample_time_ms: 44204.479
    update_time_ms: 0.003
  iterations_since_restore: 19
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.46543494244085876
    mean_inference_ms: 1.3734538260941935
    mean_processing_ms: 0.4156123321036115
  time_since_restore: 1302.0677270889282
  time_this_iter_s: 44.13802909851074
  time_total_s: 1302.0677270889282
  timestamp: 1563065285
  timesteps_since_restore: 478800
  timesteps_this_iter: 25200
  timesteps_total: 478800
  training_iteration: 19
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1302 s, 19 iter, 478800 ts, 7.77 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-48-53
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.946626717032213
  episode_reward_mean: 7.995266423266165
  episode_reward_min: -12.461106763850573
  episodes_this_iter: 168
  episodes_total: 3360
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9467.957
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.693570852279663
        kl: 0.0067595518194139
        policy_loss: -0.01078985258936882
        total_loss: 3.924631357192993
        vf_explained_var: 0.898743212223053
        vf_loss: 3.9337317943573
    load_time_ms: 1.057
    num_steps_sampled: 504000
    num_steps_trained: 500000
    sample_time_ms: 41286.912
    update_time_ms: 0.003
  iterations_since_restore: 20
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4576056668979406
    mean_inference_ms: 1.3512459082565051
    mean_processing_ms: 0.4090701938788329
  time_since_restore: 1349.4150981903076
  time_this_iter_s: 47.347371101379395
  time_total_s: 1349.4150981903076
  timestamp: 1563065333
  timesteps_since_restore: 504000
  timesteps_this_iter: 25200
  timesteps_total: 504000
  training_iteration: 20
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1349 s, 20 iter, 504000 ts, 8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-49-39
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.36327282235597
  episode_reward_mean: 7.988192612779968
  episode_reward_min: -22.521478236387118
  episodes_this_iter: 168
  episodes_total: 3528
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9340.623
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.682724714279175
        kl: 0.006912540178745985
        policy_loss: -0.01038374938070774
        total_loss: 3.2088727951049805
        vf_explained_var: 0.9136619567871094
        vf_loss: 3.2175283432006836
    load_time_ms: 1.08
    num_steps_sampled: 529200
    num_steps_trained: 525000
    sample_time_ms: 38986.121
    update_time_ms: 0.003
  iterations_since_restore: 21
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.45002426215465074
    mean_inference_ms: 1.3293081235802813
    mean_processing_ms: 0.4025218752149951
  time_since_restore: 1396.0124452114105
  time_this_iter_s: 46.597347021102905
  time_total_s: 1396.0124452114105
  timestamp: 1563065379
  timesteps_since_restore: 529200
  timesteps_this_iter: 25200
  timesteps_total: 529200
  training_iteration: 21
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1396 s, 21 iter, 529200 ts, 7.99 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-50-31
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.679003082122772
  episode_reward_mean: 8.444117647968422
  episode_reward_min: -28.545739091118776
  episodes_this_iter: 168
  episodes_total: 3696
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9106.281
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.6685595512390137
        kl: 0.00718637416139245
        policy_loss: -0.010978735983371735
        total_loss: 2.573207378387451
        vf_explained_var: 0.9292583465576172
        vf_loss: 2.5823891162872314
    load_time_ms: 1.092
    num_steps_sampled: 554400
    num_steps_trained: 550000
    sample_time_ms: 38437.891
    update_time_ms: 0.002
  iterations_since_restore: 22
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.44501728243566013
    mean_inference_ms: 1.315711490909272
    mean_processing_ms: 0.3983811976366698
  time_since_restore: 1448.144021987915
  time_this_iter_s: 52.13157677650452
  time_total_s: 1448.144021987915
  timestamp: 1563065431
  timesteps_since_restore: 554400
  timesteps_this_iter: 25200
  timesteps_total: 554400
  training_iteration: 22
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1448 s, 22 iter, 554400 ts, 8.44 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-51-16
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.848374600169993
  episode_reward_mean: 9.425003315367183
  episode_reward_min: -21.502371581249967
  episodes_this_iter: 168
  episodes_total: 3864
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9037.188
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.6537587642669678
        kl: 0.007387346122413874
        policy_loss: -0.01313740387558937
        total_loss: 3.0501604080200195
        vf_explained_var: 0.9183322787284851
        vf_loss: 3.061450719833374
    load_time_ms: 1.102
    num_steps_sampled: 579600
    num_steps_trained: 575000
    sample_time_ms: 38043.381
    update_time_ms: 0.003
  iterations_since_restore: 23
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.43839145942954716
    mean_inference_ms: 1.2961221920487573
    mean_processing_ms: 0.39264495045654746
  time_since_restore: 1492.7716541290283
  time_this_iter_s: 44.62763214111328
  time_total_s: 1492.7716541290283
  timestamp: 1563065476
  timesteps_since_restore: 579600
  timesteps_this_iter: 25200
  timesteps_total: 579600
  training_iteration: 23
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1492 s, 23 iter, 579600 ts, 9.43 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-52-04
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.60753057153253
  episode_reward_mean: 9.504009117006227
  episode_reward_min: -6.854295177154545
  episodes_this_iter: 168
  episodes_total: 4032
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9070.074
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.6399877071380615
        kl: 0.006888839416205883
        policy_loss: -0.011819913052022457
        total_loss: 2.7093732357025146
        vf_explained_var: 0.9223167300224304
        vf_loss: 2.719470739364624
    load_time_ms: 1.136
    num_steps_sampled: 604800
    num_steps_trained: 600000
    sample_time_ms: 38260.239
    update_time_ms: 0.003
  iterations_since_restore: 24
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4331048993625923
    mean_inference_ms: 1.2804956660115787
    mean_processing_ms: 0.38810388246160243
  time_since_restore: 1540.5810153484344
  time_this_iter_s: 47.80936121940613
  time_total_s: 1540.5810153484344
  timestamp: 1563065524
  timesteps_since_restore: 604800
  timesteps_this_iter: 25200
  timesteps_total: 604800
  training_iteration: 24
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1540 s, 24 iter, 604800 ts, 9.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-52-49
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.799213016174335
  episode_reward_mean: 9.443645875633852
  episode_reward_min: -22.561277492943823
  episodes_this_iter: 168
  episodes_total: 4200
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9085.888
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.6319074630737305
        kl: 0.0076787895523011684
        policy_loss: -0.010997681878507137
        total_loss: 2.5283918380737305
        vf_explained_var: 0.9292316436767578
        vf_loss: 2.5374698638916016
    load_time_ms: 1.129
    num_steps_sampled: 630000
    num_steps_trained: 625000
    sample_time_ms: 38052.396
    update_time_ms: 0.003
  iterations_since_restore: 25
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.42747147236729177
    mean_inference_ms: 1.26385150713488
    mean_processing_ms: 0.38324052022478045
  time_since_restore: 1585.840969324112
  time_this_iter_s: 45.25995397567749
  time_total_s: 1585.840969324112
  timestamp: 1563065569
  timesteps_since_restore: 630000
  timesteps_this_iter: 25200
  timesteps_total: 630000
  training_iteration: 25
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1585 s, 25 iter, 630000 ts, 9.44 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-53-36
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.61055588865479
  episode_reward_mean: 10.62125005912758
  episode_reward_min: -14.088532827024144
  episodes_this_iter: 168
  episodes_total: 4368
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9001.504
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.625300645828247
        kl: 0.007282969541847706
        policy_loss: -0.012412583455443382
        total_loss: 2.408583879470825
        vf_explained_var: 0.940142035484314
        vf_loss: 2.419175624847412
    load_time_ms: 1.107
    num_steps_sampled: 655200
    num_steps_trained: 650000
    sample_time_ms: 38251.909
    update_time_ms: 0.003
  iterations_since_restore: 26
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4230644867893726
    mean_inference_ms: 1.2507501400920515
    mean_processing_ms: 0.3794287767603734
  time_since_restore: 1633.0963892936707
  time_this_iter_s: 47.255419969558716
  time_total_s: 1633.0963892936707
  timestamp: 1563065616
  timesteps_since_restore: 655200
  timesteps_this_iter: 25200
  timesteps_total: 655200
  training_iteration: 26
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1633 s, 26 iter, 655200 ts, 10.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-54-23
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.04635261366142
  episode_reward_mean: 10.855422058203832
  episode_reward_min: -9.27526539897152
  episodes_this_iter: 168
  episodes_total: 4536
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9030.535
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.6069846153259277
        kl: 0.0075139994733035564
        policy_loss: -0.012844068929553032
        total_loss: 1.5871939659118652
        vf_explained_var: 0.9507243633270264
        vf_loss: 1.5981594324111938
    load_time_ms: 1.117
    num_steps_sampled: 680400
    num_steps_trained: 675000
    sample_time_ms: 38268.211
    update_time_ms: 0.003
  iterations_since_restore: 27
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4186143867427091
    mean_inference_ms: 1.2374621463997826
    mean_processing_ms: 0.37550663471888407
  time_since_restore: 1679.5452270507812
  time_this_iter_s: 46.448837757110596
  time_total_s: 1679.5452270507812
  timestamp: 1563065663
  timesteps_since_restore: 680400
  timesteps_this_iter: 25200
  timesteps_total: 680400
  training_iteration: 27
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1679 s, 27 iter, 680400 ts, 10.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-55-12
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.37221472778022
  episode_reward_mean: 11.844481546876152
  episode_reward_min: -11.89913936295312
  episodes_this_iter: 168
  episodes_total: 4704
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9057.485
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.5946614742279053
        kl: 0.006854991894215345
        policy_loss: -0.012039048597216606
        total_loss: 1.3323396444320679
        vf_explained_var: 0.9614788293838501
        vf_loss: 1.3426648378372192
    load_time_ms: 1.172
    num_steps_sampled: 705600
    num_steps_trained: 700000
    sample_time_ms: 38046.909
    update_time_ms: 0.003
  iterations_since_restore: 28
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4154886965288388
    mean_inference_ms: 1.2278156236483186
    mean_processing_ms: 0.3728099499570997
  time_since_restore: 1729.1424000263214
  time_this_iter_s: 49.59717297554016
  time_total_s: 1729.1424000263214
  timestamp: 1563065712
  timesteps_since_restore: 705600
  timesteps_this_iter: 25200
  timesteps_total: 705600
  training_iteration: 28
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.0/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1729 s, 28 iter, 705600 ts, 11.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-55-59
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 29.521105774227333
  episode_reward_mean: 11.36310888186874
  episode_reward_min: -13.726074654557777
  episodes_this_iter: 168
  episodes_total: 4872
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9091.582
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.580077886581421
        kl: 0.007079167291522026
        policy_loss: -0.011001781560480595
        total_loss: 1.2176591157913208
        vf_explained_var: 0.9626535177230835
        vf_loss: 1.226891040802002
    load_time_ms: 1.19
    num_steps_sampled: 730800
    num_steps_trained: 725000
    sample_time_ms: 38304.174
    update_time_ms: 0.003
  iterations_since_restore: 29
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4119552399119359
    mean_inference_ms: 1.2168118660481047
    mean_processing_ms: 0.3696233881345735
  time_since_restore: 1776.1945521831512
  time_this_iter_s: 47.052152156829834
  time_total_s: 1776.1945521831512
  timestamp: 1563065759
  timesteps_since_restore: 730800
  timesteps_this_iter: 25200
  timesteps_total: 730800
  training_iteration: 29
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1776 s, 29 iter, 730800 ts, 11.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-56-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.65470465598943
  episode_reward_mean: 12.212994169601743
  episode_reward_min: -9.82364486915337
  episodes_this_iter: 168
  episodes_total: 5040
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9109.766
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.569354772567749
        kl: 0.007998961955308914
        policy_loss: -0.012636575847864151
        total_loss: 1.2354366779327393
        vf_explained_var: 0.9665555357933044
        vf_loss: 1.2460734844207764
    load_time_ms: 1.214
    num_steps_sampled: 756000
    num_steps_trained: 750000
    sample_time_ms: 38356.902
    update_time_ms: 0.003
  iterations_since_restore: 30
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.408842788546507
    mean_inference_ms: 1.2074688810231324
    mean_processing_ms: 0.3669258920607943
  time_since_restore: 1824.2520241737366
  time_this_iter_s: 48.05747199058533
  time_total_s: 1824.2520241737366
  timestamp: 1563065807
  timesteps_since_restore: 756000
  timesteps_this_iter: 25200
  timesteps_total: 756000
  training_iteration: 30
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1824 s, 30 iter, 756000 ts, 12.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-57-34
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.078498207310574
  episode_reward_mean: 11.179336477229615
  episode_reward_min: -8.633987239705997
  episodes_this_iter: 168
  episodes_total: 5208
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9112.066
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.555765151977539
        kl: 0.008865964598953724
        policy_loss: -0.011845406144857407
        total_loss: 1.101941466331482
        vf_explained_var: 0.965491533279419
        vf_loss: 1.1115703582763672
    load_time_ms: 1.207
    num_steps_sampled: 781200
    num_steps_trained: 775000
    sample_time_ms: 38329.915
    update_time_ms: 0.003
  iterations_since_restore: 31
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.4053536729889128
    mean_inference_ms: 1.1969436651411502
    mean_processing_ms: 0.36373451325777306
  time_since_restore: 1870.6032671928406
  time_this_iter_s: 46.351243019104004
  time_total_s: 1870.6032671928406
  timestamp: 1563065854
  timesteps_since_restore: 781200
  timesteps_this_iter: 25200
  timesteps_total: 781200
  training_iteration: 31
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1870 s, 31 iter, 781200 ts, 11.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-58-21
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.58589766302339
  episode_reward_mean: 11.548163108531991
  episode_reward_min: -8.541847263520063
  episodes_this_iter: 168
  episodes_total: 5376
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9062.343
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.5363128185272217
        kl: 0.007717420347034931
        policy_loss: -0.012372973375022411
        total_loss: 1.0849493741989136
        vf_explained_var: 0.9680473804473877
        vf_loss: 1.095393180847168
    load_time_ms: 1.233
    num_steps_sampled: 806400
    num_steps_trained: 800000
    sample_time_ms: 37901.216
    update_time_ms: 0.003
  iterations_since_restore: 32
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.40243989419746196
    mean_inference_ms: 1.1882045987191354
    mean_processing_ms: 0.36119187163558264
  time_since_restore: 1917.9525372982025
  time_this_iter_s: 47.34927010536194
  time_total_s: 1917.9525372982025
  timestamp: 1563065901
  timesteps_since_restore: 806400
  timesteps_this_iter: 25200
  timesteps_total: 806400
  training_iteration: 32
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1917 s, 32 iter, 806400 ts, 11.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-59-08
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.340946803657765
  episode_reward_mean: 11.605931508997935
  episode_reward_min: -7.64253880278757
  episodes_this_iter: 168
  episodes_total: 5544
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9164.604
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.519111394882202
        kl: 0.007629973813891411
        policy_loss: -0.013615168631076813
        total_loss: 1.1352366209030151
        vf_explained_var: 0.9696372747421265
        vf_loss: 1.146944284439087
    load_time_ms: 1.23
    num_steps_sampled: 831600
    num_steps_trained: 825000
    sample_time_ms: 38023.208
    update_time_ms: 0.003
  iterations_since_restore: 33
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39948260871549135
    mean_inference_ms: 1.1793165557793477
    mean_processing_ms: 0.3585087734971778
  time_since_restore: 1964.8234202861786
  time_this_iter_s: 46.870882987976074
  time_total_s: 1964.8234202861786
  timestamp: 1563065948
  timesteps_since_restore: 831600
  timesteps_this_iter: 25200
  timesteps_total: 831600
  training_iteration: 33
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 1964 s, 33 iter, 831600 ts, 11.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_02-59-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.794955359646035
  episode_reward_mean: 11.545683543304055
  episode_reward_min: -8.99239948907358
  episodes_this_iter: 168
  episodes_total: 5712
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9129.649
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.5086829662323
        kl: 0.007088746875524521
        policy_loss: -0.012244871817529202
        total_loss: 1.5282574892044067
        vf_explained_var: 0.9557381272315979
        vf_loss: 1.5387300252914429
    load_time_ms: 1.187
    num_steps_sampled: 856800
    num_steps_trained: 850000
    sample_time_ms: 37930.065
    update_time_ms: 0.003
  iterations_since_restore: 34
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3966875479145186
    mean_inference_ms: 1.171041385715758
    mean_processing_ms: 0.3561133216833396
  time_since_restore: 2011.3506045341492
  time_this_iter_s: 46.52718424797058
  time_total_s: 2011.3506045341492
  timestamp: 1563065995
  timesteps_since_restore: 856800
  timesteps_this_iter: 25200
  timesteps_total: 856800
  training_iteration: 34
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2011 s, 34 iter, 856800 ts, 11.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-01-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.00080653850194
  episode_reward_mean: 13.46434590676453
  episode_reward_min: -8.13684028094989
  episodes_this_iter: 168
  episodes_total: 5880
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9188.084
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.4944229125976562
        kl: 0.0077511584386229515
        policy_loss: -0.015262920409440994
        total_loss: 1.0831087827682495
        vf_explained_var: 0.9709187150001526
        vf_loss: 1.0964338779449463
    load_time_ms: 1.191
    num_steps_sampled: 882000
    num_steps_trained: 875000
    sample_time_ms: 40096.408
    update_time_ms: 0.003
  iterations_since_restore: 35
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3967267545192384
    mean_inference_ms: 1.1807948784458713
    mean_processing_ms: 0.3564804648630096
  time_since_restore: 2078.8572022914886
  time_this_iter_s: 67.50659775733948
  time_total_s: 2078.8572022914886
  timestamp: 1563066062
  timesteps_since_restore: 882000
  timesteps_this_iter: 25200
  timesteps_total: 882000
  training_iteration: 35
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2078 s, 35 iter, 882000 ts, 13.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-01-48
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.589637263182464
  episode_reward_mean: 10.07363516714576
  episode_reward_min: -22.467924263919173
  episodes_this_iter: 168
  episodes_total: 6048
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9236.317
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.477546453475952
        kl: 0.007504097651690245
        policy_loss: -0.012437804602086544
        total_loss: 1.0867623090744019
        vf_explained_var: 0.9671001434326172
        vf_loss: 1.097324013710022
    load_time_ms: 1.188
    num_steps_sampled: 907200
    num_steps_trained: 900000
    sample_time_ms: 39864.195
    update_time_ms: 0.003
  iterations_since_restore: 36
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39500659531340654
    mean_inference_ms: 1.1712736409919084
    mean_processing_ms: 0.3536930939149503
  time_since_restore: 2124.271448612213
  time_this_iter_s: 45.41424632072449
  time_total_s: 2124.271448612213
  timestamp: 1563066108
  timesteps_since_restore: 907200
  timesteps_this_iter: 25200
  timesteps_total: 907200
  training_iteration: 36
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2124 s, 36 iter, 907200 ts, 10.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-02-47
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 30.911696403214016
  episode_reward_mean: 11.166487784551903
  episode_reward_min: -7.576521408066318
  episodes_this_iter: 168
  episodes_total: 6216
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9232.63
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.466132640838623
        kl: 0.007155287079513073
        policy_loss: -0.012626047246158123
        total_loss: 0.8476052284240723
        vf_explained_var: 0.973228931427002
        vf_loss: 0.8584423661231995
    load_time_ms: 1.186
    num_steps_sampled: 932400
    num_steps_trained: 925000
    sample_time_ms: 41184.239
    update_time_ms: 0.003
  iterations_since_restore: 37
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3948759085961231
    mean_inference_ms: 1.1724093224139263
    mean_processing_ms: 0.35458448995004943
  time_since_restore: 2183.8863785266876
  time_this_iter_s: 59.61492991447449
  time_total_s: 2183.8863785266876
  timestamp: 1563066167
  timesteps_since_restore: 932400
  timesteps_this_iter: 25200
  timesteps_total: 932400
  training_iteration: 37
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2183 s, 37 iter, 932400 ts, 11.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-03-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.76312654730694
  episode_reward_mean: 12.513347624197856
  episode_reward_min: -9.860450928394838
  episodes_this_iter: 168
  episodes_total: 6384
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9249.875
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.456146717071533
        kl: 0.008805564604699612
        policy_loss: -0.013460785150527954
        total_loss: 0.8614377379417419
        vf_explained_var: 0.974427342414856
        vf_loss: 0.872697114944458
    load_time_ms: 1.132
    num_steps_sampled: 957600
    num_steps_trained: 950000
    sample_time_ms: 42070.149
    update_time_ms: 0.003
  iterations_since_restore: 38
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39692920206340526
    mean_inference_ms: 1.1708448151600261
    mean_processing_ms: 0.3548028726149752
  time_since_restore: 2242.5184693336487
  time_this_iter_s: 58.63209080696106
  time_total_s: 2242.5184693336487
  timestamp: 1563066226
  timesteps_since_restore: 957600
  timesteps_this_iter: 25200
  timesteps_total: 957600
  training_iteration: 38
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2242 s, 38 iter, 957600 ts, 12.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-04-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.73743844351979
  episode_reward_mean: 13.476862454515246
  episode_reward_min: -5.670997273093243
  episodes_this_iter: 168
  episodes_total: 6552
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9290.292
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.4441540241241455
        kl: 0.009061424061655998
        policy_loss: -0.014659837819635868
        total_loss: 0.8101591467857361
        vf_explained_var: 0.978560209274292
        vf_loss: 0.8225536346435547
    load_time_ms: 1.115
    num_steps_sampled: 982800
    num_steps_trained: 975000
    sample_time_ms: 43325.045
    update_time_ms: 0.003
  iterations_since_restore: 39
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39846285546307536
    mean_inference_ms: 1.1712308063665111
    mean_processing_ms: 0.35481180216352953
  time_since_restore: 2302.522994995117
  time_this_iter_s: 60.004525661468506
  time_total_s: 2302.522994995117
  timestamp: 1563066286
  timesteps_since_restore: 982800
  timesteps_this_iter: 25200
  timesteps_total: 982800
  training_iteration: 39
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2302 s, 39 iter, 982800 ts, 13.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-05-46
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 31.647608638343254
  episode_reward_mean: 12.557387658303558
  episode_reward_min: -8.39614168128592
  episodes_this_iter: 168
  episodes_total: 6720
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9352.924
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.429349660873413
        kl: 0.007741829380393028
        policy_loss: -0.012806837446987629
        total_loss: 0.9751328825950623
        vf_explained_var: 0.9717384576797485
        vf_loss: 0.9860044121742249
    load_time_ms: 1.087
    num_steps_sampled: 1008000
    num_steps_trained: 1000000
    sample_time_ms: 44497.874
    update_time_ms: 0.003
  iterations_since_restore: 40
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.397504287283141
    mean_inference_ms: 1.1700042740802896
    mean_processing_ms: 0.35909048925915515
  time_since_restore: 2362.9334411621094
  time_this_iter_s: 60.41044616699219
  time_total_s: 2362.9334411621094
  timestamp: 1563066346
  timesteps_since_restore: 1008000
  timesteps_this_iter: 25200
  timesteps_total: 1008000
  training_iteration: 40
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2362 s, 40 iter, 1008000 ts, 12.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-07-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.053416391391906
  episode_reward_mean: 12.909204194467256
  episode_reward_min: -6.643597131770679
  episodes_this_iter: 168
  episodes_total: 6888
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9373.69
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.416720390319824
        kl: 0.008452407084405422
        policy_loss: -0.012026172131299973
        total_loss: 0.7129887938499451
        vf_explained_var: 0.9809463620185852
        vf_loss: 0.7229019403457642
    load_time_ms: 1.069
    num_steps_sampled: 1033200
    num_steps_trained: 1025000
    sample_time_ms: 49740.191
    update_time_ms: 0.003
  iterations_since_restore: 41
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3975801001830557
    mean_inference_ms: 1.2084652980928237
    mean_processing_ms: 0.3595894574594047
  time_since_restore: 2461.913715362549
  time_this_iter_s: 98.98027420043945
  time_total_s: 2461.913715362549
  timestamp: 1563066445
  timesteps_since_restore: 1033200
  timesteps_this_iter: 25200
  timesteps_total: 1033200
  training_iteration: 41
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2461 s, 41 iter, 1033200 ts, 12.9 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-08-10
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.98754745220431
  episode_reward_mean: 12.697934225411261
  episode_reward_min: -13.471193917134755
  episodes_this_iter: 168
  episodes_total: 7056
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9350.03
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.403902292251587
        kl: 0.007810063194483519
        policy_loss: -0.012736214324831963
        total_loss: 0.7348544597625732
        vf_explained_var: 0.9779756665229797
        vf_loss: 0.7456381320953369
    load_time_ms: 1.076
    num_steps_sampled: 1058400
    num_steps_trained: 1050000
    sample_time_ms: 49516.332
    update_time_ms: 0.003
  iterations_since_restore: 42
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39501970591171787
    mean_inference_ms: 1.2002879848887738
    mean_processing_ms: 0.3574137750977502
  time_since_restore: 2506.7877955436707
  time_this_iter_s: 44.874080181121826
  time_total_s: 2506.7877955436707
  timestamp: 1563066490
  timesteps_since_restore: 1058400
  timesteps_this_iter: 25200
  timesteps_total: 1058400
  training_iteration: 42
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2506 s, 42 iter, 1058400 ts, 12.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-08-55
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.04716093658317
  episode_reward_mean: 12.587484705066393
  episode_reward_min: -8.38038312562754
  episodes_this_iter: 168
  episodes_total: 7224
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9239.102
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.389683961868286
        kl: 0.008499025367200375
        policy_loss: -0.012922992929816246
        total_loss: 0.7790104150772095
        vf_explained_var: 0.9775521755218506
        vf_loss: 0.7898086309432983
    load_time_ms: 1.089
    num_steps_sampled: 1083600
    num_steps_trained: 1075000
    sample_time_ms: 49449.281
    update_time_ms: 0.003
  iterations_since_restore: 43
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39271240677169555
    mean_inference_ms: 1.192778704949591
    mean_processing_ms: 0.3554405342248379
  time_since_restore: 2551.8767607212067
  time_this_iter_s: 45.08896517753601
  time_total_s: 2551.8767607212067
  timestamp: 1563066535
  timesteps_since_restore: 1083600
  timesteps_this_iter: 25200
  timesteps_total: 1083600
  training_iteration: 43
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2551 s, 43 iter, 1083600 ts, 12.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-09-38
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.59968486764233
  episode_reward_mean: 12.287823028620432
  episode_reward_min: -7.83194372904589
  episodes_this_iter: 168
  episodes_total: 7392
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9156.227
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.382232427597046
        kl: 0.009927880950272083
        policy_loss: -0.013498974964022636
        total_loss: 0.7104172706604004
        vf_explained_var: 0.9792448282241821
        vf_loss: 0.7214341759681702
    load_time_ms: 1.136
    num_steps_sampled: 1108800
    num_steps_trained: 1100000
    sample_time_ms: 49146.362
    update_time_ms: 0.003
  iterations_since_restore: 44
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.39008971348752247
    mean_inference_ms: 1.184521600186118
    mean_processing_ms: 0.35312165405938506
  time_since_restore: 2594.5477056503296
  time_this_iter_s: 42.670944929122925
  time_total_s: 2594.5477056503296
  timestamp: 1563066578
  timesteps_since_restore: 1108800
  timesteps_this_iter: 25200
  timesteps_total: 1108800
  training_iteration: 44
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2594 s, 44 iter, 1108800 ts, 12.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-10-22
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.69769163614137
  episode_reward_mean: 13.53992401402975
  episode_reward_min: -7.141993812227049
  episodes_this_iter: 168
  episodes_total: 7560
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9002.088
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.3690080642700195
        kl: 0.009050050750374794
        policy_loss: -0.013838735409080982
        total_loss: 0.7126759886741638
        vf_explained_var: 0.9794133901596069
        vf_loss: 0.7242522239685059
    load_time_ms: 1.12
    num_steps_sampled: 1134000
    num_steps_trained: 1125000
    sample_time_ms: 46977.262
    update_time_ms: 0.003
  iterations_since_restore: 45
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.38789145489540455
    mean_inference_ms: 1.1773731943452805
    mean_processing_ms: 0.35122986988524113
  time_since_restore: 2638.8188877105713
  time_this_iter_s: 44.2711820602417
  time_total_s: 2638.8188877105713
  timestamp: 1563066622
  timesteps_since_restore: 1134000
  timesteps_this_iter: 25200
  timesteps_total: 1134000
  training_iteration: 45
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2638 s, 45 iter, 1134000 ts, 13.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-11-06
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.80419789905965
  episode_reward_mean: 14.798259462181994
  episode_reward_min: -7.175217681756689
  episodes_this_iter: 168
  episodes_total: 7728
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 9017.595
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.3545775413513184
        kl: 0.00905062910169363
        policy_loss: -0.013930768705904484
        total_loss: 0.5984416007995605
        vf_explained_var: 0.9856396317481995
        vf_loss: 0.6101097464561462
    load_time_ms: 1.122
    num_steps_sampled: 1159200
    num_steps_trained: 1150000
    sample_time_ms: 46822.278
    update_time_ms: 0.003
  iterations_since_restore: 46
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3855222054319829
    mean_inference_ms: 1.1698986286721904
    mean_processing_ms: 0.3491420891862353
  time_since_restore: 2682.8397250175476
  time_this_iter_s: 44.02083730697632
  time_total_s: 2682.8397250175476
  timestamp: 1563066666
  timesteps_since_restore: 1159200
  timesteps_this_iter: 25200
  timesteps_total: 1159200
  training_iteration: 46
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2682 s, 46 iter, 1159200 ts, 14.8 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-11-50
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.501616824628286
  episode_reward_mean: 14.077631952569288
  episode_reward_min: -3.5632128745674185
  episodes_this_iter: 168
  episodes_total: 7896
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8931.601
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.341144561767578
        kl: 0.008473393507301807
        policy_loss: -0.013455196283757687
        total_loss: 0.6095616221427917
        vf_explained_var: 0.982592761516571
        vf_loss: 0.6208984851837158
    load_time_ms: 1.118
    num_steps_sampled: 1184400
    num_steps_trained: 1175000
    sample_time_ms: 45279.452
    update_time_ms: 0.003
  iterations_since_restore: 47
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.38332624521846437
    mean_inference_ms: 1.162802102930215
    mean_processing_ms: 0.3472848504553778
  time_since_restore: 2726.1631128787994
  time_this_iter_s: 43.32338786125183
  time_total_s: 2726.1631128787994
  timestamp: 1563066710
  timesteps_since_restore: 1184400
  timesteps_this_iter: 25200
  timesteps_total: 1184400
  training_iteration: 47
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2726 s, 47 iter, 1184400 ts, 14.1 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-12-35
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.62904999811095
  episode_reward_mean: 13.621532692121502
  episode_reward_min: -7.946353755535436
  episodes_this_iter: 168
  episodes_total: 8064
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8877.644
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.327620267868042
        kl: 0.007700991816818714
        policy_loss: -0.01172372605651617
        total_loss: 0.634157121181488
        vf_explained_var: 0.9823275804519653
        vf_loss: 0.6439555883407593
    load_time_ms: 1.109
    num_steps_sampled: 1209600
    num_steps_trained: 1200000
    sample_time_ms: 43981.167
    update_time_ms: 0.003
  iterations_since_restore: 48
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3814600313546844
    mean_inference_ms: 1.1567474096007668
    mean_processing_ms: 0.34567345626384954
  time_since_restore: 2771.269035100937
  time_this_iter_s: 45.10592222213745
  time_total_s: 2771.269035100937
  timestamp: 1563066755
  timesteps_since_restore: 1209600
  timesteps_this_iter: 25200
  timesteps_total: 1209600
  training_iteration: 48
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2771 s, 48 iter, 1209600 ts, 13.6 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-13-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.079892609725064
  episode_reward_mean: 14.702595791169582
  episode_reward_min: -7.301587705223215
  episodes_this_iter: 168
  episodes_total: 8232
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8759.952
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.315535068511963
        kl: 0.008073843084275723
        policy_loss: -0.013245773501694202
        total_loss: 0.5861077308654785
        vf_explained_var: 0.9843077063560486
        vf_loss: 0.5973349213600159
    load_time_ms: 1.098
    num_steps_sampled: 1234800
    num_steps_trained: 1225000
    sample_time_ms: 42324.555
    update_time_ms: 0.003
  iterations_since_restore: 49
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3792640157010476
    mean_inference_ms: 1.1498021149543387
    mean_processing_ms: 0.34378869386906097
  time_since_restore: 2813.5312688350677
  time_this_iter_s: 42.26223373413086
  time_total_s: 2813.5312688350677
  timestamp: 1563066797
  timesteps_since_restore: 1234800
  timesteps_this_iter: 25200
  timesteps_total: 1234800
  training_iteration: 49
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2813 s, 49 iter, 1234800 ts, 14.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-14-02
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.44799396264065
  episode_reward_mean: 13.193473207600643
  episode_reward_min: -8.892243717676203
  episodes_this_iter: 168
  episodes_total: 8400
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8648.221
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.304051160812378
        kl: 0.008801349438726902
        policy_loss: -0.01273910142481327
        total_loss: 0.5699605941772461
        vf_explained_var: 0.9842237830162048
        vf_loss: 0.5804994106292725
    load_time_ms: 1.097
    num_steps_sampled: 1260000
    num_steps_trained: 1250000
    sample_time_ms: 40892.152
    update_time_ms: 0.003
  iterations_since_restore: 50
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.37757243681453856
    mean_inference_ms: 1.1443104994512543
    mean_processing_ms: 0.34234224995214435
  time_since_restore: 2858.498870611191
  time_this_iter_s: 44.96760177612305
  time_total_s: 2858.498870611191
  timestamp: 1563066842
  timesteps_since_restore: 1260000
  timesteps_this_iter: 25200
  timesteps_total: 1260000
  training_iteration: 50
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2858 s, 50 iter, 1260000 ts, 13.2 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-14-45
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.12210858983681
  episode_reward_mean: 13.413566132343787
  episode_reward_min: -8.795232225036951
  episodes_this_iter: 168
  episodes_total: 8568
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8560.285
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.2916676998138428
        kl: 0.008814716711640358
        policy_loss: -0.010963656939566135
        total_loss: 0.5782923102378845
        vf_explained_var: 0.9821135997772217
        vf_loss: 0.5870522856712341
    load_time_ms: 1.1
    num_steps_sampled: 1285200
    num_steps_trained: 1275000
    sample_time_ms: 35383.993
    update_time_ms: 0.003
  iterations_since_restore: 51
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3755445098662057
    mean_inference_ms: 1.1379222672875486
    mean_processing_ms: 0.34057801019731526
  time_since_restore: 2901.520927667618
  time_this_iter_s: 43.022057056427
  time_total_s: 2901.520927667618
  timestamp: 1563066885
  timesteps_since_restore: 1285200
  timesteps_this_iter: 25200
  timesteps_total: 1285200
  training_iteration: 51
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2901 s, 51 iter, 1285200 ts, 13.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-15-30
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.172348858769915
  episode_reward_mean: 12.34812571731217
  episode_reward_min: -16.041740350129803
  episodes_this_iter: 168
  episodes_total: 8736
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8523.777
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.276242733001709
        kl: 0.008755057118833065
        policy_loss: -0.013672193512320518
        total_loss: 0.6430361866950989
        vf_explained_var: 0.9804486632347107
        vf_loss: 0.6545196771621704
    load_time_ms: 1.065
    num_steps_sampled: 1310400
    num_steps_trained: 1300000
    sample_time_ms: 35401.373
    update_time_ms: 0.003
  iterations_since_restore: 52
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3739934181479145
    mean_inference_ms: 1.132693935360754
    mean_processing_ms: 0.33920498544755956
  time_since_restore: 2946.203011751175
  time_this_iter_s: 44.68208408355713
  time_total_s: 2946.203011751175
  timestamp: 1563066930
  timesteps_since_restore: 1310400
  timesteps_this_iter: 25200
  timesteps_total: 1310400
  training_iteration: 52
  2019-07-14 03:27:58,051	WARNING util.py:64 -- The `save_to_disk` operation took 0.6135611534118652 seconds to complete, which may be a performance bottleneck.
2019-07-14 03:27:58,060	INFO ray_trial_executor.py:187 -- Destroying actor for trial PPO_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-14 03:27:58,061	WARNING util.py:64 -- The `process_trial` operation took 0.6358411312103271 seconds to complete, which may be a performance bottleneck.

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2946 s, 52 iter, 1310400 ts, 12.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-16-13
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.49640110766432
  episode_reward_mean: 15.291280284434217
  episode_reward_min: -4.023577904714736
  episodes_this_iter: 168
  episodes_total: 8904
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8581.113
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.2557175159454346
        kl: 0.009813778102397919
        policy_loss: -0.015440410003066063
        total_loss: 0.4864340126514435
        vf_explained_var: 0.9867701530456543
        vf_loss: 0.49942103028297424
    load_time_ms: 1.044
    num_steps_sampled: 1335600
    num_steps_trained: 1325000
    sample_time_ms: 35185.52
    update_time_ms: 0.002
  iterations_since_restore: 53
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3721735701640422
    mean_inference_ms: 1.1269721307837854
    mean_processing_ms: 0.3375931559496697
  time_since_restore: 2989.7062318325043
  time_this_iter_s: 43.503220081329346
  time_total_s: 2989.7062318325043
  timestamp: 1563066973
  timesteps_since_restore: 1335600
  timesteps_this_iter: 25200
  timesteps_total: 1335600
  training_iteration: 53
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.7/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 2989 s, 53 iter, 1335600 ts, 15.3 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-16-57
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 32.583471090960145
  episode_reward_mean: 14.403670349149381
  episode_reward_min: -5.614353641689823
  episodes_this_iter: 168
  episodes_total: 9072
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8592.951
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.2428197860717773
        kl: 0.009923466481268406
        policy_loss: -0.015361657366156578
        total_loss: 0.49667888879776
        vf_explained_var: 0.9861096143722534
        vf_loss: 0.509559690952301
    load_time_ms: 1.017
    num_steps_sampled: 1360800
    num_steps_trained: 1350000
    sample_time_ms: 35300.315
    update_time_ms: 0.002
  iterations_since_restore: 54
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3706058142478418
    mean_inference_ms: 1.1218625775873667
    mean_processing_ms: 0.33628050429083334
  time_since_restore: 3033.640964746475
  time_this_iter_s: 43.93473291397095
  time_total_s: 3033.640964746475
  timestamp: 1563067017
  timesteps_since_restore: 1360800
  timesteps_this_iter: 25200
  timesteps_total: 1360800
  training_iteration: 54
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 3033 s, 54 iter, 1360800 ts, 14.4 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-17-42
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.988585234233575
  episode_reward_mean: 14.748644340936561
  episode_reward_min: -11.389209871102569
  episodes_this_iter: 168
  episodes_total: 9240
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8677.189
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.226320266723633
        kl: 0.008208499290049076
        policy_loss: -0.014362497255206108
        total_loss: 0.4926324188709259
        vf_explained_var: 0.9868744611740112
        vf_loss: 0.504942774772644
    load_time_ms: 1.027
    num_steps_sampled: 1386000
    num_steps_trained: 1375000
    sample_time_ms: 35251.3
    update_time_ms: 0.002
  iterations_since_restore: 55
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36907468351082345
    mean_inference_ms: 1.1169934960825125
    mean_processing_ms: 0.3349346505928617
  time_since_restore: 3078.2654378414154
  time_this_iter_s: 44.624473094940186
  time_total_s: 3078.2654378414154
  timestamp: 1563067062
  timesteps_since_restore: 1386000
  timesteps_this_iter: 25200
  timesteps_total: 1386000
  training_iteration: 55
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 3078 s, 55 iter, 1386000 ts, 14.7 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-18-25
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 34.423999120893406
  episode_reward_mean: 13.465864527361223
  episode_reward_min: -8.933238657943793
  episodes_this_iter: 168
  episodes_total: 9408
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 8639.163
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.215826988220215
        kl: 0.008876319974660873
        policy_loss: -0.013765973038971424
        total_loss: 0.46685487031936646
        vf_explained_var: 0.9848339557647705
        vf_loss: 0.47840172052383423
    load_time_ms: 1.036
    num_steps_sampled: 1411200
    num_steps_trained: 1400000
    sample_time_ms: 35191.701
    update_time_ms: 0.002
  iterations_since_restore: 56
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36737430614687117
    mean_inference_ms: 1.1116477609578421
    mean_processing_ms: 0.33346456285038123
  time_since_restore: 3121.3105058670044
  time_this_iter_s: 43.04506802558899
  time_total_s: 3121.3105058670044
  timestamp: 1563067105
  timesteps_since_restore: 1411200
  timesteps_this_iter: 25200
  timesteps_total: 1411200
  training_iteration: 56
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.8/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 3121 s, 56 iter, 1411200 ts, 13.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-20-17
  done: false
  episode_len_mean: 150.0
  episode_reward_max: 33.17388118949424
  episode_reward_mean: 14.468799131732892
  episode_reward_min: -5.59558702260186
  episodes_this_iter: 168
  episodes_total: 9576
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 15409.35
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.195509672164917
        kl: 0.009591351263225079
        policy_loss: -0.014165804721415043
        total_loss: 0.4984302222728729
        vf_explained_var: 0.9871880412101746
        vf_loss: 0.5101981163024902
    load_time_ms: 1.036
    num_steps_sampled: 1436400
    num_steps_trained: 1425000
    sample_time_ms: 35312.504
    update_time_ms: 0.002
  iterations_since_restore: 57
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.36605908170196033
    mean_inference_ms: 1.1073859425260828
    mean_processing_ms: 0.33229836565769594
  time_since_restore: 3233.544893026352
  time_this_iter_s: 112.23438715934753
  time_total_s: 3233.544893026352
  timestamp: 1563067217
  timesteps_since_restore: 1436400
  timesteps_this_iter: 25200
  timesteps_total: 1436400
  training_iteration: 57
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 1/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - PPO_RoboschoolReacher-v1_0:	RUNNING, [1 CPUs, 0 GPUs], [pid=1196], 3233 s, 57 iter, 1436400 ts, 14.5 rew

Result for PPO_RoboschoolReacher-v1_0:
  custom_metrics: {}
  date: 2019-07-14_03-27-57
  done: true
  episode_len_mean: 150.0
  episode_reward_max: 34.16159797364861
  episode_reward_mean: 15.36681061025474
  episode_reward_min: -4.65664069581524
  episodes_this_iter: 168
  episodes_total: 9744
  experiment_id: 815b9c5605b24604becb3b4b573c283e
  hostname: KayidmacOS
  info:
    grad_time_ms: 55608.734
    learner:
      default_policy:
        cur_kl_coeff: 0.25
        cur_lr: 9.999999747378752e-05
        entropy: 2.183765172958374
        kl: 0.008696376346051693
        policy_loss: -0.012788401916623116
        total_loss: 0.40032288432121277
        vf_explained_var: 0.9888139367103577
        vf_loss: 0.41093727946281433
    load_time_ms: 1.047
    num_steps_sampled: 1461600
    num_steps_trained: 1450000
    sample_time_ms: 36589.3
    update_time_ms: 0.003
  iterations_since_restore: 58
  node_ip: 192.168.0.3
  num_healthy_workers: 0
  num_metric_batches_dropped: 0
  off_policy_estimator: {}
  pid: 1196
  policy_reward_mean: {}
  sampler_perf:
    mean_env_wait_ms: 0.3664582161876692
    mean_inference_ms: 1.108648056988029
    mean_processing_ms: 0.33294600260134555
  time_since_restore: 3693.4194152355194
  time_this_iter_s: 459.8745222091675
  time_total_s: 3693.4194152355194
  timestamp: 1563067677
  timesteps_since_restore: 1461600
  timesteps_this_iter: 25200
  timesteps_total: 1461600
  training_iteration: 58
  
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_RoboschoolReacher-v1_0:	TERMINATED, [1 CPUs, 0 GPUs], [pid=1196], 3693 s, 58 iter, 1461600 ts, 15.4 rew

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 5.9/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline
Number of trials: 1 ({'TERMINATED': 1})
TERMINATED trials:
 - PPO_RoboschoolReacher-v1_0:	TERMINATED, [1 CPUs, 0 GPUs], [pid=1196], 3693 s, 58 iter, 1461600 ts, 15.4 rew

[32m [  3705.30733s,  INFO] Experiment took 3705.24250 seconds | 61.75404 minutes | 1.02923 hours [0m

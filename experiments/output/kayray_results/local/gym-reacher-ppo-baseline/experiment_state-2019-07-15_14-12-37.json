{
  "checkpoints": [
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 0,
        "num_workers": 3,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/Users/amrmkayid/kayray_results/local/gym-reacher-ppo-baseline",
      "experiment_tag": "0",
      "resources": {
        "cpu": 1,
        "gpu": 0,
        "extra_cpu": 3,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 21,
        "training_iteration": 500
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 39.29564386572504,
        "episode_reward_min": -4.103375264131391,
        "episode_reward_mean": 21.46426118626514,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 168,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 0.6204065692887213,
          "mean_processing_ms": 0.6013290586879604,
          "mean_inference_ms": 2.023950151479326
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 3625000,
          "num_steps_sampled": 3654000,
          "sample_time_ms": 25802.337,
          "load_time_ms": 1.293,
          "grad_time_ms": 11969.214,
          "update_time_ms": 9.44,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.28125,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.0037686247378587723,
              "policy_loss": -0.023037053644657135,
              "vf_loss": 0.02167557179927826,
              "vf_explained_var": 0.9995978474617004,
              "kl": 0.01824038103222847,
              "entropy": 0.8658803701400757
            }
          }
        },
        "timesteps_this_iter": 25200,
        "done": true,
        "timesteps_total": 3654000,
        "episodes_total": 24360,
        "training_iteration": 145,
        "experiment_id": "42ff266824004c1db5d63e9d45fc37ec",
        "date": "2019-07-15_15-50-37",
        "timestamp": 1563198637,
        "time_this_iter_s": 36.86321210861206,
        "time_total_s": 5864.773609638214,
        "pid": 69170,
        "hostname": "KayidmacOS",
        "node_ip": "192.168.0.3",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 3,
          "num_gpus": 0,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 1,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 5864.773609638214,
        "timesteps_since_restore": 3654000,
        "iterations_since_restore": 145,
        "num_healthy_workers": 3
      },
      "last_update_time": 1563198637.229244,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/Users/amrmkayid/kayray_results/local/gym-reacher-ppo-baseline/PPO_RoboschoolReacher-v1_0_2019-07-15_14-12-391mqgukjh",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563198637.229223,
      "trial_id": "d6c6315a",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    }
  ],
  "runner_data": {
    "_global_time_limit": Infinity,
    "_total_time": 5864.773609638214,
    "_iteration": 145,
    "_verbose": true,
    "_server_port": 4321,
    "_metadata_checkpoint_dir": "/Users/amrmkayid/kayray_results/local/gym-reacher-ppo-baseline",
    "_start_time": 1563192757.48065,
    "_session_str": "2019-07-15_14-12-37",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1563192757.48065,
    "timestamp": 1563198637.2470028
  }
}
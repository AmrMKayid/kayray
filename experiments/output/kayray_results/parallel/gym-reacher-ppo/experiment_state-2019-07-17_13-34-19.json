{
  "checkpoints": [
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 16,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "0_num_envs_per_worker=16,num_workers=11",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 37.254751554615915,
        "episode_reward_min": -4.956865909260587,
        "episode_reward_mean": 18.18267721733828,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 242,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 4.028075695972918,
          "mean_processing_ms": 3.4704670868800154,
          "mean_inference_ms": 1.4921540856479296
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2772000,
          "num_steps_sampled": 2795100,
          "sample_time_ms": 1770.981,
          "load_time_ms": 0.877,
          "grad_time_ms": 3463.944,
          "update_time_ms": 4.153,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.125,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.1479983776807785,
              "policy_loss": -0.016115866601467133,
              "vf_loss": 0.16206859052181244,
              "vf_explained_var": 0.995629072189331,
              "kl": 0.016365163028240204,
              "entropy": 1.795473337173462
            }
          }
        },
        "timesteps_this_iter": 36300,
        "done": true,
        "timesteps_total": 2795100,
        "episodes_total": 18634,
        "training_iteration": 77,
        "experiment_id": "278598d886d14792a8caa62751ec5540",
        "date": "2019-07-17_13-41-35",
        "timestamp": 1563363695,
        "time_this_iter_s": 4.975436687469482,
        "time_total_s": 426.56063508987427,
        "pid": 29871,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 16,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 426.56063508987427,
        "timesteps_since_restore": 2795100,
        "iterations_since_restore": 77,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563363695.5266857,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_0_num_envs_per_worker=16,num_workers=11_2019-07-17_13-34-19wzw6or25",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563363695.526678,
      "trial_id": "d10f7e22",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 8,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "1_num_envs_per_worker=8,num_workers=11",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 36.867003861844914,
        "episode_reward_min": -4.149128417261208,
        "episode_reward_mean": 18.054040107941095,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 176,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 1.8991885549161134,
          "mean_processing_ms": 1.626064856233173,
          "mean_inference_ms": 1.2198547543613254
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2470000,
          "num_steps_sampled": 2508000,
          "sample_time_ms": 1857.13,
          "load_time_ms": 0.777,
          "grad_time_ms": 2638.106,
          "update_time_ms": 4.551,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.25,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.1418607532978058,
              "policy_loss": -0.015620950609445572,
              "vf_loss": 0.15441487729549408,
              "vf_explained_var": 0.9962297677993774,
              "kl": 0.012267367914319038,
              "entropy": 1.8073737621307373
            }
          }
        },
        "timesteps_this_iter": 26400,
        "done": true,
        "timesteps_total": 2508000,
        "episodes_total": 16720,
        "training_iteration": 95,
        "experiment_id": "eef3331b7ea240cabc0c9b6e9c7e1971",
        "date": "2019-07-17_13-48-58",
        "timestamp": 1563364138,
        "time_this_iter_s": 4.630241870880127,
        "time_total_s": 430.9525029659271,
        "pid": 29869,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 8,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 430.9525029659271,
        "timesteps_since_restore": 2508000,
        "iterations_since_restore": 95,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563364138.6238008,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_1_num_envs_per_worker=8,num_workers=11_2019-07-17_13-41-35c_nobz96",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563364138.6237884,
      "trial_id": "d10f7e23",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 11,
        "num_envs_per_worker": 4,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "2_num_envs_per_worker=4,num_workers=11",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 11,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 37.202379807835825,
        "episode_reward_min": -0.9898516095469372,
        "episode_reward_mean": 18.149118592491746,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 174,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 1.0444241049722356,
          "mean_processing_ms": 0.9107195632019838,
          "mean_inference_ms": 1.2407782610437428
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2340000,
          "num_steps_sampled": 2349000,
          "sample_time_ms": 2260.073,
          "load_time_ms": 0.761,
          "grad_time_ms": 2700.744,
          "update_time_ms": 4.678,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.25,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.10949284583330154,
              "policy_loss": -0.019556643441319466,
              "vf_loss": 0.12605425715446472,
              "vf_explained_var": 0.9964748620986938,
              "kl": 0.011980959214270115,
              "entropy": 1.7183680534362793
            }
          }
        },
        "timesteps_this_iter": 26100,
        "done": true,
        "timesteps_total": 2349000,
        "episodes_total": 15660,
        "training_iteration": 90,
        "experiment_id": "c8a7a476d81344bd8ab83cc1501e2f4a",
        "date": "2019-07-17_13-56-26",
        "timestamp": 1563364586,
        "time_this_iter_s": 5.189319849014282,
        "time_total_s": 441.1526288986206,
        "pid": 30796,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.38",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 11,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 4,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 441.1526288986206,
        "timesteps_since_restore": 2349000,
        "iterations_since_restore": 90,
        "num_healthy_workers": 11
      },
      "last_update_time": 1563364586.3315632,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_2_num_envs_per_worker=4,num_workers=11_2019-07-17_13-48-586ru21lgk",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563364586.3315566,
      "trial_id": "d10f7e24",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 7,
        "num_envs_per_worker": 16,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "3_num_envs_per_worker=16,num_workers=7",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 7,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 36.65989380417932,
        "episode_reward_min": -5.051108108873594,
        "episode_reward_mean": 18.40568025036439,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 176,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 3.0084547342500456,
          "mean_processing_ms": 2.4904614201291664,
          "mean_inference_ms": 1.0362847112035936
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2210000,
          "num_steps_sampled": 2244000,
          "sample_time_ms": 2014.916,
          "load_time_ms": 0.775,
          "grad_time_ms": 2833.788,
          "update_time_ms": 3.945,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.125,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.14838893711566925,
              "policy_loss": -0.017269717529416084,
              "vf_loss": 0.16391995549201965,
              "vf_explained_var": 0.996093213558197,
              "kl": 0.013909462839365005,
              "entropy": 1.8343626260757446
            }
          }
        },
        "timesteps_this_iter": 26400,
        "done": true,
        "timesteps_total": 2244000,
        "episodes_total": 14960,
        "training_iteration": 85,
        "experiment_id": "4759e7d0028e47bfa9b0fcd246f236a2",
        "date": "2019-07-17_14-03-55",
        "timestamp": 1563365035,
        "time_this_iter_s": 4.733258008956909,
        "time_total_s": 436.5264558792114,
        "pid": 32075,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 7,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 16,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 436.5264558792114,
        "timesteps_since_restore": 2244000,
        "iterations_since_restore": 85,
        "num_healthy_workers": 7
      },
      "last_update_time": 1563365035.48246,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_3_num_envs_per_worker=16,num_workers=7_2019-07-17_13-56-261ol2mkso",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563365035.4824522,
      "trial_id": "d10f7e25",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 7,
        "num_envs_per_worker": 8,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "4_num_envs_per_worker=8,num_workers=7",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 7,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 36.60217254131696,
        "episode_reward_min": -3.334429552662748,
        "episode_reward_mean": 19.044825603547135,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 176,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 1.6143559285231062,
          "mean_processing_ms": 1.3635400283225163,
          "mean_inference_ms": 0.9849590882180302
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2418000,
          "num_steps_sampled": 2455200,
          "sample_time_ms": 2241.654,
          "load_time_ms": 0.773,
          "grad_time_ms": 2840.264,
          "update_time_ms": 4.117,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.125,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.09247453510761261,
              "policy_loss": -0.017473207786679268,
              "vf_loss": 0.10796467959880829,
              "vf_explained_var": 0.9973089694976807,
              "kl": 0.01586449332535267,
              "entropy": 1.6576424837112427
            }
          }
        },
        "timesteps_this_iter": 26400,
        "done": true,
        "timesteps_total": 2455200,
        "episodes_total": 16368,
        "training_iteration": 93,
        "experiment_id": "d08df8b5e13f4b3c8f275b54376bd89b",
        "date": "2019-07-17_14-11-51",
        "timestamp": 1563365511,
        "time_this_iter_s": 5.189098596572876,
        "time_total_s": 469.8441848754883,
        "pid": 32187,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.63",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 7,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 8,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 469.8441848754883,
        "timesteps_since_restore": 2455200,
        "iterations_since_restore": 93,
        "num_healthy_workers": 7
      },
      "last_update_time": 1563365511.3309789,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_4_num_envs_per_worker=8,num_workers=7_2019-07-17_14-03-55t67yffxa",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563365511.3309712,
      "trial_id": "d10f7e26",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    },
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 1,
        "num_workers": 7,
        "num_envs_per_worker": 4,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
      "experiment_tag": "5_num_envs_per_worker=4,num_workers=7",
      "resources": {
        "cpu": 1,
        "gpu": 1,
        "extra_cpu": 7,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "episode_reward_mean": 18,
        "timesteps_total": 5000000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 37.324899158853256,
        "episode_reward_min": -7.085011485068859,
        "episode_reward_mean": 19.61213361977675,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 174,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 0.9040803032977306,
          "mean_processing_ms": 0.7745523789886094,
          "mean_inference_ms": 0.9747234172364433
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 2158000,
          "num_steps_sampled": 2166300,
          "sample_time_ms": 2737.201,
          "load_time_ms": 0.774,
          "grad_time_ms": 2770.11,
          "update_time_ms": 4.195,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.125,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.10477656871080399,
              "policy_loss": -0.019517749547958374,
              "vf_loss": 0.12246309965848923,
              "vf_explained_var": 0.9972174167633057,
              "kl": 0.014649581164121628,
              "entropy": 1.7004773616790771
            }
          }
        },
        "timesteps_this_iter": 26100,
        "done": true,
        "timesteps_total": 2166300,
        "episodes_total": 14442,
        "training_iteration": 83,
        "experiment_id": "09ee7ea2cadd473391a74d0294d7617e",
        "date": "2019-07-17_14-19-40",
        "timestamp": 1563365980,
        "time_this_iter_s": 5.568005561828613,
        "time_total_s": 458.9745383262634,
        "pid": 32171,
        "hostname": "navel-notebook-1",
        "node_ip": "10.16.128.38",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 7,
          "num_gpus": 1,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 4,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 458.9745383262634,
        "timesteps_since_restore": 2166300,
        "iterations_since_restore": 83,
        "num_healthy_workers": 7
      },
      "last_update_time": 1563365980.7587564,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/home/amr/kayray_results/parallel/gym-reacher-ppo/PPO_RoboschoolReacher-v1_5_num_envs_per_worker=4,num_workers=7_2019-07-17_14-11-51ir4ote71",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563365980.758747,
      "trial_id": "d10f7e27",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    }
  ],
  "runner_data": {
    "_global_time_limit": Infinity,
    "_total_time": 2664.010946035385,
    "_iteration": 528,
    "_verbose": true,
    "_server_port": 4321,
    "_metadata_checkpoint_dir": "/home/amr/kayray_results/parallel/gym-reacher-ppo",
    "_start_time": 1563363259.7903645,
    "_session_str": "2019-07-17_13-34-19",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1563363259.7903645,
    "timestamp": 1563365980.7692134
  }
}
{
  "checkpoints": [
    {
      "trainable_name": "PPO",
      "config": {
        "gamma": 0.995,
        "kl_coeff": 1.0,
        "num_sgd_iter": 20,
        "lr": 0.0001,
        "sgd_minibatch_size": 1000,
        "train_batch_size": 25000,
        "model": {
          "free_log_std": true
        },
        "num_gpus": 0,
        "num_workers": 0,
        "batch_mode": "complete_episodes",
        "observation_filter": "MeanStdFilter",
        "env": "RoboschoolReacher-v1"
      },
      "local_dir": "/Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline",
      "experiment_tag": "0",
      "resources": {
        "cpu": 1,
        "gpu": 0,
        "extra_cpu": 0,
        "extra_gpu": 0,
        "custom_resources": {},
        "extra_custom_resources": {}
      },
      "stopping_criterion": {
        "time_total_s": 3600,
        "episode_reward_mean": 21,
        "training_iteration": 1000
      },
      "upload_dir": "",
      "loggers": "80049502000000000000004e2e",
      "sync_function": "80049502000000000000004e2e",
      "verbose": true,
      "max_failures": 3,
      "last_result": {
        "episode_reward_max": 34.16159797364861,
        "episode_reward_min": -4.65664069581524,
        "episode_reward_mean": 15.36681061025474,
        "episode_len_mean": 150.0,
        "episodes_this_iter": 168,
        "policy_reward_mean": {},
        "custom_metrics": {},
        "sampler_perf": {
          "mean_env_wait_ms": 0.3664582161876692,
          "mean_processing_ms": 0.33294600260134555,
          "mean_inference_ms": 1.108648056988029
        },
        "off_policy_estimator": {},
        "num_metric_batches_dropped": 0,
        "info": {
          "num_steps_trained": 1450000,
          "num_steps_sampled": 1461600,
          "sample_time_ms": 36589.3,
          "load_time_ms": 1.047,
          "grad_time_ms": 55608.734,
          "update_time_ms": 0.003,
          "learner": {
            "default_policy": {
              "cur_kl_coeff": 0.25,
              "cur_lr": 9.999999747378752e-05,
              "total_loss": 0.40032288432121277,
              "policy_loss": -0.012788401916623116,
              "vf_loss": 0.41093727946281433,
              "vf_explained_var": 0.9888139367103577,
              "kl": 0.008696376346051693,
              "entropy": 2.183765172958374
            }
          }
        },
        "timesteps_this_iter": 25200,
        "done": true,
        "timesteps_total": 1461600,
        "episodes_total": 9744,
        "training_iteration": 58,
        "experiment_id": "815b9c5605b24604becb3b4b573c283e",
        "date": "2019-07-14_03-27-57",
        "timestamp": 1563067677,
        "time_this_iter_s": 459.8745222091675,
        "time_total_s": 3693.4194152355194,
        "pid": 1196,
        "hostname": "KayidmacOS",
        "node_ip": "192.168.0.3",
        "config": {
          "monitor": false,
          "log_level": "INFO",
          "callbacks": {
            "on_episode_start": null,
            "on_episode_step": null,
            "on_episode_end": null,
            "on_sample_end": null,
            "on_train_result": null,
            "on_postprocess_traj": null
          },
          "ignore_worker_failures": false,
          "use_eager": false,
          "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
              256,
              256
            ],
            "free_log_std": true,
            "squash_to_range": false,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_preprocessor": null,
            "custom_model": null,
            "custom_options": {}
          },
          "optimizer": {},
          "gamma": 0.995,
          "horizon": null,
          "soft_horizon": false,
          "env_config": {},
          "env": "RoboschoolReacher-v1",
          "clip_rewards": null,
          "clip_actions": true,
          "preprocessor_pref": "deepmind",
          "lr": 0.0001,
          "evaluation_interval": null,
          "evaluation_num_episodes": 10,
          "evaluation_config": {},
          "num_workers": 0,
          "num_gpus": 0,
          "num_cpus_per_worker": 1,
          "num_gpus_per_worker": 0,
          "custom_resources_per_worker": {},
          "num_cpus_for_driver": 1,
          "num_envs_per_worker": 1,
          "sample_batch_size": 200,
          "train_batch_size": 25000,
          "batch_mode": "complete_episodes",
          "sample_async": false,
          "observation_filter": "MeanStdFilter",
          "synchronize_filters": true,
          "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
              "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
              "CPU": 1
            },
            "allow_soft_placement": true
          },
          "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
          },
          "compress_observations": false,
          "collect_metrics_timeout": 180,
          "metrics_smoothing_episodes": 100,
          "remote_worker_envs": false,
          "remote_env_batch_wait_ms": 0,
          "min_iter_time_s": 0,
          "timesteps_per_iteration": 0,
          "input": "sampler",
          "input_evaluation": [
            "is",
            "wis"
          ],
          "postprocess_inputs": false,
          "shuffle_buffer_size": 0,
          "output": null,
          "output_compress_columns": [
            "obs",
            "new_obs"
          ],
          "output_max_file_size": 67108864,
          "multiagent": {
            "policies": {},
            "policy_mapping_fn": null,
            "policies_to_train": null
          },
          "use_gae": true,
          "lambda": 1.0,
          "kl_coeff": 1.0,
          "sgd_minibatch_size": 1000,
          "num_sgd_iter": 20,
          "lr_schedule": null,
          "vf_share_layers": false,
          "vf_loss_coeff": 1.0,
          "entropy_coeff": 0.0,
          "clip_param": 0.3,
          "vf_clip_param": 10.0,
          "grad_clip": null,
          "kl_target": 0.01,
          "simple_optimizer": false,
          "straggler_mitigation": false
        },
        "time_since_restore": 3693.4194152355194,
        "timesteps_since_restore": 1461600,
        "iterations_since_restore": 58,
        "num_healthy_workers": 0
      },
      "last_update_time": 1563067677.434335,
      "checkpoint_freq": 100,
      "checkpoint_at_end": true,
      "history": [],
      "keep_checkpoints_num": null,
      "_cmp_greater": true,
      "best_checkpoint_attr_value": -Infinity,
      "checkpoint_score_attr": "training_iteration",
      "_checkpoint": "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",
      "export_formats": [],
      "status": "TERMINATED",
      "logdir": "/Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline/PPO_RoboschoolReacher-v1_0_2019-07-14_02-26-15_ck36yza",
      "runner": null,
      "result_logger": null,
      "last_debug": 1563067677.434311,
      "trial_id": "fdc2e6e2",
      "error_file": null,
      "num_failures": 0,
      "custom_trial_name": null,
      "results": "80049502000000000000004e2e",
      "best_result": "80049502000000000000004e2e",
      "param_config": "80049502000000000000004e2e",
      "extra_arg": "80049502000000000000004e2e",
      "_nonjson_fields": [
        "_checkpoint",
        "loggers",
        "sync_function",
        "results",
        "best_result",
        "param_config",
        "extra_arg"
      ],
      "__logger_started__": false
    }
  ],
  "runner_data": {
    "_global_time_limit": Infinity,
    "_total_time": 3693.4194152355194,
    "_iteration": 58,
    "_verbose": true,
    "_server_port": 4321,
    "_metadata_checkpoint_dir": "/Users/amrmkayid/kayray_results/gym-reacher-ppo-baseline",
    "_start_time": 1563063973.779661,
    "_session_str": "2019-07-14_02-26-13",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1563063973.779661,
    "timestamp": 1563067678.0612118
  }
}
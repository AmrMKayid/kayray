2019-07-13 02:24:52,422	WARNING worker.py:1337 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.
2019-07-13 02:24:52,426	INFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-13_02-24-52_423387_94121/logs.
2019-07-13 02:24:52,549	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:45490 to respond...
2019-07-13 02:24:52,680	INFO services.py:409 -- Waiting for redis server at 127.0.0.1:36694 to respond...
2019-07-13 02:24:52,692	INFO services.py:806 -- Starting Redis shard with 1.72 GB max memory.
2019-07-13 02:24:52,961	INFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-13_02-24-52_423387_94121/logs.
2019-07-13 02:24:52,963	INFO services.py:1446 -- Starting the Plasma object store with 2.58 GB memory using /tmp.
2019-07-13 02:24:53,382	INFO tune.py:65 -- Did not find checkpoint file in /Users/amrmkayid/kayray_results/gym-reahcer-apex.
2019-07-13 02:24:53,382	INFO tune.py:233 -- Starting a new experiment.
WARNING: Logging before flag parsing goes to stderr.
W0713 02:24:53.794039 4551976384 deprecation.py:323] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2019-07-13 02:24:56,591	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
W0713 02:24:56.597008 4551976384 deprecation_wrapper.py:119] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/logger.py:136: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.

W0713 02:24:56.598930 4551976384 deprecation_wrapper.py:119] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/logger.py:141: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2019-07-13 02:24:56,712	WARNING util.py:64 -- The `start_trial` operation took 0.12921595573425293 seconds to complete, which may be a performance bottleneck.
2019-07-13 02:25:04,002	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=94137, host=KayidmacOS)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 87, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 323, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 438, in _setup
    self._init(self.config, self.env_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 103, in _init
    self.workers = make_workers(self, env_creator, policy, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/apex.py", line 41, in defer_make_workers
    return trainer._make_workers(env_creator, policy, config, 0)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 483, in _make_workers
    logdir=self.logdir)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 64, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 214, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 311, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 715, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/tf_policy_template.py", line 128, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/dynamic_tf_policy.py", line 116, in __init__
    self, self.input_dict, obs_space, action_space, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/dqn_policy.py", line 402, in build_q_networks
    "Action space {} is not supported for DQN.".format(action_space))
ray.rllib.utils.error.UnsupportedSpaceException: Action space Box(2,) is not supported for DQN.

2019-07-13 02:25:04,008	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-13 02:25:04,012	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-13 02:25:04,017	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-13 02:25:11,312	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=94139, host=KayidmacOS)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 87, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 323, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 438, in _setup
    self._init(self.config, self.env_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 103, in _init
    self.workers = make_workers(self, env_creator, policy, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/apex.py", line 41, in defer_make_workers
    return trainer._make_workers(env_creator, policy, config, 0)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 483, in _make_workers
    logdir=self.logdir)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 64, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 214, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 311, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 715, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/tf_policy_template.py", line 128, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/dynamic_tf_policy.py", line 116, in __init__
    self, self.input_dict, obs_space, action_space, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/dqn_policy.py", line 402, in build_q_networks
    "Action space {} is not supported for DQN.".format(action_space))
ray.rllib.utils.error.UnsupportedSpaceException: Action space Box(2,) is not supported for DQN.

2019-07-13 02:25:11,314	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-13 02:25:11,319	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-13 02:25:11,325	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-13 02:25:22,888	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=94138, host=KayidmacOS)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 87, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 323, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 438, in _setup
    self._init(self.config, self.env_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 103, in _init
    self.workers = make_workers(self, env_creator, policy, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/apex.py", line 41, in defer_make_workers
    return trainer._make_workers(env_creator, policy, config, 0)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 483, in _make_workers
    logdir=self.logdir)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 64, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 214, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 311, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 715, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/tf_policy_template.py", line 128, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/dynamic_tf_policy.py", line 116, in __init__
    self, self.input_dict, obs_space, action_space, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/dqn_policy.py", line 402, in build_q_networks
    "Action space {} is not supported for DQN.".format(action_space))
ray.rllib.utils.error.UnsupportedSpaceException: Action space Box(2,) is not supported for DQN.

2019-07-13 02:25:22,889	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2019-07-13 02:25:22,897	INFO trial_runner.py:524 -- Attempting to recover trial state from last checkpoint.
2019-07-13 02:25:22,902	WARNING signature.py:108 -- The function with_updates has a **kwargs argument, which is currently not supported.
2019-07-13 02:25:36,289	ERROR trial_runner.py:487 -- Error processing event.
Traceback (most recent call last):
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trial_runner.py", line 436, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py", line 323, in fetch_result
    result = ray.get(trial_future[0])
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/worker.py", line 2195, in get
    raise value
ray.exceptions.RayTaskError: [36mray_worker[39m (pid=94140, host=KayidmacOS)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 87, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 323, in __init__
    Trainable.__init__(self, config, logger_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/trainable.py", line 87, in __init__
    self._setup(copy.deepcopy(self.config))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 438, in _setup
    self._init(self.config, self.env_creator)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer_template.py", line 103, in _init
    self.workers = make_workers(self, env_creator, policy, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/apex.py", line 41, in defer_make_workers
    return trainer._make_workers(env_creator, policy, config, 0)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/trainer.py", line 483, in _make_workers
    logdir=self.logdir)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 64, in __init__
    RolloutWorker, env_creator, policy, 0, self._local_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/worker_set.py", line 214, in _make_worker
    _fake_sampler=config.get("_fake_sampler", False))
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 311, in __init__
    self._build_policy_map(policy_dict, policy_config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/evaluation/rollout_worker.py", line 715, in _build_policy_map
    policy_map[name] = cls(obs_space, act_space, merged_conf)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/tf_policy_template.py", line 128, in __init__
    obs_include_prev_action_reward=obs_include_prev_action_reward)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/policy/dynamic_tf_policy.py", line 116, in __init__
    self, self.input_dict, obs_space, action_space, config)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/rllib/agents/dqn/dqn_policy.py", line 402, in build_q_networks
    "Action space {} is not supported for DQN.".format(action_space))
ray.rllib.utils.error.UnsupportedSpaceException: Action space Box(2,) is not supported for DQN.

2019-07-13 02:25:36,291	INFO ray_trial_executor.py:187 -- Destroying actor for trial APEX_RoboschoolReacher-v1_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
[32m [     0.01695s,  INFO] Registering env:  RoboschoolReacher-v1 [0m
[32m [     0.01819s,  INFO] Experiment configs: 
 {
  "gym-reahcer-apex": {
    "env": "RoboschoolReacher-v1",
    "local_dir": "~/kayray_results",
    "checkpoint_freq": 100,
    "checkpoint_at_end": true,
    "stop": {
      "time_total_s": 7200,
      "training_iteration": 1000,
      "episode_reward_mean": 21.5
    },
    "run": "APEX",
    "config": {
      "double_q": false,
      "dueling": false,
      "num_atoms": 1,
      "noisy": false,
      "n_step": 3,
      "lr": 0.0001,
      "adam_epsilon": 0.00015,
      "hiddens": [
        512
      ],
      "buffer_size": 1000000,
      "schedule_max_timesteps": 2000000,
      "exploration_final_eps": 0.01,
      "exploration_fraction": 0.1,
      "prioritized_replay_alpha": 0.5,
      "beta_annealing_fraction": 1.0,
      "final_prioritized_replay_beta": 1.0,
      "num_gpus": 0,
      "num_workers": 3,
      "sample_batch_size": 1000,
      "train_batch_size": 25000,
      "target_network_update_freq": 50000,
      "timesteps_per_iteration": 25000
    }
  }
} [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.7/8.6 GB

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_RoboschoolReacher-v1_0:	RUNNING

[2m[36m(pid=94137)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=94137)[0m W0713 02:25:02.411590 4536071616 deprecation.py:323] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=94137)[0m Instructions for updating:
[2m[36m(pid=94137)[0m non-resource variables are not supported in the long term
[2m[36m(pid=94137)[0m 2019-07-13 02:25:03,944	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=94137)[0m 2019-07-13 02:25:03.945611: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=94137)[0m [32m [     0.09241s,  INFO] TimeLimit:
[2m[36m(pid=94137)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=94137)[0m - action_space = Box(2,)
[2m[36m(pid=94137)[0m - observation_space = Box(9,)
[2m[36m(pid=94137)[0m - reward_range = (-inf, inf)
[2m[36m(pid=94137)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=94137)[0m - _max_episode_steps = 150
[2m[36m(pid=94137)[0m - _elapsed_steps = None [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_RoboschoolReacher-v1_0:	RUNNING, 1 failures: /Users/amrmkayid/kayray_results/gym-reahcer-apex/APEX_RoboschoolReacher-v1_0_2019-07-13_02-24-56hc3m5mmf/error_2019-07-13_02-25-04.txt

[2m[36m(pid=94139)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=94139)[0m W0713 02:25:09.860205 4443227584 deprecation.py:323] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=94139)[0m Instructions for updating:
[2m[36m(pid=94139)[0m non-resource variables are not supported in the long term
[2m[36m(pid=94139)[0m [32m [     0.05541s,  INFO] TimeLimit:
[2m[36m(pid=94139)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=94139)[0m - action_space = Box(2,)
[2m[36m(pid=94139)[0m - observation_space = Box(9,)
[2m[36m(pid=94139)[0m - reward_range = (-inf, inf)
[2m[36m(pid=94139)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=94139)[0m - _max_episode_steps = 150
[2m[36m(pid=94139)[0m - _elapsed_steps = None [0m
[2m[36m(pid=94139)[0m 2019-07-13 02:25:11,285	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=94139)[0m 2019-07-13 02:25:11.285785: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_RoboschoolReacher-v1_0:	RUNNING, 2 failures: /Users/amrmkayid/kayray_results/gym-reahcer-apex/APEX_RoboschoolReacher-v1_0_2019-07-13_02-24-56hc3m5mmf/error_2019-07-13_02-25-11.txt

[2m[36m(pid=94138)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=94138)[0m W0713 02:25:19.878400 4639253952 deprecation.py:323] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=94138)[0m Instructions for updating:
[2m[36m(pid=94138)[0m non-resource variables are not supported in the long term
[2m[36m(pid=94138)[0m 2019-07-13 02:25:22,799	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=94138)[0m 2019-07-13 02:25:22.800139: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
[2m[36m(pid=94138)[0m [32m [     0.12835s,  INFO] TimeLimit:
[2m[36m(pid=94138)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=94138)[0m - action_space = Box(2,)
[2m[36m(pid=94138)[0m - observation_space = Box(9,)
[2m[36m(pid=94138)[0m - reward_range = (-inf, inf)
[2m[36m(pid=94138)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=94138)[0m - _max_episode_steps = 150
[2m[36m(pid=94138)[0m - _elapsed_steps = None [0m
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 4/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.6/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'RUNNING': 1})
RUNNING trials:
 - APEX_RoboschoolReacher-v1_0:	RUNNING, 3 failures: /Users/amrmkayid/kayray_results/gym-reahcer-apex/APEX_RoboschoolReacher-v1_0_2019-07-13_02-24-56hc3m5mmf/error_2019-07-13_02-25-22.txt

[2m[36m(pid=94140)[0m WARNING: Logging before flag parsing goes to stderr.
[2m[36m(pid=94140)[0m W0713 02:25:33.619016 4573300160 deprecation.py:323] From /Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
[2m[36m(pid=94140)[0m Instructions for updating:
[2m[36m(pid=94140)[0m non-resource variables are not supported in the long term
[2m[36m(pid=94140)[0m [32m [     0.08308s,  INFO] TimeLimit:
[2m[36m(pid=94140)[0m - env = <RoboschoolReacher<RoboschoolReacher-v1>>
[2m[36m(pid=94140)[0m - action_space = Box(2,)
[2m[36m(pid=94140)[0m - observation_space = Box(9,)
[2m[36m(pid=94140)[0m - reward_range = (-inf, inf)
[2m[36m(pid=94140)[0m - metadata = {'render.modes': ['human', 'rgb_array'], 'video.frames_per_second': 60}
[2m[36m(pid=94140)[0m - _max_episode_steps = 150
[2m[36m(pid=94140)[0m - _elapsed_steps = None [0m
[2m[36m(pid=94140)[0m 2019-07-13 02:25:36,195	INFO rollout_worker.py:301 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)
[2m[36m(pid=94140)[0m 2019-07-13 02:25:36.199802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'ERROR': 1})
ERROR trials:
 - APEX_RoboschoolReacher-v1_0:	ERROR, 4 failures: /Users/amrmkayid/kayray_results/gym-reahcer-apex/APEX_RoboschoolReacher-v1_0_2019-07-13_02-24-56hc3m5mmf/error_2019-07-13_02-25-36.txt

== Status ==
Using FIFO scheduling algorithm.
Resources requested: 0/4 CPUs, 0/0 GPUs
Memory usage on this node: 6.5/8.6 GB
Result logdir: /Users/amrmkayid/kayray_results/gym-reahcer-apex
Number of trials: 1 ({'ERROR': 1})
ERROR trials:
 - APEX_RoboschoolReacher-v1_0:	ERROR, 4 failures: /Users/amrmkayid/kayray_results/gym-reahcer-apex/APEX_RoboschoolReacher-v1_0_2019-07-13_02-24-56hc3m5mmf/error_2019-07-13_02-25-36.txt

Traceback (most recent call last):
  File "run.py", line 181, in <module>
    run(args, parser, dot_dict)
  File "run.py", line 170, in run
    resume=args.resume)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/tune.py", line 333, in run_experiments
    raise_on_failed_trial=raise_on_failed_trial)
  File "/Users/amrmkayid/anaconda3/envs/kayddrl/lib/python3.6/site-packages/ray/tune/tune.py", line 273, in run
    raise TuneError("Trials did not complete", errored_trials)
ray.tune.error.TuneError: ('Trials did not complete', [APEX_RoboschoolReacher-v1_0])

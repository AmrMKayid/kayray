gym-reacher-ppo: 
  env: RoboschoolReacher-v1
  run: PPO 
  local_dir: ~/kayray_results
  checkpoint_freq: 100
  checkpoint_at_end: True
  stop:
      time_total_s: 3600 # 1 hours
      episode_reward_mean: 21
      training_iteration: 1000
  config: 
    gamma: 0.995
    kl_coeff: 1.0
    num_sgd_iter: 20
    lr: 0.0001
    sgd_minibatch_size: 1000
    train_batch_size: 25000
    num_gpus: 1 #0
    num_workers:
      grid_search: [64, 32, 16] # grid_search: [11, 9, 7, 5, 3]
    num_envs_per_worker:
      grid_search: [32, 16, 8] # grid_search: [8, 6, 4, 2]
    batch_mode: complete_episodes
    observation_filter: MeanStdFilter